<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>HTTPS</title>
    <url>/2022/03/23/HTTPS/</url>
    <content><![CDATA[请看正文一张图。 课外阅读TLS/SSL 最佳部署文档
测试服务器 HTTPS 配置
Security/Server Side TLS
SSL-Pulse]]></content>
      <tags>
        <tag>HTTPS</tag>
        <tag>OpenSSL</tag>
      </tags>
  </entry>
  <entry>
    <title>UML 统一建模语言</title>
    <url>/2022/02/05/UML-%E7%BB%9F%E4%B8%80%E5%BB%BA%E6%A8%A1%E8%AF%AD%E8%A8%80/</url>
    <content><![CDATA[UML 是一种开放的方法，用于说明、可视化、构建和编写一个正在开发的、面向对象的、软件密集系统的制品的开放方法。UML展现了一系列最佳工程实践，这些最佳实践在对大规模，复杂系统进行建模方面，特别是在软件架构层次已经被验证有效。 类图
面向对象程序设计(Object-Oriented Programming， 缩写为 OOP) 是一种范式， 其基本理念是将数据块及与数据相关的行为封装成为特殊的、 名为对象的实体， 同时对象实体的生成工作则是基于程序员给出的一系列蓝图， 这些蓝图就是类，在UML中，类图专门是用来描述这种实体的。如下图所示：类之间是有相互关系的，就像猫属于动物，动物和植物又属于生物体：类之间的关系可以更细分的划分为这几种：依赖，关联，聚合，组合。
 依赖
依赖是类之间最基础的、也是最微弱的关系类型。 如果修改一个类的定义可能会造成另一个类的变化，那么这两个类之 间就存在依赖关系。当你在代码中使用具体类的名称时， 通 常意味着存在依赖关系。 例如在指定方法签名类型时， 或是通过调用构造函数对对象进行初始化时等。 通过让代码依赖接口或抽象类(而不是具体类)，你可以降低其依赖程度。
通常情况下，UML 图不会展示所有依赖——它们在真实代码中的数量太多了。 为了不让依赖关系破坏 UML 图， 你必须对其进行精心选择，仅展示那些对于沟通你的想法来说重要 的依赖关系。
在UML中，依赖关系用一个虚线的箭头表示，从依赖者到被依赖者，例如教授依赖课程资料： 关联
关联是一个对象使用另一对象或与另一对象进行交互的关系。 在 UML 图中， 关联关系用起始于一个对象并指向其所使用 的对象的简单箭头来表示。 顺带一提， 双向关联也是完全正常的， 这种情况就用双向箭头来表示。 关联可视为一种特殊类型的依赖，即一个对象总是拥有访问与其交互的对象的权限，而简单的依赖关系并不会在对象间建立永久性的联系。
一般来说， 你可以使用关联关系来表示类似于类成员变量的东西。这个关系将一直存在，因此你总能通过订单来获 取其顾客。 但是它并非一定是成员变量。如果你根据接口来创建类，它也可以表示为一个可返回订单的顾客的方法。
为了区分关联和依赖，举如下的例子，Professor 依赖 Course 提供的 c.getKnowledge 方法获取知识，将其传授给关联的 Student：如果有人修改了 课程 类的 getKnowledge (获取知识)方法(修改方法名或添加一些 必须的参数等)，代码将会崩溃。这就是依赖关系。
让我们来看看名为 student (学生)的成员变量，以及如何在 teach 方法中使用该变量。我们可以肯定学生 (Student)类是教授类的依赖: 如果 remember 方法被修改， 教授的代码也将崩溃。但由于教授的所有方法总能访问 student 成员变量，所以学生类就不仅是依赖，而也是关联了。
UML图中，经常用一个单向的箭头表示关联关系： 聚合
聚合是一种特殊类型的关联， 用于表示多个对象之间的一对多、多对多或整体对部分的关系 。 普通关联仅用于描述两个对象之间的关系。通常在聚合关系中， 一个对象拥有 一组其他对象， 并扮演着容器或集合的角色。组件可以独立于容器存在， 也可以同时连接多个容器。 在 UML 图中，聚合关系使用一端是空心菱形，另一端指向组件的箭头来表示。 组合
组合是一种特殊类型的聚合， 其中一个对象由一个或多个其他对象实例构成。 组合与其他关系的区别在于组件仅能作为容器的一部分存在。 在 UML 图中，组合与聚合关系的符号相同，但箭头起始处的菱形是实心的。 OOP
面向对象程序设计的四个基本概念使其区别于其他程序设计范式，他们分别是：抽象，多态，封装以及继承。
 抽象
当使用面向对象程序设计的理念开发一款程序时， 我们会将大部分时间用于根据真实世界对象来设计程序中的对象。但是，程序中的对象并不需要能够百分之百准确地反映其原型(极少情况下才需要做到这一点)。实际上，你的对象只需模拟真实对象的特定属性和行为即可，其他内容可以忽略。
例如， 飞行模拟器和航班预订程序中都可能会包含一个飞机 Airplane 类。 但是前者需包含与实际飞行相关的详细信息，而后者则只关心座位图和哪些座位可供预订。抽象是一种反映真实世界对象或现象中特定内容的模型， 它 能高精度地反映所有与特定内容相关的详细信息， 同时忽略其他内容。
 封装
封装是指一个对象对其他对象隐藏其部分状态和行为， 而仅向程序其他部分暴露有限的接口的能力。
如果想要启动一辆车的发动机， 你只需转动钥匙或按下按钮即可， 无需打开引擎盖手动接线、转动曲轴和气缸并启动发动机的动力循环。 这些细节都隐藏在引擎盖下，你只会看到一些简单的接口: 启动开关、方向盘和一些踏板。
对象的接口——它是对象的公有部分，能够同其他对象进行交互。
封装某个内容意味着使用关键字 private 来对其进行修饰， 这样仅有其所在类中的方法才能访问这些内容。 还有一种限制程度较小的关键字 protected 保护 ， 其所修饰的对象仅允许父类访问其类中的成员。
绝大部分编程语言的接口和抽象类(或方法)都基于抽象和 封装的概念。 在现代面向对象的编程语言中， 接口机制(通常使用 interface 或 protocol 关键字来声明)允许你定义对象之间的交互协议。这也是接口仅关心对象行为，以及你不能在接口中声明成员变量的原因之一。
假如航空运输 FlyingTransport 接口中有一个 fly(origin, destination, passengers) 方法 (即以起点、 终点以及乘客为参数的飞行方法)。 在设计航空运输模拟器时， 你可以对机场 Airport 做出限制， 使其仅与实现了航空运输接口的对象进行交互。此后，你可以确保 传递给机场对象的任何对象——无论是飞机、 直升机、还是可怕的家养狮鹫 —— 都能到达或离开这种类型的机场。 继承
继承是指在根据已有类创建新类的能力。 继承最主要的好处是代码复用。如果你想要创建的类与已有的类差异不大， 那也没必要重复编写相同的代码。你只需扩展已有的类并将额外功能放入生成的子类(它会继承父类的成员变量和方法) 中即可。
使用继承后，子类将拥有与其父类相同的接口。如果父类中声明了某个方法，那么你将无法在子类中隐藏该方法。你还必须实现所有的抽象方法，即使它们对于你的子类而言没有意义。在绝大多数编程语言中， 子类仅能对一个父类进行扩展。 另一方面， 任何类都可以同时实现多个接口。 但是正如我之前提到的那样， 如果父类实现了某个接口， 那么其所有子类都 必须实现该接口。
 多态
绝大部分动物 Animals 可以发出声音。 我们需要所有子类都重写基类的 makeSound 发出声音方法，让每个子类都发出正确的声音，因此我们可以马上将其声明为抽象。 这让我们得以忽略父类中该方法的所有默认实现，从而强制要求所有子类自行提供该方法的实现。假如将几只猫和狗放入一个大袋子中。 然后，我们闭上眼睛，将动物一个一个地从袋中取出。 我们并不知道自己取出的是何种动物。 但如果我们好好地摸摸它们的话， 它就会根据自己的具体类发出特殊的欢快叫声。程序并不知道 a 变量中所包含的对象的具体类型，但幸亏有被称为多态的特殊机制， 程序可以追踪对象的子类并调用其方法，从而执行恰当的行为。
多态是指程序能够检测对象所属的实际类，并在当前上下文不知道其真实类型的情况下调用其实现的能力。
 UML
UML图经过各种大型工程的实践，被证明是一种极其有用的方式来描述可视化系统，数据可系统及其他软件系统，所有的软件开发人员都应该学习并掌握它。从种类上来说，它有以下几种类型： 类图（Class Diagram）
Class 经常被用用来描述某个具体的或者抽象的对象，这个对象经常具有一些属性和方法，而且这些属性和方法都具有不同的访问限制规则，例如一个用来描述 Dog 的类图：可以看到的是在每个属性或者方法之前都有一个 + 或者 -，这个就是访问限制规则，一共有四种：+：Public，可公开访问
-：Private
#：Protected
~：Package Local而且对于方法而言，可以通过 in，inout 或者 out 标识参数的意义：in: 该参数仅作为输入参数，不应该被修改；
inout: 该参数即可作为输入参数，也可以被内部修改；
out: 该参数仅用于作为输出参数存储库，就像传入一个地址，然后内部可以对其进行赋值；就像现实世界中不同对象之间有不同的关系一样，类图中也有描述不同类之间关系的方式，一般存在六种关系，分别是关联，继承，实现，依赖，聚合和组合。
例如，学生从老师那里学习知识，这种关系就可以表示位简单的关联关系，在表示的时候使用一个联系表示即可，也可以适当添加描述信息：继承有时候也可以称为泛化，用一个空心箭头从子类指向父类，父类可能是抽象类或者具体类：实现一般是指具体类型和接口之间关系，用一个虚线实心箭头表示：当一个对象在其方法中使用另一个类的对象，并且未存储在任何字段中时，就表示存在依赖关系，例如，Person 有一个方法 Read 接收一个 Book 的实例 book 作为参数，调用 Book 的 getknowledge 方法获取知识：聚合和组合比较相近，都表示一对多的关系，而聚合通常用来表示用类的聚合，而组合表示整体和部分的关系；例如学校有很多老师，这种表示聚合关系；而学校也有很多不同的学院，计算机学院，土木工程等，这种表示组合关系，不同类型；在表示上聚合使用空心菱形箭头，组合使用实心菱形箭头表示。 状态图（State Diagram）
UML 状态图是图表本身的名称，主要用于描述对象具有的各种状态、状态之间的转换过程以及触发状态转换的各种事件和条件。UML 状态图描述了一个状态机，可以被定义为一台机器，它定义了一个对象，这些状态控制外部或内部事件的不同状态，状态机由状态、转换、事件、活动和动作五部分组成。状态：状态指的是对象在其生命周期中的一种状况，处于某个特定状态中的对象必然会满足某些条件、执行某些动作或者是等待某些事件。一个状态的生命周期是一个有限的时间阶段；
转换：转换指的是两个不同状态之间的一种关系，表明对象在第一个状态中执行一定的动作，并且在满足某个特定条件下由某个事件触发进入第二个状态；
事件：事件指的是发生在时间和空间上的对状态机来讲有意义的那些事情。事件通常会引起状态的变迁，促使状态机从一种状态切换到另一种状态，如信号、定时器，某个条件被处罚等；
活动：活动指的是状态机中进行的非原子操作；
动作：动作指的是状态机中可以执行的哪些原子操作。所谓原子操作，指的是他们在运行的过程中不能被其他消息中断，必须一直执行下去，以至最终导致状态的变更或者返回一个值；一个状态图（Statechart Diagram）本质上就是一个状态机，或者是状态机的特殊情况，它基本上是一个状态机中元素的一个投影，这也就意味着状态图包括状态机的所有特征。
状态图描述了一个实体基于事件反映的动态行为，显示了该实体是如何根据当前所处的状态对不同的事件作出反应的。
在UML中，状态图由表示状态的节点和表示状态之间转换的带箭头的直线组成。状态的转换由事件触发，状态和状态之间由转换箭头连接。每一个状态图都有一个初始状态（实心圆），用来表示状态机的开始。还有一个中止状态（半实心圆），用来表示状态机的终止。状态图主要由元素状态、转换、初始状态、中止状态和判定等组成。
 状态
状态用于对实体在其生命周期中的各种状况进行建模，一个实体总是在有限的一段时间内保持一个状态。状态由一个带圆角的矩形表示，状态的描绘素应该包括名称、入口和出口动作、内部转换和嵌套状态。如下图，为一个简单状态：状态名指的是状态的名字，通常用字符串表示，其中每个单词的首字母大写。状态名可以包含任意数量的字母、数字和除了冒号“：”以外的一些字符，可以较长，甚至连续几行。但是一定要注意一个状态的名称在状态图所在的上下文中应该是唯一的，能够把该状态和其他状态区分开。
入口和出口动作一个状态可以具有或者没有入口和出口动作。入口和出口动作分别指的是进入和退出一个状态时所执行的“边界”动作。
内部转换指的是不导致状态改变的转换。内部转换中可以包含进入或者退出该状态应该执行的活动或动作。
嵌套状态状态分为简单状态（Simple State）和组成状态（Composite State）。简单状态是指在语义上不可分解的、对象保持一定属性值的状况，简单状态不包含其他状态：而组成状态是指内部嵌套有子状态的状态，在组成状态的嵌套状态图部分包含的就是此状态的子状态。 转换
在UML的状态建模机制中，转换用带箭头的直线表示，一端连接源状态，箭头指向目标状态。转换还可以标注与此转换相关的选项，如事件、监护条件和动作等，如下图所示。注意：如果转换上没有标注触发转换的事件，则表示此转换自动进行。在状态转换机制中需要注意的五个概念如下：状态源（Source State）：指的是激活转换之间对象处于的状态。如果一个一个状态处于源状态，当它接收到转换的触发事件或满足监护条件时，就激活了一个离开的转换。
目标状态（Event State）：指的是转换完成后对象所处的状态。
事件触发器（Event Trigger）：指的是引起源状态转换的事件。事件不是持续发生的，它只发生在时间的一点上，对象接收到事件，导致源状态发生变化，激活转换并使监护条件得到满足。
监护条件（Guard Condition）：是一个布尔表达式。当接收到触发事件要触发转换时，要对该表达式求值。如果表达式为真，则激活转换：如果表达式为假，则不激活转换，所接收到的触发事件丢失。
动作（Action）：是一个可执行的原子计算。 初始状态
每个状态图都应该有一个初始状态，它代表状态图的起始位置。初始状态是一个伪状态（一个和普通状态有连接的假状态），对象不可能保持在初始状态，必须要有一个输出的无触发转换（没有事件触发器的转换）。通常初始状态上的转换是无监护条件的，并且初始状态只能作为转换的源，而不能作为转换的目标。在UML中，一个状态图只能有一个初始状态，用一个实心圆表示。
 终止状态
终止状态是一个状态图的终点，一个状态图可以拥有一个或者多个终止状态。对象可以保持在终止状态，但是终止状态不可能有任何形式的和触发转换，它的目的就是为了激发封装状态上的转换过程的结束。因此，终止状态只能作为转换的目标而不能作为转换的源，在UML中，终止状态用一个含有实心圆的空心圆表示。
 判定
活动图和状态图中都有需要根据给定条件进行判断，然后根据不同的判断结果进行不同转换的情况。实际就是工作流在此处按监护条件的取值发生分支，在UML中，判定用空心菱形表示。 序列图（Sequence Diagram）
序列图也叫时序图，是交互图的一种，用于捕获系统运行中对象之间有时间顺序的交互，是由生命线和消息组成。时序图将交互关系表示为一个二维图。纵向是时间轴，时间沿竖线向下延伸。横向轴代表了在协作中各独立对象的类元角色。类元角色用生命线表示。当对象存在时，角色用一条虚线表示，当对象的过程处于激活状态时，生命线是一个双道线。消息用从一个对象的生命线到另一个对象生命线的箭头表示。箭头以时间顺序在图中从上到下排列。Actor（角色：代表某个由人或者设备扮演的角色，它不一定代表某个具体的实体，一般由一个小人代替；Lifetime（生命线）：在时序图中表示为从对象图标向下延伸的一条虚线，表示对象存在的时间。Activation（活动条/激活）：在生命线的徐线上可以用活动条表示某种行为的开始和结束，一般用小矩形来表示。同步消息：意味着阻塞和等待。如：A向B 发送一个消息后，对象A 必须一直等到B执行完成后返回才能继续往下执行。这就是同步消息。用实心箭头表示异步消息：就意味着是非阻塞。如：A向B发送消息后，直接可以执行下面代码，无需等待B的执行。返回消息：在从A发送消息到达B之后，B的回复消息称之为返回消息。UML在2.0时在时序图中加入了交互框。交互框用来解决交互执行的条件和方式，它允许在序列图中直接表示逻辑组件，用于通过指定条件或子进程的应用区域，为任何生命线的任何部分定义特殊条件和子进程。组合片段共有13种，名称及含义如下：举几个示例： 参考资料UML Diagrams Full Course (Unified Modeling Language)
UML建模之状态图（Statechart Diagram）
UML状态图
UML时序图/序列图]]></content>
      <tags>
        <tag>UML</tag>
      </tags>
  </entry>
  <entry>
    <title>【Homebrew】本地安装</title>
    <url>/2022/04/08/%E3%80%90Homebrew%E3%80%91%E6%9C%AC%E5%9C%B0%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[为啥会有这篇文章呢，因为我通过 brew 安装一个编译器太慢了，虽然 github 相关的网站没有被 GFW 屏蔽，但是现在速度依然感人，100MB 的东西我得下一天。
我在执行命令 brew install aarch64-unknown-linux-gnu 时经常中断，气得我肝疼，挂代理也不行：好在有一台香港的服务器，根据图片中的下载地址，我先从服务器上下载，然后 scp 到本地。通过 brew --cache 命令找到 brew 下载文件时的缓存目录：这个目录下的文件都是链接到了 &quot;$(brew --cache)/downloads&quot; 中，可以在这个 downloads 找到我们未下载未完成的文件，用我们下载好的文件将它替换掉，替换的时候删除后缀 .incomplete。然后重新执行命令 brew install aarch64-unknown-linux-gnu，它会从断点处重传，看到已经下载完成了，就不会再下载了。到这里其实就安装完成了，后面还有一些自动的依赖更新，我们可以通过设置环境变量 HOMEBREW_NO_INSTALLED_DEPENDENTS_CHECK=1 禁用这个行为。
]]></content>
      <tags>
        <tag>homebrew</tag>
      </tags>
  </entry>
  <entry>
    <title>【Linux】可执行和可链接文件格式--ELF</title>
    <url>/2022/02/16/%E3%80%90Linux%E3%80%91%E5%8F%AF%E6%89%A7%E8%A1%8C%E5%92%8C%E5%8F%AF%E9%93%BE%E6%8E%A5%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F-ELF/</url>
    <content><![CDATA[ELF(Executable and Linking Format) 是linux系统下可执行文件，目标文件，共享链接库和内核转储文件的格式。维基百科中是这样描述的：在计算机科学中，ELF文件是一种用于可执行文件、目标文件、共享库和核心转储（core dump）的标准文件格式。其中核心转储是指： 操作系统在进程收到某些信号而终止时，将此时进程地址空间的内容以及有关进程状态的其他信息写出的一个磁盘文件。这种信息往往用于调试。可重定位文件（relocatable file） 它保存了一些可以和其他目标文件链接并生成可执行文件或者共享库的二进制代码和数据；
可执行文件（excutable file） 它保存了适合直接加载到内存中执行的二进制程序；
共享库文件（shared object file 一种特殊的可重定位目标文件，可以在加载或者运行时被动态的加载进内存并链接。
核心转储文件（core dump） 是操作系统在进程收到某些信号而终止运行时，将此时进程地址空间的内容以及有关进程状态的其他信息写入一个磁盘文件。这种信息往往用于调试。ELF文件主要由四部分组成：ELF Header：主要包括文件的类型，架构，程序入口地址，Program Header 和 Section Header 的大小，数量，偏移量等；Programe Header：列举所有有效的 segments 的属性，描述如何创建进程运行时内存镜像，当内核看到这些 segments 时，使用 mmap 将他们映射到虚拟地址空间，为程序的运行准备；Section：在ELF文件中，数据和代码分开存放的，这样可以按照其功能属性分成一些区域，比如程序、数据、符号表等。这些分离存放的区域在ELF文件中反映成section；Section Header：定义ELF文件中所有的 section，用于链接和重定位。对于可执行文件，有四个主要部分：.text、.data、.rodata 和 .bss；ELF 文件各个部分的布局如下：这里有一个ARM上二进制文件的详细示例，可以参考下图： ELF Header
在C语言中，ELF Header 定义为如下的结构体：其中:
ElfN_Addr       Unsigned program address, uintN_t
ElfN_Off        Unsigned file offset, uintN_t上述结构体中各个字段的含义如下所示：e_ident：  包含一个 magic number、ABI信息，该文件使用的平台、大小端规则
e_type：   文件类型, 表示该文件属于可执行文件、可重定位文件、core dump文件或者共享库
e_machine：机器类型
e_version：通常都是1
e_entry：  表示程序执行的入口地址
e_phoff：  表示Program Header的入口偏移量（以字节为单位）
e_shoff：  表示Section Header的入口偏移量（以字节为单位）
e_flags：  保存了这个ELF文件相关的特定处理器的flag
e_ehsize： 表示ELF Header大小（以字节为单位）
e_phentsize： 表示Program Header大小（以字节为单位）
e_phnum：     表示Program Header的数量 （十进制数字）
e_shentsize： 表示Section Header大小（以字节为单位）
e_shnum：     表示Section Header的数量 （十进制数字）
e_shstrndx：  表示字符串表的索引，字符串表用来保存ELF文件中的字符串，比如段名、变量名。 然后通过字符串在表中的偏移访问字符串。 Section
在ELF文件中，数据和代码分开存放的，这样可以按照其功能属性分成一些区域，比如程序、数据、符号表等。这些分离存放的区域在ELF文件中反映成section。ELF文件中典型的section如下：.text: 已编译程序的二进制代码
.rodata: 只读数据段，比如常量
.data: 已初始化的全局变量和静态变量
.bss: 未初始化的全局变量和静态变量，所有被初始化成0的全局变量和静态变量
.sysmtab: 符号表，它存放了程序中定义和引用的函数和全局变量的信息
.debug: 调试符号表，它需要以’-g’选项编译才能得到，里面保存了程序中定义的局部变量和类型定义，程序中定义和引用的全局变量，以及原始的C文件
.line: 原始的C文件行号和.text节中机器指令之间的映射
.strtab: 字符串表，内容包括 .symtab 和 .debug 节中的符号表其他特殊的 section：
1）对于可重定位的文件，由于在编译时，并不能确定它引用的外部函数和变量的地址信息，因此，编译器在生成目标文件时，增加了两个·section·：.rel.text 保存了程序中引用的外部函数的重定位信息，这些信息用于在链接时重定位其对应的符号。
.rel.data 保存了被模块引用或定义的所有全局变量的重定位信息，这些信息用于在链接时重定位其对应的全局变量。2）对于可执行文件，由于它已经全部完成了重定位工作，可以直接加载到内存中执行，所以它不存在.rel.text和.rel.data这两个section。但是，它增加了一个section：
.init： 这个section里面保存了程序运行前的初始化代码
上述描述的各个文件中包含的这些section是必须存在的，当然除了这些section，每种文件还有一些其他的section用来存放编译器或者链接器所需要的辅助信息。
 Section Header Table
上述各个section的大小和位置等具体信息的存放是由Section Header Table来描述的。Section Header Table是一个结构体数组，对应的结构体定义如下：其中各成员的意义如下：sh_name：  表示该section的名字相对于.shstrtab section的地址偏移量。
sh_type：  表示该section中存放的内容类型，比如符号表，可重定位段等。
sh_flags： 表示该section的一些属性，比如是否可写，可执行等。
sh_addr：  表示该section在程序运行时的内存地址
sh_offset： 表示该section相对于ELF文件起始地址的偏移量
sh_size：   表示该section的大小
sh_link：   配合sh_info保存section的额外信息
sh_info：   保存该section相关的一些额外信息
sh_addralign：表示该section需要的地址对齐信息
sh_entsize：  有些section里保存的是一些固定长度的条目，比如符号表。对于这些section来讲，sh_entsize里保存的就是条目的长度。 Program Header Table
section基本是按照目标文件内容的功能来划分的一些区域，而根据其内容在内存中是否可读写等属性，又可以将不同的section划分成不同的segment。其中每个segment可以由一个或多个section组成。
在可执行文件中，ELF header下面紧接着就是Program Header Table。它描述了各个 segment 在 ELF 文件中的位置以及在程序执行过程中系统需要准备的其他信息。它也是用一个结构体数组来表示的。具体代码如下：各个字段的具体含义如下：p_type：  描述了当前segment是何种类型的或者如何解释当前segment，比如是动态链接相关的或者可加载类型的等
p_flags： 保存了该segment的flag
p_offset：表示从ELF文件到该segment第一个字节的偏移量
p_vaddr： 表示该segment的第一个字节在内存中的虚拟地址
p_paddr： 对于使用物理地址的系统来讲，这个成员表示该segment的物理地址
p_filesz：表示该segment的大小，以字节表示
p_memsz： 表示该segment在内存中的大小，以字节表示
p_align： 表示该segment在文件中或者内存中需要以多少字节对齐 实战演练
分析ELF文件经常用到的工具有：readelf，objdump，hexdump 等，我们将下面Go语言编写的 hello world 代码编写成二进制进行分析：GOOS=linux go build -o helloworld main.go首先使用 readelf -h 获取文件 ELF Header 信息，使用 hexdump -n 64 获取前64个字节：根据以上的输出我们获得以下信息：文件标识：7f 45 4c 46 代表 .ELF 是该文件类型的特殊标识；Class：声明该文件是32位还是64位，32位=01，64位=02；Data：大端序还是小端序，01=LSB(Least Significant Bit)，02=MSB(Most Significant Bit, big-endian)；Version： 目前固定是01；OS/ABI：每个操作系统在通用功能上都有很大的重叠。 此外，它们中的每一个都有特定的，或者它们之间至少有细微的差异。 正确集的定义是通过应用程序二进制接口 (ABI) 完成的。 通过这种方式，操作系统和应用程序都知道期望什么，并且功能被正确转发。 这两个字段描述了使用的 ABI 和相关版本。 在这种情况下，该值为 00，这意味着没有使用特定的扩展名。 输出将其显示为 System V；ABI version： ABI 版本号；Machine：机器类型；Type：type 字段告诉我们文件的用途是什么。有几种常见的文件类型。CORE (value 4)
DYN (Shared object file), for libraries (value 3)
EXEC (Executable file), for binaries (value 2)
REL (Relocatable file), before linked into an executable file (value 1)入口地址，代表程序运行时的第一个函数，我们通过 objdump 反汇编工具查看Go程序的入口函数是 _rt0_amd64_linux，并不是我们定义的 main 函数，因为Go语言是具有 runtime，在运行我们的 main 函数之前，首先要启动并且初始化自己的调度系统：程序头的起始位置是第64字节，一共有7个程序头，每个大小为56字节；节头的起始位置是第456字节，一共有23个section，每个大小为64字节；ELF Header 的大小为 64字节；通过 readelf --program-headers 命令我们可以获取 ELF 文件的程序头表，以及每个 segment 对应哪些 section：通过 readelf --section-headers 我们可以看到文件所有的 section：我们通过最后一个section的地址和大小可以算出该文件的大小为 0x001cc8b0 + 0x000000000000b7b7 = 0x1D8067 = 1933415 字节，可以通过 ls -l 指令进行验证：以 .zdebug 开头的 section 包含的都是调试信息，在程序真正运行时这些信息是没有意义的，可以通过 strip 工具对二进制文件进行瘦身，去掉调试信息： 参考文章The 101 of ELF files on Linux: Understanding and AnalysisELF Header
Section Header
LINUX_ELF_EM_H
Program Header
ELF man page
可执行与可链接格式
elf101]]></content>
      <tags>
        <tag>ELF</tag>
      </tags>
  </entry>
  <entry>
    <title>【dapr】应用的本地开发与调试</title>
    <url>/2021/12/12/%E3%80%90dapr%E3%80%91dapr%E5%BA%94%E7%94%A8%E7%9A%84%E6%9C%AC%E5%9C%B0%E5%BC%80%E5%8F%91%E4%B8%8E%E8%B0%83%E8%AF%95/</url>
    <content><![CDATA[本文借助 visual studio code 搭建本地的 dapr 应用开发环境，另外讲述本地调试技巧，便于问题定位。还是来调试 dapr 为我们准备的示例应用，secretstore，我们先将本地的 dapr 按照官方指导运行起来，并且将示例应用克隆到本地打开，另外还需安装好 Dapr Visual Studio Code扩展 ，并且执行 npm install 命令安装将应用的扩展，当所有就绪之后你的工作区应该看起来如下所示：首先需要创建 launch.json 文件，按照下图所示点击创建：执行 cmd+shift+p 调出 vscode 命令选择框，选择 Scaffold Dapr Tasks，然后依次选择选择 launch，并且输入应用名和端口号确定：在运行应用之前，需要将必要的秘钥存储组件复制到 ~/.dapr/components 目录下，如下所示：运行应用：设置断点并且输入调试路径：单步调试，查看调用栈：]]></content>
      <tags>
        <tag>dapr</tag>
      </tags>
  </entry>
  <entry>
    <title>【k8s】本地k8s集群部署dapr应用</title>
    <url>/2021/12/05/%E3%80%90k8s%E3%80%91%E6%9C%AC%E5%9C%B0k8s%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2dapr%E5%BA%94%E7%94%A8/</url>
    <content><![CDATA[Dapr 在 2021 年发布了 v1.0 生产可用版本，预示着这个号称分布式运行时的框架终于可以进入各种大企业。说是尝鲜那已经是晚了很多，讲内部实现目前还不了解，本文主要是记录自己在本地创建 k8s 集群并且跑起来我第一个基于dapr应用的辛酸过程，辛酸是因为对k8s及dapr都不熟悉，加之国内网络限制，M1 芯片对某些软件不支持导致。 预装软件
在开始操作之前，我们需要安装很多软件，当然我相信大多数开发者已经装了大部分软件。
 docker
首先自然是 docker，虽然不是容器技术的创造者，但容器技术的发扬光大，肯定有 docker 的功劳。docker 安装比较简单，在 MaxOS 上，直接下载 Desktop 版本即可。
 k3d
k3d 是讲 k3s 运行在 docker 中的社区软件，k3s 是轻量级的 k8s，主要部署于物联网设备，ARM 芯片设备上，耗电少体积小，易部署，我们在本地开发中想创建 k8s 集群，可以选择 k3d+k3s 的方式，当然也有 minikube，microk8s，kind 等，我首选了 minikube + multipass 的方式，奈何国内网络限制，加之 multipass 某些想要的功能 M1 还不支持，就放弃了。在 Mac 上安装 k3d 很简单：brew install k3d kubectl kubecm helm
k8s 用于容器编排，但是如果手动通过 k8s API 管理集群，那是非常累的，所以有了 helm，k8s 的包管理器，通过简单的命令就可以部署应用，MaxOS 上安装比较简单：brew install helm dapr
今天的主角是 dapr，所以安装 dapr 也是必不可少的：brew install dapr/tap/dapr-cli可能会遇到下载失败，编译失败，所以配置下 GOPROXY，有条件的话可以将 https_proxy 设置成可以科学上网的代理，加速下载。
 创建k8s集群
本接创建 k8s 集群的方式参考自 如何在本地快速启动一个 K8S 集群，执行一条命令：$ k3d cluster list
NAME           SERVERS   AGENTS   LOADBALANCER
test-cluster   1/1       3/3      true创建完成之后，会看到新建的集群已经就绪。
 安装rancher
根据官网描述，Rancher 是一个开源的企业级容器管理平台。通过Rancher，企业再也不必自己使用一系列的开源软件去从头搭建容器服务平台。Rancher提供了在生产环境中使用的管理Docker和Kubernetes的全栈化容器部署与管理平台。Rancher由以下四个部分组成：基础设施编排
容器编排与调度
应用商店
企业级权限管理安装 rancher 的过程很痛苦，失败了很多次，但是我还是要把它装好，最后总结起来就是以下的命令，最关键的就是等：成功安装 Rancher 之后，登录到 rancher 后台，我们可以在后台安装我们想要的组件，例如：prometheus，grafana等。 MySQL（just for fun）
参考 https://kubernetes.io/zh/docs/tasks/run-application/run-single-instance-stateful-application/，在我的机器上唯一不同的是，我是arm机器，mysql:5.6 镜像无法下载，替换成了 arm64v8/mariadb:latest。
 K8S 仪表盘
本节内容参考：https://docs.rancher.cn/docs/k3s/installation/kube-dashboard/_index部署仪表盘仪表盘RBAC配置 
部署 admin-user 配置：kubectl create -f dashboard.admin-user.yml -f dashboard.admin-user-role.yml获得 Tokenkubectl -n kubernetes-dashboard describe secret admin-user-token | grep ‘^token’要访问仪表盘，你必须创建一个安全通道到你的 K3s 集群kubectl proxy --port=7788 --address=‘0.0.0.0’ --disable-filter=true --accept-hosts ‘.*’使用类似下面的URL访问仪表盘， http://192.168.64.9:7788/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/#/login ，正常情况下，部署在自己的电脑上，直接使用localhost即可，但我是将集群部署到虚拟机里面，所以在访问的时候被检测到不安全访问：为了解决这个问题，使用 ssh 进行建立了一个转发隧道，参考：https://blog.fundebug.com/2017/04/24/ssh-port-forwarding/ssh -L localhost:8877:localhost:7788 -NT ubuntu@192.168.64.9然后就访问OK了： 验证集群
作为测试我们创建一个nginx应用来验证我们的集群：创建包含一个 nginx 的 Deployment创建Service，通过 ClusterIP 的方式暴露服务：创建 Ingress，Ingress 会代理我们的入口流量给我们的service，k3s 默认安装的 ingress 是 traefik 2.x，这里因为我不想把根目录直接暴露出去，每个服务都有一个前缀，例如到达 nginx service 的都得以 /nginx 开始，所以应该要有个路由重写的过程，最终采用中间件进行路由重写：安装 rancher 的好处就是能看得到，像我们刚才创建的 nginx Deployment，nginx Service，nginx Ingress以及 nginx-ingress-strip-prefix 中间件都可以在 Rancher 中观察到： 部署dapr应用
k8s集群中安装dapr，参考添加和安装-dapr-helm-图表，我使用下面的命令安装：这里我们部署他的 secretstore 示例应用：查看我们创建的service：NAME      TYPE           CLUSTER-IP     EXTERNAL-IP                        PORT(S)           AGE
nodeapp   LoadBalancer   10.43.203.13   172.18.0.3,172.18.0.4,172.18.0.5   48080:31093/TCP   3h34m为了能够访问到我们的服务，还必须创建一个 Ingress，像之前的 nginx service 那样，执行下面的命令：验证我们的密码获取请求：eHl6OTg3Ng==去我们的 nodeJs 应用查看日志，确认我们的请求被正确处理：可以再确认下我们的 Ingress： 部署 dapr 组件
这里我们参考官方文档 部署状态组件，第一步，安装 redis:redis 启动完成之后，首先部署状态组件：然后部署发布订阅消息代理组件： 参考文章https://juejin.cn/post/6940850465504493576]]></content>
      <categories>
        <category>dapr</category>
      </categories>
      <tags>
        <tag>dapr</tag>
        <tag>k3d</tag>
        <tag>k3s</tag>
        <tag>k8s</tag>
        <tag>traefik</tag>
        <tag>rancher</tag>
        <tag>helm</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>面向对象</title>
    <url>/2022/06/20/Design-Patterns/OOP/</url>
    <content><![CDATA[几年前在面试的时候，还经常被面试官问 OOP 的四个特征是什么以及他们背后代表的意思，几年过去了，除了不支持面向对象的语言之外，面向对象编程思想已经深入到了每个开发者的灵魂，只是做的好与不好罢了。
面向对象编程中有两个非常基础的概念，类和对象，面向对象编程是一种编程范式或者说编程风格，它以类或者对象作为组织代码的基本单元，并将封装，继承，抽象，多态作为代码设计和实现的基石，不像面向过程编程语言，以函数为程序中的基本单元。
面向对象编程只是一种编程思想，可以用不同的语言进行实现，即使我们用面向对象语言，也完全可以写出面向过程风格的代码。至于什么是面向对象编程语言，并没有严格的定义，只要它能实现 OOP 的四大特性，那它就是面向对象编程语言，例如：Rust，C++，GO，Java，Python 以及 PHP 等，
面向对象编程的前提是面向对象分析（OOA）和面向对象设计（OOD），这样才能进行面向对象编程（OOP），具备完整的面向对象编程的思维。面向对象分析和设计两个阶段的产物应该是类的设计，包括应用程序应该被分为哪些类，每个类该有哪些属性和方法，类与类之间如何交互等等，它们比较贴近代码，非常具体，容易落地实现。
在 OOA 和 OOD 的过程中，我们会经常用到 UML（Unified Model Language） 工具辅助我们进行工作。UML 是一种比较复杂的工具，除了包括我们常见的类图，还有用例图，顺序图，活动图，状态图，组件图等，即使是类图，类之间的关系就有泛化，实现，关联，聚合，组合以及依赖等，熟练掌握难度比较大，即便你掌握了，你同事不一定掌握，沟通成本依然很高，大多时候，我们会用草图实现我们的设计过程。 特征
这四大特性，光知道它们的定义是不够的，我们还要知道每个特性存在的意义和目的，以及它们能解决哪些编程问题。对于这四大特性，尽管大部分面向对象编程语言都提供了相应的语法机制来支持，但不同的编程语言实现这四大特性的语法机制可能会有所不同。
 封装
封装，也叫做信息隐藏或者数据访问保护。类通过暴露有限的访问接口，授权外部仅能通过类提供的方法来访问内部信息或者数据。下面是一个钱包的 Java 实现：从代码中，我们可以发现，Wallet类主要有四个属性（也可以叫作成员变量），也就是我们前面定义中提到的信息或者数据。其中，id 表示钱包的唯一编号，createTime 表示钱包创建的时间，balance 表示钱包中的余额，balanceLastModifiedTime 表示上次钱包余额变更的时间。
我们根据封装的目的，对钱包的这四个属性的访问方式进行了限制，调用者只允许通过上面六个方法来访问或者修改钱包里的数据。之所以这样设计，是因为从业务的角度来说，id、createTime在创建钱包的时候就确定好了，之后不应该再被改动，所以，我们并没有在Wallet类中，暴露id、createTime这两个属性的任何修改方法，比如set方法。而且，这两个属性的初始化设置，对于Wallet类的调用者来说，也应该是透明的，所以，我们在Wallet类的构造函数内部将其初始化设置好，而不是通过构造函数的参数来外部赋值。
封装意味着我们需要控制类的灵活性，仅通过暴露必要的操作，提高类的易用性。
 抽象
封装的目的是隐藏数据和信息，抽象的目的是隐藏方法实现，让调用这只需知道类提供了哪些能力，而不关注其具体实现。在不同的语言中，对于抽象有不同的实现，例如，Go 和 Java 中的接口，Rust 中的 Trait 或者其他语言中的抽象类。在上面的这段代码中，对于调用者而言，在使用图片存储功能的时候，只需要了解 PictureStorager 这个接口暴露了哪些方法，而不用去查看具体类对应方法的实现逻辑。
抽象作为一个非常宽泛的设计思想，在代码设计中，起到了非常重要的指导作用，很多设计原则都体现了抽象这种设计思想，比如基于接口而非实现编程、开闭原则，代码解耦等。我们在定义（或者叫命名）类的方法的时候，也要有抽象思维，不要在方法定义中，暴露太多的实现细节，以保证在某个时间点需要改变方法的实现逻辑的时候，不用去修改其定义。举个简单例子，比如getAliyunPictureUrl()就不是一个具有抽象思维的命名，因为某一天如果我们不再把图片存储在阿里云上，而是存储在私有云上，那这个命名也要随之被修改。相反，如果我们定义一个比较抽象的函数，比如叫作getPictureUrl()，那即便内部存储方式修改了，我们也不需要修改命名。
 继承
继承最大的一个好处就是代码复用。假如两个类有一些相同的属性和方法，我们就可以将这些相同的部分，抽取到父类中，让两个子类继承父类。这样，两个子类就可以重用父类中的代码，避免代码重复写多遍。不过，这一点也并不是继承所独有的，我们也可以通过其他方式来解决这个代码复用的问题，比如利用组合关系而不是继承关系。
集成呈现的是一种 is-a 关系，我们通过继承来关联两个类，反应真实世界中的这种关系，非常符合人类的认知，而且，从设计的角度来说，也有一种结构美感。例如，我们代码中有一个猫类，有一个哺乳动物类，猫属于哺乳动物，它们之间就属于集成关系。
从继承关系上来讲，继承可以分为两种模式，单继承和多继承。单继承表示一个子类只继承一个父类，多继承表示一个子类可以继承多个父类，比如猫既是哺乳动物，又是爬行动物。
为了实现继承这个特性，编程语言需要提供特殊的语法机制来支持，比如Java使用extends关键字来实现继承，C++使用冒号（class B : public A），Python使用parentheses ()，Ruby使用&lt;。
 多态
多态是指，子类可以替换父类，在实际的代码运行过程中，调用子类的方法实现。举个例子：多态这种特性也需要编程语言提供特殊的语法机制来实现。在上面的例子中，我们用到了三个语法机制来实现多态。编程语言要支持父类对象可以引用子类对象，也就是可以将SortedDynamicArray传递给DynamicArray；
编程语言要支持继承，也就是SortedDynamicArray继承了DynamicArray，才能将SortedDyamicArray传递给DynamicArray；
编程语言要支持子类可以重写（override）父类中的方法，也就是SortedDyamicArray重写了DynamicArray中的add()方法；对于多态特性的实现方式，除了利用“继承加方法重写”这种实现方式之外，我们还有其他两种比较常见的的实现方式，一个是利用接口类语法，另一个是利用duck-typing语法。不过，并不是每种编程语言都支持接口类或者duck-typing这两种语法机制，比如C++就不支持接口类语法，而duck-typing只有一些动态语言才支持，比如Python、JavaScript等。
 接口实现多态在这段代码中，Iterator是一个接口类，定义了一个可以遍历集合数据的迭代器。Array和LinkedList都实现了接口类Iterator。我们通过传递不同类型的实现类（Array、LinkedList）到print(Iterator iterator)函数中，支持动态的调用不同的next()、hasNext()实现。
 duck-typing 实现多态
duck-typing 实现多态的方式非常灵活，即使两个没有继承关系，也没有接口实现关系，只要有相同的方法就能表示它们有相同的特征。也就是说，只要两个类具有相同的方法，就可以实现多态，并不要求两个类之间有任何关系，这就是所谓的duck-typing，是一些动态语言所特有的语法机制。 优势
面向对象编程是一种编程范式或编程风格。它以类或对象作为组织代码的基本单元，并将封装、抽象、继承、多态四个特性，作为代码设计和实现的基石 。面向对象编程语言是支持类或对象的语法机制，并有现成的语法机制，能方便地实现面向对象编程四大特性（封装、抽象、继承、多态）的编程语言。
相比之下，面向过程编程也是一种编程范式或编程风格。它以过程（可以理解为方法、函数、操作）作为组织代码的基本单元，以数据（可以理解为成员变量、属性）与方法相分离为最主要的特点。面向过程风格是一种流程化的编程风格，通过拼接一组顺序执行的方法来操作数据完成一项功能。面向过程编程语言最大的特点是不支持类和对象两个语法概念，不支持丰富的面向对象编程特性（比如继承、多态、封装），仅支持面向过程编程。
从代码示例中可以看出，面向过程和面向对象最基本的区别就是，代码的组织方式不同。面向过程风格的代码被组织成了一组方法集合及其数据结构，方法和数据结构的定义是分开的。面向对象风格的代码被组织成一组类，方法和数据结构被绑定一起，定义在类中。
面向过程面向对象
对于简单程序的开发来说，不管是用面向过程编程风格，还是用面向对象编程风格，差别确实不会很大，甚至有的时候，面向过程的编程风格反倒更有优势。因为需求足够简单，整个程序的处理流程只有一条主线，很容易被划分成顺序执行的几个步骤，然后逐句翻译成代码，这就非常适合采用面向过程这种面条式的编程风格来实现。
相比起面向过程语言，面向对象语言有以下优势：思维方式上的变更，在面向过程语言的编程中，我们首先考虑的是流程的划分，将整个程序要实现的功能分成几大模块，模块内的流程该如何划分。面向对象编程是以类为思考对象，在进行面向对象编程的时候，先去思考如何给业务建模，如何将需求翻译为类，如何给类之间建立交互关系。当我们有了类的设计之后，然后再像搭积木一样，按照处理流程，将类组装起来形成整个程序。这种开发模式、思考问题的方式，能让我们在应对复杂程序开发的时候，思路更加清晰；面向对象编程还提供了一种更加清晰的、更加模块化的代码组织方式。类就是一种非常好的组织些函数和数据结构的方式，是一种将代码模块化的有效手段；代码更加容易维护，封装特性是面向对象编程相比于面向过程编程的一个最基本的区别，因为它基于的是面向对象编程中最基本的类的概念。面向对象编程通过类这种组织代码的方式，将数据和方法绑定在一起，通过访问权限控制，只允许外部调用者通过类暴露的有限方法访问数据，而不会像面向过程编程那样，数据可以被任意方法随意修改。因此，面向对象编程提供的封装特性更有利于提高代码的易维护性；代码更加容易扩展，借助面向对象的抽象特性，我们隐藏函数的具体实现，在使用函数的时候，只需要了解函数具有什么功能，而不需要了解它是怎么实现的。从这一点上，不管面向过程编程还是是面向对象编程，都支持抽象特性。不过，面向对象编程还提供了其他抽象特性的实现方式。这些实现方式是面向过程编程所不具备的，比如基于接口实现的抽象。基于接口的抽象，可以让我们在不改变原有实现的情况下，轻松替换新的实现逻辑，提高了代码的可扩展性；代码更容易复用，继承特性是面向对象编程相比于面向过程编程所特有的两个特性之一（另一个是多态）。如果两个类有一些相同的属性和方法，我们就可以将这些相同的代码，抽取到父类中，让两个子类继承父类。这样两个子类也就可以重用父类中的代码，避免了代码重复写多遍，提高了代码的复用性；基于多态特性，在需要修改一个功能实现的时候，可以通过实现一个新的子类的方式，在子类中重写原来的功能逻辑，用子类替换父类。在实际的代码运行过程中，调用子类新的功能逻辑，而不是在原有代码上做修改。这就遵从了“对修改关闭、对扩展开放”的设计原则，提高代码的扩展性。除此之外，利用多态特性，不同的类对象可以传递给相同的方法，执行不同的代码逻辑，提高了代码的复用性； 注意
有几个在面向对象编程中常犯的错误，会导致最终写出的代码跟面向过程没什么却别。不要滥用 getter 和 setter 方法，面向对象语言提供了封装特性，可以将一些数据进行隐藏，不对外公开，为的是对重要数据的保护。但是如果我们对所有内部状态都提供一个 getter 和 setter 方法，相当于公开属性了。例如：itemsCount和totalPrice。虽然我们将它们定义成private私有属性，但是提供了public的getter、setter方法，这就跟将这两个属性定义为public公有属性，没有什么两样了。外部可以通过setter方法随意地修改这两个属性的值。除此之外，任何代码都可以随意调用setter方法，来重新设置itemsCount、totalPrice属性的值，这也会导致其跟items属性的值不一致。
面向对象封装的定义是：通过访问权限控制，隐藏内部数据，外部仅能通过类提供的有限的接口访问、修改内部数据。所以，暴露不应该暴露的setter方法，明显违反了面向对象的封装特性。
对于items这个属性，我们定义了它的getter方法和addItem()方法，并没有定义它的setter方法。这样的设计貌似看起来没有什么问题，但实际上并不是。对于itemsCount和totalPrice这两个属性来说，定义一个public的getter方法，确实无伤大雅，毕竟getter方法不会修改数据。但是，对于items属性就不一样了，这是因为items属性的getter方法，返回的是一个List集合容器。外部调用者在拿到这个容器之后，是可以操作容器内部数据的，也就是说，外部代码还是能修改items中的数据：不要滥用全局变量和全局方法。在使用C语言这样的面向过程语言开发时，应该随处可见全局变量和全局方法。在面向对象编程中，常见的全局变量有单例类对象、静态成员变量、常量等，常见的全局方法有静态方法。单例类对象在全局代码中只有一份，所以，它相当于一个全局变量。静态成员变量是归属于类上的数据，被所有的实例化对象所共享，也相当于一定程度上的全局变量。而常量是一种非常常见的全局变量，比如一些代码中的配置参数，一般都设置为常量，放到一个 Constants 类中，静态方法一般用来操作静态变量或者外部数据。静态方法将方法与数据分离，破坏了封装特性，是典型的面向过程风格。当然不能说面向过程风格就不好，有时候一些必要的 Utils 类（没有自己的属性），定义了一大部分静态方法处理公共数据能极大提高我们的开发效率。不要定义数据和方法分离的类。不过话虽这么说，干WEB的程序员应该都知道，前后端分离的项目一般被分为：Controller层、Service层、Repository层，Controller层负责暴露接口给前端调用，Service层负责核心业务逻辑，Repository层负责数据读写。而在每一层中，我们又会定义相应的VO（View Object）、BO（Business Object）、Entity。一般情况下，VO、BO、Entity中只会定义数据，不会定义方法，所有操作这些数据的业务逻辑都定义在对应的Controller类、Service类、Repository类中。这就是典型的面向过程的编程风格。 接口、抽象类
不同的编程语言对接口和抽象类的定义可能有些区别，但是大多数面向对象语言都支持接口。抽象类有以下特点：抽象类不允许被实例化，只能被继承；
抽象类可以包含属性和方法，方法既可以包含代码实现，也可以不包含代码实现，不包含代码实现的方法叫作抽象方法；
子类继承抽象类，必须实现抽象类中的所有抽象方法；相比抽象类，接口简单很多：接口不能包含属性（也就是成员变量）；
接口只能声明方法，方法不能包含代码实现；
类实现接口的时候，必须实现接口中声明的所有方法；抽象类也是为代码复用而生的。多个子类可以继承抽象类中定义的属性和方法，避免在子类中，重复编写相同的代码，结合了抽象和继承的优点。
如果我们要表示一种is-a的关系，并且是为了解决代码复用的问题，我们就用抽象类；如果我们要表示一种has-a关系，并且是为了解决抽象而非代码复用的问题，那我们就可以使用接口。
从类的继承层次上来看，抽象类是一种自下而上的设计思路，先有子类的代码重复，然后再抽象成上层的父类（也就是抽象类）。而接口正好相反，它是一种自上而下的设计思路。我们在编程的时候，一般都是先设计接口，再去考虑具体的实现。
 基于接口编程
基于接口而非实现编程这条原则的另一个表述方式，是基于抽象而非实现编程。后者的表述方式其实更能体现这条原则的设计初衷。在软件开发中，最大的挑战之一就是需求的不断变化，这也是考验代码设计好坏的一个标准。越抽象、越顶层、越脱离具体某一实现的设计，越能提高代码的灵活性，越能应对未来的需求变化。好的代码设计，不仅能应对当下的需求，而且在将来需求发生变化的时候，仍然能够在不破坏原有代码设计的情况下灵活应对。而抽象就是提高代码扩展性、灵活性、可维护性最有效的手段之一。
举个例子，假设我们的系统中有很多涉及图片处理和存储的业务逻辑。图片经过处理之后被上传到阿里云上。为了代码复用，我们封装了图片存储相关的代码逻辑，提供了一个统一的AliyunImageStore类，供整个系统来使用。具体的代码实现如下所示：整个上传流程包含三个步骤：创建bucket（你可以简单理解为存储目录）、生成access token访问凭证、携带access token上传图片到指定的bucket中。代码实现非常简单，类中的几个方法定义得都很干净，用起来也很清晰，乍看起来没有太大问题，完全能满足我们将图片存储在阿里云的业务需求。
但是，如果随着需求的变化，我们要将图片上传到私有云，所以我们可能会实现一个 PrivateImageStore 类，并且将原来的 AliyunImageStore 替换，这样的修改听起来并不复杂，只是简单替换而已，对整个代码的改动并不大。不过，我们经常说细节是魔鬼。这句话在软件开发中特别适用。实际上，刚刚的设计实现方式，就隐藏了很多容易出问题的魔鬼细节：AliyunImageStore类中有些函数命名暴露了实现细节，比如，uploadToAliyun()和downloadFromAliyun()。如果开发这个功能的同事没有接口意识、抽象思维，那这种暴露实现细节的命名方式就不足为奇了，毕竟最初我们只考虑将图片存储在阿里云上。而我们把这种包含“aliyun”字眼的方法，照抄到PrivateImageStore类中，显然是不合适的；如果我们在新类中重新命名uploadToAliyun()、downloadFromAliyun()这些方法，那就意味着，我们要修改项目中所有使用到这两个方法的代码，代码修改量可能就会很大；其次，将图片存储到阿里云的流程，跟存储到私有云的流程，可能并不是完全一致的。比如，阿里云的图片上传和下载的过程中，需要生产access token，而私有云不需要access token。一方面，AliyunImageStore中定义的generateAccessToken()方法不能照抄到PrivateImageStore中；另一方面，我们在使用AliyunImageStore上传、下载图片的时候，代码中用到了generateAccessToken()方法，如果要改为私有云的上传下载流程，这些代码都需要做调整；解决这个问题的根本方法就是，在编写代码的时候，要遵从基于接口而非实现编程的原则，具体来讲，我们需要做到下面这3点：函数的命名不能暴露任何实现细节。比如，前面提到的uploadToAliyun()就不符合要求，应该改为去掉aliyun这样的字眼，改为更加抽象的命名方式，比如：upload()；
封装具体的实现细节。比如，跟阿里云相关的特殊上传（或下载）流程不应该暴露给调用者。我们对上传（或下载）流程进行封装，对外提供一个包裹所有上传（或下载）细节的方法，给调用者使用；
为实现类定义抽象的接口。具体的实现类都依赖统一的接口定义，遵从一致的上传功能协议。使用者依赖接口，而不是具体的实现类来编程；重构之后的代码如下：基于接口而非实现编程，并不是说需要给每个实现类都定义对应的接口，过度使用这条原则，非得给每个类都定义接口，接口满天飞，也会导致不必要的开发负担。
至于什么时候，该为某个类定义接口，实现基于接口的编程，什么时候不需要定义接口，直接使用实现类编程，我们做权衡的根本依据，还是要回归到设计原则诞生的初衷上来。只要搞清楚了这条原则是为了解决什么样的问题而产生的，你就会发现，很多之前模棱两可的问题，都会变得豁然开朗。
前面我们也提到，这条原则的设计初衷是，将接口和实现相分离，封装不稳定的实现，暴露稳定的接口。上游系统面向接口而非实现编程，不依赖不稳定的实现细节，这样当实现发生变化的时候，上游系统的代码基本上不需要做改动，以此来降低代码间的耦合性，提高代码的扩展性。
从这个设计初衷上来看，如果在我们的业务场景中，某个功能只有一种实现方式，未来也不可能被其他实现方式替换，那我们就没有必要为其设计接口，也没有必要基于接口编程，直接使用实现类就可以了。
除此之外，越是不稳定的系统，我们越是要在代码的扩展性、维护性上下功夫。相反，如果某个系统特别稳定，在开发完之后，基本上不需要做维护，那我们就没有必要为其扩展性，投入不必要的开发时间。
 组合或许优于继承
继承是面向对象的四大特性之一，用来表示类之间的 is-a 关系，可以解决代码复用的问题，但是如果继承层次过深，过复杂，继承了不必要的功能，也会影响到代码的可维护性。
举个例子，我们如果要写一个关于鸟的类，首先定义一个 AbsctractBird，具体的麻雀，鸽子，乌鸦都会继承自这个类，那么我们能否在这个抽象类中定义一个 fly() 方法？当然不能，因为还有不会飞的鸟，比如说鸵鸟。如果鸵鸟类继承自 AbsctractBird，鸵鸟就能飞了，不符合事实。有人可能说，我们重写 fly() 让它抛出异常岂不是就可以了，可以是可以，但是不够优雅：而且，不会飞的鸟有很多，还有企鹅，我们都需要重写 fly() 方法，抛出异常。到这里，支持继承的一方可能还会提出，可将鸟类分成能飞的鸟（AbsctractFlyableBird），和不能飞的鸟（AbsctractUnFlyableBird），它们都继承自 AbsctractBird，那么再实现具体类，这个时候继承深度已经达到三层了。如果再要区分能不能下蛋，能不能叫，我们就得设计能飞能下蛋能叫的鸟这种抽象类，继承爆炸：如何使用组合来优化这种继承爆炸的问题呢？我们可以将飞，叫，下蛋定义为一种能力，哪种鸟有就给哪种鸟加上。我们会使用接口，组合，委托的技术来实现我们的诉求：继承的三个作用：表示 is-a 关系，支持多态，代码复用。这三个作用都可以通过其他技术手段来实现。例如，我们可以用组合和接口的 has-a 来实现 is-a，多态可以用接口来实现；代码复用可以用组合和委托来实现。
上面的例子虽然证明了组合优于继承，但不是说继承一无是处。如果类的继承结构稳定，继承层次比较浅，继承关系也不复杂，我们可以用继承。反之，如果系统不稳定，继承层次还比较深，继承关系比较复杂，我们就考虑使用组合替换它。
关于继承可以实现代码复用，需要就具体情况具体分析，因为继承首先表明一种 is-a 关系，然后才考虑复用，例如，我们可以将能飞的鸟，飞，这个功能提取到父类中，实现代码复用。但是，对于 Crawler 和 PageAnalyzer 这两个都用到了 URL 拼接功能的类，我们没法抽象出一个父类，将这个公共的方法提取到父类中达到代码复用的目的，因为这个两个类不同宗也不同源，没有任何关系，硬生生扯出一个公共的类，只会影响代码的可读性。
所以，结论是，虽然鼓励多用组合少用继承，但组合也并不完美，继承也不是说一无是处，实际项目中，还要根据具体的情况进行分析。
 类之间的交互关系
UML 统一建模语言中定义了六种类之间的关系：泛化、实现、关联、聚合、组合、依赖。其中泛化可以理解位简单的继承关系：实现指的是接口和实现类之间的关系：聚合是一种包含关系，A 类的对象包含 B 类的对象，B 类对象的生命周期可以不依赖 A 类对象的生命周期，也就是说可以单独销毁 A 类对象但是不影响 B 类对象，比如学生和课程之间的关系：组合也是一种包含关系，但是如果 A 类对象包含 B 类对象，B 类对象的生命周期依赖 A 类对象的生命周期，B 类对象不可以单独存在，比如，鸟和翅膀的关系：关联是一种非常弱的关系，包含聚合和组合两种关系，具体到代码里面，如果 B 类对象是 A 类对象的成员变量，那 B 类和 A 类就是关联关系。具体到 Java 代码就是下面这样：依赖是一种比关联关系更加弱的关系，包含关联关系。不管是 B 类对象是 A 类对象的成员变量，还是 A 类的方法使用 B 类对象作为参数或者返回值、局部变量，只要 A 类对象使用到了 B 类对象，我们都称它们有依赖关系。具体到 Java 代码就是下面这样：从实用的角度来说，我们只保留泛化、实现、依赖和组合即可。
]]></content>
      <categories>
        <category>设计原则</category>
      </categories>
      <tags>
        <tag>面向对象</tag>
      </tags>
  </entry>
  <entry>
    <title>SOLID 设计原则</title>
    <url>/2022/07/19/Design-Patterns/solid-design-principles/</url>
    <content><![CDATA[SOLID 设计原则并非单纯的一个原则，它实际上包含5个设计原则：单一职责原则、开闭原则、里氏替换替换原则，接口隔离原则和依赖反转原则。
 单一职责原则（SRP）
SRP(Single Responsibility Principle) 这个原则的意思是一个类或者一个模块只负责完成一个功能。所以，这里有两种理解方式，一种理解是把模块看做比类更加抽象的概念，类也可以看做是模块。另一种理解是把类看做是比类更加粗粒度的代码块，模块中包含多个类。
单一职责原则定义非常简单，不难理解。一个类只负责完成一个职责或者功能，也就是说，不要设计大而全的类，要设计粒度小、功能单一的类。换个角度来讲就是，一个雷包含了两个或者两个以上业务不相干的功能，那我们就说它职责不够单一，应该将它拆分成多个功能更加单一、粒度更细的类。举例来讲，如果一个类包含了用户和订单的一些操作，而用户和订单又是独立的业务领域模型，我们将它们放到一起就违反了单一职责原则，我们就需要进行拆分。
不同的应用场景、不同阶段的需求背景、不同的业务层面，对于同一个类的职责是否单一，可能会有不用的判定结果。实际上，一些侧面的判断指标更具有指导意义和可执行性，比如，代码行数过度，函数或者属性过多都可能是违反单一职责原则的表象。
例如，下面的 UserInfo 类，这个类里面除了用户的基本信息，还有地址信息。或许一个观点是都属于用户的基本信息应该放在一起，另一个观点是可以拆分出 UserAddress 类，UserInfo 只保留除 Address 之外的其他信息，拆分之后两个类的职责更加单一。是否应该拆分，取决于具体情况，如果实际中地址信息和基本信息总是同时出现，那放在一起没有问题。但是如果地址信息单独在其他模块中使用，就应该单独抽象成 UserAddress：单一职责原则指导设计粒度较小的类，职责清晰的类，类的依赖以及被依赖的其他类也很会变少，从而降低代码的耦合性，实现高内聚、低耦合。但是如果拆分的过细，可能会适得其反，影响代码的可维护性。 开闭原则（OCP）
OCP(Open Closed Principle) 它的意思是软件实体应该对修改关闭，对扩展开放。详细描述就是，添加一个新功能应该是在已有代码基础上扩展代码（新增模块，类，方法等），而不是修改已有代码。
下面是一个 API 监控告警的例子，其中，AlertRule 存储告警规则，可以自由设置。Notification 是告警通知类，支持邮件、短信、微信、手机等多种通知渠道。NotificationEmergencyLevel 表示通知的紧急程度，包括 SEVERE（严重）、URGENCY（紧急）、NORMAL（普通）、TRIVIAL（无关紧要），不同的紧急程度对应不同的发送渠道。上面这段代码非常简单，业务逻辑主要集中在 check() 函数中。当接口的 TPS 超过某个预先设置的最大值时，以及当接口请求出错数大于某个最大允许值时，就会触发告警。
现在，如果我们需要添加一个功能，当每秒钟接口超时请求个数，超过某个预先设置的最大阈值时，我们也要触发告警发送通知。最能想到的则是下面的这种修改方案，主要的改动有两处：修改 check() 函数的入参，添加一个新的统计数据 timeoutCount，表示超时接口请求数；
在 check() 函数中添加新的告警逻辑；这种修改方案存在两个问题：我们对接口进行了修改，这就意味着调用这个接口的代码都要做相应的修改；
另一方面，修改了 check() 函数，相应的单元测试都需要修改;这种代码的改动就是基于“修改”的方式来实现新功能，我们再来看一种基于 OCP 原则修改代码，但是这种修改需要对原有的代码进行重构，包含两方面：将 check() 函数的多个入参封装成 ApiStatInfo 类；
引入 handler 的概念，将 if 判断逻辑分散在各个 handler 中；上面的代码是对 Alert 的重构，我们再来看下，重构之后的 Alert 该如何使用呢？具体的使用代码我也写在这里了。其中，ApplicationContext 是一个单例类，负责 Alert 的创建、组装（alertRule 和 notification 的依赖注入）、初始化（添加 handlers）工作。基于重构之后的代码，如果再添加上面讲到的那个新功能，每秒钟接口超时请求个数超过某个最大阈值就告警，我们就容易扩展多了，主要的改动有下面四处。第一处改动是：在 ApiStatInfo 类中添加新的属性 timeoutCount；
第二处改动是：添加新的 TimeoutAlertHander 类；
第三处改动是：在 ApplicationContext 类的 initializeBeans() 方法中，往 alert 对象中注册新的 timeoutAlertHandler；
第四处改动是：在使用 Alert 类的时候，需要给 check() 函数的入参 apiStatInfo 对象设置 timeoutCount 的值；完整代码如下所示：重构之后的代码更加灵活和易扩展。如果我们要想添加新的告警逻辑，只需要基于扩展的方式创建新的 handler 类即可，不需要改动原来的 check() 函数的逻辑。而且，我们只需要为新的 handler 类添加单元测试，老的单元测试都不会失败，也不用修改。
OCP 原则实际上不是不让改，而是通过添加属性、类、方法等方式扩展代码，这个原则实际上讲的就是代码的扩展性问题。如果某段代码在应对未来需求变化的时候，能够做到“对扩展开放、对修改关闭”，那就说明这段代码的扩展性比较好。所以，问如何才能做到“对扩展开放、对修改关闭”，也就粗略地等同于在问，如何才能写出扩展性好的代码。
为了尽量写出扩展性好的代码，我们要时刻具备扩展意识、抽象意识、封装意识。
在写代码的时候后，我们要多花点时间往前多思考一下，这段代码未来可能有哪些需求变更、如何设计代码结构，事先留好扩展点，以便在未来需求变更的时候，不需要改动代码整体结构、做到最小代码改动的情况下，新的代码能够很灵活地插入到扩展点上，做到“对扩展开放、对修改关闭”。
在识别出代码可变部分和不可变部分之后，我们要将可变部分封装起来，隔离变化，提供抽象化的不可变接口，给上层系统使用。当具体的实现发生变化的时候，我们只需要基于相同的抽象接口，扩展一个新的实现，替换掉老的实现即可，上游系统的代码几乎不需要修改。
在众多的设计原则、思想、模式中，最常用来提高代码扩展性的方法有：多态、依赖注入、基于接口而非实现编程，以及大部分的设计模式（比如，装饰、策略、模板、职责链、状态等）。其中，多态、依赖注入、基于接口而非实现编程，以及前面提到的抽象意识，说的都是同一种设计思路，只是从不同的角度、不同的层面来阐述而已。这也体现了“很多设计原则、思想、模式都是相通的”这一思想。
 Example
我们要实现一个基于 kafka 来发送异步消息的功能。对于这样一个功能的开发，我们要学会将其抽象成一组跟具体消息队列（Kafka）无关的异步消息接口。所有上层系统都依赖这组抽象的接口编程，并且通过依赖注入的方式来调用。当我们要替换新的消息队列的时候，比如将 Kafka 替换成 RocketMQ，可以很方便地拔掉老的消息队列实现，插入新的消息队列实现。具体代码如下所示： 里氏替换原则（LSP）
LSP(Liskov Substitution Principle) ，这条原则用中文描述出来，是这样的：子类对象能够替换程序中父类对象出现的任何地方，并且保证原来程序的逻辑行为不变及正确性不被破坏。
举例说明，如下代码中，父类 Transporter 使用 org.apache.http 库中的 HttpClient 类来传输网络数据。子类 SecurityTransporter 继承父类 Transporter，增加了额外的功能，支持传输 appId 和 appToken 安全认证信息。在上面的代码中，子类 SecurityTransporter 的设计完全符合里式替换原则，可以替换父类出现的任何位置，并且原来代码的逻辑行为不变且正确性也没有被破坏。
从刚刚的例子和定义描述来看，里式替换原则跟多态看起来确实有点类似，但实际上它们完全是两回事。还是通过刚才这个例子来解释一下。不过，我们需要对 SecurityTransporter 类中 sendRequest() 函数稍加改造一下。改造前，如果 appId 或者 appToken 没有设置，我们就不做校验；改造后，如果 appId 或者 appToken 没有设置，则直接抛出 NoAuthorizationRuntimeException 未授权异常。改造前后的代码对比如下所示：
改造前改造后
在改造之后的代码中，如果传递进 demoFunction() 函数的是父类 Transporter 对象，那 demoFunction() 函数并不会有异常抛出，但如果传递给 demoFunction() 函数的是子类 SecurityTransporter 对象，那 demoFunction() 有可能会有异常抛出。尽管代码中抛出的是运行时异常（Runtime Exception），我们可以不在代码中显式地捕获处理，但子类替换父类传递进 demoFunction 函数之后，整个程序的逻辑行为有了改变。
虽然改造之后的代码仍然可以通过 Java 的多态语法，动态地用子类 SecurityTransporter 来替换父类 Transporter，也并不会导致程序编译或者运行报错。但是，从设计思路上来讲，SecurityTransporter 的设计是不符合里式替换原则的。
虽然从定义描述和代码实现上来看，多态和里式替换有点类似，但它们关注的角度是不一样的。多态是面向对象编程的一大特性，也是面向对象编程语言的一种语法，它是一种代码实现的思路。而里式替换是一种设计原则，是用来指导继承关系中子类该如何设计的，子类的设计要保证在替换父类的时候，不改变原有程序的逻辑以及不破坏原有程序的正确性。
里式替换原则还有另外一个更加能落地、更有指导意义的描述，那就是 Design By Contract，中文翻译就是按照协议来设计。
子类在设计的时候，要遵守父类的行为约定（或者叫协议）。父类定义了函数的行为约定，那子类可以改变函数的内部实现逻辑，但不能改变函数原有的行为约定。这里的行为约定包括：函数声明要实现的功能；对输入、输出、异常的约定，甚至包括注释中所罗列的任何特殊说明。实际上，定义中父类和子类之间的关系，也可以替换成接口和实现类之间的关系。
常见的违反里氏替换原则的几个误区：子类违背父类声明要实现的功能：
父类中提供的 sortOrdersByAmount() 订单排序函数，是按照金额从小到大来给订单排序的，而子类重写这个 sortOrdersByAmount() 订单排序函数之后，是按照创建日期来给订单排序的。那子类的设计就违背里式替换原则。子类违背父类对输入、输出、异常的约定：在父类中，某个函数约定：运行出错的时候返回 null；获取数据为空的时候返回空集合。而子类重载函数之后，实现变了，运行出错返回异常，获取不到数据返回 null。那子类的设计就违背里式替换原则；
在父类中，某个函数约定，输入数据可以是任意整数，但子类实现的时候，只允许输入数据是正整数，负数就抛出，也就是说，子类对输入的数据的校验比父类更加严格，那子类的设计就违背了里式替换原则；
在父类中，某个函数约定，只会抛出 ArgumentNullException 异常，那子类的设计实现中只允许抛出 ArgumentNullException 异常，任何其他异常的抛出，都会导致子类违背里式替换原则；子类违背父类注释中所罗列的任何特殊说明
父类中定义的 withdraw() 提现函数的注释是这么写的：“用户的提现金额不得超过账户余额……”，而子类重写 withdraw() 函数之后，针对 VIP 账号实现了透支提现的功能，也就是提现金额可以大于账户余额，那这个子类的设计也是不符合里式替换原则的。以上便是三种典型的违背里式替换原则的情况。除此之外，判断子类的设计实现是否违背里式替换原则，还有一个小窍门，那就是拿父类的单元测试去验证子类的代码。如果某些单元测试运行失败，就有可能说明，子类的设计实现没有完全地遵守父类的约定，子类有可能违背了里式替换原则。
里式替换这个原则是非常宽松的。一般情况下，我们写的代码都不怎么会违背它。
 接口隔离原则（ISP）
ISP(Interface Segregation Principle)，客户端不应该被强迫依赖它不需要的接口。其中的客户端，可以理解为接口的调用者或者使用者。
接口这个名词可以用在很多场合中，在软件开发中，我们既可以把它看作一组抽象的约定，也可以具体指系统与系统之间的 API 接口，还可以特指面向对象编程语言中的接口等。理解接口隔离原则的关键，就是理解其中的“接口”二字。在这条原则中，我们可以把“接口”理解为下面三种东西： 一组 API 接口集合；单个 API 接口或函数；OOP 中的接口概念。
 把“接口”理解为一组 API 接口集合
举个例子，微服务用户系统提供了一组跟用户相关的 API 给其他系统使用，比如：注册、登录、获取用户信息等。具体代码如下所示：现在，我们的后台管理系统要实现删除用户的功能，希望用户系统提供一个删除用户的接口。这个时候我们该如何来做呢？你可能会说，这不是很简单吗，我只需要在 UserService 中新添加一个 deleteUserByCellphone() 或 deleteUserById() 接口就可以了。这个方法可以解决问题，但是也隐藏了一些安全隐患。
删除用户是一个非常慎重的操作，我们只希望通过后台管理系统来执行，所以这个接口只限于给后台管理系统使用。如果我们把它放到 UserService 中，那所有使用到 UserService 的系统，都可以调用这个接口。不加限制地被其他业务系统调用，就有可能导致误删用户。
当然，最好的解决方案是从架构设计的层面，通过接口鉴权的方式来限制接口的调用。不过，如果暂时没有鉴权框架来支持，我们还可以从代码设计的层面，尽量避免接口被误用。我们参照接口隔离原则，调用者不应该强迫依赖它不需要的接口，将删除接口单独放到另外一个接口 RestrictedUserService 中，然后将 RestrictedUserService 只打包提供给后台管理系统来使用。具体的代码实现如下所示：在刚刚的这个例子中，我们把接口隔离原则中的接口，理解为一组接口集合，它可以是某个微服务的接口，也可以是某个类库的接口等等。在设计微服务或者类库接口的时候，如果部分接口只被部分调用者使用，那我们就需要将这部分接口隔离出来，单独给对应的调用者使用，而不是强迫其他调用者也依赖这部分不会被用到的接口。
 把“接口”理解为单个 API 接口或函数
把接口理解为单个接口或函数，那接口隔离原则就可以理解为：函数的设计要功能单一，不要将多个不同的功能逻辑在一个函数中实现。接下来，我们还是通过一个例子来解释一下：在上面的代码中，count() 函数的功能不够单一，包含很多不同的统计功能，比如，求最大值、最小值、平均值等等。按照接口隔离原则，我们应该把 count() 函数拆成几个更小粒度的函数，每个函数负责一个独立的统计功能。拆分之后的代码如下所示：在某种意义上讲，count() 函数也不能算是职责不够单一，毕竟它做的事情只跟统计相关。实际上，判定功能是否单一，除了很强的主观性，还需要结合具体的场景。
如果在项目中，对每个统计需求，Statistics 定义的那几个统计信息都有涉及，那 count() 函数的设计就是合理的。相反，如果每个统计需求只涉及 Statistics 罗列的统计信息中一部分，比如，有的只需要用到 max、min、average 这三类统计信息，有的只需要用到 average、sum。而 count() 函数每次都会把所有的统计信息计算一遍，就会做很多无用功，势必影响代码的性能，特别是在需要统计的数据量很大的时候。所以，在这个应用场景下，count() 函数的设计就有点不合理了，我们应该按照第二种设计思路，将其拆分成粒度更细的多个统计函数。接口隔离原则跟单一职责原则有点类似，不过稍微还是有点区别。单一职责原则针对的是模块、类、接口的设计。而接口隔离原则相对于单一职责原则，一方面它更侧重于接口的设计，另一方面它的思考的角度不同。它提供了一种判断接口是否职责单一的标准：通过调用者如何使用接口来间接地判定。如果调用者只使用部分接口或接口的部分功能，那接口的设计就不够职责单一。 把“接口”理解为 OOP 中的接口概念
还可以把“接口”理解为 OOP 中的接口概念，比如 Java 中的 interface。假设我们的项目中用到了三个外部系统：Redis、MySQL、Kafka。每个系统都对应一系列配置信息，比如地址、端口、访问超时时间等。为了在内存中存储这些配置信息，供项目中的其他模块来使用，我们分别设计实现了三个 Configuration 类：RedisConfig、MysqlConfig、KafkaConfig。现在，我们有一个新的功能需求，希望支持 Redis 和 Kafka 配置信息的热更新。所谓“热更新（hot update）”就是，如果在配置中心中更改了配置信息，我们希望在不用重启系统的情况下，能将最新的配置信息加载到内存中（也就是 RedisConfig、KafkaConfig 类中）。但是，因为某些原因，我们并不希望对 MySQL 的配置信息进行热更新。
为了实现这样一个功能需求，我们设计实现了一个 ScheduledUpdater 类，以固定时间频率（periodInSeconds）来调用 RedisConfig、KafkaConfig 的 update() 方法更新配置信息。具体的代码实现如下所示：当需要增加通过Web查看 MySQL 和 Redis 的配置信息时，我们可以在项目中开发一个内嵌的 SimpleHttpServer，输出项目的配置信息到一个固定的 HTTP 地址，比如：http://127.0.0.1:2389/config。我们只需要在浏览器中输入这个地址，就可以显示出系统的配置信息。不过，出于某些原因，我们只想暴露 MySQL 和 Redis 的配置信息，不想暴露 Kafka 的配置信息。我们设计了两个功能非常单一的接口：Updater 和 Viewer。ScheduledUpdater 只依赖 Updater 这个跟热更新相关的接口，不需要被强迫去依赖不需要的 Viewer 接口，满足接口隔离原则。同理，SimpleHttpServer 只依赖跟查看信息相关的 Viewer 接口，不依赖不需要的 Updater 接口，也满足接口隔离原则。但是如果设计一个大而全的 Config 接口又有什么错呢？这样的设计思路也是能工作的，但是对比前后两个设计思路，在同样的代码量、实现复杂度、同等可读性的情况下，第一种设计思路显然要比第二种好很多。原因如下：
原因一原因二第一种设计思路更加灵活、易扩展、易复用。因为 Updater、Viewer 职责更加单一，单一就意味了通用、复用性好。比如，我们现在又有一个新的需求，开发一个 Metrics 性能统计模块，并且希望将 Metrics 也通过 SimpleHttpServer 显示在网页上，以方便查看。这个时候，尽管 Metrics 跟 RedisConfig 等没有任何关系，但我们仍然可以让 Metrics 类实现非常通用的 Viewer 接口，复用 SimpleHttpServer 的代码实现。具体的代码如下所示：
第二种设计思路在代码实现上做了一些无用功。因为 Config 接口中包含两类不相关的接口，一类是 update()，一类是 output() 和 outputInPlainText()。理论上，KafkaConfig 只需要实现 update() 接口，并不需要实现 output() 相关的接口。同理，MysqlConfig 只需要实现 output() 相关接口，并需要实现 update() 接口。但第二种设计思路要求 RedisConfig、KafkaConfig、MySqlConfig 必须同时实现 Config 的所有接口函数（update、output、outputInPlainText）。除此之外，如果我们要往 Config 中继续添加一个新的接口，那所有的实现类都要改动。相反，如果我们的接口粒度比较小，那涉及改动的类就比较少。
 依赖反转
在 SOLID 最后一个原则依赖反转中，经常会提到另外两个相似的概念，控制反转(IOC) 和依赖注入。
 控制反转（IOC）
控制反转的英文翻译是 Inversion Of Control，缩写为 IOC，请看下面的示例：在上面的代码中，所有的流程都由程序员来控制。如果我们抽象出一个下面这样一个框架，我们再来看，如何利用框架来实现同样的功能。具体的代码实现如下所示：把这个简化版本的测试框架引入到工程中之后，我们只需要在框架预留的扩展点，也就是 TestCase 类中的 doTest() 抽象函数中，填充具体的测试代码就可以实现之前的功能了，完全不需要写负责执行流程的 main() 函数了。 具体的代码如下所示：刚刚举的这个例子，就是典型的通过框架来实现“控制反转”的例子。框架提供了一个可扩展的代码骨架，用来组装对象、管理整个执行流程。程序员利用框架进行开发的时候，只需要往预留的扩展点上，添加跟自己业务相关的代码，就可以利用框架来驱动整个程序流程的执行。
这里的“控制”指的是对程序执行流程的控制，而“反转”指的是在没有使用框架之前，程序员自己控制整个程序的执行。在使用框架之后，整个程序的执行流程可以通过框架来控制。流程的控制权从程序员“反转”到了框架。
实际上，实现控制反转的方法有很多，除了刚才例子中所示的类似于模板设计模式的方法之外，还有马上要讲到的依赖注入等方法，所以，控制反转并不是一种具体的实现技巧，而是一个比较笼统的设计思想，一般用来指导框架层面的设计。
 依赖注入（DI）
依赖注入跟控制反转恰恰相反，它是一种具体的编码技巧。依赖注入的英文翻译是 Dependency Injection，缩写为 DI。用一句话来概括就是：不通过 new() 的方式在类内部创建依赖类对象，而是将依赖的类对象在外部创建好之后，通过构造函数、函数参数等方式传递（或注入）给类使用。
举个例子，Notification 类负责消息推送，依赖 MessageSender 类实现推送商品促销、验证码等消息给用户。我们分别用依赖注入和非依赖注入两种方式来实现一下。具体的实现代码如下所示：
非依赖注入方式依赖注入方式
通过依赖注入的方式来将依赖的类对象传递进来，这样就提高了代码的扩展性，我们可以灵活地替换依赖的类。这一点在我们之前讲“开闭原则”的时候也提到过。当然，上面代码还有继续优化的空间，我们还可以把 MessageSender 定义成接口，基于接口而非实现编程。改造后的代码如下所示： 依赖注入框架
在采用依赖注入实现的 Notification 类中，虽然我们不需要用类似 hard code 的方式，在类内部通过 new 来创建 MessageSender 对象，但是，这个创建对象、组装（或注入）对象的工作仅仅是被移动到了更上层代码而已，还是需要我们程序员自己来实现。具体代码如下所示：在实际的软件开发中，一些项目可能会涉及几十、上百、甚至几百个类，类对象的创建和依赖注入会变得非常复杂。如果这部分工作都是靠程序员自己写代码来完成，容易出错且开发成本也比较高。而对象创建和依赖注入的工作，本身跟具体的业务无关，我们完全可以抽象成“依赖注入框架”来自动完成。我们只需要通过依赖注入框架提供的扩展点，简单配置一下所有需要创建的类对象、类与类之间的依赖关系，就可以实现由框架来自动创建对象、管理对象的生命周期、依赖注入等原本需要程序员来做的事情。
现成的依赖注入框架有很多，比如 Google Guice、Java Spring、Pico Container、Butterfly Container 等。
 依赖反转原则（DIP）
依赖反转原则的英文翻译是 Dependency Inversion Principle，缩写为 DIP，中文翻译有时候也叫依赖倒置原则。大概意思就是：高层模块不要依赖低层模块。高层模块和低层模块应该通过抽象来互相依赖。除此之外，抽象不要依赖具体实现细节，具体实现细节依赖抽象。
所谓高层模块和低层模块的划分，简单来说就是，在调用链上，调用者属于高层，被调用者属于低层。在平时的业务代码开发中，高层模块依赖底层模块是没有任何问题的。实际上，这条原则主要还是用来指导框架层面的设计，跟前面讲到的控制反转类似。
我们拿 Tomcat 这个 Servlet 容器作为例子来解释一下。Tomcat 是运行 Java Web 应用程序的容器。我们编写的 Web 应用程序代码只需要部署在 Tomcat 容器下，便可以被 Tomcat 容器调用执行。按照之前的划分原则，Tomcat 就是高层模块，我们编写的 Web 应用程序代码就是低层模块。Tomcat 和应用程序代码之间并没有直接的依赖关系，两者都依赖同一个“抽象”，也就是 Servlet 规范。Servlet 规范不依赖具体的 Tomcat 容器和应用程序的实现细节，而 Tomcat 容器和应用程序依赖 Servlet 规范。
]]></content>
      <categories>
        <category>设计原则</category>
      </categories>
      <tags>
        <tag>SOLID</tag>
      </tags>
  </entry>
  <entry>
    <title>设计模式</title>
    <url>/2022/10/07/Design-Patterns/design-patterns/</url>
    <content><![CDATA[设计模式]]></content>
      <categories>
        <category>设计原则</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>容器技术探索及实践</title>
    <url>/2023/12/22/Docker/create-contaienr-with-linux-original-tech/</url>
    <content><![CDATA[容器其实是一种沙盒技术。顾名思义，沙盒就是能够像一个集装箱一样，把你的应用装起来的技术。这样，应用与应用之间，就因为有了边界而不至于相互干扰。对于应用来说，它的静态表现就是程序，平常都安安静静地待在磁盘上；而一旦运行起来，它就变成了计算机里的数据和状态的总和，这就是它的动态表现。容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个边界。对于Docker等大多数Linux容器来说，Cgroups技术是用来制造约束的主要手段，而Namespace技术则是用来修改进程视图的主要方法。本篇文章的主要目标就是手动利用Linux提供的 Cgroup 和 Namespace 技术创建出一个容器。
 容器镜像
首先我们从容器镜像开始，从我们对容器的认识来说，进入到容器之后，看到了一个独立的文件系统，和宿主机完全隔离，包含了应用程序所需要的数据、文件以及所有依赖，而容器镜像就是用来构建应用程序所需的文件系统，容器镜像有一个更为专业的名字，叫做 rootfs 根文件系统，当我们启动一个进程时，为进程启用Linux Namespace配置，设置Cgroup参数用于资源限制，切换进程的根目录，这样它看起来就像在一个独立的系统中运行。但是需要明确的是，rootfs只是一个操作系统所包含的文件、配置和目录，并不包括操作系统内核。在Linux操作系统中，这两部分是分开存放的，操作系统只有在开机启动时才会加载指定版本的内核镜像。因此同一台机器上的所有容器，都共享宿主机操作系统的内核。
这就意味着，如果我们的应用程序需要配置内核参数、加载额外的内核模块，以及跟内核进行直接的交互，就需要注意了：这些操作和依赖的对象，都是宿主机操作系统的内核，它对于该机器上的所有容器来说是一个“全局变量”，牵一发而动全身。这也是容器相比于虚拟机的主要缺陷之一：毕竟后者不仅有模拟出来的硬件机器充当沙盒，而且每个沙盒里还运行着一个完整的Guest OS给应用随便折腾。
所以，容器启动快是因为本质上就是宿主机上的一个进程而已，启动一个进程的速度当然比启动一个虚拟机的速度快。不过，正是由于rootfs的存在，容器才有了一个被反复宣传至今的重要特性：一致性，rootfs里打包的不只是应用，而是整个操作系统的文件和目录，也就意味着，应用以及它运行所需要的所有依赖，都被封装在了一起。无论在本地、云端，还是在一台任何地方的机器上，用户只需要解压打包好的容器镜像，那么这个应用运行所需要的完整的执行环境就被重现出来了。这种深入到操作系统级别的运行环境一致性，打通了应用在本地开发和远端执行环境之间难以逾越的鸿沟。 UnionFS
为了减少镜像占用的磁盘空间大小，也为了简化镜像制作的难度，Docker在镜像的设计中引入了分层的设计，将用户制作镜像的每一步操作，都生成一个层，也就是一个增量rootfs，最后将这些不同的层通过联合挂载生成最终的文件系统。举个例子，就像我们利用Ubuntu的基础镜像运行一个Python应用，首先安装好Python的环境，最后部署我们的应用，我们可以将在安装好的Python的环境打包成一个的新的层，这样不同的人都可以在这个层上构建自己的应用，当在相同主机上跑多个不同应用的时候大家的基础镜像一致，也不会造成额外的空间浪费，带有Python环境的rootfs都是相同的，只是最后联合挂载了不同的应用层而已。
Docekr 目前使用overlay2存储驱动作为它的联合文件系统实现，当然可以更换，使用下面的命令可以查看Docker当前使用的文件系统是什么：overlay2 的目录是镜像和容器分层的基础，而把这些层统一展现到同一的目录下的过程称为联合挂载（union mount）。overlay2把目录的下一层叫作lowerdir，上一层叫作upperdir，联合挂载后的结果叫作merged，我们来使用 overlay 做个联合挂载的示例，在本地准备如下的目录和文件结构，work 目录是 overlay 的内部目录，merged 是我们合并之后的目录：使用如下的命令进行联合挂载：mount -t overlay overlay -o lowerdir=./lower2:./lower1,upperdir=./upper,workdir=./work ./merged根据结果可以看到，这三层的顺序从高到低一次是：upper，lower2以及lower1，遇到相同的文件，高层的会覆盖底层的。可以使用如下的命令查看当前系统是使用overlay挂在的所有目录：mount -t overlay联合挂载会对三个个目录进行合并，相同的文件会以上层的为准，下层的被覆盖。取消挂载使用下面的命令：umount ./merged/ Docker镜像
我们来看看 ubuntu:16.04 镜像的内部的rootfs是怎么样的，使用如下的命令可以查看镜像内部是如何组织的：docker image inspect ubuntu:16.04从 RootFS.Layers 可以看到这个镜像一共有四层，这里面的顺序是从低层到高层，从 .GraphDriver.Data 中的数据我们可以看到每一层在宿主机上的存储位置，GraphDriver.Data.LowerDir 的顺序是从高层到最底层，也就是说列表中最后一个元素是最底层的。所以对于这个镜像来说的，它的四层层级关系从低到高是这样的：那么每一层是如何知道上一层是什么呢？进入到第二层中，我们会发现存在以下文件：diff 目录保存的是当前层的内容，link 存储的是这个层对应的短id，因为mount命令挂在的时候对参数长度有限制，所以将/opt/docker/overlay2/l/短id 映射到该层的diff目录，挂在的时候就可以使用这个较短的路径：cd /opt/docker/overlay2/l/H3AOMG26MY5WYIL3VZDJBCHVLUlower 文件存储的是上一层diff目录的段路径，省略了/opt/docker/overlay2 这个前缀，可以通过下面的输出进行对比当前层lower文件内容和上次的 link 文件中的id：对于第三层来说，它的 lower 中存储的是前两层中的diff目录段路径：这样对于Docekr来说，基于相同层构建的镜像在相同的主机上它们知会存储一份，大大减少了磁盘占用，这种层概念的引入也方便了镜像的制作和分发。
 容器RootFS
上面我们介绍Docker镜像中每个层的内容以及联合挂载，我们现在来看一个运行中的容器它的RootFS是怎么样的。使用下面的命令启动一个容器进行观察：docker run --rm -it -d --name ubuntu1604 ubuntu:16.04然后查看容器运行时的联合目录挂载在哪里，我们可以使用docker inspect命令进行查看：docker inspect --format '&#123;&#123;json .GraphDriver.Data &#125;&#125;'  ubuntu1604从这里我们可以看到这个容器在启动的时候增加了两层，分别是init层和当前的UpperDir，其他的四层都是我们镜像中的，这些层可以分为3类：镜像层，镜像层的内容是原始镜像中，我们不可以对这些文件进行修改，即使看起来在修改可读镜像中的文件，只不过是在 UpperDir 中生成了同样的文件而已，而且将镜像层的文件进行覆盖了；init层：Init层是Docker项目单独生成的一个内部层，专门用来存放/etc/hosts、/etc/resolv.conf等信息。需要这样一层的原因是，这些文件本来属于只读的Ubuntu镜像的一部分，但是用户往往需要在启动容器时写入一些指定的值比如hostname，所以就需要在可读写层对它们进行修改。可是，这些修改往往只对当前的容器有效，我们并不希望执行docker commit时，把这些信息连同可读写层一起提交掉。所以，Docker做法是，在修改了这些文件之后，以一个单独的层挂载了出来。而用户执行docker commit只会提交可读写层，所以是不包含这些内容的；UpperDir，这个目录是 Docekr 在启动容器的时候自动帮我们生成，当我们在容器里面修改或者创建文件的时候，都会体现在这个层，docker commit 会提交这个层的内容。例如，进入容器，创建一个文件：然后查看宿主机上的 MergedDir 和 UpperDir：对容器中的文件进行操作，都反映在了联合挂载的目录中，以及Docker自动创建的层。那么如果对于删除文件该如何进行的呢？使用如下的命令在删除容器中的文件，这个文件是基础镜像层提供的：这个时候我们去 MergedDir 中查看该文件已经是不存在的了，但是去UpperDir发现生成了一个特殊文件：这里的c代表字符设备，设备编号 是 0/0，这是 overlay 文件系统的处理方式，当我们删除了一个 lower 中的文件时，会在 Upper 中生成一个特殊的编号 0/0 的字符设备文件，这样在最终的 merged 目录中，发现这个文件和某个 lower 中的文件匹配时就不显示了。整个容器运行时的 RootFS 可以用如下的图描述： Cgroup
Linux Cgroups就是Linux内核中用来为进程设置资源限制的一个重要功能，它的全称是Linux Control Group。它最主要的作用，就是限制一个进程组能够使用的资源上限，包括CPU、内存、磁盘、网络带宽等等。此外，Cgroups还能够对进程进行优先级设置、审计，以及将进程挂起和恢复等操作。
在Linux中，Cgroups给用户暴露出来的操作接口是文件系统，即它以文件和目录的方式组织在操作系统的/sys/fs/cgroup路径下。我们可以使用如下的命令将他们展示出来:mount -t cgroup它的输出结果，是一系列文件系统目录。如果自己的机器上没有看到这些目录，就需要自己去挂载Cgroups，具体做法可以自行Google。可以看到，在/sys/fs/cgroup下面有很多诸如cpuset、cpu、 memory这样的子目录，也叫子系统。这些都是我这台机器当前可以被Cgroups进行限制的资源种类。而在子系统对应的资源种类下，你就可以看到该类资源具体可以被限制的方法。比如，对CPU子系统来说，我们就可以看到如下几个配置文件，这个指令是：/sys/fs/cgroup/cpu如果熟悉Linux CPU管理的话，就会在它的输出里注意到cfs_period和cfs_quota这样的关键词。这两个参数需要组合使用，可以用来限制进程在长度为cfs_period的一段时间内，只能被分配到总量为cfs_quota的CPU时间。我们在这个 /sys/fs/cgroup/cpu 创建一个目录，这个目录被称为控制组，而且在新创建的目录下，自动生成该子系统对应的资源限制文件：然后我们在后台执行一个死循环，让他把CPU吃到100%：while : ; do : ; done &amp;这里得到这个后台进程的PID是1904248，使用 top 命令可以看到它把1个CPU给干到100%了：top -p 1904248此时，我们可以通过查看container目录下的文件，看到container控制组里的CPU quota还没有任何限制（即：-1），CPU period则是默认的100 ms（100000 us）：如果想限制它只能使用20%的CPU，只需要往cpu.cfs_quota_us写入20000，表示在100ms的时间里，只能使用20ms的CPU时间：echo 20000 &gt; /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us然后我们被限制的进程id写到控制组里面的tasks文件，上面的配置就会对该进程生效：echo 1904248 &gt; /sys/fs/cgroup/cpu/container/tasks再去查看该进程的CPU使用率已经降到20%了：Linux Cgroups的设计还是比较易用的，简单粗暴地理解呢，它就是一个子系统目录加上一组资源限制文件的组合。而对于Docker等Linux容器项目来说，它们只需要在每个子系统下面，为每个容器创建一个控制组（即创建一个新目录），然后在启动容器进程之后，把这个进程的PID填写到对应控制组的tasks文件中就可以了。而至于在这些控制组下面的资源文件里填上什么值，就靠用户执行docker run时的参数指定了，比如这样一条命令：docker run -it --cpu-period=100000 --cpu-quota=20000 -d --name ubuntu1604-cgroup ubuntu:16.04然后该容器在宿主机上的进程ID：查看该进程的控制组信息：cat  /proc/1912775/cgroup查看CPU的资源限制信息：cat /sys/fs/cgroup/cpu/system.slice/docker-db8fca9e0714adc51c895a250123e66f1c6eae73db85e1ae098f97d0ec1c61ef.scope/cpu.cfs_period_us
cat /sys/fs/cgroup/cpu/system.slice/docker-db8fca9e0714adc51c895a250123e66f1c6eae73db85e1ae098f97d0ec1c61ef.scope/cpu.cfs_quota_us这就意味着这个ubuntu1604-cgroup容器，只能使用到20%的CPU。
 Namespace
Cgroups 用来限制进程使用资源的上限，而Namespace技术则是用来修改进程动态视图的主要方法，它对内核资源进行隔离，让一组进程只看到与自己相关的一部分资源。Linux一共为我们提供了8种Namespace，它们分别是：Mount，系统调用参数：CLONE_NEWNS，用于隔离挂载点；
User，系统调用参数：CLONE_NEWUSER，隔离用户和用户组；
PID，系统调用参数：CLONE_NEWPID，隔离进程ID；
IPC，系统调用参数：CLONE_NEWIPC，用于隔离信号量、消息队列和共享内存；
Network，系统调用参数：CLONE_NEWNET，隔离网络设备，网络栈、端口等；
UTS，系统调用参数：CLONE_NEWUTS，隔离主机名和域名；
Time，系统调用参数：CLONE_NEWTIME，允许进城看到不同的系统时间；
Cgroup，系统调用参数：CLONE_NEWCGROUP，隔离Cgroup根目录；Namespace 可能未来还会增加，不过当前使用这些构建容器已经足够了，接下来我们使用不同的方式来创建一个隔离的进程。
 Rust
我们首先使用代码调用Linux的系统调用创建容器，这是最直接的方式，其他方式也都是构建于这个基础之上，这里我们使用Rust编程语言，调用C接口，Rust安装方式可以使用国内镜像rsproxy，完成示例请见container-create。
测试环境信息：安装必要的构建工具：apt install build-essential本地首先调用下面的方式创建工程和添加依赖：在正式开始之前，我们先准备一个完整的 rootfs 供我们使用，依次执行下面的命令： Mount
我们先来隔离容器的挂载点，让它有自己的系统目录，看起来是在独立的环境中运行：使用如下的命令运行：cargo +nightly run PID
从上面的打印的日志来看，在容器启动的第一个进程PID不是1，因为我们还没有对PID进程隔离，接下来我们隔离PID，做出如下改动，增加 libc::CLONE_NEWPID：再次运行，看到容器中的首进程PID已经变成1了：但是运行 ps失败了，提示我们挂载 proc，proc 是Linux运行中内核的一些信息，我们在容器进程中使用下面的代码进行挂载：再次编译运行，执行ps命令可以看到当前进程中的pid是从1开始的： NET
但是如果这个时候查看网络设备，发现很多宿主机上的设备：这是因为没有为容器隔离网络设备，需要作如下的改动，在启动容器进程的时候，增加 libc::CLONE_NEWNET：再次查看，发现看不到宿主机上的网络设备，只有一个 lo，而且还没启用：这样的话，我们的容器是没法直接跟外部通信的，我们需要给我们新建的容器添加网卡，设置IP，参考单机容器通信网络，我们给我们的容器赋予和外界通信的能力。首先在宿主机上，查看我们容器的PID，根据父进程 pid：13607 进行查看：pstree -a -p 13607在宿主机上执行下面的命令，创建一对 veth 设备：ip link add veth-host type veth peer name ceth-container将 ceth-container 添加到我们的容器中：ip link set ceth-container netns 13609执行下面的命令，启用 veth-host：ip link set veth-host up执行下面的命令给 veth-host 添加IP：ip addr add 172.17.0.11/16 dev veth-host将 veth-host 添加到我们的 docker0 网桥上，这样它和我们通过 docker 创建的容器就可以互通了：ip link set veth-host master docker0所有上面在主机上的操作如下如所示：然后我们在我们的容器中执行下面的命令，启用lo，ceth-container，以及为 ceth-container 设置IP：ip link set lo up
ip link set ceth-container up
ip addr add 172.17.0.12/16 dev ceth-container所有在容器中的操作如下图所示：这个时候，假如我们在宿主机有这样一个通过 docker 启动的容器：然后在我们手动创建的容器中使用ping命令测试连通性，它肯定是联通的： UTS
UTS 命名空间允许单个系统对不同进程显示不同的主机名和域名，在没有设置容器名称的时候，和宿主机名称是一致的，例如上面的docker1，我们在创建我们的容器的时候启用 libc::CLONE_NEWUTS，然后给容器设置自定义的名称，全量代码如下：
完整代码使用如下的命令运行，可以看到的容器名称已经更新成 mycontainer ：cargo +nightly run -- mycontainer User
到目前为止，我们自己创建的容器中的用户名还是 root，还没有和宿主机隔离开，在 clone 容器的时候添加 libc::CLONE_NEWUSER，重新创建容器：cargo +nightly run -- mycontainer在容器内运行id命令以查看当前进程的UID、GID和组时。在新的命名空间中，该进程属于nobody用户，其UID和GID为65534，该用户是系统中的默认用户。当用户ID在命名空间内没有映射时，返回用户ID的系统调用将返回文件/proc/sys/kernel/overflowuid中定义的值。
 unshare
所有上面通过代码做的这些操作，我们可以使用一句 unshare 命令完成：uunshare --mount --net --pid --user --uts --root ./rootfs/ --wd=/home --fork --mount-proc --map-root-user /bin/bash nsenter
可以通过nsenter进入到容器进程的命名空间中去执行命令，这在容器中没有某些工具，而Host上有的时候比较方便。例如，下面k8s集群中的nginx容器，没有ifconfig命令，我们可以进入到他的网络空间在主机上执行而查看它的网络配置：crictl是用于CRI容器运行时的工具，更多的可以看这里。
 参考链接Creating Your Own Containers
Understanding Linux Namespaces
How to Use Linux Network Namespace
Building containers by hand using namespaces: The net namespace
Separation Anxiety: A Tutorial for Isolating Your System with Linux Namespaces
Building a container by hand using namespaces: The mount namespace
容器工作原理简述
Container Runtime in Rust — Part I
How Container Networking Works - Building a Linux Bridge Network From Scratch
Linux setup default gateway with route command
Diving into Linux Namespaces: Understanding User Namespaces in Docker]]></content>
      <categories>
        <category>Docker</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Container</tag>
      </tags>
  </entry>
  <entry>
    <title>设计模式及其示例</title>
    <url>/2024/11/19/Design-Patterns/example-design-patterns/</url>
    <content><![CDATA[设计模式及其示例]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker 磁盘占用空间清理</title>
    <url>/2023/11/22/Docker/reclaim-docker-used-space/</url>
    <content><![CDATA[记录几种用于清理 Docker 磁盘空间占用的几种方式。删除不想要的容器、网络、镜像以及构建缓存等，首先使用如下的命令查看 Docker 空间占用：docker system df如果使用 -v 参数可以查看更具体的每个镜像，容器的占用。使用 docker system prune 命令删除停止状态的容器，未关联容器的网络以及 dangling 镜像，如果使用 -a 参数，还将清除未使用的镜像，-f 表示强制操作:docker system prune -a -f如果仅仅是删除未使用的和dangling 镜像使用：docker image prune -a类似的，下面的两条命令用于清除停止的容器以及未使用的卷：docker container prune
docker volume prune仅删除 dangling 镜像：docker rmi $(docker images -f “dangling=true” -q)如果是删除退出的容器：docker rm -v $(docker ps -aq -f status=exited)清理日志，编辑文件：/etc/docker/daemon.json：vi /etc/docker/daemon.json添加下面这些配置：重启:systemctl daemon-reload systemctl restart dockerk8s 环境的清理，首先驱逐节点：kubectl drain this_node --ignore-daemonsets --delete-local-data停止 kubelet 服务：kubelet stop重启 Docker：service docker restart清理 Docker：docker system prune --all --volumes --force相当于重装 Docker：systemctl stop docker
rm -rf /var/lib/docker
systemctl start docker]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>磁盘清理</tag>
      </tags>
  </entry>
  <entry>
    <title>【Docker】拉取k8s.gcr.io镜像失败</title>
    <url>/2022/04/02/Docker/%E3%80%90Docker%E3%80%91%E6%8B%89%E5%8F%96k8s-gcr-io%E9%95%9C%E5%83%8F%E5%A4%B1%E8%B4%A5/</url>
    <content><![CDATA[在部署k8s的时候，因为某些众所周知的原因，k8s.gcr.io 的镜像会拉取失败，本文示例一种或方式能正常拉取镜像，前提是你能科学上网，示例环境：
ubuntu@vm-docker:~/workdir$ lsb_release -a
No LSB modules are available.
Distributor ID:	Ubuntu
Description:	Ubuntu 21.10
Release:	21.10
Codename:	impish为 docker 服务创建一个内嵌的 systemd 目录：mkdir -p /etc/systemd/system/docker.service.d创建配置文件 /etc/systemd/system/docker.service.d/http-proxy.conf，并且写入以下内容；配置规则请看 https://docs.docker.com/network/proxy/#use-environment-variables：
ubuntu@vm-docker:~/workdir$ cat /etc/systemd/system/docker.service.d/http-proxy.conf
[Service]
Environment=&quot;HTTP_PROXY=http://192.168.3.100:1087&quot;
Environment=&quot;HTTPS_PROXY=http://192.168.3.100:1087&quot;
Environment=&quot;NO_PROXY=localhost,127.0.0.1,https://******.mirror.aliyuncs.com&quot;更新配置并且重启docker：systemctl daemon-reload &amp;&amp; systemctl restart docker验证配置加载成功：
ubuntu@vm-docker:~/workdir$ sudo systemctl show --property=Environment docker
Environment=HTTP_PROXY=http://192.168.3.100:1087 HTTPS_PROXY=http://192.168.3.100:1087 NO_PROXY=localhost,127.0.0.1,https://******.mirror.aliyuncs.com
ubuntu@vm-docker:~/workdir$测试镜像拉取： 参考文章下载k8s.gcr.io仓库的镜像的两个方式]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Protobuf Go 代码生成</title>
    <url>/2023/12/07/Go/generated-protobuf-go-code/</url>
    <content><![CDATA[Protobuf 是 Google 出品的消息编码工具，相比常用的 json 等编码方式，以牺牲可读性，而提高编码效率，减少编码之后消息体占用的字节大小，以提升传输效率。本篇文章主要分享如何生成 Go 语言 pb 版本，对于 Go 语言而言，protoc 不能直接生成 Go 代码，需要额外的插件。对于这个插件，官方有自己的实现，也有第三方的 gogo/protobuf，本节主要是用来厘清他们之间的区别以及用法。在开始之前，我们先澄清一些基本的概念：golang/protobuf 是官方早期的插件实现；
google.golang.org/protobuf 是上面的继承者，有更新和更简化的 API，以及其他许多改进，是官方当前的实现；
gogo/protobuf 社区实现，该实现目前被废弃，但是在历史中依然后很多著名的软件在使用，例如 etcd；
protoc 是 protobuf 的编译器，用于将 .proto 文件编译成各自语言的实现；
protobuf 是一般用于指这门编码语言，该语言目前有两个版本，proto2 和 proto3；关于 protobuf 编码是如何优化编码效率，可以查看这篇文章：Protocol Buffers 编码。 准备工作
在本地创建一个目录 proto，下载 protoc 对应平台的版本到本地目录，然后创建一个 hello.proto 文件，内容如下：目前新创建的 proto 目录内容如下： gogo/protobuf
在生成 gogo/protobuf 代码之前，我们还需要下载 gogo/protobuf 的插件，它实现了多种插件，在生成的代码速度等其他方面有些差别，例如：protoc-gen-gofast，protoc-gen-gogofast，protoc-gen-gogofaster 等，我们以 protoc-gen-gogofaster 为例，本地下载插件直接使用命令：go install github.com/gogo/protobuf/protoc-gen-gogofaster@latest命令执行成功之后，插件会安装在 $GOPATH/bin 目录下，确保该目录在系统的 $PATH 目录中。安装成功之后，我们执行以下命令来生成 pb 代码：./protoc/bin/protoc --gogofaster_out=./ hello.proto注意 protoc 引用插件的方式，不包含前缀 protoc-gen-。该命令执行成功之后，会在和 hello.proto 命令同级目录下生成 hello.pb.go 文件。在生成的代码中，可以看到引入的 Post.details 字段引入和的 Any 类型引用到了 google 的实现：虽然应该是这样的，用谁的 proto 定义就用谁的代码实现，但是对应的我们就得引入 google.golang.org/protobuf 这个包了。如果想处理这个问题，我们可以通过设置如下的参数解决，给 gogofaster 插件传递参数以 , 进行分割，以 : 结束：./protoc/bin/protoc --gogofaster_out=Mgoogle/protobuf/any.proto=github.com/gogo/protobuf/types:./ hello.proto这样在生成代码时，google/protobuf/any.proto 就会使用 github.com/gogo/protobuf/types 这个导入路径，指定 proto 文件的导入路径参数规则是：M$&#123;PROTO_FILE&#125;=$&#123;GO_IMPORT_PATH&#125;。如下是新生成的代码：上面生成的 pb 代码都是在当前目录下，包名都是 hello。有时候我们想指定新的包名，例如：example.com/hello/proto/types，这种该如何处理呢？proto 的 package 声明的包名和 Go 语言不能很好的兼容，protobuf 对于语言的差别提供了自定义选项，对于 Go 是通过 option go_package = &quot;example.com/hello/proto/types&quot;; 这样的语法声明，如下新增包名声明：我们再来生成代码，发现生成的代码位于 ./example.com/hello/proto/types/hello.pb.go，包名也变成了 types：默认情况下，这会自动创建一系列的目录，如果将输出目录指定为 $GOPATH/src 应该是默认模式最好的选择。如果我们只想生成一个简单源码文件，和 *.proto 放一起，只是想改变包名而已，就得指定 paths=source_relative 这个参数了，如下所示：./protoc/bin/protoc --gogofaster_out=Mgoogle/protobuf/any.proto=github.com/gogo/protobuf/types,paths=source_relative:./ hello.proto这个时候生成的文件和 hello.proto 在相同的位置，这种结果可能是我们大多情况下想要的。
如果要生成 grpc 代码，执行下面的命令，启用 grpc 插件，plugins=grpc：./protoc/bin/protoc --gogofaster_out=plugins=grpc,Mgoogle/protobuf/any.proto=github.com/gogo/protobuf/types,paths=source_relative:./ hello.proto google/protobuf
官方的说明文档详见：https://protobuf.dev/reference/go/go-generated/。
同样在编译我们的 proto 代码之前，得下载对应的插件：go install google.golang.org/protobuf/cmd/protoc-gen-go@latest同样插件会自动安装 $GOPATH/bin 目录下，如果没有设置 $GOPATH，默认是：$&#123;HOME&#125;/go。执行下面的命令生成 pb 代码：./protoc/bin/protoc --go_out=. hello.proto官方之间指定参数得使用 --go_opt，例如指定 pb 文件的输出位置是相对于 .proto 源文件：./protoc/bin/protoc --go_out=. --go_opt=paths=source_relative  hello.proto或者指定 proto 文件的导入路径：./protoc/bin/protoc --go_out=. --go_opt=paths=source_relative  --go_opt=Mgoogle/protobuf/any.proto=github.com/gogo/protobuf/types  hello.proto可以通过多个 --go_opt 传递参数。
如果指定了 module=$PREFIX 参数，则输出文件将放置在以 Go 包的导入路径命名的目录中，但会从输出文件名中删除指定的目录前缀。例如，输入文件 protos/buzz.proto 的 Go 导入路径为 example.com/project/protos/fizz 且指定为模块前缀 example.com/project 会生成位于 protos/fizz/buzz.pb 的输出文件。在模块路径之外生成任何 Go 包都会导致错误，此模式对于将生成的文件直接输出到 Go 模块非常有用。
例如，对于我们的 hello.proto（加了 option go_package = &quot;example.com/hello/proto/types&quot;;），执行下面的编译命令：./protoc/bin/protoc --go_out=. --go_opt=module=example.com/hello/proto  hello.proto这会生成 types/hello.pb.go 文件，该参数和 --go_opt=paths=source_relative 冲突，不能一起使用。
如果想要生成 grpc 代码，得先下载grpc 插件：go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@latest然后执行如下命令生成：./protoc/bin/protoc --go_out=. --go_opt=paths=source_relative --go-grpc_out=. --go-grpc_opt=paths=source_relative hello.proto将会输出 hello.pb.go 和  hello_grpc.pb.go 两个文件。
]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>protobuf</tag>
        <tag>gogoprotobuf</tag>
      </tags>
  </entry>
  <entry>
    <title>【Golang】Interface 底层实现（未完）</title>
    <url>/2022/06/03/Go/interface-undeylying-implement/</url>
    <content><![CDATA[接口是高级语言中的一个规约，是一组方法签名的集合。Go 的 Interface 是非侵入式的，具体类型实现 Interface 不需要在语法上显式的声明，只需要具体类型的方法集合是 Interface 方法集合的超集，就表示该类实现了这一 Interface。编译器在编译时会进行 Interface 校验，Interface 和具体类型不同，它不能实现具体逻辑，也不能定义字段。
在 Go 语言中，Interface 和函数一样，都是第一公民，Interface 可以用在任何使用变量的地方。可以作为结构体内的字段，可以作为函数的形参和返回值，可以作为其他 Interface 定义的内嵌字段。Interface 在大型项目中常常用来解耦，在层与层之间用 Interface 进行抽象和解耦，使得抽象出来的代码特别简洁，这也符合 Go 语言设计之初的哲学。
先看一个易错的例子：这将输出：
true
falseInterface 实际上包含两部分，类型和值。对于 x 而言，它的类型和值都是 nil，所以 x == nil 是 true；对于 y，它的类型是 *int，值是 nil，所以 y == nil 是 false。因此，我们在看 Interface 的时候，需要关注类型和值两部分。 底层实现
Go 语言中描述接口底层结构体的是 iface 和 eface 这两个结构体，其中 iface 表示非空结构体，eface 表示空结构体：代表 tab 字段的 *itab 代表接口的类型和赋给这个接口的实体类型；字段 data 则指向接口具体的值，一般是一个指向堆内存的指针。如上所述，itab 中有 5 个字段：inter：描述了接口的类型，它包装了 _type；还有一个表示接口定义的方法列表的的 mhdr 字段，以及 pkgpath 记录定义了接口的包名；_type：指得是赋给接口的变量的类型；hash：等同于 _type 中的 hash 字段，用于类型转换；fun： 保存一个函数指针，它指向的是具体类型的函数方法。虽然这里只有一个函数指针，但是它可以调用很多方法。在这个指针对应内存地址的后面依次存储了多个方法，利用指针偏移便可以找到它们；由于 Go 语言是强类型语言，编译时对每个变量的类型信息做强校验，所以每个类型的元信息要用一个结构体描述。再者 Go 的反射也是基于类型的元信息实现的，_type 就是所有类型最原始的元信息。str 和 ptrToThis，对应的类型是 nameoff 和 typeOff，这两个字段的值是在链接器段合并和符号重定向的时候赋值的。运行时类型名称和具体类型值由 runtime.resolveNameOff 和 runtime.resolveTypeOff 函数计算出来的。
其他的类型，如数组，channel 以及 map 在运行时也是基于 _type 这个元信息表示，它们除了表示类型表自身，还需要表示它的元素的类型，例如：相比起 iface，eface 就简单多了，它只需一个 _type 字段表示存储的具体值的类型和用于存储实际值的 data。
 参考文章深入研究 Go interface 底层实现
Interface types]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title>【Golang】谈谈 map 是怎么实现的</title>
    <url>/2022/05/22/Go/map-undeylying-implement/</url>
    <content><![CDATA[map 的目的是设计一种数据结构来维护一个集合的数据，并且能够对集合进行增删改查，实现 map 主要有两种数据结构：HashTable 和 搜索树。
HashTable 会用一个 hash 函数将将 key 分配到不同的 bucket 中，因此，开销主要在 hash 函数计算 key 哈希值上，大多时候，HashTable 的性能还是很高的。不过 HashTable 一般会存在碰撞，或者说冲突的问题，就是不同的 key 被映射到了同一个 bucket，对于这个问题，一般由两种应对方法，链表法和开放寻址法：链表法是将一个 bucket 实现成一个链表，落在同一个 bucket 中的 key 都会插入这个链表；
开放寻址法是在发生冲突时，根据一定的规律，在 bucket 后面选择一个空位用来放置新的 key；搜索树一般会采用自平衡搜索树实现，包括：AVL 树，红黑树或者 B-Tree，搜索实现中的查找效率是 O(logN)，而 HashTable 平均查找效率是 O(1)，hash 函数如果设计良好，不会出现 hash 碰撞的情况。两者不同的，搜索树可以实现按照 key 的顺序遍历，而 HashTable 的顺序是随机的。
有的语言中用两种不同的数据结构实现了 map，就像 Rust 中的 std::collections::BTreeMap 和 std::collections::HashMap。
Go 语言中采用了 HashTable 的方式来实现 map，并且使用链表法解决哈希冲突，本文基于 go1.18 darwin/arm64。 底层结构
底层的数据结构在 src/runtime/map.go 中，其中 hmap 是 hashmap 的缩写：buckets 是一个指向 bmap 数组的指针，bmap 的结构体如下所示：但是在编译时，编译器会重建这个结构体，bmap会被重建成：bmap 就是常说的桶，桶里面最多会装 8 个 KV 对，这些 key 之所以会落入同一个桶，是因为它们经哈希计算之后，得到的哈希值的后 B 个 bit 位是相同的（后面再讨论 bucket 的定位过程），这用来决定将 key 放在哪一个桶中。而在桶内，又会根据哈希值的前 8 位来决定 key 放在哪个具体位置上，hmap 整体如下图所示：当 map 的 key 和 elem 都不包含指针，并且 size 都小于 128 字节的情况下，会把 bmap 标记为不包含指针，这样可以避免 GC 扫描整个 hmap，以提升效率。但是 bmap 因为有一个 overflow 字段，是指针类型的，破坏了 bmap 不包含指针的设计。这个时候会把 overflow 移动到 extra 字段中去，启用 overflow 和 oldoverflow 字段。bmap 是真正存放 kv 的地方，它的内存模型如下图所示：可以看到的 key 和 elem 不是存放在一起的，这样做的好处是在某些情况下可以省略调 pad 字段节省空间。例如，对于 map[int64]int8 这样的 map，如果按照 key/elem/key/elem 这样的形式组织，那么在每个 key/elem 之后都需要 padding 7 个字节（为了防止伪共享），而使用 key/elem/key/elem 只需要在最后添加 padding。
每个 bucket 设计成最多只能存放 8 个 kv 对，如果超过，那就需要构建一个 bucket，并且通过 overflow 指针连接起来，这就是所谓的链表法。
 创建过程
创建 map 有以下几种方式：通过查看汇编代码，我们可以看到创建 map 实际调用的函数是 runtime.makemap。而在 runtime.makeBucketArray 中：当桶的数量小于 242^424 时，由于数据较少，创建溢出桶的可能性较低，会省略部分创建过程，以减少开销；
当桶的数量大于 242^424 时，会额外创建一些溢出桶；这个时候看到的正常桶和溢出桶应该如下图所示，它们是连接在一起的： 哈希函数
hmap 是否高效很大一部分取决于哈希函数的选择，即要快，也要冲突少。在程序启动的时候，Go 会检测 CPU 是否支持 AES，如果支持则会使用 AES 哈希，通过硬件加速提高效率，这部分实现是在 runtime.alginit 中：而它是在调度初始化过程中被调用的，在 runtime.schedinit 中，判断 CPU 是否支持 AES，然后设置标志位并且生产必须的随机数。每个 map 类型都由下面的结构体表示：其中的 hasher 就是用于计算哈希值的函数，对于 map[string]int，它对应的函数就是 runtime.strhash它是使用汇编语言实现的，内容如下：如果支持 AES 就会调用硬件计算哈希，如 aeshashbody 中实现所示，如果不支持，就调用 runtime.strhashFallback，在内存中计算哈希值： 查找过程
对于 map 访问，Go 中有两种方式，一种是返回一个值，另一种是除了返回值之外还会返回一个 bool 值表示这个值是否存在，因为访问 map 时，如果不存在就会返回零值：Go 中为这两种方式提供了两种不同的函数，例如我们这里的 runtime.mapaccess1_faststr 和 runtime.mapaccess2_faststr，我们来看下 mapaccess2_faststr 的实现：代码整体上比较简单，一共分了两种情况，只有 1 个桶时直接比较便利当前桶，通过比 较key 是否相等寻找，否则计算 key 的哈希值，找到对应的桶，然后遍历，这个通过计算key的哈希值再定位 key 的过程可以用如下的图所示：里面有几个重要的过程，我们再分析下，首先是 key 和 value 的定位公式：既然是拉链法实现，那么就肯定得遍历 bucket 链，外层循环就是遍历所有链上的 bucket，内层循环就是遍历每个 bucket 的 8 个 key，调用 b.overflow(t) 可以获取到下一个 bucket。根据 bmap 运行时实际的内存表示，它的最后一个字节存储的下一个 bucket 的地址：访问过程中，map 可能正在扩容，那么就首先得去查看旧的 bucekt 是否已经搬迁，如果没有，那就得从旧的 bucket 中查找，使用 evacuated 判断是否搬迁，如果第一个 tophash 的值大于 emptyOne 小于 minTopHash，说明已经搬到新 map 中了：一个 bucket 的状态也是存储在它的 tophash 中的，当它取值以下的值时，表示特殊的意义：所以说，只要 b.tophash[0] 是 evacuatedX，evacuatedY 或者 evacuatedEmpty，都说明此 bucket 已经搬迁了。
 赋值过程
通过获取汇编代码我们可以知道，map 赋值过程是通过一系列的 mapassign 函数完成，根据 key 类型的不同的，在编译的时候会生成不同函数调用：key类型
函数uint64
func mapassign_fast64(t *maptype, h *hmap, key uint64) unsafe.Pointeruin32
func mapassign_fast32(t *maptype, h *hmap, key uint32) unsafe.Pointerstring
func mapassign_faststr(t *maptype, h *hmap, s string) unsafe.Pointer通用
func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer我们来看个示例：
示例代码使用通用的 runtime.mapassign 函数进行赋值：从上面的函数中可以看到下面这些信息：对值为 nil 的 map 会引发 panic；
map 不支持并发读写，并发读写会引发 panic；
map 的扩容涉及到数据搬迁，为了避免在数据搬迁过程中引起 CPU 陡增，Go 将数据搬迁平摊到了每次操作中；
key 和 elem 对应内存位置的定位公式和前一节讲的是相同的；
因为 map 的操作可能是更新，也有可能是新插入，所以在遍历 bucket 及其 overflow bucket 的过程中会将第一个遇到的空闲位置记录下来，分别保存在 inserti，insertk 以及 elem 中。 如果 key 已经存在，那么直接跳转到末尾位置将 elem 的内存地址返回；
如果不存在就新插入一个，但是如果发现当前 map 的负载系数超过 6.5并且还没有扩容，那就开始扩容，扩容之后，key 要存放的位置就会变化，所以要从查找 bucket 的过程重新开始；
如果新插入的时候，发现 key 对应的 bucket 及其 overflow bucket 中都没有空闲位置了，那就重新申请一个 overflow bucket 链接在 bucket 后面，并且更新 inserti，insertk 以及 elem 为新的溢出桶的第一个槽位；
接下来就是将 key 放到对应的内存位置，如果是新插入则更新计数并且返回存放 elem 的内存地址；除了上述这些信息之外，我们还有一些小函数应该将它的原理搞清楚。runtime.(*maptype).indirectkey：间接 key 就是 bucket 中对应存放 key 的位置存的不是 key 对应的值本身，而是指向 key 的地址，每个 map 在编译时都有对应的 maptype，由编译器来决定。另外 runtime.(*maptype).needkeyupdate 决定在更新键值对的时候要不要重新覆盖 key：runtime.(*hmap).newoverflow 用于创建溢出桶，首先会从预先创建的溢出桶中获取一个，如果没有就使用 newobject 新创建一个：runtime.(*hmap).growing 用于判断当前 map 是否在扩容过程中：runtime.overLoadFactor 判断当前的 map 是否过载，其实就是当 map 中元素的总量超过 6.5 * (1 &lt;&lt; h.B)，即每个桶平均存放超过 6.5 个 key 时：runtime.tooManyOverflowBuckets 用于判断是否有太多溢出桶，当 h.B &lt; 15 时溢出桶最多可以有 2^B 个，当 h.B &gt;= 15 时溢出桶最多是 2152^{15}215 个：当 map 变得过大，装载太多元素，或者有太多的的溢出桶时就会扩容，调用 runtime.hashGrow 函数进行：如果已经达到装载系数，那么桶数量就增大一倍；
否则进行等量扩容，等量扩容是由于删除操作让 bucket 及其溢出桶变得比较稀疏，重新进行规整；这里只是扩充容量，申请内存，但实际并未进行数据搬迁，数据搬迁是在每次的删除或者赋值过程中进行的。这里还有几个二进制操作，&amp;^ 叫做按位置 0 运算符。例如，对于如下示例，如果 y 对应 bit 位为 1，那么 z 对应 bit 位为 0，否则 z 对应 bit 位为和 x 保持一致：所以下面的操作：将清除 h.flags 中的 hashWriting 标记；
或者将 h.flags 中的 iterator 和 oldIterator 清零；我们在这里可以找到 map 的4个标志位： 扩容过程
使用哈希表的目的就是能快速找到 key，但是随着像 map 中添加越来越多的 key，发生 key 碰撞的概率就会越来越大。当 bucket 中的 8 个 cell 都被塞满，增删改查的效率就会很低，理想的情况是每个 bucket 中存储一个 key，这样就能达到 O(1) 的查找速率，但是这样会消耗大量的内存。
从前面的示例中可以看出，Go 中每个 bucket 实际上可以装载 8 个 key，查找 key 就包含查找包含 key 的 bucket 和查找具体的槽位两个过程，这实际上又是使用时间换空间。
但是，如果当所有的 key 都落到同一个 bucket 中，那么 map 相当于退化成链表了，查找的复杂度就成 O(n) 了，因为包含的元素太多导致了查找效率降低。
另外一种情况就是，当 map 在大量插入又大量删除之后，bucket 就变得很稀疏，可能 bucket 链上挂了很多溢出桶，但其实这个 bucket 链上没存储几个元素，这也会导致查找效率降低。
针对这两种情况，Go 有两种扩容的方式，即我们上面看到的：对于第一个条件，Go 语言中使用装载因子来衡量是否需要扩容，计算公式为：loadFactor := count / (2^B)，当 loadFactor &gt;= 6.5 时，表明很多 bucket 都快要装满了，所以扩容是有必要的；对于第二个条件，就是由于大量的删除操作使得 bucket 变得很稀疏，查找效率降低，根据溢出桶的数量进行判断，当 h.B &lt; 15 时，如果溢出桶的数量大于 2^B；或者当 h.B &gt;= 15，溢出桶的数量大于等于 2^15 就进行扩容，这种场景下的扩容方式叫做等量扩容，就是说 bucket 的总数没有增加，相当于一个碎片整理；触发扩容的时机已经在赋值过程中讲解过了，我们继续分析分摊到每个赋值和删除过程中的数据迁移，这部分代码在 runtime.growWork 中：growWork 中的 bucekt 是正要删除或者更新的 key 在新的 map 中对应的桶编号，举个例子：假设旧的 h.B = 2，进行增量扩容之后 h.B = 3，那么旧 map 和新 map 的bucketMsask(桶掩码)就是 3(0b11) 和 7(0b111)，它们等于 2^B - 1；假设正要操作的 key 对应的 hash 值后 3 个 bit 位为 110，那么它在旧 map 中对应的桶编号为 110 &amp; 0b11 = 2，在新桶中的编号为 110 &amp; 0b111 = 6；bucket&amp;h.oldbucketmask() = 6 &amp; 3 = 2，对应于 key 在旧桶中的编号；下面我们来看看搬迁的具体过程，在 runtime.evacuate 中实现：搬迁的目的就是将老的 bucket 搬迁到了新 bucket。对于等量扩容，由于 bucket 数量不变，所以可以按照喜好进行搬迁，就是 key 原来在 0 号 bucket，那么搬迁到新 bucket 之后依然是 0 号 bucket。
对于增量扩容，每次 bucekt 的数量会增加为原来的 2 倍，所以要重新计算 key 的哈希值，才能决定它到底落入哪个桶。例如，h.oldB = 5，可以由 key 哈希值的低 5 位决定它落入哪个桶，现在 h.newB = 6，需要哈希值的后 6 位才能决定它落入新 map 的哪个桶。从扩容的过程中我们看到了一种特殊的数据类型 math.NaN，这种类型作 key 时，不可能通过正常的 key 查找找到它，因为它的哈希值不稳定，每次计算都得到不同的哈希值，没法对它进行定位，只能通过遍历访问它们。所以也可以在 map 中插入任意数量的 math.NaN。遇到这种类型的 key，通过 tophash 的最低位决定把它放到 xPart 还是 yPart（增量扩容），0 就放到 xPart，否则就是 yPart。
我们在前面说过，等量扩容类似于碎片整理，能提高查找效率，用一个图来展示这种效果，假设 h.B = 2，由于溢出桶太多，触发了等量扩容。扩容之前可能有如下的状态：等量扩容之后，bucket 的数量没变，溢出桶的数量会减少，原先分散的 key 会被整合到一起，提高查询效率：对于增量扩容，可能会涉及到 key 映射到新 map 中的其他 bucket，我们假设 h.oldB = 2，那么扩容之后 h.newB = 3。假设在扩容之前，我们有下面场景，key1 和 key2 都在旧 map 中的 1 号桶：在扩容搬迁之后，这些 key1 依然会在新 map 的 1 号桶，key2 会被移动动 5 号桶： 删除过程
和赋值一样，删除也有一些快速函数：key类型
函数uint64
func mapdelete_fast64(t *maptype, h *hmap, key uint64)uin32
func mapdelete_fast32(t *maptype, h *hmap, key uint32)string
func mapdelete_faststr(t *maptype, h *hmap, ky string)通用
func mapdelete(t *maptype, h *hmap, key unsafe.Pointer)我们来看看通用的 mapdelete 的过程： 遍历过程
直接用脑袋想 map 的遍历过程可能很简单，遍历所有的 bucket 及其溢出桶中所有 cell 即可，但是大多数情况下，map 处于扩容过程中，每次赋值和删除操作只能迁移两个 bucket，所以，map 遍历过程实际上涉及到新老 bucket 的遍历，这是问题所在。我们来看个示例：通过汇编指令得知，map 遍历首先会调用 runtime.mapiterinit 初始化 runtime.hiter 结构体，然后调用 runtime.mapiternext 获取下一个 kv。
首先来看下 hiter 这个结构体：首先看下 runtime.mapiterinit 的过程：从上面的代中可以解释为什么 map 的遍历是无序的，每次遍历的起始 bucket 和 cell 编号都是随机的。我们再来看看 runtime.mapiternext 的实现过程：我们来看一个示例，假设 h.oldB = 1，扩容之后 h.newB = 2，原先 oldBuckets 中 0 号桶需要搬迁到 buckets 中的 0 号和 2 号桶，但是还没有搬迁；原先 oldBuckets 中 1 号桶需要搬迁到 buckets 中的 1 号和 3 号桶，目前已经搬迁结束，重新哈希之后，key1 落到了 buckets 中的 1 号桶，key2，key3 和 key4 落到了 buckets 中的 3 号桶。如下图所示：假设经过初始化之后，it.startBucket = 3，it.offset = 2，也就是会从上面 buckets 的 3 号桶的第 3 个 cell 开始遍历，遍历完 3 号桶及其溢出桶的 8 个 cell 之后，依次得到了 key3，key2 和 key4 这三个键。
然后从 bucekts 的 0 号桶开始，发现 0 号桶还没有搬迁，那么就从 oldbuckets 中的 0 号找到那些将要搬迁到 buckets 中 0 号桶的键，即 key5。
0 号桶遍历结束之后，接着遍历 buckets 的 1 号桶，找到了 key1；
在遍历 buckets 的 2 号桶时，发现它应该从 oldbuckets 的 0 号桶迁移过来，目前 oldbuckets 的 0 号桶还没有迁移结束，那就从oldbuckets 的 0 号桶中找到要搬迁到 buckets 中 2 号桶的 key6；
至此遍历结束，依次得到了 key3，key2，key4，key5，key1，key6。
 为何遍历map是无序的 ?
这个获取是为了避免误解吧，因为 map 扩容之后，同一个 bucket 中的 key 要么保留在当前 bucket 中，要么转移到其他 bucket。如果按顺序遍历 bucket，按顺序遍历 cell ，在扩容之后这个顺序就无法避免了，所以干脆就让它保持这种无序，因此在遍历的时候引入随机数，每次都随机选择某个桶的某个 cell 开始。
 浮点数是否可以作为键?
从语法上看，Go 语言中除了 slice，map，function 这几种不支持比较的类型之外都可以作为map 的键，具体包括：布尔值，数字，字符串，指针，通道，接口类型，结构体，以及只包含这些类型的数组。这些类型的共同特征是支持 == 和 != 运算符，当 k1 == k2 时，它们可以被认为是同一个 key，如果是结构体，只有哈希后的值相等即字面值相等，才被认为是相同的 key。
来看一个浮点数做 key 的示例：代码编译运行输出：
numbers length: 4
key: NaN, value: 0
key: 2.400000000001, value: 0
key: 2.4, value: 1
false说明浮点数可以作为 key，但是由于浮点数精度的问题会出现一些意想不到的问题。例如，NaN 是一个合法的浮点数，但是 NaN != NaN，虽然 NaN 返回的是一个固定值：但是在计算浮点数哈希值的时候做了一些额外的处理，NaN 的哈希值计算引入了额外的随机数，导致每次使用runtime.f64hash计算 NaN 的哈希值都会得到不同的结果，所以可以往浮点数做键的 map 中插入任意数量的 NaN：而对于 2.40000000000000000000000000001，浮点数在作为键的时候，会使用 math.Float64bits 将其转换为 uint64 再插入：这将输出：
4612586738352862003
4612586738352864255
4612586738352862003所以说浮点数是有精度限制的，具体看 IEEE 754，在做比较以及作为键值的时候要慎用。
 map 是否是协程安全的？
显然不是，在读、写、删除以及遍历的时候都会检测是否存在 goroutine 在写 map，如果有直接 panic。
如果要使用协程安全的 map，建议使用 sync.Map。
 map 遍历时可以删除吗？
map 不是一个线程安全的结构，如果同时有多个 goroutine 读写、遍历或者删除 key 可能会引发 panic，但是在同一个 goroutine 中是可以这样做的，因为每次删除 key 之后，会将写 map 的标记位清除掉，而且每次只在迭代 mapiternext 的开始检测是否存在其他 goroutine 写 map。但是如果遍历时删除了尚未访问的 key，那么就不能再遍历到了。
 map 元素是否可以取地址？
当然不能，因为扩容之后存储 key 的地址就会发生变化，我们获取 map 元素地址的代码也是不能编译的。 map 使用注意事项相同的功能如果可以使用 slice 就不要用 map，因为 map 的 key 查找涉及到哈希值计算，bucket 和 key 的寻址等，而 slice 只是指针的移动。使用一个简单的例子来标间二者的性能差距：测试数据如下：
 BenchmarkAccessSlicePersons
 BenchmarkAccessSlicePersons-10    	1000000000	         0.0003243 ns/op
 BenchmarkAccessMapPersons
 BenchmarkAccessMapPersons-10      	1000000000	         0.04320 ns/op]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>map</tag>
      </tags>
  </entry>
  <entry>
    <title>【Golang】谈谈 slice 的实现</title>
    <url>/2022/05/15/Go/slice-implement/</url>
    <content><![CDATA[slice 是 Go 里面最常用的数据结构之一，相比起长度固定的数组，slice 使用起来更加灵活，它可以动态扩容，可以从其他 slice 或者数组创建。不过 slice 的底层依然是一个固定长度的数组，也就是一片连续内存，当插入新的元素时，如果当前容量不够，就需要扩容，申请一片足够大的内存，并将原有的内容的复制进去。
接下来的测试使用的 Go 版本都是：go version go1.18 darwin/arm64。
创建一个 slice，我们有下面几种方法（Go 官方文档中也有详细的说明）：这将输出：
[1 2 3 4] 4 4
[0 0 0 0 0 0 0 0 0 0] 10 10
[2 3 4 5 6 7] 6 8
[3 4 5] 3 6
[2 3] 2 8 底层实现
slice 在运行时被表示为 reflect.SliceHeader，其中的 Len 和 Cap 分别对应长度和容量，Data 是指向底层数组的指针：可以从底层的数组同时创建多个切片，那么只要修改这些切片的中的一个就会影响到其他的，append 超过底层数组的容量还会创建更大容量的新数组，我们来看一个例子。
 第一步这将输出：
[0 1 2 3 4 5 6 7 8 9] 10 10
[2 3 4] 3 8
[4 5 6 7] 4 5这时候我们来看 numbers，num1 和 num2 之间的关系，都是基于底层相同的数组创建： 第二步
如果这个时候我们更新 num2[0]，并且再 num2 后面再追加一个元素，按道理应该会同时影响到 numbers 和 num1：这将输出：
[0 1 2 3 99 5 6 7 100 9] 10 10
[2 3 99 5 6 7 100 9] 3 8
[99 5 6 7 100] 5 5我们再来看 numbers，num1 和 num2 的状态：num2[0] 的修改影响到了 numbers[4] 和 num1[2]，而 append(num2, 0) 也会影响到底层的数数组。
 第三步
如果我们再往 num2 后面追加，这会超过 num2 的容量，理论上需要创建新的底层数组，但是这不会再影响 num1 和 numbers 了：这将输出：
true
true
true
true
[0 1 2 3 99 5 6 7 100 9] 10 10
[2 3 99 5 6 7 100 9] 3 8
[88 5 6 7 100 100] 6 10我们再来看 numbers，num1 和 num2 的状态，num2 已经有了自己的底层数组，和 number 以及 num1 完全没有关系了： 作为函数参数
slice 当然可以做为函数参数传递，而且 slice 运行时就是表示为 reflect.SliceHeader，所以在将 slice 作为参数传递时，就姑且把它当成 reflect.SliceHeader 的一个值。只要通过这个值修改了底层的数组，自然而然是可以反映到外层的切片中去的，例如：这将输出：
[9 9 9 9 9]
[1 9 9 9 9]在 updateNumbers 中为 num[0] 赋值，会修改底层数组，所以会影响到 main 函数中的 numbers。那么我们再来看看在函数中为 slice 追加值又会如何，看下面的例子：这将输出：
[] [1 0]
[] [2 0]
[2] [2 0]这说明 appendNumbers 确实修改了底层的数组，但并未影响 numbers 的表现，因为它的长度是 0，所以，我们可以把传入 appendNumbers 的 num 看做是 numbers 的一个切片，即 num = numbers[:]，numbers 看不到只是因为它的长度不够，不允许而已，底层的数组已经改变了，只要我们改变它的长度，就可以读到相应的数据了。
但是这种修改不见得每一次都能对 main 中的 numbers 产生影响，我们再来看个例子：这将输出：
[] []都是空的，没问题，因为这次传入 appendNumbers 的切片在 append 的时候发生了扩容，两者的底层数组已经不同了，不会相互影响了。所以我们如果想将修改传递到 main 函数中，可以将 appendNumbers 中的 num 返回，重新赋值给 numbers：不过这种方式显得有点不是那么优雅，我们可以通过传递 slice 指针的方式，让对 appendNumbers 中的修改，追加都能体现在 main 的 numbers 上：这将输出：
[0]
[99 888]总的来说，就是当两个切片引用相同的底层数组时，修改是相互影响的，只是有的因为长度不够看不到而已，但数据确实修改了。另外给函数传递 slice 值作为参数，可以看做是实参的一个相同长度相同容量的切片，传递指针时，可以看做是传递实参自身。
 扩容过程
如果 slice 底层的数组满了，就需要扩容，那么扩容的策略又是什么呢？请看下面的例子：这将输出（不同的Go版本输出可能会有不同，底层的 slice 扩容策略可能随着版本修改）：
after insert    0, capacity becomes    1
after insert    1, capacity becomes    2
after insert    2, capacity becomes    4
after insert    4, capacity becomes    8
after insert    8, capacity becomes   16
after insert   16, capacity becomes   32
after insert   32, capacity becomes   64
after insert   64, capacity becomes  128
after insert  128, capacity becomes  256
after insert  256, capacity becomes  512
after insert  512, capacity becomes  848
after insert  848, capacity becomes 1280
after insert 1280, capacity becomes 1792
after insert 1792, capacity becomes 2560可以看到在容量小于 1024 时，成倍增长，在 1024 之后，增速放缓，开始是 1.25 倍，可以通过执行下面的命令找到 slice 扩容的处理逻辑：这部分的逻辑是在 runtime/slice.go 中，该函数有两部分重要逻辑：这第一部分的完事之后，我们再来看第二部分，编译器会对于一些特殊的类型，做一些优化。例如，我们这里的 et.size 等于 goarch.PtrSize，也就是一个指针大小，即 64 为系统下是 8，示例的中切片元素类型 int 的大小也是 8：经过第二部分的优化，最终的 newcap 也和我们输出中的结果对应，也就是开始容量小于 256 时成倍增长，后面则降低了增长速度，并且还会一些特殊大小的类型做些优化。
 参考链接https://ueokande.github.io/go-slice-tricks/]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>slice</tag>
      </tags>
  </entry>
  <entry>
    <title>【Golang】Application Binary Interface</title>
    <url>/2022/03/24/Go/%E3%80%90Golang%E3%80%91Application-Binary-Interface/</url>
    <content><![CDATA[ABI（Application Binary Interface），即应用程序二进制接口，定义了函数调用时参数和返回值如何传递。就像C语言 x86-64 系统中，返回值保存在寄存器 %rax 中，前6个参数分别通过寄存器 %rdi，%rsi，%rdx，%rcx，%r8 以及 %r9 传递。
但是 Go 语言使用了一套跨架构通用 ABI 设计，它定义了数据在内存上的布局和函数之间的调用规约，这个调用规约是不稳定的，是会随着 Go 的版本进行变换的，称之为 ABIInternal。如果我们想开发汇编代码，应该使用稳定的 ABI0。所有原代码中定义的 Go 函数都遵循 ABIInternal，两种调用规约下的函数可以通过透明的 wrapper 相互调用。
之所以有两套调用规约，并且一个是稳定的（ABI0，承诺向后兼容），一个是不稳定的（ABIInternal，不承诺向后兼容）是因为一开始Go的调用规约约定所有的参数和返回值都通过栈传递，并且很多Go内部的包中有很多基于这个机制编写的汇编代码，例如 math/big，如果现在想升级调用规约，那么这么多汇编代码都得重写，显然不是很现实。所以，比较好的办法是引入一种新的私有约定，不承诺向后兼容，但可以在多个调用规约之间透明互调。私有的调用规约用于Go代码最终汇编的生成，稳定的调用规约用于汇编代码开发，由编译器完成两者之间的自动互调用。更多的内容可以查看 Proposal: Create an undefined internal calling convention。
Go1.17 Release Notes Compiler 就对原有的调用规约做了更新，从基于栈的参数传递更新成基于寄存器，基准测试发现，性能有 5% 的提升，二进制大小减少 2%，但是 Go1.17 只在 Amd64 平台上实现了。
Go1.18 Release Notes Compiler 开始支持 GOARCH=arm64，OARCH=ppc64, ppc64le。在 64 位 ARM 和 64 位 PowerPC 系统上，基准测试显示性能提升 10% 或更多。
也就是说，在Go的调用规约中，我们需要遵循以下这些点：如果想写汇编代码，那么可以基于 ABI0，通过栈传递参数，汇编中使用 FP 等伪寄存器传递和访问参数以及返回值；
ABI0 是当前的调用约定，它在堆栈上传递参数和结果，在调用时破坏所有寄存器，并且有一些平台相关的固定寄存器；
ABIInternal 不稳定，可能会随版本变化。最初的时候它是与 ABI0 相同的，但 ABIInternal 为扩展提供了更多的可能性；为了测试Go不同版本的调用规约，我们使用下面的示例代码：测试机的系统信息如下：Linux ecs-335906 4.18.0-348.7.1.el8_5.x86_64 #1 SMP Wed Dec 22 13:25:12 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux使用下面的指令获取Go的汇编代码：go tool compile -S -l abi.go go version go1.17.8 linux/amd64
从下面的汇编代码中可以看出，Go1.17 中，前9个参数是通过寄存器传递的分别是 AX，BX，CX，DI，SI，R8，R9，R10以及R11，从第10个开始在栈上传递；返回值的传递使用相同的规则。当调用函数 add 时，此时的栈结构如下图所示: go version go1.16.15 linux/amd64
可以很明显的看出这个版本中指令较多，参数传递都是通过栈来传递，需要计算的时候再复制到寄存器中进行运算。栈结构如下图所示： ABIInternal 调用 ABI0 函数
假设我们有下面的Go程序，并且使用汇编实现函数p和函数q，并且采用栈传参的调用规约 ABI0，但是我们使用 Go 1.17 版本编译改代码，发现编译器会自动生成Wrapper函数。
编译方法，把 main.go 和 asm.s 保存在 msa 目录中，放在 GOPATH 目录下，使用下面的指令编译：go version go1.17.8 linux/amd64
go build -o testmsa -gcflags=“-S -l” msa生成的wrapper函数main.goasm.sGo编译器生成了新的函数 p 和 q，分别调用我们汇编中的函数，这样就有两个同名的函数，所以使用了 DUPOK 这个标记，允许存在多个同名函数，ABIWRAPPER 表明这只是一个 ABI 包装器。 相关链接Go internal ABI specification
Proposal: Create an undefined internal calling convention
go1.18 编译器改动
go1.17 编译器改动]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title>【Golang】Dependency Injection</title>
    <url>/2022/03/28/Go/%E3%80%90Golang%E3%80%91Dependency-Injection/</url>
    <content><![CDATA[依赖注入是一种通用技术，通过显式地为组件提供它们工作所需的所有依赖关系，生成灵活且松耦合的代码。在Go语言中，我们经常采用下面这样的方式为构造器传递依赖：这种技术在小规模上效果很好，但较大的应用程序可能有一个复杂的依赖关系图，导致一大块初始化代码依赖于顺序。通常很难干净地分解这段代码，尤其是某些依赖项被多次使用。如果涉及到服务替换可能会更痛苦，因为它涉及通过添加一组全新的依赖项，我们需要修改依赖关系图。如果大家干过这种事情，发现这种代码的修改很繁琐。
依赖注入工具旨在简化初始化代码的管理，我们只需要将自己的服务及其依赖关系描述为代码或配置，然后依赖注入工具会处理生成的依赖关系图，确定排序并且为每个服务自动传递所需要的依赖。通过更改函数签名，添加或删除初始化程序就可以更改应用程序的依赖项，然后依赖注入完成为整个依赖关系图生成初始化代码的繁琐工作。
在Go语言中，这样依赖工具有不少，例如：dig，inject 以及 wire。这次我们着重介绍 wire，相对其他两个有如下优势：wire 使用代码生成而不是运行时反射。因为当依赖图变得复杂时，运行时依赖注入可能很难跟踪和调试。使用代码生成意味着在运行时执行的初始化代码是常规的、惯用的 Go 代码，易于理解和调试；wire 使用Go类型名称识别依赖项，不用像其他的服务定位器，需要为每个依赖项定义一个名称；wire 更容易避免依赖膨胀。 Wire 生成的代码只会导入需要的依赖项，因此二进制文件不会有未使用的导入。然而运行时依赖注入器直到运行时才能识别未使用的依赖项；Wire 的依赖图是静态可知的，便于工具可视化； 工作原理
Wire 有两个基本的概念，providers 和 injectors，provider 其实就是Go原生的函数，它们接受某些参数，称之为返回值的依赖，然后返回某个想要的类型示例。例如：可以对经常一起使用的 provider 进行分组，例如创建上面的 UserStore 实例的时候都会使用 *Config，所以，我们可以将 NewUserStore 和 NewDefaultConfig 分组成一个 ProviderSet。Injectors 是按依赖顺序调用 providers 的函数。我们可以按照下面这样的格式写 injector 的签名，包括任何需要的参数，特殊的是需要插入一个带有一系列 provides 或者 providerSet 的 wire.Build： 最佳实践
使用标准的 go install 即可安装 wire 工具：go install github.com/google/wire/cmd/wire@latest使用 go get 命令安装 wire 扩展:go get github.com/google/wire@latest使用我们前一小节介绍时使用到的代码来完成最后的代码生成，我们的代码目录结构和其中代码应该是这个样子的：providers.goinjectors.gowire_gen.go这里必须添加一个条件编译指令，wire 命令会识别它，在 go1.17 及其之后是：//go:build wireinjectgo1.17 之前是:// +build wireinject详细的变动可以看 Go1.17 release notes 和 https://go.dev/design/draft-gobuild。
initUserStore 是我们的业务代码实际使用到的初始化函数，里面的依赖逻辑和顺序由 wire 帮我们自动维护。 参考文章Compile-time Dependency Injection With Go Cloud’s Wire]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title>【Golang】Go Modules</title>
    <url>/2021/09/16/Go/%E3%80%90Golang%E3%80%91Go-Modules/</url>
    <content><![CDATA[每个语言都有自己的依赖管理系统，就像 Cargo，npm，Composer， Nuget， Pip， Maven 等，Go 语言也不能例外，在 go mod 出来之前，有两种模式：GOPATH 模式，这种模式把问题想象的太过于简单理想化，可以说是Go语言设计的败笔，因为不支持对依赖的版本管理，不同的项目依赖同一个第三方库的不同版本，GOPATH 就无法搞定，只能切来切去。vendor 模式，这种模式将第三方依赖下载到项目的 vendor 目录下，实现了不同项目之间相互隔离，但是也不支持对依赖的版本管理，没有统一的地方进行声明，一更新就会升级到最新版本，不像很多语言中，将项目的依赖固化到一个 *_lock.json 版本中，这样在项目转移到其他地方进行编译，能确保得到一致的功能。当然，也有很多人喜欢将 vendor 目录上传到仓库，保持不同地方编译后二进制一致性，不过这样会导致仓库体积过大，有利有弊。在这种背景下，诞生了很多第三方的依赖管理工具，如：govendor，glide，dep等，为了解决这种乱象，Go官方出品了 Go Modules，一统江山，其他第三方管理工具就都成为了历时。 go.mod
go.mod 文件描述了Go模块的一些属性，模块是包的集合，模块中的每个包都是同一目录中编译在一起的源文件的集合，包路径（package path），就是将模块路径（module path），和包含包的子目录连接起来，例如 golang.org/x/net 模块在 html 目录中包含一个包，那么这个包的路径就是 golang.org/x/net/html。go.mod 要包括第三方依赖信息和Go版本，下面是 etcd 的 go.mod 文件。该文件被设计成人类可读的文本文件，由注释，关键字，空行以及允许的 , 和 =&gt; 组成。初始化一个 module 可以使用 go mod init 命令，还有很多用于模块的命令，更多请看：Module-aware commands。
 module
module 关键字声明[模块路径]((https://golang.google.cn/ref/mod#module-path)，包含两层意思，当前模块是什么和去哪里找。通常情况下，模块路径由仓库根路径、仓库中的目录和可选的版本后缀（用于v2版本或者更高版本）组成。
go 的下载命令会根据模块路径构造查询请求，找到模块的源码下载路径和协议。如 github.com/bgentry/speakeasy 模块，Go 在查找此模块时，会先构造查询请求：https://github.com/bgentry/speakeasy?go-get=1，这个请求的返回内容中，通常包含一个特殊的 HTML META 标签，格式为：&lt;meta name=&quot;go-import&quot; content=&quot;root-path vcs repo-url&quot;&gt;，包含三部分信息：root-path 存储仓库的根路径，和模块路径相对应，该目录下包含了 go.mod文件，它必须是所请求模块路径的前缀或完全匹配。
vcs       版本控制系统，例如：git、svn、hg
repo-url  仓库的URL如何从一个 package path 解析找到module，点击查看详情。
 注释
以 // 开头的行被当做注释，/**/ 这种注释是不允许的。当开发一个新的版本，想要将老版本标记为弃用时，通常在 module 关键在上方，以一行包含 Deprecated 的注释标记，如： go
go 表示该模块在指定的Go版本下编写验证通过，必须是一个有效的版本号。这个指令的引入了是为了防止发生语言上向后不兼容的更改，自引入模块以来，没有发生不兼容的语言更改，但 go 指令仍然影响新语言功能的使用：对于模块内的包，编译器拒绝使用在指定版本后的语言功能。例如，如果一个模块有 go 1.12 指令，它的包可能不会使用像 1_000_000 这样的数字文字，这是在 Go 1.13 中引入的。
如果使用较旧的Go版本编译遇到错误，编译器会指出这个模块使用了较新版本的语言功能。例如，假设一个模块的版本为 1.13，一个包使用数字文字 1_000_000。如过用 Go 1.12 构建，编译器做出提示。另外，go 命令 会根据 go 指令 指定的版本更改行为，如：在 go1.14 或者更高版本，如果模块内存在  vendor/modules.txt 文件，并且与 go.mod 一致，会自动启用  vendor 模式，无需显示使用 -mod=vendor 标记；在 go1.16 或者更高版本，all 包模式仅仅匹配主模块中的包和tests导入的包，不像在低版本，还包括主模块导入的包中的测试包；在 go1.17 或者更高版本时：go.mod 文件为每个模块包含一个显式的 require 指令，该指令提供由主模块中的包或测试传递导入的任何包；
因为可能比之前的 ·go· 版本有更多的 // indirect 间接依赖，间接依赖被记录在 go.mod 文件中的一个单独的块中；
go mod vendor 或会略 vendor 目录中其他依赖的 go.mod 和 go.sum，这样go命令在 vendor 子目录中使用时，就能正确识别主模块；
go mod vendor 会在 vendor/modules.txt 文件中记录 vendor 中每个依赖的 go 版本；示例：go 1.14 require
require 声明模块依赖的最小版本号。对每个指定的依赖，go命令 会加载该依赖版本的 go.mod 文件，并合并该文件指定的依赖，以此类推，当加载所有依赖之后，go命令 会使用 MVS 算法生成构建列表。
对于间接依赖，go 命令会自动添加 // indirect 注释。
示例： exclude
exclude 阻止 go 命令加载某个版本的依赖。go 命令仅使用主模块中的 exclude 声明。
从 Go 1.16 开始，任何 go.mod 文件中使用 require 指令指定的依赖版本被主模块的中 exclude 指令排除，这些 require 将失去作用。这可能导致 go get 和 go mod tidy 自动添加一个更新版本的依赖信息到 go.mod。
示例： reaplce
replace 将从任何 go.mod 中找到的指定版本依赖替换为另一个版本。
如果 =&gt; 左侧的版本号没有省略，那么只会替换特定版本依赖，其他都是正常的，如果左侧的版本号被省略了，那么指定的依赖所有版本将被替换。
如果右侧的是一个以 ./ 或者 ../ 开头的本地路径，那么这个路径下必须包含一个 go.mod 文件，并且版本号必须要省略。如果不是本地路径，那么它必须是一个有效的模块路径，这种情况下，版本号是必须的，
示例： retract
retract 指令表示不应该依赖本模块的某个或者某些版本。当发现版本发布过早或者版本发布后出现严重问题，这个指令是非常有用的。撤回的版本不应该被删除掉，确保他们在代码仓中可用，以确保依赖于他们的构建不会被破坏，撤回并不是不可用，而是不应该用，它依然有用。
想要撤回一个版本，应该发布一个新版本并且在新版本的 go.mod 文件中使用 retract 指令声明撤回的版本。
go list -m -versions  中列出的版本会屏蔽撤回的版本，除非加上 -retracted。版本查询 如 @&gt;=v1.2.3 或者 @latest 也会忽略撤回的版本。
可以在一个版本中撤回自己，如果模块的最高发行版或预发行版撤回自己，则在排除收回的版本后，@latest 查询将解析为较低版本。举个例子，有个模块 example.com/m 的 v1.0.0 存在问题，然后作者发新的 v1.0.1 版本，但是他在 go.mod 中将 v1.0.1 也撤回：当运行命令 go get example.com/m@latest 时，会从 v1.0.1 解析到 retract 信息，又由于 v1.0.1 和 v1.0.0 都被撤回，go 命令可能选择较老的版本：v0.9.x。
每个撤回指令都应该有一个注释来解释撤回的理由，尽管这不是强制性的。 go 命令可能会在有关撤回版本的警告和 go list 输出中显示撤回原因。注释可以写在撤回指令的正上方（中间没有空行），也可以写在同一行之后。如果注释出现在块上方，则它适用于块内没有自己注释的所有收回指令，原理注释可能跨越多行。
示例：这个指令是 Go1.16 才加的，低版本使用会报告错误。
 版本号
版本可以视为模块的一个快照，它可以是发布版本或预发布版。每个版本都以字母 v 开头，后跟一个语义版本。
总的来说，语义版本由三个由 . 分隔的非负整数（分别表示主版本、次版本和补丁版本，从左到右）组成。补丁版本后面可以跟一个以 - 开头的可选预发布字符串。预发布字符串或补丁版本后面可以跟一个以+号开头的构建元数据信息。例如，v0.0.0、v1.12.134、v8.0.5-pre、v2.0.9+meta 都是有效版本。
版本的每一部分都表示版本是否稳定以及是否与以前的版本兼容。在对模块的公共接口或记录的功能进行向后不兼容的更改后，例如，在删除包之后，必须增加 major version，并且次版本和补丁版本必须设置为 0。
对于向后兼容更改，例如，在添加新功能之后，minor version必须递增并且补丁版本设置为 0。
patch version必须在不影响模块公共接口的更改后递增，例如错误修复或优化。
预发布后缀表示版本是pre release。预发布版本排在相应的发布版本之前。例如，v1.2.3-pre 出现在 v1.2.3 之前。
出于比较版本的目的，将忽略构建元数据后缀，版本控制存储库中会忽略带有构建元数据的标签。如果一个版本的主版本号是 0 或者它有一个预发布后缀，那么它被认为是不稳定的。不稳定的版本不受兼容性要求的限制。例如，v0.2.0 可能与 v0.1.0 不兼容，v1.5.0-beta 可能与 v1.5.0 不兼容。
 伪版本号
伪版本是一种特殊格式的预发布版本，它在版本控制存储库中对有关特定修订的信息进行编码，例如 v0.0.0-20191109021931-daa7c04131f5 就是一个伪版本，伪版本经常用来应用于没有打标签的仓库。伪版本有三个部分：一个基本前缀如：vX.0.0或者vX.Y.Z-0；
一个时间戳：yyyymmddhhmmss，一般指Git仓库中的提交时间；
一个修订表示符，一般是commit 哈希值的前12个字符；每个伪版本可能是三种形式之一，具体取决于基本版本。这些形式确保伪版本比其基本版本高，但比下一个标记版本低。当没有已知的基本版本时，使用 vX.0.0-yyyymmddhhmmss-abcdefabcdef。与所有版本一样，主要版本 X 必须与模块的主要版本后缀匹配
vX.Y.Z-pre.0.yyyymmddhhmmss-abcdefabcdef 用于基础版本是像 vX.Y.Z-pre 这样的预发布版本。
vX.Y.(Z+1)-0.yyyymmddhhmmss-abcdefabcdef 当基础版本是像 vX.Y.Z 这样的发行版本时使用。 主版本后缀
从主版本 v2 开始，模块路径必须具有与主要版本匹配的主要版本后缀，例如 /v2。例如，如果模块在 v1.0.0 中具有路径 example.com/mod，则在 v2.0.0 版本中它必须具有路径 example.com/mod/v2。
主要版本后缀实现了导入兼容性规则：如果旧包和新包具有相同的导入路径，则新包必须向后兼容旧包。根据定义，模块的新主版本中的包与先前主要版本中的相应包不向后兼容。因此，从 v2 开始，包需要新的导入路径。这是通过向模块路径添加主版本后缀来实现的。由于模块路径是模块内每个包的导入路径的前缀，因此将主版本后缀添加到模块路径可为每个不兼容的版本提供不同的导入路径。
主版本 v0 或 v1 不允许使用主要版本后缀。 v0 和 v1 之间的模块路径不需要更改，因为 v0 版本不稳定，没有兼容性保证。此外，对于大多数模块，v1 向后兼容最新的 v0 版本； v1 版本作为对兼容性的承诺，而不是与 v0 相比不兼容更改的指示。
作为一种特殊情况，以 gopkg.in/ 开头的模块路径必须始终具有主版本后缀，即使是 v0 和 v1。后缀必须以.而不是/开头（例如，gopkg.in/yaml.v2）。
 +incompatible
为了确保从 GOPATH 到 Go  Module 的平滑过渡，go命令也可以支持下载和构建非Module仓库。
当 go 命令直接从存储库下载给定版本的模块时，如果模块路径等于存储库根路径，并且存储库根目录不包含 go.mod 文件，则 go 命令会在模块缓存中合成一个 go.mod 文件，该文件包含一个模块指令，仅此而已。由于合成 go.mod 文件不包含它们的依赖项的 require 指令，依赖它们的其他模块可能需要额外的 require 指令（带有 // indirect 注释）以确保每个依赖项在每次构建时都以相同的版本获取。
以主版本 v2 或更高版本发布的模块必须在其模块路径上具有匹配的主版本后缀。例如，如果一个模块是在 v2.0.0 发布的，它的路径必须有一个 /v2 后缀。这允许 go 命令将项目的多个主要版本视为不同的模块，即使它们是在同一个存储库中开发的，如：module go.etcd.io/etcd/v3如果在这个要求引入之前，肯定已经有很多仓库发布了 v2 或者更高版本，为了保持与这些存储库的兼容性，go 命令在没有 go.mod 文件的主版本 v2 或更高版本中添加了 +incompatible 后缀。 +incompatible 表示某个版本与具有较低主要版本号的版本属于同一模块；因此， go 命令可能会自动升级到更高的 +incompatible 版本，如：require example.com/m v4.1.2+incompatible 环境变量
go命令中的模块行为可以由下面列出的环境变量进行配置，所有的环境请查看：https://pkg.go.dev/cmd/go#hdr-Environment_variablesGO111MODULE，控制 go命令以模块方式运行还是 GOPATH 模式，有三个可选的值：off：go命令忽略 go.mod 文件并且以 GOPATH 模式运行；
on，或者不设置，go命令将以模块的方式运行，即使没有找到 go.mod 文件；
auto，Go1.15 之前的默认值，如过在当当前目录或者父目录中找到 go.mod 文件，将以模块方式运行；GOMODCACHE，go命令用于存储下载的模块和相关文件，默认是：$GOPATH/pkg/mod，更多请读Module cache ；GOINSECURE，逗号分隔的以模块路径为前缀的模式匹配列表；GONOPROXY，逗号分隔的以模块路径为前缀的模式匹配列表，匹配的模块将直接从仓库下载；GONOSUMDB，逗号分隔的以模块路径为前缀的模式匹配列表，匹配的模块不会去做校验；GOPATH，包含Go代码的列表；模块模式下，模块缓存被放在第一个 GOPATH 目录的 pkg/mod 子目录，如果没有设置，默认是 $HOME/go；GOPROXY，模块代理 URL 列表，以 , 或 | 分隔。当 go 命令查找某个模块的信息时，它会依次访问列表中的每个代理，直到收到成功响应或终端错误为止。代理可能会以 404（未找到）或 410（已消失）状态响应，以指示该模块在该服务器上不可用。
go 命令的错误回退行为由 URL 之间的分隔符决定。如果代理 URL 后跟 ,，则 go 命令在 404 或 410 错误后回退到下一个 URL，所有其他错误都被视为终端错误。如果代理 URL 后跟一个 |，则 go 命令在出现任何错误（包括超时等非 HTTP 错误）后会回退到下一个源。
GOPROXY URL 可能具有 https、http 或 file 协议。默认为 https，模块缓存可以直接用作文件代理：GOPROXY=file://$(go env GOMODCACHE)/cache/download有两个关键字可以用在 proxy url 列表中：off：禁止从任何源下载模块；
direct：直接从代码仓下载模块，而不是代理；GOPROXY 默认值是 https://proxy.golang.org,direct，可以查看 nodule proxy 获取更多信息。GOSUMDB，标识要使用的校验数据库的名称以及可选的其公钥和 URL。例如：go命令知道连接到 sum.golang.org 和 sum.golang.google.cn 的公钥。
如果 GOSUMDB 设置为 off 或者使用 go get -insecure，则不会查询校验数据库，并接受所有无法识别的模块，代价是放弃对所有模块进行已验证的可重复下载的安全保证。绕过特定模块的校验和数据库的更好方法是使用 GOPRIVATE 或 GONOSUMDB 环境变量。GOVCS，控制 go 命令可以用来下载公共和私有模块或其他与模式匹配的模块的版本控制工具集。如果未设置 GOVCS，或者模块与 GOVCS 中的任何模式都不匹配，则 go 命令可能对公共模块使用 git 和 hg，或对私有模块使用任何已知的版本控制工具。具体来说，go 命令就像 GOVCS 被设置为：public:git|hg,private:all 参考链接go.mod referenceGo Modules referenceGo Modules: v2 and Beyond]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>依赖管理</tag>
      </tags>
  </entry>
  <entry>
    <title>【Golang】Mutex 的实现原理</title>
    <url>/2021/12/15/Go/%E3%80%90Golang%E3%80%91Mutex-%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[在Go语言中，实现并发编程相当简单，因此存在大量场景需要同步操作限制对临界区的修改，避免出现不可期望的情况。因此，Go 语言在 sync 中提供了大量的基本同步原语，例如，最常见的互斥锁 sync.Mutex，它的名字应该来源于：Mutual Exclusion 的前缀组合，它对外只暴露了两个方法：Lock 和 Unlock，本篇文章将详细了解加解锁背后的逻辑。 加锁
正如上面所显示的源码，Mutex 的结构体足够简单，只有两个成员无需额外的初始化，其中 state 表示当前锁的状态，而 sema 是用于排队唤醒的信号量。state 的各个bit位的用途表示如下：mutexLocked — 表示互斥锁的锁定状态；
mutexWoken —  表示从正常模式被唤醒；
mutexStarving — 当前的互斥锁进入饥饿状态；
waitersCount —  当前互斥锁上等待的 Goroutine 个数默认情况下呢，互斥锁的所有位都是0，表示未锁定状态，为了保证公平性，设计上锁是有两种状态的：正常状态和饥饿状态。
在正常模式下，所有等待锁的 goroutine 按照FIFO顺序等待。唤醒的goroutine不会直接拥有锁，而是会和新请求锁的goroutine竞争锁，因为新请求锁的goroutine 正在CPU上执行，把锁交给他可以最大化利用CPU的时间片，也因此刚刚唤醒的goroutine，也就是之前排队的goroutine有很大可能在锁竞争中失败。在这种情况下，这个被唤醒的goroutine会加入到等待队列的前面。 如果一个等待的goroutine超过1ms没有获取锁，那么它将会把锁转变为饥饿模式。
饥饿模式下，锁的所有权将从unlock的gorutine直接交给交给等待队列中的第一个。新来的goroutine将不会尝试去获得锁，即使锁看起来是unlock状态, 也不会去尝试自旋操作，而是放在等待队列的尾部。
如果一个等待的goroutine获取了锁，并且它是队列中的最后一个或者它的等待时间小于1ms，锁将由饥饿状态切换回正常状态。正常状态能最大化利用CPU，饥饿状态能有效防止尾部延迟，接下来我们分下代码的实现。
 快速路径
快速路径下，直接通过CAS获取锁，如果当前锁的状态位全是0，也就是刚初始化的状态，那么直接上锁。 慢速路径
如果没有通过快速路径直接获取到锁，那么就进入慢速路径，我们在理解这些代码的时候，要想象成很多goroutine都在执行这段代码，这样才能便于我们理解其中的意义所在。慢速路径中首先定义了一些状态：如果当一个goroutine尝试加锁时，其他goroutine已经加锁且没有释放，而且锁处在正常模式下，那么就检查是否达到自旋的条件，如果可以那么就尝试自旋。对于是否能够自旋，需要满足以下以下条件：需要多核CPU。因为如果是单核场景，自旋的goroutine在等待持有锁的goroutine释放锁，持有锁的goroutine在等待自旋的goroutine让出CPU，这种情况下自旋没有意义。或者说 GOMAXPROCS=1，又或者说 GOMAXPROCS&gt;1，但是当前只有1个P在运行，也和单核场景类似，意图就是除了当前的P之外还有人在干活，这种情况下自旋才有意义；当前P的本地 runq 为空。因为如果当前的P的runq不为空，与其让当前CPU自旋浪费CPU时间，还不如让CPU去执行runq的goroutine；自旋的次数小于 4次，不能一直自旋；所以就有了 runtime_canSpin 这样的实现：在满足自旋条件之后，goroutine 在自旋之前会先争抢 mutex 的唤醒标识位，设置 mutexWoken 标识位的目的是，在正常模式下，告知持有锁的goroutine在unlock 的时候就不要唤醒其他的goroutine了，已经有goroutine在这里等候了，以免唤醒太多等待协程。这里的自旋是通过 runtime_doSpin() 来实现，底层是通过 proc 执行30次 PAUSE 指令来实现。在每次自旋结束之后都会重新检查自旋条件，如果已经自旋4次，或者锁被释放了，或者锁进入饥饿模式了，都会结束自旋。结束自旋或者根本没有自旋的goroutine就尝试通过原子操作修改mutex的状态，老的状态记为old，要修改的最终状态记为new，如果mutex没处于处于饥饿模式，就尝试设置lock位；如果处于饥饿状态或者加锁状态，那么他就得去排队，通过下面的代码实现：如果当前goroutine等待的时间已经超过1ms，并且锁还没有被释放，那么就将锁切换成饥饿模式。这里要求进入饥饿模式必须是锁没有释放，是因为如果锁被释放了，那么怎么着也得先试试，否则进入饥饿模式就得直接排队：在设置好相应的状态为，最终执行原子操作之前，如果当前goroutine持有唤醒标识，还要将唤醒标识位重置，因为接下来：如果原子操作失败，当前goroutine操作期间，有其他goroutine修改了state，当前goroutine就得从头来过；
如果原子操作成功，抢到锁或者去排队，当前goroutine都不需要再被唤醒了；完整计算 new 的代码如下：接下来继续展开原子操作成功的分支，如果是抢到了锁，那么就直接退出了：如果是排队规模设置成功了，还要决定排在队头还是队尾，如果当前goroutine已经排过对了，是被unlock操作唤醒的，那么就要排在队列头部；如果是第一次排队，那么就得排在等待队列的尾部，并且从第一次排队开始，记录当前goroutine的等待时间，接下来就会将自己休眠，进入到等待队列中：等到goroutine被唤醒时，会接着从上次休眠的位置继续执行。首先判断如果锁处于正常模式，会接着从自旋操作开始重新执行。如果唤醒之后发现锁处于饥饿模式，那就说明当前goroutine之前进入排队被放在了队首，此次自己被唤醒是因为要将锁给自己了，那么就只需要将mutex设置位加锁状态，并且将等待队列数目减1即可，再看看是不是切换回正常模式，更新好状态之后就可以退出了： 解锁
解锁操作相对比较简单，首先将lock位减1，看最终得到状态是不是0，如果是就直接退出了：如果进入到slowpath，说明除了lock位，还有其他位不为0。如果一开始处在正常模式，并且等待队列不为空，或者已经有其他goroutine被换新获得了锁，或者锁进入了饥饿模式，那么不需要唤醒某个goroutine，直接返回即可；否则尝试设置mutex唤醒标志位，获取唤醒一个goroutine的权利，成功之后就会通过 runtime_Semrelease 唤醒一个goroutine，唤醒的goroutine又要开始竞争了，如果不成功就循环尝试。如果一开始就处于饥饿模式，那么就直接唤醒等待队列中的首个goroutine，将锁交给它，所以不用再设置唤醒标志位了。 参考文章Go语言之sync.Mutex 源码分析
【golang】sync.Mutex互斥锁的实现原理
【Golang】Mutex秘籍]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>sync.Mutex</tag>
      </tags>
  </entry>
  <entry>
    <title>【Golang】sync.Pool 的设计与实现</title>
    <url>/2021/12/04/Go/%E3%80%90Golang%E3%80%91sync-Pool-%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[sync.Pool 是一组临时对象，可以用来被复用，以减少内存分配次数，降低GC压力，在大量相同临时对象存在的场景下使用，能较好处理因GC导致CPU突增的情况。sync.Pool 使用比较简单，只有三个简单的 API：New，Get 和 Put，并且它是并发安全的，意味着它可以在 goroutine 中安全地使用。 示例
example 是最好的解释，说明它是什么以及怎么用：output：
creating a new person
1st time get: &amp;&#123;first&#125;
put p
2ed time get: &amp;&#123;first&#125;在这个例子中，我们首先初始化 pool，并且设置 New 函数，当通过 Get 函数从缓存池中获取对象时，如果对象池是空的，就会通过 New 创建新的对象，当对象使用完成后，我们调用 Put 将它放回 pool 中。由于我们在将对象放入 pool 的时候没有将它清空，所在第二次 Get 的时候，之前设置的信息依然存在。但是在实际使用过程中，我们应该在归还对象之前将它清空。
另外，在官方的 fmt 包中我们也能看到它的身影，在经常使用 fmt.Printf 函数中就能看到 sync.Pool 的参与：fmt.Printf 通过调用 fmt.Fprintf 将信息输出到标准输出，其中 newPrinter() 函数获取一个 pp 对象用于具体输出信息的构造：ppFree 是一个 sync.Pool 对象，在包初始化的时候他就被创建好了:在信息输出结束之后，会调用 p.free 对象，用于将对象各个字段清空然后归还给 ppFree: 实现原理
本节将从 Pool 结构体以及存取过程解释 sync.Pool 的实现过程。
 Pool 结构体
pool 是创建之后就不能再被 Copy 的，通过内嵌 noCopy 结构体来实现，具体的讨论详见：https://github.com/golang/go/issues/8005#issuecomment-190753527实际缓存的数据存储在 local 中，local 实际的类型是 poolLocal：其中 pad 字段是为了防止因 伪共享 带来性能下降。CPU缓存是以缓存行（Cache line）为最小数据单位，缓存行是2的整数幂个连续字节，主流大小是64个字节。如果多个变量同属于一个缓存行，在并发环境下同时修改，因为写屏障及内存一致性协议会导致同一时间只能一个线程操作该缓存行，进而因为竞争导致性能下降，这就是“伪共享”。如果没有 pad 字段，假设我们要加载索引为0的 poolLocal，CPU 将会同时加载索引为1的 poolLocal，如果只修改索引为0的，那么索引为1的将被禁止访问。如果此时有其他线程想访问索引为1的，由于缓存失效它就得重新加载，这将会导致严重的新能下降。添加 pad 来将缓存行补齐，就可以让不同的 poolLocal 单独加载，将不存在伪共享的问题了。
再来一起看看 poolLocalInternal 及其内部嵌套的结构体：画个图来说就是下面这个样子的： Get
sync.Pool 对象内部为每个P都分配了一个 private 区和shared区，private 区只能存放一个可复用对象，因为每个 P 在任意时刻只运行一个 G，所以在private 区上写入和取出对象是不用加锁的；shared是一个动态大小的 poolDequeue，但 shared 区上写入和取出对象要加锁，因为别的 P 可能过来偷对象。我们将 race 相关的代码注释掉之后，再看 Get 的实现：首先，调用 p.pin() 函数 将当前的 G 绑定到 P，并且禁止抢占，然后返回 poollocal 和 PID；
将 l.private 赋值给 x，然后将 l.private 置为 nil；
如果 x 是 nil，将从 l.shared 的头部弹出一个赋值给 x ；
如果 x 依然是空，那么将调用 getSlow 方法从其他的P双向队列链表的尾部偷取一个；
在 pool 相关的操作完成之后，调用 runtime_procUnpin 删掉前面打的禁止抢占标记；
最后，如果依然没有获取到对象，那么就调用 New 重新生成一个； pinpin 函数将当前的 goroutine 和 P 绑定到一起，并且禁止抢占，并且获取当前的P的ID。我们来看看 runtime_procPin() 的实现：回到 pin 函数中，通过原子操作获取 p.localSize 和 p.local，如果获取到的 PID 小于 p.localSize，那么直接从 p.local 中根据 PID 直接获取对应的 poolLocal，否则调用 pinSlow 创建。 popHead
回到 Get 函数中，我们再看另外一个关键函数：popHeadpopHead 仅仅能被生产者调用，首先获取 head 节点，如果 head 节点不为空，尝试调用 head 节点的 popHead 方法。两个 popHead 是不相同的，head 节点的 popHead 方法实际调用 poolDequeue.popHead()：poolDequeue 是实际上缓存对象的地方，整个函数的核心是无限循环，是go中常见的无锁编程形式。首先判断队列是否为空，如果队列为空，那么就直接返回失败。否则，将头指针向后移动一位，即头值减少1，pack重新打包头尾指针。使用原子操作CompareAndSwapUint64比较头尾是否在这里变化。如果没有变化，则相当于获取锁。然后更新headtail的值。并将vals对应索引处的元素赋给slot。因为长度只能是2的n次方，假设 head 是 6，len(d.vals) 为 8，那么 head&amp;uint32(len(d.vals)-1) 其实是 1。
在获取到对应slot的元素之后，进行类型转换判断它是不是 dequeueNil，如果是，那意味着没有获取到对象，返回 nil。最后要在返回之前，将得到 slot 零值化。
 getSlow
如果没有从当前P 的 poolLocal 获取到值，那么只能调用 getSlow 从其他 P 那里偷了：首先从当前 P 的下一个 P 开始偷，其实就是从其他P的 poolLocal 最后那个 poolDequeue 的尾部开始偷。要是没偷到，那就从 victim 中拿，顺序也是先从当前P的 victim 拿，然后从其他 P 的 victim 偷，如果最终还是没拿到，就把当前 victimSize 设置为 0 。
 popTail
继续看下 poolChain 的 popTail 函数，焦点应该for循环的顶部，我们在获取到poolChain的最后一个环形队列之后，又获取到了它的next队列，实际上是的前一个队列，如果d为空，我们要向将 d 摘除，那么 next 不能是空，摘除 next 之后，我们继续从前面的环形队列查找。最后再看一下 poolDequeue.popTail，它是从环形队列的尾部查找。如果为空返回 false，这个函数可能会有多个消费者调用，多个人来偷，核心代码仍然是无锁无限for循环。 Put
相较于 Get 的流程，Put 则简单多了，在删除race相关的代码之后，主要有两个流程：绑定P 和 G，将 x 赋值给 l.private 字段
如果失败，调用 pushHead 把它放到双向循环队列的头部 pushHead先判断 head 节点是不是空，如果是空，那就新生成1个8个元素的双向循环队列，然后调用 poolDequeue 的 pushHead 方法插入。如果不为空，那么直接插入，但是如果插入的过程中发现头部的双向循环队列满了，那也新建一个，只是新建的循环队列的长度是之前的2倍，但是最大值是 dequeueLimit : pack/unpack
pack 和 unpack 函数将 head 和 tail 两个指针合并到一起，两个 uint32 的值合并成一个 uint64 的值： GC
对于 sync.Pool，它不能无限扩展，否则它将占用太多的内存而造成内存泄漏。几乎所有的池化技术中，某些对象在某个时刻要被清空掉。在 pool.go 的 init 函数中，注册了用于在GC时清理pool 的函数。poolCleanup 的设计十分简单，仅仅是交换 local 和 victim，交换之前将旧的 victim 置为空，
 参考文章https://developpaper.com/deep-decryption-of-go-language-sync-pool/]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>sync.Pool</tag>
      </tags>
  </entry>
  <entry>
    <title>【Golang】多版本管理安装</title>
    <url>/2022/04/09/Go/%E3%80%90Golang%E3%80%91%E5%A4%9A%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[Go 管理多个版本不用使用额外的版本管理器，直接使用 go install 即可。]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title>【Golang】影响runtime行为的环境变量</title>
    <url>/2022/02/23/Go/%E3%80%90Golang%E3%80%91%E5%BD%B1%E5%93%8Druntime%E8%A1%8C%E4%B8%BA%E7%9A%84%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/</url>
    <content><![CDATA[在Go语言中，为了控制低级别的 runtime 行为，官方提供了一些环境变量，主要有：GOGC
GODEBUG
GOMAXPROCS
GORACE
GOTRACEBACK初次之外，还有用于编译期的 GOROOT，GOPATH，GOOS 和 GOARCH，以及用于玩转SSA的 GOSSAFUNC。在 src/runtime/extern.go 文件中详细描述了这些环境变量的背景和意义。在调度器初始化阶段，解析环境变量并且把他们放进全局变量 envs 中。 GOGC
GOGC 用于控制GC的触发频率，默认值是：100，意思是直到上次垃圾回收堆内存上涨 100% 时触发 GC。如果设置 GOGC=off将彻底关闭 GC。在运行时可以通过 debug.SetGCPercent 进行动态调整。
 GODEBUG
GODEBUG 用于控制运行时中的调试参数，形式上是 , 分割的键值对，例如：GODEBUG=‘gctrace=1,inittrace=1’ go run main.go在调度系统初始化的时候，首先解析环境变量，然后解析调试参数：调试参数解析结束之后，都保存在全局变量 dbgvars 中： allocfreetrace
allocfreetrace=1 会对于每次的内存分配都会进行概要分析，并且在分配内存和释放时打印调用栈。
 clobberfree
clobberfree=1 会使垃圾回收期在释放对象，破坏持有非法内容对象的内存。
 cgocheck
设置 cgocheck=0 会禁用对错误传递Go指针到非Go代码的检查。cgocheck=1（默认值）会开启相对简单的检查，这可能导致一些错误被忽略。cgocheck=2会采取相对严格的校验规则，会导致程序运行较慢，但是不会遗漏错误。
 efence
设置 efence=1 会让内存分配器在分配内存时将每个对象分配在唯一的内存页上，并且这个地址永远不会被回收。
 gccheckmark
setting gccheckmark=1 enables verification of the garbage collector’s concurrent mark phase by performing a second mark pass while the world is stopped.  If the second pass finds a reachable object that was not found by concurrent mark, the garbage collector will panic.
 gcpacertrace
设置 gcpacertrace=1 会使垃圾回收器打印并发 pacer 的内部状态信息。
 gcshrinkstackoff
设置 gcshrinkstackoff=1 进制 goroutine 缩栈，这种模式下，goroutine 的栈只能增长。
 gcstoptheworld
设置 gcstoptheworld=1 将禁用并发 GC，这样每次垃圾回收都会 STW。gcstoptheworld=2 处禁用并发收集之外还会禁用后续的并发清扫。
 gctrace
设置 gctrace=1 会在每次 GC 时，向标准错误输出一行信息，包括收集的总量，停顿的时长等。输出的格式可能会变，目前的格式如下：gc # @#s #%: #+#+# ms clock, #+#/#/#+# ms cpu, #-&gt;#-&gt;# MB, # MB goal, # P每个字段的解释如下：gc：gc 的次数，随着每次垃圾回收自增；
@#s：程序的运行时间，单位是秒；
#%：从程序运行开始到当前 GC，花费在 GC上的时间占比；
#+#+# ms clock： GC 各个阶段占用的时间；，
#+#/#/#+# ms cpu：垃圾回收占用的CPU时间；
#-&gt;#-&gt;# MB：分别表示  GC 开始，结束以及当前的堆内存大小；
# MB goal：当堆内存达到这个值时，触发下次  GC；
# P：P 的个数；例如查看下面程序的  GC 信息： inittrace
设置 inittrace=1 会让 runtime 打印每个 package 初始化工作的信息，包括执行时间和内存申请信息。对于没有用户定义和编译器生成的初始化工作的包，作为插件加载时，不会有任何信息打印。信息格式目前如下：init # @#ms, # ms clock, # bytes, # allocs每个字段的意义如下：init #：包名；
@# ms：从程序开始启动到init执行时的时间，单位是毫秒；
# clock：包初始化工作耗时；
bytes：申请的堆内存大小；
allocs：内存申请次数； madvdontneed
设置 madvdontneed=0 在linux系统，归还内存给操作系统时使用 MADV_FREE 而不是 MADV_DONTNEED，这很高效，但是同时意味着 RSS 数量只会在系统压力较小时下降。
 memprofilerate
设置 memprofilerate=X 会更新 runtime.MemProfileRate 的值，设置位0时，禁用内存分析功能。 invalidptr
设置 invalidptr=1（默认）会使垃圾回收和栈赋值在遇到无效指针是，让程序奔溃。nvalidptr=0 会禁用该检查，这应该仅仅用于临时的代码debug。
 sbrk
设置 sbrk=1 会使用普通的内存申请器，这会直接从操作系统申请内存并且永不释放。
 scavtrace
设置 scavtrace=1 会让运行时系统在每次  GC 周期打印还给操作系统的内存总量和预估物理内存利用量。目前的格式如下：scav # # KiB work, # KiB total, #% utilscav #：清扫周期；
KiB work：从上次到当前，归还给操作的内存总量；
KiB total：归还给操作系统的内存总量；
#% util：正在使用的所有未清理内存的比例；如果该行信息以 (forced) 结束，那说明调用了 debug.FreeOSMemory()。
 scheddetail
设置 schedtrace=X 和 scheddetail=1 会让调度器每隔 X ms 打印调度器，处理器，线程和goroutine的状态。
 tracebackancestors
setting tracebackancestors=N extends tracebacks with the stacks at which goroutines were created, where N limits the number of ancestor goroutines to report. This also extends the information returned by runtime.Stack. Ancestor’s goroutine IDs will refer to the ID of the goroutine at the time of creation; it’s possible for this ID to be reused for another goroutine. Setting N to 0 will report no ancestry information.
 asyncpreemptoff
设置 asyncpreemptoff=1 会禁用基于信号的异步goroutine抢占。这会使一些循环不可抢占，这可能会延迟  GC 以及 goroutine 调度。这对于调试  GC 问题很有用，因为他禁用了用于异步 goroutine 抢占的保守栈扫描。
 GOMAXPROCS
GOMAXPROCS 限制用于同时执行用户代码的线程数量，Go语言中没有限制阻塞在系统调用的线程的数量，这些线程不计入 GOMAXPROCS 的限制。runtime.GOMAXPROCS 可以在运行时对此进行修改，一般情况下和系统的逻辑CPU数量相同。
 GORACE
该环境变量用于配置数据竞争检测器，在程序构建时可以使用 -race 标记，https://go.dev/doc/articles/race_detector 这里有详细描述。
 GOTRACEBACK
GOTRACEBACK 变量控制当 Go 程序由于未恢复的恐慌或意外的运行时条件而失败时生成的信息。默认情况下，失败打印当前 goroutine 的堆栈跟踪，省略运行时系统内部的函数，然后以退出代码 2 退出。如果没有当前 goroutine 或者是运行时内部失败，会打印所有 goroutine 信息。GOTRACEBACK=none 省略整个 goroutine 栈；
GOTRACEBACK=single (默认) 和上面描述的一样；
GOTRACEBACK=all 相比之前的会增加所有用户创建的 goroutine 栈；
GOTRACEBACK=system 在 all 的基础之上，会增加运行时函数的栈帧，并且显示内部创建的 gorotuine；
GOTRACEBACK=crash 和 system 类似， 但以特定于操作系统的方式崩溃而不是退出。例如，在 Unix 系统上，崩溃会引发 SIGABRT 以触发核心转储； 参考内容wall-clock time and cpu time]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title>【Golang】汇编语言</title>
    <url>/2022/03/01/Go/%E3%80%90Golang%E3%80%91%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/</url>
    <content><![CDATA[汇编语言是最接近机器代码的人类可读语言，通过阅读汇编代码，我们可以了解到自己所编写的高级语言代码最终生成的指令都是什么，以便更好的掌握高级语言和了解计算机系统。Go 语言的汇编器基于 Plan9 汇编器，并且在此基础之上定义了一些创新。 X86-64 汇编
在学习 Go 语言的汇编语法之前，先大致了解下基于 X86-64 系列处理器的汇编语言，X86-64 是最常见的 Intel 处理器系列，普遍应用于桌面电脑和服务器中，本节的内容大都总结于《深入理解计算机系统》这本书。
 示例
演示一段简单的C代码生成的汇编指令。假设我们写了一个 C 语言代码文件，mstore.c，它包含如下的函数定义：使用如下的指令生成汇编代码，汇编代码会保存在 mstore.s 中：gcc -Og -S mstore.c其内容位：我们也可以使用 -c 命令行选项，编译并汇编该段代码，这会生成一个二进制文件 mstore.o，我们可以使用 GDB 调试工具查看 multstore 生成的汇编指令：或者使用反汇编工具将二进制文件翻译成汇编代码格式：我们可以看到 multstore 函数编译成二进制文件之后，占据了 14 字节，反汇编工具将它们分成了 6 组，每组 1~5 个字节不等，每组都是一条指令，右边是等价的汇编语言。其中一些关于机器代码和它的反汇编表示的特性值得注意：x86-64的指令长度从1到15个字节不等。常用的指令以及操作数较少的指令所需的子节数少，而那些不太常用或操作数较多的指令所需字节数较多。
设计指令格式的方式是，从某个给定位置开始，可以将字节唯一地解码成机器指令。例如，只有指令 pushg %rbx 是以字节值 53 开头的。
反汇编器只是基于机器代码文件中的字节序列来确定汇编代码。它不需要访问该程序的源代码或汇编代码。
反汇编器使用的指令命名规则与 GCC 生成的汇编代码使用的有些细微的差别。在我们的示例中，它省略了很多指令结尾的 q。这些后缀是大小指示符，在大多数情况中可以省略。相反，反汇编器给 call 和 ret 指令添加了 q 后缀，同样，省略这些后缀也没有问题。以 . 开头的都是指导汇编器和链接器工作的伪指令，去除它们之后，我们可以看到 multstore 函数转换成汇编语言之后的指令位：我们常用的 GCC，OBJDUMP 生成的汇编代码是 ATT（根据 AT&amp;T 命名，它是运营贝尔实验室多年的公司） 格式，有些 Microsoft 生成的格式是 Intel 的，这两种格式在许多方面有所不同，例如，我们可以用下面的指令生成 multstore 函数的 Intel 格式的汇编代码：gcc -Og -S -masm=intel mstore.c 数据格式
大多数GCC生成的汇编代码都有一个字符的后缀，表明操作数的大小。例如数据传送指令有四个变种：movb（传送字节），movw（传送字），movl（传送双字） 以及 movq（传送四字）。汇编代使用后缀 l表示4字节整数和8字节双精度浮点数，这不会产生歧义，因为浮点数使用的一组完全不同的指令和寄存器。
Intel 派系中，“字（Word）”表示16位数据类型，因此，32位称之为 “双字”，64位称之为 “四字”。下表给出C语言数据类型和对应的 X86-64 表示。C声明
Intel 数据类型
汇编代码后缀
大小（字节）char
字节
b
1short
字
w
2int
双字
l
4long
四字
q
8char*
四字
q
8float
单精度
s
4double
双精度
l
8 寄存器
一个 X86-64 的CPU包含一组16个存储64位值得通用目的寄存器，这些寄存器可以用来存储整数数据和指针。名称都是以 %r 开头，不过后面还跟着一些不同的命名规则的名字，这是由于指令集烟花而来的。最初 8086 CPU 有8个16位的寄存器，即 %ax ~ %sp，每个寄存器都有特殊的用途。扩展到 IA32架构时，这些寄存器也扩展成32位的，标号从 %eax ~ %esp。扩展到 X86-64 之后，原来的8个寄存器扩展成64位，标号从 %rax ~ %rsp，除此之外，还增加了8个新的寄存器，它们的标号是按照新的命名规则制定的：从 %r8 ~ %r15。
在常见的程序里，不同的寄存器扮演着不同的角色，其中最特别的是栈指针：%rsp，用来指明运行时栈的结束为止，约定的用途如下：有很多指令能用于复制生成1字节，2字节，4字节和8字节的值。当这些指令以寄存器作为目标时，对于生成小于8字节结果的指令，寄存器中剩余的字节会被按照以下两条规则处理：生成1字节和2字节数字的指令，会保持剩下的字节不变；
生成4字节数字的指令，会把高位4字节置为0； 操作数
大多数指令有一个或者多个操作数（operand），指示处执行一个操作中要使用的源数据值，以及放置结果的目标位置。X86-64 支持多种数据格式，源数据可以是常数值，或者从寄存器或者内存中读出，而结果呢可以放在寄存器或者内存中，因此各种不同的操作数可以分为三种类型：立即数，寄存器， 内存引用。
 立即数
在ATT密码格式中，立即数的表示是 $ 后面跟一个用标准C表示法的表示的整数。比如 %-577 或者 $0x1F。不同的指令允许的立即数范围不同，汇编器会自动选择最紧凑的方式进行数值编码。
 寄存器
寄存器表示寄存器中的内容，所有16个寄存器中的1字节，2字节，4字节或者8字节中一个作为操作数，这些字节数分别对应于8位，16位，32位或者64位。我们用表示 rar_ara​ 表示任意寄存器 a，用引用 R[ra]R[r_a]R[ra​] 表示它的值，这是将寄存器看成一个数组 R，用寄存器标识符作为索引。
 内存引用
内存引用根据计算出来的地址（通常称为有效地址）访问某个内存位置。通常情况下，我们将内存看成一个大的字节数组，因此用符号 Mb[Addr]M_b[Addr]Mb​[Addr] 表示对存储在内存中从地址 Addr 开始的 b 个字节值的引用，为了方便，通常省去下标 b，最常用的内存引用表示形式是 Imm(rb,ri,s)Imm(r_b,r_i,s)Imm(rb​,ri​,s) ，这里的引用有四个组成部分：Imm：立即数偏移；
rbr_brb​：基址寄存器，必须是64位寄存器；
rir_iri​：变址寄存器，必须是64位寄存器；
s：比例因子，必须是 1，2，4，或者 8，编译器根据源代码中数组的类型来确定比例因子，char 类型是 1，int 类型是 4，double 类型是8。有效地址被计算为：Imm+R[rb]+R[ri]⋅sImm + R[r_b] + R[r_i] · sImm+R[rb​]+R[ri​]⋅s，引用数组元素时，会用到通用模式，其他形式都是这种通用形式的特殊情况，省略了某些部分而已，有关计算机寻址方式可以查看：基址加变址寻址方式-百度百科
寻址模式-维基百科下面的表格给出常用的操作数类型机器含义：类型
格式
操作数值
名称立即数
$Imm
Imm
立即数值寄存器
rar_ara​
R[ra]R[r_a]R[ra​]
寄存器寻址存储器
Imm
M[Imm]
绝对寻址存储器
(ra)(r_a)(ra​)
M[R[ra]]M[R[r_a]]M[R[ra​]]
间接寻址存储器
Imm(rb)Imm(r_b)Imm(rb​)
M[Imm+R[rb]]M[Imm+R[r_b]]M[Imm+R[rb​]]
(基址+偏移量)寻址存储器
(rb,ri)(r_b,r_i)(rb​,ri​)
M[R[rb]+R[ri]]M[R[r_b]+R[r_i]]M[R[rb​]+R[ri​]]
变址寻址存储器
Imm(rb,ri)Imm(r_b,r_i)Imm(rb​,ri​)
M[Imm+R[rb]+R[ri]]M[Imm+R[r_b]+R[r_i]]M[Imm+R[rb​]+R[ri​]]
变址寻址存储器
(,ri,s)(,r_i,s)(,ri​,s)
M[R[ri]⋅s]M[R[r_i]·s]M[R[ri​]⋅s]
比例变址寻址存储器
Imm(,ri,s)Imm(,r_i,s)Imm(,ri​,s)
M[Imm+R[ri]⋅s]M[Imm+R[r_i]·s]M[Imm+R[ri​]⋅s]
比例变址寻址存储器
(rb,ri,s)(r_b,r_i,s)(rb​,ri​,s)
M[R[rb]+R[ri]⋅s]M[R[r_b]+R[r_i]·s]M[R[rb​]+R[ri​]⋅s]
比例变址寻址存储器
Imm(rb,ri,s)Imm(r_b,r_i,s)Imm(rb​,ri​,s)
M[Imm+R[rb]+R[ri]⋅s]M[Imm+R[r_b]+R[r_i]·s]M[Imm+R[rb​]+R[ri​]⋅s]
比例变址寻址 数据传送
汇编代码中最常见的就是数据传送指令，经常需要将数据从一个位置复制到另外一个位置。操作数表示的通用性使得一条简单的数据传送指令能够许多机器中好几条不同的指令才能完成的功能。最简单的数据传送指令是 MOV 类，这些指令把数据从源位置复制到目的位置，不能做任何变化。MOV 类指令主要由四条指令组成：movb，movw，movl 以及 movq，这些指令执行同样的操作，区别在于它们传送的数据大小不同，分别是：1，2，4 和 8 字节。指令
效果
描述MOV S, D
D&lt;-S
传送movb传送字节movw传送字movl传送双字movq传送四字movabsq I, R
R&lt;-I
传送绝对四字源操作数指定的是一个立即数，存储在寄存器或者内存中，目的操作数指定一个位置，要么是一个寄存器，要么是一个内存地址。X86-64 添加了一条限制，传送指令两个操作数不能都指向内存地址，所以要在内存之间传送数据，就需要两次操作。
大多数情况下， MOV 指令大多数情况下，只会更新目的操作数指定的那些寄存器或者内存位置，根据指令最后一个字符指定的大小，例如每次 movb 指令只会更新一个字节，movw 更新双字16个字。有个例外就是 movl 指令以寄存器位目的地址时，它会把寄存器的高4字节置为0（X86-64惯例）。
下面是几个数据传送的指令：movl $0x4050, %eax       立即数-&gt;寄存器，4字节
movw %bp, %sp              寄存器-&gt;寄存器，2字节
movb (%rdi, %rcx), %al       内  存-&gt;寄存器，1字节
movb ($-17, (%rsp))      立即数-&gt;内  存，1字节
movq %rax, -12(%rbp)   寄存器-&gt;内  存，8字节除此之外，movq 指令只能以表示32位补码数字的立即数位源操作数，然后把这个值符号扩展到64位的值，放到目的位置。而 movabsq 指令能够以任何64位立即数值作为源操作数，并且只能以寄存器作为目的。
还有两类寄存器，在移动数据时能够对符号位进行扩展，MOVZ 类中的指令把目的剩余字节填充位0，而 MOVS 类中的指令通过符号扩展来填充，把源操作数的最高位进行赋值，这两类指令最后两个字符都是大小指示符，第一个字符指定源操作数的大小，第二个指定目的大小。指令
效果
描述MOVZ S, R
D&lt;-S（零扩展）
以零扩展进行传送movzbw将做了零扩展的字节传送到字movzbl将做了零扩展的字节传送到双字movzwl将做了零扩展的字传送到双字movzbq将做了零扩展的字节传送到四字movzwq将做了零扩展的字传送到四字或者指令
效果
描述MOVZ S, R
D&lt;-S（符号扩展）
以传送符号扩展的字节movsbw将做了符号扩展的字节传送到字movsbl将做了符号扩展的字节传送到双字movswl将做了符号扩展的字传送到双字movsbq将做了符号扩展的字节传送到四字movswq将做了符号扩展的字传送到四字下面是一段 C 代码的示例生成的汇编代码：
源代码汇编代码根据约定，参数 xp 和 y 分别存储在寄存器 %rdi 和 %rsi 中，返回值存储在 %rax 中。先将 xp 中的值放到 %rax 中返回，然后将 y 的值放到  xp 指向的内存地址。 压栈和出栈
栈在处理函数（过程）调用中起到至关重要的作用，栈是一种数据结构，可以添加或者删除，遵循后进先出的原则。通过 push 操作将数据压入栈中，通过 pop 操作删除数据，因此，弹出的值永远是最近被压入而且仍然在栈中的值。
在实现上，栈可以以数组的形式实现，总是从数据的一段插入和删除元素，这一端称为 栈顶。在 x86-64 中，程序栈放在内存中的某个区域，栈是从高地址向低地址增长，栈顶元素的地址是所有栈元素地址中最低的。指令
效果
描述pushq S
R[%rsp]&lt;-R[%rsp]-8；M[R[%rsp]] &lt;- S
将四字压入栈popq  D
D&lt;-M[R[%rsp]]；R[%rsp]&lt;-R[%rsp]+8
将四字弹出栈pushq 的功能是将数据压入到栈上，而 popq 指令是弹出数据，这些指令都只有一个操作数，压入的数据和弹出的数据目的地。
pushq 在压栈之前，首先要将栈指针减8，然后将数据写到栈顶位置，因此，指令 pushq %rbp的行为等于下面两条指令：由于压栈和出栈操作太频繁，所以用一个单独的指令实现，减小最终生成的二进制文件体积。因为，上面两条指令在机器代码中占用8个字节，而 pushq 只需要1个字节。x86-64 中，栈的方向是向低地址增长，所以压栈是减小栈指针（%rsp）的值，并将数据存储到内存中，而出栈是从内存中读取数据，并增加栈的指针。
 算数和逻辑操作
下面的表格列出了一些整数和逻辑操作，大多数操作都分成了指令类，这些指令类有各种带不同大小操作数的变种。指令类 ADD 由四条加法指令组成：addb，addw，addl 和 addq，下面给出的每个指令都有对这四种不同大小数据的变种（除 leaq 之外），这些指令被分成四组：加载有效地址，一元操作，二元操作和移位。指令
效果
描述leaq S, D
D&lt;-&amp;S
加载有效地址INC D
D &lt;-  D+1
加1DEC D
D &lt;-  D-1
减1NEG D
D &lt;-  - D
取负NOT D
D &lt;-  ~ D
取补ADD S, D
D &lt;-  D + S
加SUB S, D
D &lt;-  D - S
减IMUL S, D
D &lt;- D * S
乘XOR  S, D
D &lt;- D ^ S
异或OR   S, D
`D &lt;- D
S`AND  S, D
D &lt;- D &amp; S
与SAL  k, D
D &lt;- D &lt;&lt; k
左移SHL  k, D
D &lt;- D &lt;&lt; k
左移（等同于 SAL）SAR  k, D
D &lt;- D &gt;&gt;A_AA​ k
算数右移SHR  k, D
D &lt;- D &gt;&gt;L_LL​ k
逻辑右移 加载有效地址
leaq（加载有效地址）指令实际上是 movq 指令的变形，它的指令形式是从内存读取数据到寄存器，但实际上根本就没有引用内存。它的第一个操作数看上去是一个内存引用，但是该指令实际上并不从指定位置读取数据，而是将有效地址写入到目的操作数。
除此之外，它还可以简单的描述普通的算数操作，例如，如果寄存器 %rdx 的值为 x，那么指令 leaq 7(%rdx, %rdx, 4), %rax 将设置寄存器 %rax 的值为 7 + (x + x * 4) = 5x + 7，编译器经常会使用 leaq 的一些灵活用法，看下面的示例代码：%rdi = x, %rsi = y, %rdx = z, %rax = t，编译之后的汇编代码位： 一元操作和二元操作
一元操作，及时源又是目的，这个操作数可以是寄存器，也可以是内存位置。例如，incq (%rsp) 会使栈顶的8字节元素加1，这种语法类似于C语言的++ 和 -- 从操作。
二元操作中，第二个操作数既是源又是目的，类似于C语言中的 -=，+=，*= 运算操作符。例如，subq %rax, %rdx 是将寄存器 %rdx 减去 %rax 的结果保存在 %rdx 中，第一个操作数可以使立即数，寄存器或是任意内存位置，第二个操作数可以是寄存器或是内存位置。
 移位操作
移位操作，先给出移位量，然后第二项给出的是要移位的数，可以进行算数和逻辑右移。移位量可以是一个立即数，或者放在单字节寄存器 %cl 中（这些指令很特别，只允许以这个特定的寄存器作为操作数）。原则上来说，1字节的移位量使得移位量的编码范围可以达到 28−1=2552^8-1=25528−1=255。
x86-64 中，移位操作对 w 位长的数据值进行操作，移位量由 %cl 寄存器的低 m 位决定，这里 2m=w2^m=w2m=w，高位会被忽略。所以，当寄存器 %cl 的十六进制位 %0xFF 时，指令 salb 会移 7 位，salw 会移 15 位，sall 会移 31 位，salq 会移 63 位。
左移指令有两个名字：SAL 和 SHL，两者的效果是一样的，都是讲右边填上0。右移指令不同， SAR 执行算数移位（填上符号位），而 SHR 执行逻辑移位（填上0）。移位操作的目的操作数可以是一个寄存器或者一个内存位置。
 特殊的算数操作
两个64位有符号或无符号整数相乘得到的乘积需要128位来表示。 x86-64 指令集对128位（16字节）数的操作提供有限的支持。延续字（2字节），双字（四字节），四字（8字节）的命令管理，Intel 将16字节的数称为八字（oct word）。指令
效果
描述imulq S
R[%rdx]: R[%rax] &lt;- s * R[%rax]
有符号全乘法mulq S
R[%rdx]: R[%rax] &lt;- s * R[%rax]
无符号全乘法cqto S
R[%rdx]: R[%rax] &lt;- 符号扩展（R[%rax]）
转换为八字idivq S
R[%rdx]&lt;-R[%rdx] &lt;- R[%rax] mod S; R[%rax]&lt;-R[%rdx] &lt;- R[%rax] ÷ S; 
有符号除法divq S
R[%rdx]&lt;-R[%rdx] &lt;- R[%rax] mod S; R[%rax]&lt;-R[%rdx] &lt;- R[%rax] ÷ S; 
无符号除法imulq 指令有两种不同的形式，双操作数和单操作数，单操作数时，计算两个64位值得全128位乘积，位补码乘法。而 mulq 是无符号乘法。这两个指令都要求一个参数必须在寄存器 %rax 中，而另一个作为指令的源操作数给出。然后乘积的高64位放在 %rdx 中，低64位放在 %rax 中。
看下面的代码示例，使用文件 inttypes.h 的定义，它是标准C扩展的一部分，只不过，它没有提供128位的值，因此只能依赖GCC提供的对128位的支持，声明一个新的类型 uint128_t。gcc -Og -S imulq.c生成的汇编代码如下，dest in %rdi, x in %rsi, y in %rdx， 函数调用
函数（过程）是软件设计中一种重要的抽象，它提供了一种封装代码的方式，用一组指定的参数和可选的一个或者多个返回值实现某种功能，然后又可以在程序的不同位置调用这个函数。
假设函数 P 调用函数 Q，要在机器级实现 P 调用 Q，然后从 Q 返回，我们必须考虑以下动作：传递控制：在进入函数 Q 的时候，程序计数器必须被设置位 Q 的起始地址，然后再返回时，必须将程序计数器设置为 P 调用 Q 后面的那条指令地址；传递数据：P 必须能向 Q 提供一个或者多个参数， Q 必须能够向 P 返回一个值；内存释放和分配：在调用开始时，Q 可能需要位局部变量分配空间，而在返回时，需要释放这些空间；C 语言中，函数调用机制的实现得在于应用栈这个先进后出内存管理原则。在 P 调用 Q 的过程中，当 Q 在执行时，P 以及向上追溯到 P 的调用链的函数，都是暂时挂起的。当 Q 运行时，它只需要为局部变量分配新的存储空间，当它返回时，任何为它分配的局部存储空间都可以释放。所以，程序可以用栈来管理它的函数调用所需要的存储空间，栈和程序寄存器存放这传递控制 和 传递数据，以及分配内存所需要的信息。当 P 调用 Q，控制和数据信息添加到栈尾，当 P 返回时，这些信息会被释放掉。
在 x86-64 中，栈是向低地址方向增长的，栈指针 %rsp 指向栈顶元素（低地址），可以使用 pushq 或者 popq 指令将数据存入栈上或者从栈上弹出。将栈指针减小一个适当的量可以为没有指定初始值得数据在栈上分配空间，类似，可以通过增加指针来释放空间。
当 x86-64 函数调用需要的存储空间超出寄存器能够存放的大小时，就会在栈上分配空间，这部分内存空间就称为 栈帧。
如下图所示，当前正在执行的函数的帧总是在栈顶，当 P 调用 Q 时，会把返回地址压入栈中，指明当 Q 返回时，要从 P 程序的那个位置开始执行，我们这个返回地址当做P的栈帧的一部分，因为它存放的是与 P 相关的状态。Q 的代码会扩展当前栈的边界，分配它的栈帧所需要的空间。在这个空间中，它可以保存寄存器的值，分配局部变量空间，为它调用的函数设置参数。通过寄存器，P 可以传递最多6个整数值（也就是指针和整数），但是如果Q需要更多的参数，那么 P 可以在调用之前在自己的栈帧里存储好这些参数。 转移控制
将控制从函数 P 转移到函数 Q，只需要简单地把程序计数器（PC）设置为 Q 的起始地址。不过稍后从 Q 返回的时候，处理器必须记录好它需要从 P 的哪个位置继续执行。在 X86-64 系统中，这个信息是用指令 call Q 调用函数 Q 来记录的，该指令会把紧跟在 call 指令后面那条指令的地址压入栈中，并且把 PC 计数器设置为 Q 的起始地址，压入栈中的下一条指令的地址被称作返回地址。而对应的 ret 指令会从栈中弹出返回地址，并且把 PC 更新。指令
描述call Label
函数调用call *Operand
函数调用ret
从函数调用中返回 数据传送
当函数调用时，除了要将控制传递给他并且在函数调用结束时再传递回来，函数调用还需要传递参数和返回值。x86-64 中，大部分的数据传递是通过寄存器实现的。当函数 P 调用 Q 时，P 的代码首先必须把参数复制到合适的寄存器中，而当 Q 返回时，P 的代码可以通过寄存器 %rax 而获取 Q 的返回值。
x86-64 中，可以通过寄存器最多传递6个整形（即整数和指针参数）。寄存器的使用也是有特殊顺序的，根据参数在参数列表中的顺序为他们分配寄存器，寄存器使用的名字取决于要传递的数据类型的大小。可以通过 64 位寄存器适当的部分访问小于 64 位的参数，例如，如果第一个参数是 32 位的，可以通过寄存器 %edi 来访问它。操作数大小
参数1
参数2
参数3
参数4
参数5
参数664
%rdi
%rsi
rdx
%rcx
%r8
%r932
%edi
%esi
%edx
%ecx
%r8d
%r9d16
%di
%si
%dx
%cx
%r8w
%r9w8
%dil
%sil
%dl
%cl
%r8b
%r9b如果一个函数有大雨6个整形参数，超出6个的部分就要通过栈来传递。假设函数 P 调用 Q，有 n 个整形参数，且 n &gt; 6，那么 P 的代码分配的栈帧必须能够容纳 7 到 n 好参数的存储空间。也就是说，要把参数 1~6 复制到对应的寄存器，把参数 7~n 放到栈上，而参数 7 位于栈顶。通过栈传递参数的时候，所有的数据大小都向 8 的倍数对齐。参数放置到对应的位置以后，程序就可以执行 call 指令将控制转移到函数 Q 了，函数 Q 可以通过寄存器访问参数，有必要的话也可以通过栈访问。相应地，如果函数 Q 调用了某个有超过6个参数的函数，它也需要在自己的栈帧中为超过6个部分的参数分配空间，对应于栈帧结构图中的参数构造区。
数据传送源代码示例数据传送汇编代码解释使用下面的命令输出汇编代码：gcc -Og -S test.c 跳转
程序开发中，除了顺序执行之外，还有就是分支语句，循环语句以及条件语句，根据数据测试的结果来决定执行哪些代码，这就涉及到程序的跳转执行。C语言中的语句和机器代码中的指令都是严格按照它们在程序中出现的次序顺序执行。可以使用 jump 指令改变一组机器代码指令的执行顺序，jump 指令指定控制应该被传递到程序的某个其他部分。
 条件码
除了整数寄存器，CPU还维护者一组单个bit位的条件码寄存器，它们描述了最新的算数或者逻辑操作的属性，可以检测这些寄存器来执行条件分支指令，最常用的条件码有：CF：进位标志。最近的操作使最高位产生了进位，可以用来检查无符号操作的溢出。
例如，对于下面的代码，由于最高位会发生进位操作，相加的结果发生溢出，此时进位标志 CF 会被置为1。ZF：零标志。最近的操作得出的结果位0；
例如，对于下面的代码，当 a + b 的结果等于0时，此时零标志 ZF 会被置为1：SF：符号标志。最近的操作得出的结果位负数；OF：溢出标志。最近的操作导致一个补码溢出，正溢出或者负溢出。用一个统一的例子来说明条件码寄存器的变化，我们可以用一个 ADD 指令完成类似于 C 中 t = a + b 的操作，然后根据下面的表达式对条件码寄存器赋值：CF：当 (unsigned) t &lt; (unsignd) a 时，设置 CF 为1，表示存在无符号溢出；
ZF：当 t == 0 时，设置 ZF 为1，表示最近计算结果位0；
SF：当 t &lt; 0 时，设置 SF 为1，表示最近计算结果位负数；
OF：当 (a &lt;0==b&lt;0) &amp;&amp; (t &lt; 0 ! =a&lt;0) 设置 OF 为1；条件码寄存器的值是有ALU在执行算数和运算指令时写入的，下面的这些算数运算指令都会改变条件码寄存器的内容：一元操作指令：INC D
DEC D
NEG D
NOT D二元操作指令：ADD S, D
SUB S, D
IMUL S, D
OR S, D
XOR S, D
AND S, D移位操作指令SAL k, D
SHL k, D
SAR k, D
SHR k, D 访问条件码
条件码同行不会被直接读取，常用的使用方法有三种：可以根据条件码的某种组合将1个字节设置位0后者1；
可以条件跳转到程序的某个其他的部分；
可以有条件地传送数据；对于方法一，我们有一类 SET 指令，它们之间区别是它们考虑的条件码组合是什么，这些指令的不同后缀表明了它们所考虑的条件码组合而不是操作数的大小。例如：sete 表示相等时设置（set when equal）
setl 表示小于时设置（set when less）
setb 表示低于时设置（set when below）
setg 表示大于时设置（set when greater）
setnle 表示不下于等于时设置，等同于 setg所有 SET 类的指令的列表由下表给出：指令
同义名
效果
设置条件sete D
setz
D&lt;-ZF
相等/零setne D
setnz
D&lt;-~ZF
不等/非零sets DD&lt;-SF
负数setns DD&lt;-~SF
非负数setg D
setnle
D&lt;-~(SF^OF) &amp; ~ZF
大于（有符号）setge D
setnl
D&lt;-~(SF^OF)
大于等于（有符号）setl D
setnge
D&lt;-SF^OF
小于（有符号）setle D
setng
`D&lt;-(SF^OF)
ZF`seta
setnbe
D&lt;-~CF &amp; ~ZF
超过（无符号&gt;）setae
setnb
D&lt;-~CF
超过或者相等（无符号&gt;=）setb
setnae
D&lt;-CF
低于（无符号&lt;）setbe
setna
`D&lt;-CF
ZF` CMP 和 TEST
CMP S1, S2 指令会根据 S2-S1 之差来设置条件码寄存器，除了只设置条件码寄存器而不更新目的寄存器之外，和 SUB 是一样的。
TEST S1, S2 指令会根据 S1 &amp; S2 来设置条件码寄存器，除了只设置条件码寄存器而不更新目的寄存器之外，和 AND 是一样的。示例1，对于下面的代码，我们目的是 a==b 相等返回1，不相等返回0输出的汇编程序如下，参数 a 会被放在 %rdi 中，参数 b 会被放在 %rsi 中，那么 cmpq	%rsi, %rdi 就会执行 a - b，决定是否将 ZF 条件码寄存器设置为 1，否则是 0。最终 sete 指令将 ZF 指令的值放到 %al 寄存器，并由 movzbl 进行零扩展。示例1，对于下面的代码，我们目的是 a &lt; b 相等返回1，不相等返回0输出的汇编程序如下，读取条件码寄存器的指令由之前的 sete 变成了现在的 setl，含义是如果 a&lt;b，就将 al 设置为1。setl 指令的结果实际上是由 SF ^ OF 计算得出，因为是有符号数相减我们需要考虑溢出的情况，单独考虑 SF 标志无法得出正确的结论：a &lt; b，那么 t &lt; 0，所以 SF = 1，OF = 0，结果 SF ^ OF = 1；
a &gt; b，那么 t &gt; 0，所以 SF = 0, OF = 0，结果 SF ^ OF = 0；
a &lt; b，例如 a = -2, b = 127，但是 a - b = 127 &gt; 0 ，所以 SF = 0，OF = 1，结果 SF ^ OF = 1；
a &gt; b，例如 a = 1, b = -128，但是 a - b = -127 &lt; 0，所以 SF = 1，OF = 1，结果 SF ^ OF = 0 跳转指令
正常执行情况下，指令会按照它们出现的顺序一条一条的执行，跳转指令会导致执行切换到程序的一个全新的位置，在汇编代码中，这些跳转的目的地通常用一个标号标明，我们看下面的示例：其中，jle .L2 指令表示如果 a &lt;= b 则跳转到 .L2 处继续执行，它是根据 (SF ^ OF) | ZF 条件指令的组合的结果进行跳转。还有一种无条件跳转指令 jmp，它可以是直接跳转，即跳转目标时作为指令的一部分编码的；也可以是间接跳转，即跳转目标是从寄存器或者内存位置中读出的。汇编语言中，直接跳转时给出一个标号作为跳转目标的，例如上面中的 .L2。间接跳转的写法是 *后面跟一个操作数指示符。例如：jmp *%rax 用寄存器 %rax 的值作为跳转目标
jmp *(%rax) 从寄存器 %rax 代表的内存地址读出跳转目标以下列出常用的跳转指令列表：指令
同义名
跳转条件
描述jmp Label1
直接跳转jmp *Oprand*1
间接跳转je Label
jz
ZF
相等/零jne Label
jnz
~ZF
不相等/非零js LabelSF
负数jns Label~SF
非负数jg Label
jnle
~(SF^OF) &amp; ~ZF
大于（有符号）jge Label
jnl
~(SF^OF)
大于等于（有符号）jl Label
jnge
(SF^OF)
小于（有符号）jle Label
jng
`(SF^OF)
ZF`ja Label
jnbe
~CF &amp; ~ZF
超过（无符号）jae Label
jnb
~CF
超过或者相等（无符号）jb Label
jnae
CF
低于（无符号）jbe Label
jna
`CF
ZF` 条件移动指令
跳转指令会运用到CPU的分支预测功能，如果预测失败会带来较大的性能损耗，如果我们对上面的 absi 代码使用编译器优化 gcc -O1 -S source.c，就会得到下面的汇编指令：可以看到的是这里没有了跳转指令，而是使用了 cmovg 指令，按照寄存器的使用规则，参数 a 是在 %edi 中，参数 b 是在 %esi 中，返回值会放在 %eax 中返回，更多的条件移动指令如下表所示，理解下面的描述一般情况下结合之前的 cmp 指令更容易理解：指令
同义名
传送条件
描述cmove S,R
comvz
ZF
相等/零cmovne S,R
comvnz
~ZF
不相等/非零cmovs S,RSF
负数cmovns S,R~SF
非负数cmovg S,R
cmovnle
~(SF ^ OF) &amp; ~ZF
大于（有符号）cmovge S,R
cmovnl
~(SF ^ OF)
大于等于（有符号&gt;=）cmovl S,R
cmovnge
SF ^ OF
小于（有符号&lt;）cmovle S,R
cmovng
`(SF ^ OF)
ZF`cmova S,R
cmovnbe
~CF &amp; ~ZF
超过（无符号）cmovae S,R
cmovnb
~CF
超过或相等（无符号&gt;=）cmovb S,R
cmovnae
CF
低于（无符号&lt;）cmovbe S,R
cmovna
`CF
ZF` Go 汇编
众所周知，Go 汇编器基于 plan9 汇编。那什么是 plan9 呢？plan9 来自于贝尔实验室的第九号计划，是一种概念操作系统， 基于现代化思想重新设计操作系统，目标是实现 UNIX 最初的承诺：一切皆文件。Plan 9的特色功能有：将所有本地和远程资源以文件形式组织的9P协议，union mounts，改进的进程文件系统以及本地的Unicode支持。在Plan 9中，所有的系统接口（如网络和用户界面接口），都是作为文件系统的一部分呈现，而不像其他操作系统上一样拥有自己独立的接口。
Go语言采用 plan9 系统的汇编部分原因是开发者都是同一批人，Go 编译器输出的汇编其是一种抽象，并没有映射到实际的硬件， Go 汇编器会将这个伪汇编翻译成目标硬件的机器语言。拥有这样一个中间层的最大优势在于它更容易适应新的架构，更多详细的可以看 GopherCon 2016: Rob Pike - The Design of the Go Assembler。关于 Go 汇编最重要的一点是 Go 汇编不直接对应于目标硬件这一事实，有些与硬件直接相关，但有些则没有。就像当我们类似 MOV 指令时，工具链位该操作实际生成的可能根本不是移动指令，可能是清除指令或加载指令等，或者他可能与具有该名称的机器指令完全对应。Go汇编作为连接器的输入，在生成机器码的时候才转换成对应平台相关的指令。
 汇编示例
Go 的汇编程序是一种解析该半抽象指令集的描述并将其转换为要输入到链接器的指令的方法，我们来看以下面一段简单的 Go 代码被Go编译器转换成 Go汇编 是什么样子：环境信息如下：go version go1.17.8 linux/amd64
Linux ecs-335906 4.18.0-348.7.1.el8_5.x86_64 #1 SMP Wed Dec 22 13:25:12 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux我们可以使用下面的不同的命令查看 Go汇编代码 和 目标平台汇编代码，对比发现 Go汇编 中存在很多的伪指令。
Go汇编目标机器汇编使用命令：go tool compile -S add.go，这将生成的 GO 表示的汇编，或者可以使用命令 go build -gcflags=&quot;-S&quot; add.go 生成。如果我们已经生成可执行文件，我们还可以通过 GO 提供的反汇编工具查看 Go汇编:
在生成对应平台的二进制文件之后，我们通过调试工具查看 add 函数的汇编代码。第一种方式我们可以通过 dlv ：或者通过 gdb：或者通过反汇编工具 objdump：objdump -d add &gt; add.obj 编译过程
本节内容主要来源于 Go: Overview of the Compiler 和 Introduction to the Go compiler。Go的编译过程包含四个阶段，被分成两类：编译前端：此阶段从源代码运行分析并生成源代码的抽象句法结构，称为 AST。编译后端：第二阶段将源代码的表示形式转换为机器代码，并进行一些优化。由下面的一段代码展示这四个过程： 解析
这个阶段的主要实现是在 cmd/compile/internal/syntax 中，在编译的第一阶段，对源代码进行分词（词法分析）、解析（语法分析），并为每个源文件构建语法树。
每个语法树都是相应源文件的精确表示，其节点对应于源文件的各种元素，例如表达式、声明和语句。语法树还包括位置信息，用于错误报告和调试信息的创建。
分词结果分词代码
分词之后就可以拿去构建语法树。
 类型检查和AST转换
这部分的代码实现主要在 cmd/compile/internal/gc，小写 gc 代表 go compile，大写 GC 代表 Garbage Collector。
这个阶段的第一件事情是将 cmd/compile/internal/syntax 的语法树转换为编译器的 AST 表示，接下来就是名称解析和类型推断，确定哪个对象属于哪个标识符，以及每个表达式具有什么类型。
这个阶段还会做一些优化，例如内联，我们可以使用 go tool compile -w 查看这些细节：
允许内敛优化禁用内敛优化将我们的代码保存为 main.go 之后，我们可以使用 go tool compile -w 查看这个过程，我们没有看到第7行存在函数调用。
禁用内敛优化，我们可以使用 go tool compile -w -l 查看这个过程，我们在第7行看到了调用 add 函数。 SSA 代码生成
这个阶段会将 AST 被转换为静态单一分配 (SSA（静态单赋值形式）) 形式，这是一种具有特定属性的较低级别的中间表示，可以更轻松地实现优化并最终从中生成机器代码。 在此转换期间，编译器将会根据情况应用高度优化的代码完成代码自动优化。
在 AST 到 SSA 的转换过程中，某些节点也被降低为更简单的组件，以便编译器的其余部分可以使用它们。例如，内建的 copy 被内存移动所取代，并且 range 循环被重写为 for 循环。
然后，应用一系列与机器无关的通行证和规则。这些不涉及任何单一的计算机架构，因此可以在所有 GOARCH 变体上运行。这些通用传递的一些示例包括消除死代码、删除不需要的 nil 检查和删除未使用的分支。通用重写规则主要关注表达式，比如用常量值替换一些表达式，优化乘法和浮点运算。
这部分的实现在：cmd/compile/internal/gc （AST 转换成SSA）
cmd/compile/internal/ssa （应用一系列优化手段和基于架构的一些规则）生成优化的SSA代码对比生成未优化的SSA代码使用如下的命令可以生成 SSA 代码：GOSSAFUNC=main go tool compile main.go &amp;&amp; open ssa.html这个生成的 HTML 文档会展示在生成最终代码的过程中应用了哪些规则，例如下面的，由于我们代码中的 a 和 b 是常量，a + b 的和也是已知的，所以应用 opt 规则，直接将其结果存储，并将原来的 a 和 b 删除。一旦将所有能用的优化手段都运用完之后，就会生成一个中间的汇编代码，就是我们的 GO汇编：
使用如下的命令可以生成 SSA 代码：GOSSAFUNC=main go tool compile -l main.go &amp;&amp; open ssa.html这里我们禁用优化，可以看到最终生成的 SSA 和我们的源代码基本相同，a 和 b 两个变量没有被优化掉，没有使用 opt 优化规则：生成的Go汇编中也可以证明这个： 生成机器代码
这部分的实现主要在：cmd/compile/internal/ssa (SSA 降级成平台相关的表示，并且进行优化，不再是中间码)
cmd/internal/obj （机器代码生成）一旦 SSA 被“降低”并且更具体到目标架构，最终的代码优化通道就会运行。这包括另一个死代码消除过程、将值移近它们的用途、删除从不读取的局部变量以及寄存器分配。
作为此步骤的一部分完成的其他重要工作包括堆栈帧布局，它将堆栈偏移量分配给局部变量，以及指针活性分析，它计算在每个 GC 安全点处哪些堆栈指针处于活动状态。
在 SSA 生成阶段结束时，Go 函数已转换为一系列 obj.Prog 指令。这些被传递给汇编器（cmd/internal/obj），汇编器将它们转换为机器代码并写出最终的目标文件。目标文件还将包含反射数据、导出数据和调试信息。
Go 汇编 可以作为链接器的直接输入生成机器代码，例如：使用 go tool compile -S hello.go 将会直接输出 Go汇编 并且生成这个 hello.o 文件。使用 go tool link hello.o 将会链接并且生成可执行文件： 汇编语言
本节的内容主要基于https://go.dev/doc/asm，详细描述Go汇编语言与 x86-64 不同的地方，相对于 x86-64，Go汇编 添加了一些伪指令用于汇编代码的快速开发，但是使用的指令还有通用寄存器命令仍然与特定平台相关，伪寄存器在链接阶段会被转换。
以 x86-64 平台为例，我们可以在以下文件中找到寄存器和指令列表：src/cmd/internal/obj/x86/list6.go (寄存器列表)
src/cmd/internal/obj/x86/anames.go (指令列表)以通用64位寄存器为例，Go汇编中对寄存器的名称做了些许修改：X86-64
rax
rbx
rcx
rdx
rdi
rsi
rbp
rsp
r8
r9
r10
r11
r12
r13
r14
ripGo汇编
AX
BX
CX
DX
DI
SI
BP
SP
R8
R9
R10
R11
R12
R13
R14
PC也有一些指令别名，例如 MOVD 实际上就是 MOVQ 的别名，这些定义可以查看https://github.com/golang/go/blob/7ca6902c171b336d98adbb103d701a013229c806/src/cmd/asm/internal/arch/arch.go#L102。
从Go源代码转换为Go汇编有3中不同的方式，根据场景自行取用：go tool compile -S x.go
go build -gcflags=&quot;-S&quot; x.go
go build -o main main.go &amp;&amp; go tool objdump -s main.main main （先编译然后反汇编） 常量
虽然Go汇编受 plan9 影响，但仍然有众多不同。在常量估值方面，汇编代码中常量表达式使用Go的运算符优先级规则解析，而不是原始的C规则。例如，对于表达式 3&amp;1&lt;&lt;2，它的结果是 4（(3&amp;1)&lt;&lt;2），而不是 0（3&amp;(1&lt;&lt;2)）。还有就是数值常量总是被计算为 64 位无符号整数，因此 -2 会被计算为具有相同二进制形式的整数，它最终表现为 -2 还是 65534，取决于我们为这个变量添加的类型。例如，下面的代码会输出：num1=65534, num2=-2源代码，asm.go源代码，asm.s
在Go汇编中，全局变量由一系列的 DATA 指令和紧跟其后的 GLOBL 指令完成，每个 DATA 指令初始化对应内存的一部分，没有被显示初始化的内存将被清零，DATA 指令的通用形式是：DATA	symbol+offset(SB)/width, value具体含义是，将变量 symbol 从 offset 开始的 width 宽度的内存，用 value 对应的值进行初始化，width 必须是 1，2，4，或者 8，offset和 width 对应的单位都是字节。
GLOBL 指令一般跟在 DATA 指令之后，声明变量是全局变量，如果 DATA 没有对它进行初始化，它的值将是全0。例如：这个例子中定义和声明了文件私有的（&lt;&gt;），64 Bytes 的变量 divtab。也声明了一个 4 Bytes 的未包含指针（NOPTR）的只读（RODATA）零值变量 runtime·tlsoffset。GLOBL 除了声明符号的大小之外，可能还会有1个参数用来指定符号的一些属性，这些属性定义在文件 src/runtime/textflag.h 中，主要有：NOPROF   = 1: (For TEXT items.) Don’t profile the marked function. This flag is deprecated；
DUPOK    = 2: 允许相同符号在二进制文件中有多个，链接器选择其中一个使用即可；
NOSPLIT  = 4: (For TEXT items.) 不要插入用来检查是否需要栈扩展的代码；
RODATA   = 8: (For DATA and GLOBL items.) 声明变量是只读的，将被放在二进制文件只读段；
NOPTR   = 16: (For DATA and GLOBL items.) 声明的变量不包含任何指针，垃圾回收器不用扫描；
WRAPPER = 32: (For TEXT items.) This is a wrapper function and should not count as disabling recover；
NEEDCTXT= 64: (For TEXT items.) This function is a closure so it uses its incoming context register；
LOCAL  = 128: 此符号是动态共享对象的本地符号；
TLSBSS = 256: (For DATA and GLOBL items.) 把这个变量放到线程的本地存储中；
NOFRAME = 512: （对于 TEXT 项。）不要插入指令来分配堆栈帧并保存/恢复返回地址，即使这不是叶函数。仅对声明帧大小为 0 的函数有效；
TOPFRAME = 2048: (For TEXT items.) Function is the outermost frame of the call stack. Traceback should stop at this function；
ABIWRAPPER：表示函数是一个ABI包装器； 寄存器
Go汇编定义了一些由工具链维护的伪寄存器，这些寄存器对所有的架构都是通用的：FP：用于访问函数参数和局部变量；
PC：程序计数器，等同于x86-64中的 %rip ；
SB：静态基指针，用于访问全局变量；
SP：栈指针，指向函数栈帧的高地址；通过 SB 和 FP 这两个伪寄存器，我们可以访问所有我们定义的函数和变量。
 SB
SB 寄存器可以被看做是对原始内存的访问，所以 foo(SB) 指向变量 foo 的内存地址，它被用于去引用全局变量和函数。在定义的符号后面添加 &lt;&gt; 表示这个符号只能在当前文件内被使用。在符号后面可以添加一个 offset，例如 foo+4(SB) 表示从 foo 的第四个字节开始。
例如，我们定义一个 uint16 的变量 num，给他赋值 0xABCD，十进制是 43981，二进制表示是 10101011 11001101，我们可以用下面的汇编代码对他进行初始化，Go汇编代码有个要求就是结尾必须有个空行，否则编译会报错： FP
栈帧是操作系统为函数调用在栈上开辟的内存空间，它包含自己的局部变量和被调函数的参数。我们可以通过Go语言中的 FP伪寄存器和一个偏移量访问当前函数的参数。所以说在 64位系统上， 0(FP)是第一个参数，8(FP) 是第二个参数。但是当使用这种方式引用函数参数时，我们必须加上变量名，例如 first_arg+0(FP)，second_arg+8(FP)，这是Go的汇编器强制要求，但是名称是什么无所谓，不必须和函数签名一致。要注意区分的是，foo+8(FP) 和 foo+8(SB)，前者时相对于 FP 进行偏移，而后者是相对于 foo 的起始地址进行偏移。
对于Go定义的函数，go vet 将会检查参数名称是否和偏移量匹配。另外，在32 位系统上，64 位值得低 32 位和高 32 位可以通过在名称后面添加 _lo 和 _hi 后缀进行区分。例如，arg_lo+0(FP) 和 arg_hi+4(FP)，如果函数没有对返回值命名，那么默认为 ret。
为了说明对 FP 伪寄存器的使用，我们准备如下的例子，例子很简单，就是实现对全局变量 numa 和 numb 的交换，我们使用汇编实现 p 和 q 函数，就是想演示通过栈如何传递参数以及栈的布局，这两个函数如果用Go实现就是：func p() {numa, numb = q(numa, numb)}func q(a, b uint32) (ret0, ret1 uint32) {return b, a}main.goasm.s
将汇编代码和Go代码一起编译运行是没有任何问题的，现在我们来画处当进入 q 函数内时，p 和 q 栈帧示意图。有一点需要提前了解的是，我们在为 p 函数分配栈帧的时候，不需要分配它调用 q 时存储返回地址（CALL 指令下一条指令地址）的空间，CALL 指令执行的时候会自动扩展栈，将返回地址压栈，可以通过 dlv 调试代码查看寄存器值得变化以及对应内存值。所以当我们执行 q 函数的时候，看到的栈空间以及 FP 的位置如下图：
下面的汇编代码中，只使用了虚拟寄存器 FP，在函数 q 中，使用硬件寄存器 SP 将 q 的参数放置到栈上： SP
虚拟机寄存器 SP 是一个虚拟栈指针，用于访问局部变量和那些为函数调用准备的参数，它指向栈帧的最高地址，所以引用应该用负偏移量，区间是 [−framesize, 0)，例如 x-8(SP)，以及 y-4(SP) 等。
也有个硬件寄存器 SP，区分两者的特征是有没有一个前缀符号，例如 x-8(SP) 是引用伪寄存器，而 8(SP) 则是引用硬件寄存器。还有一个就是伪寄存器使用负数作为偏移量，而物理寄存器SP使用正数作为偏移量。Go汇编中，由于 SP 和 PC 是某些物理寄存器的别名，所以要想访问真实的寄存器，需要使用真正的以 R 开头的名字，例如，在 ARM 上，SP 和 PC 对应于 R13 和 R15。
还是上面 FP 中的示例，不过在前面，我们在函数 p 中是使用物理寄存器SP为被调函数 q 准备参数和访问其返回值，这次我们使用伪寄存器SP 做这些事情，并且下面给出的是函数 p 的栈帧示意图和汇编实现：
伪寄存器SP栈帧示意图汇编代码 asm.s
 常量与结构体
如果 go 的包包含 .s 文件，go build 就会让编译器输出一个特殊的头文件 go_asm.h，然后这个 .s 文件可以 #include &quot;go_asm.h&quot;。这个文件中包含了Go代码中定义的常量符号，以及结构的大小和结构体字段的偏移量。例如，我们有下面的常量和结构体定义：那么会生的 go_asm.h 文件内容如下，所以我们可以在汇编代码中以 const_bufSize 访问常量 bufSize；通过 reader__size 获取 reader 结构体的大小；通过 reader_buf  和 reader_r 可以获取字段 buf 和字段 r 相对于 reader 的偏移量。可以通过 go build -work -x 命令输出编译过程和工作目录，在工作目录中可以找到到 go_asm.h。我们做个示例，使用 outputVars 调用 printInt 函数，输出 const_bufSize，reader__size，reader.buf[1] 以及 reader.r，Go 代码和汇编代码如下所示，运行这段代码将会输出:
1024 4100 1 8update.smain.go
 运行时
Go 是一个具有垃圾回收的语言，为了让 GC 运行正确，运行时必须清楚地指导指针在全局数据中和栈帧中的位置。当编译Go代码的时候，编译器会输出这个信息，但是汇编程序必须显示地定义它。
带有 NOPTR 标识的符号被认为不包含任何指针，带有 RODATA 标志的数据会会在只读内存空间中分配内存，隐式带有 NOPTR 标记。如果一个数据的总大小小于指针大小（8字节），也会被隐式打上 NOPTR 标记。在汇编代码中定义一个指针变量是不可能的，这样的数据必须被定义在Go代码中。既是声明的某个变量在汇编代码中没有被用 DATA 和 GLOBL 指令声明，汇编代码仍然可以按名称访问到它。一般情况下，我们只在Go代码中定义非 RODATA 的数据。
每个函数也需要给出它的参数，返回值以及栈帧中可能包含的指针的位置。对于没有指针结果、没有本地堆栈帧或没有函数调用的汇编函数，唯一的要求是在同一包中的 Go 源文件中为函数定义 Go 原型签名。汇编代码中的函数不能包含包名，例如，对于 syscall 包中的 Syscall 函数，在 Text 指令中应该使用 ·Syscall 而不是 syscall·Syscall。对于其他更复杂的场景，可以使用定义在 src/runtime/funcdata.h 中的伪指令。
如果一个函数没有参数也没有结果，指针信息是可以被省略的。这在 Text 指令中可以使用 $n-0 这样的帧参数大小形式声明。否则指针信息必须在Go文件中通过Go原型声明提供。在函数开始部分，函数参数是被认为初始化的，但是返回值是被认为是未初始化的。如果返回值在函数调用期间保存了指针，则该函数应首先将返回值归零，然后执行伪指令 GO_RESULTS_INITIALIZED。该指令表示返回值现在已经初始化并且应该在堆栈移动和垃圾收集期间进行扫描。通常情况下汇编函数不应该返回指针或不包含调用指令，标准库中没有汇编函数使用 GO_RESULTS_INITIALIZED。
如果一个函数没有栈帧，指针信息是会被省略的，在 Text 指令中，会被表示成 $0-n。如果函数是叶子函数，也就是没有函数调用，指针信息也是可以被省略的。否则，必须通过指令 NO_LOCAL_POINTERS 来说明函数栈帧是没有包含任何指针的。因为堆栈大小调整是通过移动堆栈来实现的，所以堆栈指针可能会在任何函数调用期间发生变化：即使指向堆栈数据的指针也不能保存在局部变量中。
写汇编函数的时候，我们应该总是提供Go的原型声明，也就是使用Go代码呈现函数签名，这样，既可以位参数和结果提供指针信息，也可以让 go vet 检查用于访问它们的偏移量是否正确。
 架构相关信息
列出某个平台的所有指令或者其他细节是不现实的，想要看到特定平台下面有哪些指令，例如：ARM 平台，我们可以去这里 src/cmd/internal/obj/arm，这个文件里面有一系列以字母 A 开头的常量，例如：这个列表中指令的名字和拼写，这个平台下对应的汇编器和链接器都是已知的。每个指令虽然都是以 A 开头，例如 AAND，但是它实际代表的指令是 AND ，在汇编代码中也是写作 AND。我们熟知的 X86-64 结构对应的指令列表是在 cmd/internal/obj/x86/a.out.go。
所有架构共享以下的寻址方式，每个架构可能也有自己特定的寻址方式：(R1)， 寄存器简洁寻址；
4(R1)，寄存器使用偏移量间接寻址；
$foo(SB)，绝对寻址在Go汇编系统中，如我们上面描述的例子所展示的那样，汇编指令中，我们的数据都是从左流向右，即源操作数在做，目的操作数在右。例如：MOVQ $0, CX，将 0 移动到 CX 寄存器，已达到清空寄存器的目的。这个数据流向规则在那些使用相反方向数据流的架构中依然适用。
下面我们展示几个我们熟知的架构 X86平台，其他的请看A Quick Guide to Go’s Assembler：
 32-bit Intel 386
指向 g 结构的运行时指针是通过 MMU 中未使用的（就 Go 而言）寄存器的值来维护的。在运行时包中，汇编代码可以包含 go_tls.h，它定义了一个依赖于操作系统和体系结构的宏 get_tls 用于访问该寄存器。get_tls 宏接受一个参数，即加载 g 指针的寄存器。
例如，可以使用下面的代码将 g 和 g.m 分别加载 AX 和 BX 中：这个宏在 amd64 架构下也有定义，请查看 src/runtime/go_tls.h，它的内容是:x86 系统中， TLS 中存储的是当前 g 的地址，goroutine ID 存储在 g.goid 字段中，go1.16.* 版本中，g.goid 的偏移量是 152，我们可以通过下面的代码实现goid的获取：
asm.smain.go
偏移量的计算我们可以通过 dlv 调试器在用户态任意函数任意位置断住，使用如下的指令获取：
(dlv) p &amp;runtime.curg
(*runtime.g)(0xc000000180)
(dlv) p &amp;runtime.curg.goid
(*int64)(0xc000000218)
(dlv) p 0xc000000218-0xc000000180
152
(dlv)特有的寻址方式如下：(DI)(BX*2): 代表的地址是：DI + BX * 2
64(DI)(BX*2): 代表的地址是：64 + DI + BX * 2，比例因子只能是 1，2，4 或者 8。使用编译器和汇编器的 -dynlink 或 -shared 模式时，必须假设对固定内存位置（例如全局变量）的任何加载或存储都会覆盖 CX。因此，为了安全使用这些模式，汇编代码通常应避免使用 CX，除非在内存引用之间。
 64-bit Intel 386 (AMD64)
这两种架构在汇编级别表现基本相同，访问运行时 g 和 m 的方式也和 32 bit x86 架构是一样的，只是这里的使用的指令是 MOVQ 而不是 MOVL。另外。
作为被调用者需要保存 BP，汇编器会自动在帧大于0的函数中插入 BP 保存和恢复的指令。允许使用 BP 作为通用寄存器，但是这会干扰采样分析。
 参考链接A Quick Guide to Go’s Assembler
第3章 Go汇编语言
Golang Calling Convention
数学公式语法——Mathjax教程
Plan9 wiki
Go at Google: Language Design in the Service of Software Engineering
Go 使用的 plan9 汇编语言初探
从Go走进plan9汇编
Getting Started with Go Assembly
Calling Go funcs from asm and JITed code]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title>K8S 证书管理</title>
    <url>/2024/02/29/K8S/cert-manage-service/</url>
    <content><![CDATA[本篇文章主要简单讲解TLS证书的基本知识以及如何在K8S中使用证书提供安全服务。
 证书
TLS证书用于证明访问目标的有效性，当访问某个网站时，浏览器会自动验证证书是否有效，并且会通过证书中提供的Server公钥和Server协商出用于接下来安全数据传输的对称加密秘钥。浏览器（或者客户端，例如：curl）验证服务端证书的流程如下：浏览器或者客户端在和服务端建立加密通信的流程中，会下载服务端的证书到本地，这个证书中包含了服务端证书的公钥，并且这个证书会使用可信任的CA机构的私钥进行签名；
浏览器或者操作系统中安装了大多数著名机构的根证书，浏览器或者客户端会使用这些机构根证书的公钥验证收到的证书是否是可信任机构颁发的；
如果浏览器或者客户端收到的证书是有效的，紧接着会验证证书中包含的服务器或者IP地址是不是和当前打开的地址匹配；
紧接着浏览器会和服务端协商出用于本次数据加密的对称秘钥，使用对称秘钥一是这个秘钥是在每次数据通信时动态协商出来的，会话结束就是小了，防止公钥泄漏带来的安全问题，而是对称加解密密相比非对称加解密有更好的性能表现；X.509 公钥证书中有一些常用的扩展名，如下所示是它们的含义：.csr：证书请求文件，是由 RFC 2986定义的PKCS10格式，包含部分/全部的请求证书的信息，比如，主题, 机构，国家等，并且包含了请求证书的公玥，这些被CA中心签名后返回一张证书，返回的证书是公钥证书（只包含公玥不含私钥）；
.pem：是一种容器格式，可能仅包含公钥证书，也可以包含完整的证书链（包括公玥，私钥，和根证书）。也可能用来编码 CSR文件；
.key：就是一个pem格式只包含私玥的文件，.key 作为文件名只是作为一个明显的别名；
.pkcs12 .pfx .p12：pkcs即 RSA定义的公玥密码学(Public-Key Cryptography Standards)标准，有多个标准pkcs12只是其一，是描述个人信息交换语法标准，有的文件直接使用其作为文件后缀名。这种文件包含公钥和私玥证书对，跟pem文件不同的是，它的内容是完全加密的。用openssl可以把其转换成包含公玥和私玥的.pem文件。命令：openssl pkcs12 -in file-to-convert.p12 -out converted-file.pem -nodes；
.der：der是ASN.1众多编码方案中的一个，使用der编码方案编码的pem文件。der编码是使用二进制编码，一般pem文件使用的是base64进行编码，所以完全可以把der编码的文件转换成pem文件，命令：openssl x509 -inform der -in to-convert.der -out converted.pem 使用der编码的pem文件，后缀名可以为.der，也可以为 .cert .cer .crt；
.cert .cer .crt：pem或者der编码格式的证书文件，这些文件后缀名都会被windows资源管理器认为是证书文件。有趣的是, .pem 反而不会被认为是证书文件； openssl
本节使用 openssl 生成自签名的证书，首先第一步生成 CA 证书的私钥及其证书文件：openssl req -x509 -sha256 -days 356 -nodes -newkey rsa:2048 -subj &quot;/CN=ca.local.dev/C=CN/L=SH&quot; -keyout rootCA.key -out rootCA.crt从证书文件中解析公钥：openssl x509 -inform pem -in rootCA.crt -pubkey -noout生成Server的私钥以及证书请求文件：openssl req -newkey rsa:2048 -nodes -days 365 -keyout server.key -out server.csr根据server.csr生成证书，并且使用rootCA.key进行签名：至此生成了CA和Server的私钥和证书文件。使用如下的一段python代码启用https服务器：pip install Flask启动Server：python3 server.py打开另外一个终端使用curl命令进行测试：curl https://127.0.0.1:8091/hello这里显示找不到证书签名的机构，没法对证书进行验证，这是因为没把自签名的根证书放入系统的证书链中。系统保存的根证书在目录 /etc/ssl/certs/ 中，但是如果要添加自定义的根证书，只需按照如下的方式操作：apt install -y ca-certificates
cp rootCA.crt /usr/local/share/ca-certificates
sudo update-ca-certificates再次使用 curl 命令进行验证正确返回结果：可以使用如下的命令获取到服务端的证书：openssl s_client -connect 127.0.0.1:8091 -showcerts可以使用如下的命令进行证书验证：openssl verify -CAfile rootCA.crt server.crt mkcert
除了使用 openssl 工具进行证书的创建，还可以使用mkcert这个开源工具进行证书的创建，下载之后，首先安装根证书到系统的证书链中，执行下面的命令：mkcert -install然后生成服务端的证书文件：mkcert --cert-file test1.server.crt -key-file test1.server.key test1.local.dev localhost 127.0.0.1 ::1使用下面的命令查看证书的内容：openssl x509 -in test1.server.crt -noout -text K8S TLS 证书
假设我们使用如下的方式创建了一个 Ingress 服务，然后使用不同的方式进行创建TLS证书并加载（这部分要求安装 nginx ingress controller 和 metalb）：kubectl create ns ingress-tls
kubectl create -n ingress-tls  deployment whoami --image=traefik/whoami -r 3 --port=80
kubectl expose -n ingress-tls deployment whoami --port=8080 --target-port=80 --type=ClusterIP --name=whoami查看 ingress 的入口地址：kubectl get svc -n ingress-nginx ingress-nginx-controller此时，可以使用直接使用 http 协议进行访问： mkcert
使用 mkcert 创建证书： mkcert --cert-file whoami.svc.local.crt -key-file whoami.svc.local.key whoami.svc.local 172.31.46.242然后创建 tls 类型的 secret，包含新创建的证书内容：kubectl create -n ingress-tls secret tls mkcert-tls-secret --cert=whoami.svc.local.crt --key=whoami.svc.local.key紧接着更新创建的 Ingress，增加 tls 配置：此时，如果还使用http协议访问，已经会被永久重定向：curl -i --resolve whoami.svc.local:80:172.31.46.242 http://whoami.svc.local使用 https 协议进行访问，返回结果符合预期： cert-manager
使用 cert-manager 可以自动的生成证书并且应用到 Ingress 或者 Gateway 中，使用 cert-manager 的第一步是安装，支持多种安装方式，这里使用如下方式：kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.14.3/cert-manager.yaml等待所有 Pod 就绪: 自签名证书
使用 cert-manaer 前提是先要配置Issuer或者ClusterIssuer，前者属于命名空间资源，后者属于集群资源，为了简单测试，这里先试用自签名证书进行演示：更新Ingress，使用自签名的Issuer自动生成证书并且配置，metadata.annotations.cert-manager.io/issuer: selfsigned-issuer 表示引用的 Issuer，tls中的secret表示生成的证书保存在哪个secret中：命令执行成功之后，可以看到自动生成的证书中还包含了ca.crt：如果不把这里的 ca.crt 存放到系统的证书链中，访问 whoami.svc.local，就会出现自签名证书不能被信任，连接建立失败的提示：有两种解决方案，一种是在访问的时候添加-k参数，表示忽略证书验证，一种是将selfsigned-issuer-secret中的ca.crt保存到系统的证书链中。可以使用下面的命令到处 ca.crt： CA Issuer
可以将外部创建的已经受信任的CA根证书上传到k8s中，然后使用该CA证书签名生成新的证书。例如，在上面的实验中，已经将 mkcert 的根证书安装到了系统中，现在将它也上传到cert-manager中，用于签发新的证书，也可以使用 openssl 创建的根证书。首先使用下面的命令查看根证书和私钥的位置：将 mkcert 的根证书以 Secret 的形式保存到集群中：kubectl create -n ingress-tls secret tls mkcert-ca-secret --cert=/root/.local/share/mkcert/rootCA.pem --key=/root/.local/share/mkcert/rootCA-key.pem然后创建的新的Issuer，指定使用 mkcert-ca-secret 这个根证书：更新 whoami-ingress，使用新建的 mkcert-ca-issuer 进行证书签发：现在访问 https://whoami.svc.local，不会再有证书验证失败的问题了，因为签发使用的根证书已在系统中安装： Gateway
前面的测试都是为 Ingress 增加 tls 证书，接下来示例为 Gateway 增加 tls 证书。首先创建一个 ClusterIssuer，使用 mkcert 的 CA 证书：kubectl create -n cert-manager secret tls mkcert-ca-secret --cert=/root/.local/share/mkcert/rootCA.pem --key=/root/.local/share/mkcert/rootCA-key.pem然后创建 ClusterIssuer，ClusterIssuer 资源的默认命名空间其实就是 cert-manager，这也是为何上面的根证书要放在 cert-manager 之内：除此之外，cert-manager 对 Gateway 的支持还处于实验性阶段，需要安装 Gateway CRDs，以及更新 cert-manager 的启动参数：接下来创建应用、路由、网关以及命名空间这些资源：有几个比较重要的地方需要额外说明：gateway 中指定使用 cert-manager.io/cluster-issuer: mkcert-ca-cluster-issuer 这个 ClusterIssuer 为生成的证书进行签名；
gateway 中的 listener 指定了 gateway-auto-tls.local.dev 这个域名，并且采用 HTTPS 协议，在 tls 块中制定了使用的证书的 Secret 名称：gateway-auto-tls.local.dev-crt，它会被自动创建出来的；
whoami-http-route 这个路由中，通过域名 gateway-auto-tls.local.dev 要使用哪个 listener；执行成功之后会看到如下的资源信息，包括 Service、Pod、Certificate、Secret、HTTPRoute、Gateway：使用 curl 命令进行测试： Certificate
如果想直接生成一个证书，而不是随 Ingress 或者 Gateway 自动生成，可以通过创建 Certificate 这么一个资源，Certificate 以人类可读的方式描述了一个证书，然后被 cert-manager 处理签发。为了演示生成更多证书格式的功能，这里需要对 cert-manager 和 cert-manager-webhook 进行更新：kubectl edit deploy -n cert-manager cert-manager
kubectl edit deploy -n cert-manager cert-manager-webhook添加如下的参数：--feature-gates=AdditionalCertificateOutputFormats=true然后创建下面的资源：这里会使用上一节创建的 mkcert-ca-cluster-issuer 签发证书，执行成功之后会创建如下的资源：将 tls.crt 导出进行查看： 参考链接https://www.bastionxp.com/blog/how-to-create-self-signed-ssl-tls-x.509-certificates-using-openssl/
https://www.cnblogs.com/linianhui/p/security-x509.html
https://ubuntu.com/server/docs/security-trust-store
https://www.jokerbai.com/archives/kubernetes-shi-yong-cert-manager-qian-fa-zheng-shu]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>证书</tag>
        <tag>cert-manager</tag>
        <tag>mkcert</tag>
        <tag>openssl</tag>
      </tags>
  </entry>
  <entry>
    <title>【Golang】进程初始化和调度系统</title>
    <url>/2021/12/19/Go/%E3%80%90Golang%E3%80%91%E8%BF%9B%E7%A8%8B%E7%9A%84%E5%90%AF%E5%8A%A8%E5%92%8C%E5%88%9D%E5%A7%8B%E5%8C%96/</url>
    <content><![CDATA[本篇文章记录 Go 进程的启动和初始化过程，从程序入口开始调试，探索 Go 的各个组件初始化，以最简单的 hello world 为示例。 程序入口
以 linux 操作系统为例，程序编译之后生成可执行文件，可执行文件的格式在 linux 上是 ELF，Windows 上是 PE，linux 通过 readelf 工具查看程序的入口地址，操作系统执行可执行文件的时候，首先解析 ELF Header，然后从 entry point 开始执行代码，通过 delve 执行程序，在入口处打断点：关于 ELF 可执行文件的描述可以参考下面的pdf文件。当然还可以通过 GDB 获得程序的入口地址： 启动流程
实验环境信息如下：Darwin fudenglongdeMacBook-Pro.local 21.2.0 Darwin Kernel Version 21.2.0: Sun Nov 28 20:28:41 PST 2021; root:xnu-8019.61.5~1/RELEASE_ARM64_T6000 arm64go version go1.17.5 linux/arm64通过单步调试，将程序从启动到执行 main.main 函数的全部流程全部总结如下： g0 和 m0
在进程启动的开始就完成了 g0 和 m0 的初始化，这两个是运行时的全局变量，定义在 proc.go 中：m0，m0 表示进程启动的第一个线程，也叫主线程。它和其他的 m 没有什么区别，进程启动通过汇编直接赋值；g0，每个 m 都有一个 g0，因为每个线程有一个系统堆栈，g0的主要作用是提供一个栈供 runtime 代码执行，调度器就运行在 g0 上；其中全局 g0 的初始化如下所示：设置好 g0 相关的信息之后，在 x86 系统上还会设置线程的 Fs_base 寄存器，但是在 arm64 上，仅仅完成了 m0 和 g0 的相互绑定： 并发调度
相比其他语言复杂的并发系统设计，Go语言中在面向用户时，仅提供一个 go 关键字即可实现异步任务和并发调度，但是因其简单，所以在一般系统中，百万级别的 g 也是常有的，为了保证这些 goroutine 的公平调度，不饿死也不撑死，所以得有一套公平的调度系统，在经历了初期几代的发展之后，现在逐渐形成了当前的 GPM 模型。
 GPM
理解调度器首先要理解三个主要概念：G: Goroutine，即我们在 Go 程序中使用 go 关键字创建的执行体；
M: Machine，或 worker thread，即传统意义上进程的线程；
P: Processor，即一种人为抽象的、用于执行 Go 代码被要求的局部资源。只有当 M 与一个 P 关联后才能执行 Go 代码。M 发生阻塞或在进行系统调用时间过长时，是没有与之关联的 P；在这种GPM模型中，数量相对固定的是 P，大多数情况下都是和 CPU 数量相等，多了也没有意义。而 M 和 G 的数量是动态的，在调度初始化中，只设置了 M 的上限是 10000；对于G而言浮动范围就相对较大，少则数百，多则可能达到百万级别。 M
M 是 OS 线程的实体，它的结构体字段有60多个，定义在 runtime2.go 文件中，但是它有一些比较重要的字段：在Go中M只有两个状态：自旋还是非自旋。M的初始化是在 mcommoninit 函数中进行，不管是系统刚运行起来时，主线 m0 的初始化还是新建 M 的初始化都会调用这个函数： P
P 只是处理器的一种抽象，而并非真正的处理器，它是可以通过 runtime 提供的方法动态调整的，用来实现 work stealing，每个 P 都持有一个G的本地队列。如果没有P的存在，所有的G只能放在全局的队列中，当M执行完一个G，必须锁住全局队列然后取下一个G拿来运行，这会严重降低运行效率。当有了 P 之后，每个P都有一个存储 G 的本地队列，当和 P 关联的 M 运行完一个 G 之后，它会按照：当前P的本地队列、全局、网络、偷取的方式获取一个可运行的 G。目前情况下，P 一共有四种状态，_Pidle，_Prunning，_Psyscall，_Pgcstop 和 _Pdead：_Pidle：表示没有使用 P 来运行用户代码或调度程序。通常，它位于空闲 P 列表中并且可供调度程序使用，但它可能只是在其他状态之间转换，空闲状态下它的 runq 队列是空的。_Prunning：表示 P正在被 M 持有运行用户代码或者调度器。只有当 M 持有 P 时，它的状态才被允许修改到 _Prunning。如果没有活干，那么P将切换到 _Pidle 状态；当进行系统调用的时候会切换到 _Psyscall；GC 期间会切换到 _Pgcstop；M 也可以将 P 的所有权直接交给另一个 M（例如，调度到锁定的 G）；_Psyscall：说明 P 没有在运行用户代码，它与系统调用中的 M 有亲和关系，但不属于它，并且可能被另一个 M 窃取。这与 _Pidle 类似，但使用轻量级转换并保持 M 亲缘关系;_Pgcstop：这意味着P由于STW而暂停并且被触发STW的M拥有；STW 的 M 会继续使用 P；从 _Prunning 转换到 _Pgcstop 会导致M释放它的P并且停止；P 会保留它的运行队列，starttheworld 将在具有非空运行队列的P上重启调度程序；_Pdead：这个状态说明P将不再被使用；如果 GOMAXPROCS 增加，这个P还将被重新使用；一个死的 P 大部分资源都会被剥夺。如果用一张图来说明 P 的状态转换，那么就如下所示：通常情况下（在程序运行时不调整P的个数），P只会在四种状态下进行切换。 当程序刚开始运行进行初始化时，所有的 P 都处于 _Pgcstop 状态， 随着P的初始化（在runtime.procresize），会被置于 _Pidle。
当M需要运行时，会runtime.acquirep，并通过runtime.releasep来释放。 当G执行时需要进入系统调用时，P会被设置为_Psyscall， 如果这个时候被系统监控抢夺（runtime.retake），则P会被重新修改为_Pidle。 如果在程序运行中发生GC，则P会被设置为_Pgcstop， 并在runtime.startTheWorld 时重新调整为_Pidle或者_Prunning。
P的初始化是在 runtime.procresize 函数中进行的，位于 proc.go 文件中：procresize 这个函数相对较长，我们来总结一下它主要干了什么事情：调用时已经 STW，记录调整 P 的时间；
按需调整 allp 的大小；
按需初始化 allp 中的 P；
如果当前的 P 还可以继续使用（没有被移除），则将 P 设置为 _Prunning；
否则将第一个 P 抢过来给当前 G 的 M 进行绑定；
从 allp 移除不需要的 P，将释放的 P 队列中的任务扔进全局队列；
最后挨个检查 P，将没有任务的 P 放入 idle 队列；
除去当前 P 之外，将有任务的 P 彼此串联成链表，将没有任务的 P 放回到 idle 链表中； GOMAXPROCS
一般情况下没有人会动态调整P的数量，都是跟CPU的数量保持相同的；为了达到某些测试目的或者其他情况下，可能会对P的数量进行调整，运行时系统向用户层提供了 runtime.GOMAXPROCS 来处理：这个函数会STW，并且更新全局变量 newprocs，在 startTheWorldGC() 中会调用 startTheWorldWithSema 函数，对P的数量重新调整： GG 其实就是用户函数体，里面保存了要执行的函数参数，函数体的入口。相比于 P，G 的状态相对较多，主要有以下这些：G 的初始化是在 runtime.newproc 函数中完成的：详细的参数获取过程需要编译器的配合，也是实现 Goroutine 的关键，下面是 X86 上面一个简单的事例：LEAQ go.string.*+1874(SB), AX // 将 &quot;hello world&quot; 的地址给 AX
MOVQ AX, 0x10(SP)             // 将 AX 的值放到 0x10
MOVL $0x10, 0(SP)             // 将最后一个参数的位置存到栈顶 0x00
LEAQ go.func.*+67(SB), AX     // 将 go 语句调用的函数入口地址给 AX
MOVQ AX, 0x8(SP)              // 将 AX 存入 0x08
CALL runtime.newproc(SB)      // 调用 newproc这个时候栈的布局如下图所示：
            栈布局
    |                 |       高地址
    |                 |
    +-----------------+ 
    | &amp;&quot;hello world&quot;  |
0x10  +-----------------+ &lt;--- fn + sys.PtrSize
    |      hello      |
0x08  +-----------------+ &lt;--- fn
    |       size      |
0x00  +-----------------+ SP
    |    newproc PC   |  
    +-----------------+ callerpc: 要运行的 Goroutine 的 PC
    |                 |
    |                 |       低地址从而当 newproc 开始运行时，先获得 size 作为第一个参数，再获得 fn 作为第二个参数， 然后通过 add 计算出 fn 参数开始的位置。现在我们知道 newproc 会获取需要执行的 Goroutine 要执行的函数体的地址、 参数起始地址、参数长度、以及 Goroutine 的调用地址。 然后在 g0 系统栈上通过 newproc1 创建并初始化新的 Goroutine ，下面我们来看 newproc1。为了证明创建新的goroutine是在系统栈运行，可以debug程序，在 newproc1 函数中断点，查看此时的goroutine是哪个：
(dlv) c
&gt; runtime.newproc1() /usr/local/go/src/runtime/proc.go:4286 (hits total:1) (PC: 0x4de9c)
Warning: debugging optimized function
4281:			throw(&quot;go with non-empty frame&quot;)
4282:		&#125;
4283:
4284:		_g_ := getg()
4285:
=&gt;4286:		if fn == nil &#123;
4287:			_g_.m.throwing = -1 // do not dump full stacks
4288:			throw(&quot;go of nil func value&quot;)
4289:		&#125;
4290:		acquirem() // disable preemption because it can be holding p in a local var
4291:		siz := narg
(dlv) p _g_.m.g0.goid
0
(dlv) p _g_.goid
0  // 当前g关联的m的g0ID和当前g的id相同，说明是在g0栈上运行
(dlv)由于执行 newproc1 是在 systemstack() 函数中，我们来看这个函数的描述：创建 G 的过程也是相对比较复杂的，我们来总结一下这个过程：首先尝试从 P 本地 gfree 链表或全局 gfree 队列获取已经执行过的 g
初始化过程中程序无论是本地队列还是全局队列都不可能获取到 g，因此创建一个新的 g，并为其分配运行线程（执行栈），这时 g 处于 _Gidle 状态
创建完成后，g 被更改为 _Gdead 状态，并根据要执行函数的入口地址和参数，初始化执行栈的 SP 和参数的入栈位置，并将需要的参数拷贝一份存入执行栈中
根据 SP、参数，在 g.sched 中保存 SP 和 PC 指针来初始化 g 的运行现场
将调用方、要执行的函数的入口 PC 进行保存，并将 g 的状态更改为 _Grunnable
给 Goroutine 分配 id，并将其放入 P 本地队列的队头或全局队列（初始化阶段队列肯定不是满的，因此不可能放入全局队列）
检查空闲的 P，将其唤醒，准备执行 G，但我们目前处于初始化阶段，主 Goroutine 尚未开始执行，因此这里不会唤醒 P。 sched
runtime2.go 文件中结束位置定义了很多全局变量，其中有一个 sched，它包含了很多全局资源，访问这些全局资源一般需要锁：我们再来看看 schedinit 函数，了解下 GPM 的初始化流程：TEXT runtime·rt0_go(SB),NOSPLIT,$0
    ...
    MOVW	8(RSP), R0	// copy argc
    MOVW	R0, -8(RSP)
    MOVD	16(RSP), R0		// copy argv
    MOVD	R0, 0(RSP)
    BL	runtime·args(SB)
    BL	runtime·osinit(SB)
    BL	runtime·schedinit(SB)    // create a new goroutine to start program
    MOVD	$runtime·mainPC(SB), R0		// entry
    MOVD	RSP, R7
    MOVD.W	$0, -8(R7)
    MOVD.W	R0, -8(R7)
    MOVD.W	$0, -8(R7)
    MOVD.W	$0, -8(R7)
    MOVD	R7, RSP
    BL	runtime·newproc(SB)   //G 的初始化
    ADD	$32, RSPDATA	runtime·mainPC+0(SB)/8,$runtime·main(SB)
GLOBL	runtime·mainPC(SB),RODATA,$8M/P/G 彼此的初始化顺序遵循：mcommoninit、procresize、newproc，他们分别负责初始化 M 资源池（allm）、P 资源池（allp）、G 的运行现场（g.sched）以及调度队列（p.runq）。
 调度循环
当所有准备工作都就绪之后，也就是调度器初始化，主Goroutine也创建好之后，就是启动调度器调度我们的主Goroutine开始运行了，在我们的Go程序引导启动的最后一步有如下的过程，其中 mstart 就是启动调度的入口：mstart 是新创建的M的入口，由汇编完成。从汇编代码中可以看到，mstart 仅仅调用了 mstart0，而且它不会返回。继续看 mstart1 函数： M 和 P 的绑定
M 与 P 的绑定过程只是简单的将 P 链表中的 P ，保存到 M 中的 P 指针上。 绑定前，P 的状态一定是 _Pidle，绑定后 P 的状态一定为 _Prunning，具体实现是在 acquirep 中处理： M 的暂止和复始
M 是系统线程的抽象，它只有两种状态：park 和 unpark。无论出于什么原因，当 M 需要被暂止时，会调用 stopm 将 M 进行暂止，并阻塞到它被复始时，这一过程就是工作线程的暂止和复始。它的流程也非常简单，将 M 放回至空闲列表中，而后使用 note 注册一个暂止通知， 阻塞到它重新被复始。 核心调度
核心调度是在 shedule 函数中进行的，目的就是找到一个可运行的G去运行。我们接着看 execute 函数：当开始执行 execute 后，g 会被切换到 _Grunning 状态。 设置自身的抢占信号，将 m 和 g 进行绑定。 最终调用 gogo 开始执行，gogo 使用汇编实现：使用 JMP BX 指令执行G（里面的过程着实有点复杂），在执行结束之后会调用 runtime.goexit 函数进行运行现场的清理： 偷取 Goroutine
全局 g 链式队列中取 max 个 g，其中第一个用于执行，max-1 个放入本地队列。 如果放不下，则只在本地队列中放下能放的。过程比较简单：从本地队列中取，首先看 next 是否有已经安排要运行的 g ，如果有，则返回下一个要运行的 g 否则，以 cas 的方式从本地队列中取一个 g。如果是已经安排要运行的 g，则继承剩余的可运行时间片进行运行，否则以一个新的时间片来运行。偷取（steal）的实现是一个非常复杂的过程。这个过程来源于我们 需要仔细的思考什么时候对调度器进行加锁、什么时候对 m 进行暂止、 什么时候将 m 从自旋向非自旋切换等等。 唤醒M 新建M
M 是通过 newm 来创生的，一般情况下，能够非常简单的创建， 某些特殊情况（线程状态被污染），M 的创建需要一个叫做模板线程的功能加以配合：当 m 被创建时，会转去运行 mstart：如果当前程序为 cgo 程序，则会通过 asmcgocall 来创建线程并调用 mstart
否则会调用 newosproc 来创建线程，从而调用 mstart。既然是 newosproc ，我们此刻仍在 Go 的空间中，那么实现就是操作系统特定的了，以下是linux上的： M/G 解绑
实际上就是指将当前 g 的 m 置空、将当前 m 的 g 置空，从而完成解绑，通过 dropg 完成：整个调度器循环可以以下面的一张图来描述： 系统监控
在创建主goroutine的时候，也在系统栈上启动了 sysmon，是时候了解下它的作用了：系统监控在独立的 M 上运行，不需要 P，所以不能出现写屏障：系统监控在运行时扮演的角色无需多言， 因为使用的是运行时通知机制，在 Linux 上由 Futex 实现，不依赖调度器， 因此它自身通过 newm 在一个 M 上独立运行， 自身永远保持在一个循环内直到应用结束。休眠有好几种不同的休眠策略：至少休眠 20us
如果抢占 P 和 G 失败次数超过50、且没有触发 GC，则说明很闲，翻倍休眠
如果休眠翻倍时间超过 10ms，保持休眠 10ms 不变
休眠结束后，先观察目前的系统状态，如果正在进行 GC，那么继续休眠。 这时的休眠会被设置超时。如果没有超时被唤醒，则说明 GC 已经结束，一切都很好，继续做本职工作。 如果超时，则无关 GC，必须开始进行本职善后：如果 cgo 调用被 libc 拦截，继续触发起调用
如果已经有 10ms 没有 poll 网络数据，则 poll 一下网络数据
抢占在系统调用中阻塞的 P 已经运行时间过长的 G
检查是不是该触发 GC 了
如果距离上一次堆清理已经超过了两分半，则执行清理工作 线程管理
Go语言编程中，用户基本上不会涉及到线程的管理，都是由调度系统完成的，但仍然有一些与线程管理相关的接口。
 LockOSThread
该方法在 runtime 包中分别提供了私有和公开方法，私有的方法整个运行时只有在 runtime.main 调用 main.init 、和 cgo 的 C 调用 Go 时候才会使用， 其中 main.init 其实也是为了 cgo 里 Go 调用某些 C 图形库时需要主线程支持才使用的。而用户态的公开方法则不同，还额外增加了一个模板线程的处理。
私有方法公有方法dolockOSThread
 UnlockOSThread
Unlock 的部分非常简单，减少计数，再实际 dounlock：dounlockOSThread 只是简单的将 lockedg 和 lockedm 两个字段清零： 参考链接GDB 命令帮助文档
https://www.codepng.app/
欧神·并发调度]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title>容器运行时</title>
    <url>/2023/12/20/K8S/container-runtime/</url>
    <content><![CDATA[在使用k8s的过程中，始终绕不开容器运行时这个关键组件，当通过kubectl创建一个应用时，节点上的kubelet组件接收到这个事件，然后调用容器运行时实现的CRI接口创建容器。当我们开始关注这个容器运行时的实现和生态的时候，发现存在很多关键词，例如：docker、containerd、runc、OCI 以及 CRI 等等，本篇文章主要记录厘清这些关键词所代表的概念及其出现的背景。
从公众的视野来看，Docker比K8S要早得多，2013年，Docker 就凭借着 Build，Ship and Run Any App, Anywhere 这句名满世界的广告语，迅速进入了开发者的视线中，方便、快速使它得到空前的发展，一时间内，容器化、微服务化成了各大公司技术团队主要的技术方向。由于 Docker 大火，有人比较眼红，CoreOS 实现了自己的容器引擎rkt，为了避免容器技术领域分裂和一家独大的场面出现，在2015年，Docker公司联合Linux基金会联合推动发起了OCI（Open Container Initiative）倡议，其内容主要包括OCI Runtime Spec（容器运行时规范）、OCI Image Spec（镜像格式规范）、OCI Distribution Spec（镜像分发规范）。同时，Docker公司将libcontainer模块捐给社区，作为OCI标准的实现，并改名为 runc，这就是我们常说的runc的由来，后面交由在2015年成立的 CNCF 基金会管理，为其他玩家不依赖于Docker构建自家平台提供了可能性，所以说 OCI 是大家为了避免命脉被别人把住的协商结果。
k8s 和 Docker 的竞争主要是围绕容器编排领域展开，Docker 除了自身的容器引擎，后续还逐步发展出了 docker swarm 容器集群管理管理系统，以及配套的 docker machine、docker compose 等工具，但由于Docker公司始终在Docekr的规划中占据着话语权，让社区以及其他玩家不服，所以开始主推 k8s，由于 k8s 先进的pod、sidecar 设计理念以及在社区的民主化架构，从API到容器运行时的每一层，Kubernetes项目都为开发者暴露出了可以扩展的插件机制，鼓励用户通过代码的方式介入Kubernetes项目的每一个阶段。Kubernetes项目的这个变革的效果立竿见影，很快在整个容器社区中催生出了大量的、基于Kubernetes API和扩展接口的创新工作，涌现了一大批优秀的项目，比如：Istio、Rook。Docekr发现在和k8s竞争出现劣势的时候，强行将自家的容器编排系统docker swarm 内置到docker中，这种内置容器编排、集群管理和负载均衡能力，固然可以使得Docker项目的边界直接扩大到一个完整的PaaS项目的范畴，但这种变更带来的技术复杂度和维护难度，长远来看对Docker项目是不利的，从外界来看就是一条道走到黑，要保持霸权地位，不开放。
由于 k8s 的茁壮成长，Docker 发现竞争无望，将自己的容器运行时 containerd 从架构上独立出来，并且捐赠给社区维护，放弃和 k8s 的竞争，Docker 项目改名 moby，Docker 全面升级成 PaaS 平台，从此 k8s 一统江湖。 dockershim
在 Docker 一鸣天下的时候，k8s 还是 Google 内部的项目，它负责容器编排，而 Docker 负责容器运行时，为了将容器编排和容器运行时解耦开来，让更多的人能参与进来共同建设，所以在2016年，自 Kubernetes 1.5开始，Container Runtime Interface（CRI）发布，通过 CRI 可以支持 kubelet 使用不同的容器运行时，而不需要重新编译，所以这里的 CRI 也叫 Kubelet Container Runtime Interface (CRI)。但是由于那个时候，Docker 是大哥，k8s 是小弟，所以 Docker 没有实现 CRI，而且 k8s 要借 Docker 的势发展自身，所以在 k8s 自己就实现了 dockershim，用来将 CRI 请求转换为对 Docker 的调用，shim 中文垫片的意思，就是个适配层，在 k8s 早期的版本中（v1.24.0之前），dockershim 还是默认选项：代码仓中也能发现 dockershim 的实现，但是自v1.24.0 以来，dockershim 相关的代码彻底从 kubelet 的主干中移除，k8s 适配 docker 从此成为历史，因为通过 dockershim 创建容器的调用链实在太长了： cri-dockerd
dockershim 被从 kubelet 的主干代码中移除了，那么还想使用 Docker 作为容器运行时的人怎么办呢？所以就诞生了 cri-dockerd 这个项目，它的作用和 dockershim 类似，实现 CRI 接口，将 CRI 请求转换为对 Docker Daemon 的请求，从它的配置文件就可以看出这点，它自己的监听地址 unix:///var/run/cri-dockerd.sock 接收 CRI请求，转换之后转发给 unix:///var/run/docker.sock，官方也存在指导文档，有这部分需求的人可以按照这份指导进行适配，看完这篇文章，我估计你也没这个需求了。
 crictl
crictl 是用于 CRI 的客户端工具，就像通过 docker 这个命令行工具访问 docker daemon 一样，但是 crictl 在使用的过程中需要制定你使用哪个容器运行时作为你的后端，它的文件配置在 /etc/crictl.yaml：本地测试环境使用 k3s 搭建的集群，使用 docker 作为容器运行时，docker 命令到 crictl 命令的映射可以看这里，比起 docker，crictrl 可以管理 pod，pod 是 CRI 实现者要理解的概念，而向 docker 这样的底层容器运行时，不需要理解pod，只负责管理容器和镜像。 containerd
containerd是行业标准的容器运行时，强调简单性、稳健性和可移植性。在这里要将容器运行运行时进一步分为高级别容器运行时和低级别容器运行时，高级别以 containerd 为代表的，实现了 kubelet CRI 标准的容器运行时，还有 cri-o，而低级别是以runc为代表的，实现了 OCI（Open Container Initiative） 的容器运行时，利用 Linux 提供的 namespace 、cgroup 等特性创建容器，高级容器运行时理解 kubelet CRI，转而调用低级别的 runc 等创建容器。 containerd 的架构图如下所示：containerd 和 runc 都是最初 Docker 贡献出来的，现在也存在于 docker 的架构中，所以安装 Docker 之后这些组件就存在了，当然也可以单独安装，更多的运行时请看CNCF Contaienr Runtime。从 containerd 的发布件来看，它里面包含这些工具：bin/containerd：containerd 的守护进程文件，用于启动 containerd 服务，一般位于配置 /etc/systemd/system/containerd.service 中；
bin/containerd-shim：containerd 套件，其目的主要是隔离containerd和容器。containerd守护进程收到gRPC调用请求（比如来自Kubelet或Docker的创建容器请求），便会启动/usr/bin/containerd-shim套件；
bin/containerd-shim-runc-v2：containerd-shim 启动后会去启动/usr/bin/containerd-shim-runc-v2，然后立即退出，此时containerd-shim-runc-v2的父进程就变成了systemd(1)，这样containerd-shim-runc-v2就和containerd脱离了关系，即便containerd退出也不会影响到容器，v2 版本的运行时架构及其原理可以查看官方说明；
bin/containerd-shim-runc-v1：contaienrd 运行时的 v1 版本，v2 相比 v1会有更高的性能个更丰富的特性；
bin/ctr： containerd 的客户端；接下来我们使用 ctr 命令创建两个容器，首先，查看 containerd 进程：systemctl status containerd这里获得的进程 id 是 2985246，然后使用下面的命令拉取镜像，不像 docker 那么友好，在发现没有镜像的时候自动拉取：ctr image pull docker.io/library/nginx:alpine然后使用下面的命令，基于不同的运行时创建两个容器，使用 --runtime 参数指定 runtime 版本，可以使用版本号，也可以直接使用二进制文件：ctr run -d --runtime io.containerd.runc.v2 docker.io/library/nginx:alpine nginx1
ctr run -d --runtime /usr/local/bin/containerd-shim-runc-v1 docker.io/library/nginx:alpine nginx2可以使用 ctr task 命令查看容器中的首进程 PID，如下所示：然后可以进一步使用 ps 命令查看 4021721 的子进程和父进程，可以看到容器里面的nginx进程是4021701的子进程，而 4021701 已经和 containerd 脱离了关系。pstree -a -s -l -n -S -p 4021721可以使用 ctr task exec 进入到容器内部执行命令：ctr task exec --exec-id ps nginx1 ps -ef要删除创建的容器，要执行下面这些命令，依次停止任务，删除任务，删除容器：ctr t kill -s 9 nginx1
ctr t del nginx1
ctr c rm nginx1这里如果要了解 containerd 中的 task 概念，可以查看说明书。
 runc vs crun vs youki
runc、crun、youki 都是实现了 OCI 规范的低级别容器运行时，runc 使用 Go 语言编写，crun 使用 C 语言编写，youki 使用 Rust 语言编写。
下面是直接使用 youki 创建容器的示例：创建一个包含 roots 的空目录，例如：mkdir -p tutorial/rootfs进入到 tutorial 目录，借助 docker 构建一个完整的容器文件系统：cd tutorial
docker export $(docker create busybox) | tar -C rootfs -xvf -现在需要一个 config.json 文件来描述进程的权限、配置和约束信息，下面的命令将生成一个默认的配置：youki spec然后就可以手动修改这个文件定义容器进程的行为，如果不想修改保持默认也行；接下来可以创建容器，-b 参数指向包含 config.json 的目录：youki create -b tutorial busybox_with_youki查看容器状态，现在是 created：youki state busybox_with_youki启动容器：youki start busybox_with_youki列出容器：youki list查看容器进程：youki ps busybox_with_youki删除容器：youki delete busybox_with_youki其实上面从第三步开始可以将 youki 换成 runc 执行，完全兼容，都实现的相同的标准。
 参考文章cri-tools(crictl)
Docker vs Containerd vs RunC
Youki User and Developer Documentation
Alternative container runtimes
Containerd组件 —— containerd-shim-runc-v2作用
浅谈dockerd、contaierd、containerd-shim、runC之间的关系
CRI Plugin Config Guide
containerd-runtimeV2
容器运行时探讨–从dockershim正式从K8s移除说起
cri-o
How to run and manage containers using ctr]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>容器运行时</tag>
        <tag>OCI</tag>
        <tag>CRI</tag>
        <tag>containerd</tag>
        <tag>dockershim</tag>
        <tag>ctr</tag>
        <tag>crictl</tag>
        <tag>containerd-shim-runc-v2</tag>
        <tag>crun</tag>
        <tag>runc</tag>
        <tag>youki</tag>
        <tag>gvisor</tag>
        <tag>podman</tag>
        <tag>cri-o</tag>
      </tags>
  </entry>
  <entry>
    <title>K8S Gateway</title>
    <url>/2024/03/01/K8S/gateway/</url>
    <content><![CDATA[为了从外部能够访问到集群中的服务，k8S 提供了多种方式，从 NodePort 类型的 Service，LoadBalancer 类型的 Service，到 Ingress，一直在改进，NodePort类型的服务流量从单一节点进来，没法在节点之间负载均衡，进而衍生出LoadBalancer类型的服务，该类型的服务虽然解决了前面存在的问题，但是需要云厂商的支持，况且针对每个Service粒度提供一个公网IP地址，未免有点浪费，进而衍生出 Ingress，支持7层代理，能够通过单一的入口，以及域名和Path匹配等机制将流量转发到不同的后端服务中去。Ingress 虽然解决了LoadBalancer存在的问题，但它在实际的使用场景中又遇到了新的问题：Ingress 仅支持7层，没法对四层的流量进行转发；
Ingress 在设计的时候只考虑一种用户角色，既整个系统的运维人员和管理员，这种模型在许多拥有多个团队的企业中都不适用，包括应用开发人员、平台运维人员、安全管理员等，他们在协作开发和交付应用的过程中需要控制Ingress配置的不同方面；
Ingress 中使用了很多annotion实现自定义功能，对于不同的 ingress controller 没法做到一致性，例如，这里的 nginx annotions，这些在原本的 Ingress 对象中都是不支持的；在这些问题的促使下，社区又提出了新的概念：Gateway，明确定义并划分不同角色的职责范围有助于简化管理，对三个主要的 Gateway API 资源（GatewayClass、Gateway 和 Route）进行了标准化。具体来说，基础架构提供商负责为 Kubernetes 集群定义 GatewayClasses，集群运维人员则负责在集群中部署和配置 Gateway（包括策略），而应用开发人员可以自由地将 Route 附加到 Gateway，以对外暴露应用。 安装
Gateway 相关的资源没有在K8S中预置，因为它还在不断发展，在使用之前需要先安装相关的资源，这里分为两个版本：稳定版和实验版，实验版本相比标准稳定版多了 TCPRoute，TLSRoute，UDPRoute，GRPCRoute，根据选用的的 Gateway Controller 的支持程度做选择即可。稳定版执行下下面的命令进行安装：kubectl apply -f https://github.com/kubernetes-sigs/gateway-api/releases/download/v1.0.0/standard-install.yaml实验版本使用下面的命令进行安装：kubectl apply -f https://github.com/kubernetes-sigs/gateway-api/releases/download/v1.0.0/experimental-install.yaml这里选用的 istio 作为Gateway的实现，参考istio的安装指南进行安装。安装成功之后，能看到一个 istio 的 GatewayClass 对象： Gateway
上面的安装步骤完成之后，就可以创建一个Gateway进行使用了，这部分主要是集群运维人员的工作。为了能全面的展示Gateway API，这里使用了https协议，首先创建证书并且上传，使用到的mkcert需要提前安装：mkcert --cert-file web.local.dev.crt -key-file web.local.dev.key web.local.dev
kubectl create -n nginx-gateway secret tls web.local.dev-crt --cert=web.local.dev.crt --key=web.local.dev.key对 Gateway 中的重点概念做下解释：spec.gatewayClassName：指定要使用的 Gateway Controller，这里使用上一节安装的 istio；
spec.listeners.hostname：网关的名称，如果要使用 HTTPS 协议， 在指定了 spec.listeners.tls 时，该字段必须指定，且附加到该网关的 HTTPRoute 中的 hostnames 字段至少包含这里声明的 hostname；
spec.listeners.allowedRoutes.namespace：指定允许哪些命名空间的 HTTProute 附加到这个网关中：kinds：允许那种路由添加到这个网关中；
from：可以取值 Same，表示只有和网关在相同命名空间的路由才可以添加到这个网关中；All 表示允许所有命名空间的路由添加到这个网关中；Selector 允许选择器选择匹配的命名空间中的路由添加到这个网关中；
selector.matchLabels：选择具有 shared-gateway-access: &quot;true&quot; 标记的命名空间；
selector.matchLabels：这里允许 gateway-test 这个命名中的路由添加到网关；执行成功之后，能看到下面的对象，其中 local-gateway-istio service 是整个 local-gateway 的入口，被metalb分配了172.19.106.241地址，它接受到的请求转发给 local-gateway-istio-fb7447f46-g56gm 这个 Pod 进行处理，它负责对路由配置的解释，根据 HTTPRoute 配置的规则将流量转发给对应的后端服务： 功能介绍
前面的配置一般由集群的运维人员进行，现在需要开发人员登场将自己的开发的应用接入到网关中，这样用户就可以从外部进行访问了。
 HTTPRoute
使用 kubectl 部署下面的 whoami 服务进行测试：对上面的一些关键点进行解释：命名空间的名称 gateway-test 以及它的标签：shared-gateway-access: &quot;true&quot; 是他被Gateway认可的标识，在创建 Gateway 的时候指定具有这个特征的命名空间中的HTTPRoute才会被接受；
创建 whoami-svc 用于处理实际的请求，它会将请求转发到具有 app=whoami 的 Pod 进行处理；
创建 HTTPRoute 路由，使用 istio-system 命名空间中的 local-gateway Gateway 作为网关，匹配Host为web.local.dev，且以/whoami开始的请求转发给whoami-svc的8080端口进行处理；上面的命令执行成功之后，将能看到下面这些资源信息：kubectl get svc,pod,deploy,rs,httproute -n gateway-test -owide使用 curl 命令进行结果验证：curl -i --resolve web.local.dev:9443:172.19.106.241 https://web.local.dev:9443/whoami ReferenceGrant
上面的 HTTPRoute 和引用的后端服务在同一个命名空间中，如果不在同一个命名空间，就需要使用 ReferenceGrant 进行显示授权，ReferenceGrant 允许和它在同一个命名空间中的 Service 被其他命名空间中的 HTTPRoute 进行引用，对前面的示例进行改造然后进行演示，首先删除原来命名空间中的资源：kubectl delete ns --cascade gateway-test然后重新创建下面的资源：对上面的资源配置做以下解释：HTTPRoute 依然在 gateway-test 命名空间中，是为了能让 local-gateway 接受此路由，而且它引用的whoami-svc目前被放在了gateway-test-svc中，通过 namespace 显示指定；
为了能让 gateway-test 中的 HTTPRoute 引用 gateway-test-svc 的 Service，使用 ReferenceGrant 显示进行授权；部署成功之后，使用下面的命令依然能够访问成功：curl -i --resolve web.local.dev:9443:172.19.106.241 https://web.local.dev:9443/whoami 重定向
使用 HTTPRoute 还可完成重定向和路由重写功能。
 协议重定向
在 HTTP 协议中，经常会将不安全的http访问重定向到https协议，为了测试这个功能，首先对local-gateway进行更新，允许它处理来自http的报文：这个更新让 web.local.dev 可以通过 http 和 https 两种协议进行访问。
重定向之前重定向之后承接 ReferenceGrant 中的测试案例，这个时候可以使用http协议访问 whoami 服务：curl -i --resolve web.local.dev:9080:172.19.106.241 http://web.local.dev:9080/whoami如果想将所有的 http 访问全部重定向到 https，需要对 gateway-test 中的HTTPRoute进行更改，使用 sectionName 区分两个路由引用的协议，这样可以单独设置通过http协议访问时的动作：执行上面的操作之后，再次通过 http 协议进行访问，会发现已经重定向了： 路径重定向
路径重定向使用 HTTP 路径修饰符来替换整个路径或路径前缀，如下所示：然后当访问以 /whamo 开头的请求时都会被全部重定向到 /whoami：当访问以 /who 开头的请求时，仅仅 /who 会被完全替换为 /whoami： HTTP 头修改
通过 HTTPRoute 中的 RequestHeaderModifier 可以添加、修改或者删除请求头，例如下面的HTTPRoute中将对以/whoami开头的请求添加request-with-correct-path: true 这样的请求头：当在请求的时候，会返回如下的结果： 参考链接https://www.nginx-cn.net/blog/5-things-to-know-about-nginx-kubernetes-gateway/]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>gateway</tag>
        <tag>ingress</tag>
        <tag>istio-gateway</tag>
      </tags>
  </entry>
  <entry>
    <title>Istio 实践笔记</title>
    <url>/2024/03/04/K8S/istio/</url>
    <content><![CDATA[Istio 是服务网格，即ServiceMesh的一种实现，服务网格通常用于描述构成应用程序的网络以及它们之间的交互。在从单体应用向分布式微服务架构转型的过程中，虽然从中获益良多，但是随着规模和复杂性的增长，服务网格越来越难以理解，给开发人员和运维人员带来的挑战快速增加。这些挑战包括：服务发现，负载均衡，故障恢复，指标收集，监控以及一些更加复杂的运维需求，例如：A/B测试、金丝雀发布、限流、访问控制，端到端认证等。而 Istio 提供了一个完整的解决方案，通过为整个服务网格提供行为洞察和操作控制来满足微服务应用程序的多样化需求。
Istio 以非常简单的方式来为已部署的服务建立网络，对应用程序代码只需要进行一点或者不需要做任何改动，要想让服务支持Istio，只需要在应用旁边部署一个 sidecar 代理，使用 Istio 的控制面进行功能配置和管理代理，拦截服务之间的所有网络通信，已达到：HTTP、gRPC、WebSocket 和 TCP 流量的自动负载均衡；
通过丰富的路由规则、重试、故障转移和故障注入，可以对流量行为进行细粒度控制；
可插入的策略层和配置 API，支持访问控制、速率限制和配额；
对出入集群入口和出口中所有流量的自动度量指标、日志记录和追踪；
通过强大的基于身份的验证和授权，在集群中实现安全的服务间通信；综上，对 Istio 的核心功能可以总结为以下几点：流量管理，通过简单的规则配置和流量路由，可以控制服务之间的流量和API调用。Istio 简化了断路器、超时和重试等服务级别属性的配置，并且可以轻松设置A/B测试、金丝雀部署和基于百分比的流量分割的分阶段部署等重要任务；
安全，Istio 的安全功能使开发人员可以专注于应用程序级别的安全性。Istio 提供底层安全通信信道，并大规模管理服务通信的认证、授权和加密。使用Istio，服务通信在默认情况下是安全的，它允许您跨多种协议和运行时一致地实施策略——所有这些都很少或根本不需要应用程序更改；
可观察性，Istio 强大的追踪、监控和日志记录可让开发或者运维人员深入了解服务网格部署。通过 Istio 的监控功能，可以真正了解服务性能如何影响上游和下游的功能，而其自定义仪表板可以提供对所有服务性能的可视性；在架构上，Istio 服务网格逻辑上分为数据平面和控制平面，其中：数据平面由一组以 sidecar 方式部署的智能代理（Envoy）组成。这些代理负责协调和控制微服务之间的所有网络通信。 它们还收集和报告所有网格流量的遥测数据；
控制平面 管理并配置代理来进行流量路由；架构图如下图所示：Envoy：是用 C++ 开发的高性能代理，用于协调服务网格中所有服务的入站和出站流量。Envoy 代理是唯一与数据平面流量交互的 Istio 组件。Envoy 被部署为服务的 Sidecar，在逻辑上为服务增加了 Envoy 的许多内置特性，例如：动态服务发现，负载均衡，TLS 终端，HTTP/2 与 gRPC 代理，熔断器，健康检查，基于百分比流量分割的分阶段发布，故障注入，丰富的指标；
Sidecar 代理模型还允许您向现有的部署添加 Istio 功能，而不需要重新设计架构或重写代码。由 Envoy 代理启用的一些 Istio 的功能和任务包括：流量控制功能：通过丰富的 HTTP、gRPC、WebSocket 和 TCP 流量路由规则来执行细粒度的流量控制；
网络弹性特性：重试设置、故障转移、熔断器和故障注入；
安全性和身份认证特性：执行安全性策略，并强制实行通过配置 API 定义的访问控制和速率限制；
基于 WebAssembly 的可插拔扩展模型，允许通过自定义策略执行和生成网格流量的遥测；Istiod 将控制流量行为的高级路由规则转换为 Envoy 特定的配置， 并在运行时将其传播给 Sidecar。Pilot 提取了特定平台的服务发现机制，并将其综合为一种标准格式，任何符合 Envoy API 的 Sidecar 都可以使用。以及通过内置的身份和凭证管理，实现了强大的服务对服务和终端用户认证，可以使用 Istio 来升级服务网格中未加密的流量，这样运营商可以基于服务身份而不是相对不稳定的第3层或第4层网络标识符来执行策略。Istiod 还可以充当证书授权（CA），生成证书以允许在数据平面中进行安全的 mTLS 通信。 安装
本节使用 istioctl 安装 istio，可以从发布页面下载预编译的版本，在安装的时候根据需要选择不同的配置，这里为了后续的演示和示例，选择 demo 配置项，这将会安装 istio-ingressgateway、istio-egressgateway 和 istiod：istioctl install --set profile=demo可以通过下面的命令查看安装到集群中的 istio 的配置：kubectl -n istio-system get IstioOperator installed-state -o yaml可以通过下面的命令验证在集群中安装的资源信息：./bin/istioctl verify-install --revision default查看安装的 Pod、SVC 以及 Deploy 这些关键资源：kubectl get svc,pod,deploy -n istio-system -owide 功能介绍
接下来使用 istio 发布件中的 bookinfo 应用来演示 istio 的各项功能，首先是安装该应用，使用如下的步骤进行安装，：上面最重要的流程是给 bookinfo-test 命名空间添加了 istio-injection=enabled 标签，这样 istio 会为这个命名空间中的 pod 自动注入 istio-proxy 这个 Sidecar 容器。
 创建网关
这里有多种方式作为入口流量的网关，可以使用 Istio Gateway、K8S Gateway 以及 K8S Ingress，要注意的是 Istio Gateway 和 K8S Gateway 虽然资源名称是一样的，都叫 Gateway，但是它们在使用方式是完全不一样的，下面的示例中以 Istio Gateway 为示例进行。创建用于 bookinfo 应用的网关使用如下的命令：kubectl apply -n bookinfo-test -f samples/bookinfo/networking/bookinfo-gateway.yaml该 yaml 文件中的内容如下：上面的 yaml 中，Gateway 的 API 版本是 networking.istio.io/v1alpha3，这和 K8S Gateway 是完全不一样的，所以他们是两个完全不一样的资源。Gateway 中的 spec.selector 使用选择使用哪个 Pod 来处理该网关的请求，这里选择的是安装章节中在 istio-system 命名空间中创建的 pod/istio-ingressgateway-86446666f9-qn4f2，该 Pod 具有标签 istio=ingressgateway：kubectl describe pod -n istio-system stio-ingressgateway-86446666f9-tgmrp而 Gateway 中的端口 8080 匹配的到 pod/istio-ingressgateway-86446666f9-qn4f2 中暴露的端口 8080。集群的流量入口是从绑定到pod/istio-ingressgateway-86446666f9-qn4f2的service/istio-ingressgateway流入，然后根据 Gateway 所绑定的端口和配置将流量导入到最终的业务 Pod 中：kubectl describe svc -n istio-system istio-ingressgatewayistio-ingressgateway 的外部IP是 192.168.67.241，对于 bookinfo-gateway 流量从 192.168.67.241:80 进入，然后转发到 10.244.2.19:8080，再根据 Gateway 和 VirtualService 的配置分发流量，VirtualService 就像 K8S Gateway 中的路由，可以根据具体的匹配条件将流量分发到不同的应用。上面简单介绍了网关的概念和入口流量的处理流程，创建成功之后能够得到下面的资源：在上面的流程分析中，其实已经得到网关入口的地址。也可以使用下面的命令进行获取，如果环境中安装了 MetaLB，也就是 service/istio-ingressgateway 有 External-IP 的时候使用下面的方式：所以可以使用 http://192.168.67.241/productpage 访问应用。如果没有安装 MetaLB，也可以使用节点的公网IP和service/istio-ingressgateway的NodePort进行访问，如下也可以使用 http://192.168.67.8:30298/productpage 端口进行访问： 流量观测
为了能直观地看到上述服务中的流量转发情况，安装kiali和prometheus进行演示：kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.20/samples/addons/kiali.yaml
kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.20/samples/addons/prometheus.yaml安装成功之后，可以看到如下的 Service：kiali 默认是 ClusterIP 类型的，没法直接从外部进行访问，实验环境下可以将它改成NodePort或者LoadBlancer类型，这样就获得了从外部访问的入口。也可以通过下面的命令临时获得公网入口，172.19.106.26 是节点公网地址：刷新 productpage 页面几次，然后在 kiali 页面看到如下的请求示意图： 目标规则
在刷新产品页面的时候，会发现书籍的星级评分有时候有，有时候是红色的，有时候是黑色的，是因为服务的 reviews 的版本有三个，请求到不同的 pod 就会出现不同的结果：目标规则的意思就是将这些相同服务但不同版本以显示的方式指定，然后可以供 VirtualService 在转发流量是进行选择，在继续后面的章节之前，先应用默认的路由规则：kubectl apply -n bookinfo-test -f samples/bookinfo/networking/destination-rule-all.yaml在 destination-rule-all.yaml 有一些用于后续实验的规则，挑其中一个进行说明：这里的 host 指的是服务的名称，subsets 用来声明这个服务内在的版本，这里指定了三个版本v1、v2和v3，分别用三个标签指向3个reviews的Pod。
 流量管理
Istio 的流量管理功能可以体现在路由版本分发，故障注入，流量转移，请求设置超时，熔断，地域负载均衡等过个方面。
 路由版本分发
本节继续基于前面的测试，将路由分发到具体的版本，例如，在这之前，刷新产品页面数据的评论信息一直在变动，这里通过简单的配置让他们都访问 v1 版本：virtual-service-all-v1.yaml 中的内容如下，拿 reviews 这个 VirtualService 的配置来说，它会让所有访问 reviews 服务的请求都转发到 v1 版本：此时如果再去刷新产品页面，评论信息是不会再有所变动的。还可以匹配具体的HTTP头信息，让具有某个请求头的用户访问某个版本。例如，更新刚才创建的review VirtualService，让用户jason访问 v2版本：kubectl apply -n bookinfo-test -f samples/bookinfo/networking/virtual-service-reviews-test-v2.yaml使用jason登录，密码任意，然后发现不管怎么刷新页面，书籍的评论都是固定的黑色星级样式。截止到目前，请求的流程如下所示：productpage → reviews:v2 → ratings (针对 jason 用户)
productpage → reviews:v1 (其他用户) 故障注入
故障注入可以分为延迟故障和abort故障。例如，针对下面的测试，在jason用户在访问ratings服务时，会引入1个7s的延迟：kubectl apply -n bookinfo-test -f samples/bookinfo/networking/virtual-service-ratings-test-delay.yaml如下在jason用户在访问ratings服务时，引入500响应，此时访问产品页，在评论的地方会出现 Ratings service is currently unavailable 这样的信息：kubectl apply -n bookinfo-test  -f samples/bookinfo/networking/virtual-service-ratings-test-abort.yaml清除本节注入的故障:kubectl delete -n bookinfo-test -f samples/bookinfo/networking/virtual-service-ratings-test-delay.yaml
kubectl delete -n bookinfo-test  -f samples/bookinfo/networking/virtual-service-ratings-test-abort.yaml 流量转移
流量转移通常用于版本升级过程中新版本不完全可信的时候，可以只将少部分的流量转移到新版本进行测试，待测试通过之后，再讲全部的流量进行导入。为了验证，这里先讲所有的流量都恢复到所有应用的v1版本：kubectl apply -n bookinfo-test -f samples/bookinfo/networking/virtual-service-all-v1.yaml此时，假设对 reviews 应用进行了版本升级，要导入一部分流量进行测试，这里将导入50%的流量到reviews v3应用：kubectl apply -n bookinfo-test -f samples/bookinfo/networking/virtual-service-reviews-50-v3.yaml此时刷新产品页，应该有50%的几率看到红色的星级评价。如果测试完成，可以将全部流量导入到reviews v3：kubectl apply -n bookinfo-test -f samples/bookinfo/networking/virtual-service-reviews-v3.yaml 请求超时
将所有对 reviews 的访问都路由到 v2 版本，并且设置对ratings的访问增加固定的2s延迟：此时刷新产品页，页面响应正常，但是有2s延迟。现在设置对reviews的访问最大0.5s超时：再去刷新页面，发现页面会在1s左右响应，但是评论获取失败。可以使用下面的命令将应用恢复到所有服务的v1版本：kubectl apply -n bookinfo-test -f samples/bookinfo/networking/virtual-service-all-v1.yaml TCP流量转移
在测试之前首先设置测试环境：创建命名空间
kubectl create namespace istio-io-tcp-traffic-shifting
部署 sleep 应用程序，作为请求的测试源
kubectl apply -f samples/sleep/sleep.yaml -n istio-io-tcp-traffic-shifting
部署 tcp-echo 服务的 v1 和 v2 版本，作为服务端
kubectl apply -f samples/tcp-echo/tcp-echo-services.yaml -n istio-io-tcp-traffic-shifting首先将所有流量路由到v1版本的tcp-echo，VirtualService 中根据端口进行匹配：kubectl apply -f samples/tcp-echo/tcp-echo-all-v1.yaml -n istio-io-tcp-traffic-shifting然后确定TCP流量的入口端口和IP，使用下面的命令进行获取：发送流量进行测试，响应都来自tcp-echo的v1版本（时间戳前面的one代表v1版本）:接下来将20%的流量路由到v2版本：kubectl apply -f samples/tcp-echo/tcp-echo-20-v2.yaml -n istio-io-tcp-traffic-shifting然后再进行测试，发现有20%的响应带有two前缀：清理使用下面的命令：kubectl delete ns --cascade istio-io-tcp-traffic-shifting 熔断
常见的服务容错措施包括，主动超时，限流，熔断，隔离，降级，其中熔断是指类似保险丝的保护措施，当某个异常情况出现时，切断前端服务和后端服务之间的链接，保护后端服务不受冲击。为了验证熔断场景的，首先做一些准备工作：创建命名空间并且设定标签：kubectl create ns circuit-breaking-test
kubectl label ns circuit-breaking-test istio-injection=enabled创建用于测试的服务端：kubectl apply -n circuit-breaking-test -f samples/httpbin/httpbin.yaml配置熔断器，设置熔断规则，这里指定连接池的最大连接数是1，最大等待等请求数是1，这意味着如果并发的连接和请求数超过一个，在istio-proxy进行进一步的请求和连接时，后续的请求或者连接都会被阻止：创建用于测试的客户端，这里使用fortio，它可以控制连接数、并发数及发送HTTP请求的延迟，通过Fortio能够有效的触发前面在DestinationRule中设置的熔断策略：kubectl apply -n circuit-breaking-test -f samples/httpbin/sample-client/fortio-deploy.yaml进入fortio客户端进行测试：触发熔断规则，设置并发数3，结果显示只有30%的请求成功：查看 istio-proxy 的状态以了解更多熔断的信息：kubectl exec -n circuit-breaking-test &quot;$FORTIO_POD&quot; -c istio-proxy -- pilot-agent request GET stats | grep httpbin | grep pending清理测试现场使用如下方式：kubectl delete ns --cascade circuit-breaking-test 安全网关
前面章节创建的网关都是非安全类型的，本节演示如何使用 TLS 或者 mTLS 公开安全的 HTTPS 服务。首先，创建命名空间及部署用于测试httpbin服务：kubectl create ns istio-tls-ingress-test
kubectl apply -n istio-tls-ingress-test -f samples/httpbin/httpbin.yaml使用mkcert创建证书并且上传：mkcert --cert-file httpbin.example.com.crt --key-file httpbin.example.com.key httpbin.example.com
kubectl create -n istio-system secret tls httpbin-credential --key=httpbin.example.com.key --cert=httpbin.example.com.crt紧接着创建Gateway 和 VirtualService，为httpbin.example.com配置证书：获取安全入口网关的地址和端口：mkcert 的根证书如果没有安装到系统的证书链中，可以在请求的时候显示添加。使用下面的命令查看 mkcert 的根证书位置:使用 curl 命令进行测试： mTLS
还可以配置服务端来验证客户端的是不是可信的，首先创建的包含证书的httpbin-credential需要包含CA证书：kubectl delete secret -n istio-system httpbin-credential
kubectl create -n istio-system secret generic httpbin-credential --from-file=tls.key=httpbin.example.com.key \
  --from-file=tls.crt=httpbin.example.com.crt --from-file=ca.crt=/root/.local/share/mkcert/rootCA.pem然后将 mygateway 的 tls 模式设置为 MUTUAL：在不提供客户端证书和私钥的情况下访问服务端必然错误：要解决该问题，首先需要生成客户端证书：mkcert -client --cert-file client.crt --key-file client.key client.example.com然后附带客户端证书再去访问：清理现场使用如下的命令：kubectl delete ns --cascade istio-tls-ingress-test
kubectl delete secret -n istio-system httpbin-credential TLS 终止
TLS 终止（也被称为 SSL 终止）是一个网络架构策略，其中 TLS/SSL 的连接或会话是在网络的某一层次上“终止”的，而不是在目标应用服务器上。这意味着解密操作（以及在响应中重新加密操作）发生在这一层次，而不是在实际的应用服务器上。这经常用于负载均衡器或专用的硬件设备中。简单来说就是在应用的入口处使用 tls，然而内部就全部采用 HTTP 协议，这样既保证了从外部进入的流量的安全，也保证了性能。
接下来会在一个名叫tls-terminate-test的命名空间中部署httpbin应用，期望在命名空间内使用http协议就可以访问引用，但是从其他命名空间访问时就必须使用安全的协议。为了实现这一点，得启用 ENABLE_TLS_ON_SIDECAR_INGRESS 功能：istioctl install --set profile=demo --set values.pilot.env.ENABLE_TLS_ON_SIDECAR_INGRESS=true然后创建命名空间：kubectl create ns tls-terminate-test
kubectl label namespace tls-terminate-test istio-injection=enabled在该命名空间内，默认对所有工作负载启用 mTLS 功能，PeerAuthentication 定义是否以安全的方式将流量导入到 Sidecar：创建用于客户端和服务端的证书：mkcert --cert-file httpbin.svc.crt --key-file httpbin.svc.key httpbin.tls-terminate-test.svc.cluster.local
mkcert -client --cert-file client.crt --key-file client.key client.tls-terminate-test.svc.cluster.local上传服务端的证书以及CA证书：kubectl -n tls-terminate-test create secret generic ca-secret --from-file=ca.crt=/root/.local/share/mkcert/rootCA.pem
kubectl -n tls-terminate-test create secret tls httpbin-svc-secret --cert httpbin.svc.crt --key httpbin.svc.key部署测试应用，在下面的模板使用 sidecar.istio.io/userVolumeMount 注解为 istio-proxy Sidecar 挂载证书，目前 Istio Sidecar 还不支持 credentialName 配置：接下来配置 Sidecar 让它监听 9433 和 9080 端口的流量，并且在 9443 端口上启用 mTLS 验证：最后为了达到能在应用内部通过 http 协议进行访问的目标，使用 PeerAuthentication 禁用 9080 的 mTLS 验证：准备就绪之后，开始测试，首先安装在 tls-terminate-test 和 default 安装客户端：kubectl apply -f samples/sleep/sleep.yaml
kubectl -n tls-terminate-test apply -f samples/sleep/sleep.yaml然后在tls-terminate-test内部测试80端口的可用性：从外部测试443端口的可用性，从外部测试，需要将客户端证书复制到default.sleep中再进行测试，443端口请求成功，而80端口则被拒绝：清理测试现场使用如下的命令：kubectl delete ns --cascade tls-terminate-test
kubectl delete svc,deploy sleep TLS 非终止
TLS 终止是将安全会话在网关层结束掉，在流量进入内部的时候，使用非安全协议以提升性能，TLS 非终止的意思就是将安全流量直接送达到应用，那么应用也需要能够处理安全流量。为了验证，首先做以下准备：mkcert --cert-file nginx.example.com.crt --key-file nginx.example.com.key nginx.example.com
kubectl create ns tls-passthrough-test
kubectl create -n tls-passthrough-test secret tls nginx-tls-secret --cert=nginx.example.com.crt --key=nginx.example.com.key将下面的的Nginx的配置信息保存在nginx.conf文件中：从配置文件创建 configmap：kubectl create -n tls-passthrough-test configmap nginx-configmap --from-file=nginx.conf=./nginx.conf创建应用，挂载配置文件以及证书：创建网关和路由，注意的是这里网关tls的模式是PASSTHROUGH，路由信息中也是用了 SNI 匹配具体的 nginx.example.com 的流量：获取网关的安全入口：使用 curl 命令进行测试：清理测试环境：kubectl delete ns --cascade tls-passthrough-test 指标可视化
本节的展示需要安装 Grafana 和 prometheus 组件，以及部署 bookinfo 测试应用。如果没有部署的话，可以按照下面的命令：kubectl create ns bookinfo-test
kubectl label namespace bookinfo-test istio-injection=enabled
kubectl apply -n bookinfo-test -f samples/bookinfo/platform/kube/bookinfo.yaml
kubectl apply -n bookinfo-test -f samples/bookinfo/networking/bookinfo-gateway.yaml
kubectl apply -f samples/addons/grafana.yaml
kubectl apply -f samples/addons/prometheus.yaml等待所有的 pod 就绪之后，可以在 istio-system 命名空间中看到如下的服务：通过下面的方式获取网关的入口：请求 http://192.168.67.241/productpage，以获得数据，可以使用压测工具持续发送流量。打开 prometheus 查看指标：istioctl dashboard prometheus --address 192.168.67.241输入查询语句以获得指标和图标可视化：istio_requests_totalGrafana 是一个开源的监控解决方案，可以用来为 Istio 配置仪表板。使用如下的命令打开 grafana 指标：istioctl dashboard grafana --address 192.168.67.241打开 http://192.168.67.241:3000/dashboards 页面，可以查看相关的指标： 插入CA证书
本节为了测试，最好卸载重新安装 istio：istioctl uninstall --purge
istioctl install --set profile=demo
kubectl create namespace istio-system这里导入 mkcert 的根证书，保存在 istio-system 命名空间中名为 cacerts 的 secret 中：部署应用进行测试：kubectl create ns foo
kubectl apply -f &lt;(istioctl kube-inject -f samples/httpbin/httpbin.yaml) -n foo
kubectl apply -f &lt;(istioctl kube-inject -f samples/sleep/sleep.yaml) -n foo在 foo 命名空间中部署一个策略，只接受双向 mTLS 流量：等待策略生效并且导出证书：解析证书链中的证书：验证服务的证书是否OK：也可以通过下面的的方式查看Pod证书： 增加端口
istio 默认的网关只有固定的几个端口，如果有需要新增端口，可以按照下面的流程操作。首先编辑 istio-ingressgateway 增加端口：部署应用进行验证：清理现场使用：kubectl delete ns --cascade custom-port-test 参考链接https://istio.io/latest/docs/
https://www.ctyun.cn/developer/article/453939699036229]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>istio</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes CNI 网络</title>
    <url>/2023/12/29/K8S/k8s-cni-network/</url>
    <content><![CDATA[在容器网络-跨主机容器通信中，我们使用flannel实现了容器的跨主机通信，在使用kubeadm创建多借点集群时，在集群初始化之后，首先安装了kube-flannel CNI插件，用于k8s集群pod之间互通，这是集群节点Ready的必要条件，因为k8s自身并不能实现pod之间互通，需要借助CNI完成此功能。
单机容器通信是将主上的容器通过连接在docker0网桥实现，然后跨主机容器通信是通过vxlan中的flannel.x设备实现跨主机之间的容器通信，k8s的flannel-cni插件处理不同pod之间互通的方式就和跨主机容器通信的方式一样，只不过在k8s集群中将用于单机上容器互通的docker0网桥换成了cni0。
k8s之所以要创建一个与docker0功能相同的网桥，是因为k8s并没有使用Docker的网络模型，它并不希望和Docker之间有强依赖，所以不具备配置这样一个网桥的能力。
所以在使用flannel-cni插件的模式下，k8s之间不同pod互通的模式下如下图所示，和容器网络-跨主机容器通信唯一区别是网桥名称的变化： Pod网络创建
在使用kubeadm创建多借点集群中，使用了如下的命令的来初始化flannel-cni 插件：kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml这个过程会在各个节点上创建flannel-cni的配置，并且会运行一个和容器网络-跨主机容器通信中flanneld相同功能的Flannel DaemonSet，flannel DaemonSet的配置以ConfigMap的形式创建并且挂到了容器中，如果你初始化k8s集群时没有使用10.244.0.0/16这个Pod网络，就需要修改kube-flannel.yml。可以使用如下命令查看配置信息：kubectl describe configmaps -n kube-flannel kube-flannel-cfgflannel-cni的配置也是放在了kube-flannel-cfg中，它最终挂在到了每个节点上的 /etc/cni/net.d/10-flannel.conflist 中：还有它会把flannel-cni的二进制文件放在节点上的 /opt/cni/bin/flannel：这个配置文件的使用者是CRI，在我的集群配置中就是containerd，由CRI容器运行时负责调用CNI实现Pod的网络配置。这里要注意的是，目前k8s不支持多个CNI插件使用，所以即使你在/etc/cni/net.d/目录中配置多个CNI插件，它也只会加载一个，可以点击查看containerd 默认配置：在containerd启动的过程中，会读取配置：当kubelet创建Pod的时候，它首先调用containerd的RunPodSandbox方法创建一个沙盒，在这个沙盒里面创建用于pod内网络共享的的命名空间并且设置网络，而containerd并不会自己创建网络，它必须调用flannel-cni插件来实现，所以在这个 RunPodSandbox 中就是准备flannel-cni 所需的参数，并且调用它，这部分的实现主要在setupPodNetwork中： CNI插件参数
从cni-operations规范我们可以看到，它定义了四种操作：ADD，DEL，CHECK 和 和VERSION，其实有用的只有ADD，DEL，给这两操作传递参数是通过环境变量和标准输入进行的。以ADD操作为例，我们需要在调用CNI插件的时候，将操作的名称通过环境变量CNI_COMMAND设置，另外还需要设置CNI_IFNAME（网卡名称）、CNI_NETNS（Pod的网络命名空间路径）以及 CNI_CONTAINERID（容器ID）。
对于 flannel-cni 为例，它实现 CNI 的插件在 /opt/cni/bin/flannel，我们来看看它里面实现的ADD操作如下：/opt/cni/bin/flannel在每次被调用的时候会读取配置每个节点上的配置文件 /run/flannel/subnet.env，这部分代码实现请看这里。在setupPodNetwork中，沿着 netPlugin.SetupSerially 最终会到达这里，由它去调用/opt/cni/bin/flannel:打开containerd的debug日志之后，通过下面的命令可以查看在创建Pod的时候，通过标准输入提供给/opt/cni/bin/flannel的参数：SYSTEMD_LESS=&quot;&quot; journalctl  -eu containerd点击查看示例上面的参数还会保存在/var/lib/cni/flannel/路径下，按照PodID保存：而且在/var/lib/cni/networks/cbr0/目录下还保存了已分配的IP和Pod的对应关系，cbr0指的是网络插件的名称，和 /etc/cni/net.d/10-flannel.conflist 里面的保持一致： 通用网络插件
当我们去看 /opt/cni/bin/flannel 的代码实现的时候，发现它并没有做什么创建网络的操作，它又调用了其他的插件：从CRI传递给flannel的参数来看，实际调用的是bridge，所以说 flannel 这个网络插件实际上并没有做什么，他把具体的活又委托了出去。在flannel-cni插件的配置中有一个delegate字段，这个字段的意思表明了这个插件需要调用其他CNI的内置插件来完成，对于flannel来说，如果没有指定，就是 bridge，这些通用的网络插件 由官方维护，它会被统一安装在 /opt/cni/bin 目录下：这些插件可以分为三类：Main插件，它们是用来创建具体网络设备的二进制文件，比如：bridge、ipvlan、loopback、tap、macvlan 等；
IPAM插件，负责IP地址的分配，比如 dhcp，它会向DHCP服务器发起请求；host-local 会使用预先配置的地址段来进行分配，flannel 使用这种方式，它的本机上的分配的地址段放在了/run/flannel/subnet.env文件中，已分配的IP放在了 /var/lib/cni/networks/cbr0/ 中；
Meta插件，例如通过sysctl调整网络设备参数的tuning，通过iptables配置端口映射的portmap，以及使用TBF来进行限流的bandwidth等，flannel也属于这一类，委托其他插件干活；这些插件可以从containernetworking/plugins 预编译的包中获取，解压到 /opt/cni/bin 目录下就可以了。
我们的cni0网桥就是在bridge中创建的，它在创建Pod网络的时候会检查cni0是否存在，不存在就创建，具体代码可以查看这里。
通过一些简单的命令来演示下上述bridge创建网络的过程，首先 bridge 会检查宿主机上的 cni0 是否存在，没有的话就创建，相当于：接下来就是进入到pod的网络空间内，创建一对 veth 设备，并且把其中一端移动到Host上：然后在宿主机上将 vethb4963f3 加入 cni0 网桥：这部分请看这里，如下所示：这里有意思的是在将veth设备加入到网桥之后，还会将它设置为发夹模式（HairPin Mode），这是因为默认情况下，网桥设备不允许数据包从一个端口进来再从这个端口出去，但是设置为HairPin Mode就取消这个限制了。
这个特性，主要用在容器需要通过NAT（即：端口映射）的方式，自己访问自己的场景下。举个例子，比如我们执行docker run -p 8080:80，就是在宿主机上通过iptables设置了一条DNAT（目的地址转换）转发规则。这条规则的作用是，当宿主机上的进程访问＜宿主机的IP地址＞:8080时，iptables会把该请求直接转发到＜容器的IP地址＞:80上。也就是说，这个请求最终会经过docker0网桥进入容器里面。但如果是在容器里面访问宿主机的8080端口，那么这个容器里发出的IP包会经过vethb4963f3设备（端口）和docker0网桥，来到宿主机上。此时，根据上述DNAT规则，这个IP包又需要回到docker0网桥，并且还是通过vethb4963f3端口进入到容器里。所以，这种情况下，我们就需要开启vethb4963f3端口的Hairpin Mode了。
因此，Flannel插件要在CNI配置文件里声明hairpinMode=true。这样，将来这个集群里的Pod才可以通过它自己的Service访问到自己。
接下来，bridge插件会调用CNI ipam插件，从ipam.subnet字段规定的网段里为容器分配一个可用的IP地址。然后，CNI bridge插件就会把这个IP地址添加在容器的eth0网卡上，同时为容器设置默认路由。这相当于在容器里执行：最后bridge会为cni0设置IP地址，相当于执行：上述这一系列昨晚之后，CNI插件会把结果一路返回到containerd中，这是我们从containerd的日志中获取到的结果信息： 多个网络插件
通常 Pod 内只有一个 eth0 网口，如果通过创建多个网络接口实现网络流量隔离，可以考虑使用multus-cni。Multus CNI 是 Kubernetes 的一个容器网络接口 (CNI) 插件，可为 Pod 附加多个网络接口。下面是由 Multus CNI 提供的连接到 pod 的网络接口示意图。图中显示 pod 有三个接口：eth0、net0 和 net1。eth0 连接 kubernetes 集群网络，用于连接 kubernetes 服务器（如 kubernetes api-server、kubelet 等），属于集群默认网络。net0 和 net1 是附加网络接口，通过使用其他 CNI 插件（如 vlan/vxlan/ptp）连接其他网络。Multus CNI 有两种类型，thick and thin，其中 thick 由 multus-daemon 和 multus-shim 两个二进制文件组成 插件。multus-daemon 将作为本地代理部署到所有节点，相比 thin 具备额外功能（如度量），由于具有这些附加功能，要比 thin 消耗更多资源。Multus CNI 需要部署在已经安装默认 CNI 的集群中，并将其作为集群网络插件，可以参考它的 quick-start 进行安装，这里使用 thick 类型：kubectl apply -f https://raw.githubusercontent.com/k8snetworkplumbingwg/multus-cni/master/deployments/multus-daemonset-thick.yml安装之后，可以看到类似的Pod正常运行即可：如果遇到启动失败，提示 Error response from daemon: path /opt/cni/bin is mounted on / but it is not a shared mount 这样的信息时，需要将Host的/目录标记为共享的，在Host上执行命令 mount --make-rshared /。如果默认的 CNI 插件使用 cilium，需要编辑它的Agent配置，设置 cni-exclusive: &quot;false&quot;（kubectl edit cm -n kube-system cilium-config）。
接下来创建附加网络的定义，这里的 master 指的的 macvlan 模式下的父接口，不同的插件配置有所不同：然后创建 Pod 进行测试：验证 samplepod 具有多个网口 net1 和 eth0： 参考链接CNI
CNI with Multus
Use Multus CNI in Kubernetes
Kubernetes Network Model]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>cni</tag>
        <tag>multus-cni</tag>
        <tag>flannel</tag>
        <tag>cni plugin</tag>
      </tags>
  </entry>
  <entry>
    <title>K8S 容器编排</title>
    <url>/2024/01/10/K8S/k8s-job-manage/</url>
    <content><![CDATA[Pod 是K8S中的调度单位，它是一个逻辑概念，用于将一些关系密切的容器部署在一起提供对外服务，这些容器互相之间会发生直接的文件交换、使用localhost或者Socket文件进行本地通信、会发生非常频繁的远程调用、需要共享某些Linux Namespace等等，Pod 中的所有容器都共享同一个Network Namespace。K8S 中为了实现不同的目的，在Pod基础之上衍生出了不同的部署模型，例如，常见的 Deployment、Replicaset、以及StatefulSet等等，本文就来举例并且说明它们之间的区别。
这些对象之间的关系如下图所示： Pod
Pod 这个看似复杂的API对象，实际上就是对容器的进一步抽象和封装而已，Pod对象，其实就是容器的升级版，它对容器进行了组合，添加了更多的属性和字段。依据PodAPI 编写一个Pod模板，然后使用kubectl提交到集群中，这个Pod里面包含两个容器，whoami监听80端口，提供一个简单的服务返回主机名，nettool 是一个工具容器，提供了很多可用的网络工具供测试使用：执行之后，使用下面的命令查看创建成功的Pod：查看Pod中的容器：进入nettool，通过localhost就能访问whoami容器中的服务，因为它们共享网络栈，在同一个网络空间内：测试环境中使用docker作为容器运行时，查看Pod中的容器时，会存在一个pause容器，它使用的是一个非常特殊的镜像，叫作：k8s.gcr.io/pause，这个镜像是一个用汇编语言编写的、永远处于暂停状态的容器，解压后的大小也只有100~200 KB左右。在这Pause容器启动之后，Pod中的其他容器就可以加入这个Pause容器的命名空间，从而实现共享，但是mnt、pid以及uts这三个命名空间默认不共享，pid可以通过spec.shareProcessNamespace单独设置：清理现场使用下面的命令：kubectl delete ns --cascade whoami ReplicaSet
Pod 将具有亲密关系的容器部署在同一个盒子中，统一对外提供服务，但是当流量较多的时候，单个Pod就无法支撑，这个时候就需要多个实例，这正是ReplicaSet的意义，为Pod提供多实例部署，根据需要实现水平扩缩容。下面是一个ReplicaSet对象的示例：相较于Pod，ReplicaSet 增加了一些字段：.spec.replicas 表示这个 ReplicaSet 对象的副本个数，会将匹配的Pod扩展到这个数量；
.spec.selector.matchLabels 用于匹配根据标签Pod，表示这个ReplicaSet对象要作用到哪些Pod上；
.spec.template 是一个完整的Pod模板，用于描述这个ReplicaSet管理的Pod，其中.spec.template.metadata.labels 用于给Pod打标签，通常它至少包含.spec.selector.matchLabels，这样ReplicaSet的策略才能作用到这个Pod，.spec.template.spec.containers 就是用来描述Pod中的容器；执行上面的命令之后，查看新建的的Pod 和 ReplicaSet 对象，这3个不同的Pod表示不同的副本：在 rs 的输出中，DESIRED 表示期望的副本数量，CURRENT 表示当前处于 Running 状态的数量，READY 表示既是 Running 又健康检查ok的数量，关于健康检查请看这里。清理现场使用下面的命令：kubectl delete ns --cascade rs Deployment
通常情况下，我们在生产环境不会直接使用 ReplicaSet，因为它不支持滚动更新，所谓的滚动更新就是当我们升级Pod的时候，可以在不中断服务的情况下，通过交替升级的方式，让所有的Pod都达到最新的状态，除此之外还可以实现版本控制，根据需要回滚到具体的版本，这些操作对于 ReplicaSet 就得手动操作。下面是一个Deployment的示例：相比 ReplicaSet，主要增加了 .spec.strategy 字段，其中：.spec.strategy.type，表示Pod更新时的策略，默认是RollingUpdate，表示滚动更新，如果取值 Recreate，它会直接将老的Pod停止，再创建新的Pod；
.spec.strategy.rollingUpdate，表示滚动更新时的策略：maxUnavailable，它是一个可选字段，用来指定更新过程中不可用的Pod的个数上限。该值可以是绝对数字（例如，5），也可以是所需 Pod 的百分比（例如，10%）。百分比值会转换成绝对数并去除小数部分。 如果 maxSurge 为 0，则此值不能为 0。 默认值为 25%。例如，当此值设置为30%时，滚动更新开始时会立即将旧ReplicaSet缩容到期望Pod个数的70%。新Pod准备就绪后，可以继续缩容旧有的ReplicaSet，然后对新的ReplicaSet扩容，确保在更新期间可用的Pod总数在任何时候都至少为所需的Pod个数的70%。
maxSurge，是一个可选字段，用来指定可以创建的超出期望Pod个数的Pod数量。此值可以是绝对数（例如，5）或所需Pod的百分比（例如，10%）。如果MaxUnavailable为0，则此值不能为0。百分比值会通过向上取整转换为绝对数。此字段的默认值为25%。例如，当此值为30%时，启动滚动更新后，会立即对新的ReplicaSet扩容，同时保证新旧Pod的总数不超过所需Pod总数的130%。一旦旧Pod被杀死，新的ReplicaSet可以进一步扩容，同时确保更新期间的任何时候运行中的Pod总数最多为所需Pod总数的130%。执行上面的部署命令之后，查询pod、rs以及deployment的状态如下所示：kubectl get pod,rs,deploy -n deploy-test -owide从这可以看到，Deployment 通过控制 ReplicaSet来满足Pod 数量的要求，相比ReplicaSet增加了以下字段：UP-TO-DATE：表示当前处于最新版本的Pod数量，所谓最新版本指的是Pod的Spec部分与Deployment里Pod模板里定义的完全一致；
AVAILABLE：当前已经可用的Pod的个数，即：既是Running状态，又是最新版本，并且已经处于Ready（健康检查正确）状态的Pod的个数； 更新
使用下面的命令更新Pod：kubectl set image -n deploy-test deployment/nginx-deploy nginx=nginx:1.16.1 --record执行结束之后，查询pod、rs以及deployment的状态如下所示：可以看到旧的nginx-deploy-6b5d947665已经被缩容至0个Pod，新建的nginx-deploy-5dd86f689f被扩容至3个Pod。通过查看nginx-deploy的详情，可以看到滚动更新的过程：kubectl describe deploy -n deploy-test nginx-deploy滚动更新过程中可以使用下面的命令查看滚动更新的过程：kubectl rollout status -n deploy-test deployment/nginx-deploy滚动更新的历史可以使用下面的命令查看：kubectl rollout history -n deploy-test deployment/nginx-deploy 回滚
当更新出错，或者需要回滚到历史版本的时候，可以使用下面的命令进行操作，--to-revision指定目标历史版本：kubectl rollout undo -n deploy-test deployment/nginx-deploy --to-revision=1 缩放
可以使用下面的命令对Deployment 进行扩缩容：kubectl scale deployment/nginx-deploy -n deploy-test --replicas=5 StatefulSet
在Deployment中，所有Pod是完全一样的，它们互相之间没有顺序，也无所谓运行在哪台宿主机上。需要的时候，Deployment就可以通过Pod模板创建新的Pod，不需要的时候，Deployment就可以杀掉任意一个Pod。但是，在实际的场景中，并不是所有的应用都可以满足这样的要求。尤其是分布式应用，它的多个实例之间，往往有依赖关系，比如：主从关系、主备关系。还有就是数据存储类应用，它的多个实例，往往都会在本地磁盘上保存一份数据。而这些实例一旦被杀掉，即便重建出来，实例与数据之间的对应关系也已经丢失，从而导致应用失败。所以，这种实例之间有不对等关系，以及实例对外部数据有依赖关系的应用，就被称为有状态应用（Stateful Application）。Kubernetes项目很早就在Deployment的基础上，扩展出了对有状态应用的初步支持，这个编排功能，就是：StatefulSet，它提供了：稳定的、唯一的网络标识符，持久的数据存储，相较于 Deployment，StatefulSet直接管理的是Pod，而不是ReplicaSet，这是因为，StatefulSet里的不同Pod实例，不再像ReplicaSet中那样都是完全一样的，而是有了细微区别的。比如，每个Pod的hostname、名字等都是不同的、携带了编号的。而StatefulSet区分这些实例的方式，就是通过在Pod的名字里加上事先约定好的编号。
 网络持久化
先来看下网络持久化是怎么做到的，下面是用来验证的示例：当执行上面的命令之后，除了创建 StatefulSet 对象之外，还会创建一个nginx无头服务：kubectl get pods,sts,svc -n sts-test -owide这个nginx无头服务创建之后，它所代理的Pod都会被分配一个固定的DNS记录，如下面的格式：&lt;pod-name&gt;.&lt;svc-name&gt;.&lt;namespace&gt;.svc.cluster.local使用下面的命令进入nettool这个工具容器进行验证，可以看到每个Pod的地址都被正确解析，StatefulSet中的.spec.serviceName字段就是告诉StatefulSet控制器，在创建这写Pod的时候，使用nginx这个无头服务来保证Pod的网络身份稳定：kubectl exec nginx-sts-0 -n sts-test -it -c nettool -- /bin/bash从上面的Pod的名字也可以看出和Deployment的区别，StatefulSet使用固定了的编号，&lt;sts-name&gt;-&lt;index&gt;，这些编号从0开始累加，而且这些Pod的创建也是严格按照编号顺序进行的，在nginx-sts-0进入Ready之前，nginx-sts-1会一直Pending。而且即使将nginx-sts-0删除之后，创建出来的Pod名称依然是nginx-sts-0，这就是所谓的网络持久化，网络身份固定，当我们使用 nginx-sts-0.nginx 这个域名访问时，依然可以解析到正确的Pod，但是IP发生了变化，所以对于有状态的实例进行访问，应该使用域名： 存储持久化
有状态Pod除了网络身份持久化之外，就是存储状态持久化了，希望在Pod重启或者重建之后，依然保证数据库不丢失。在开始之后，需要先制作PV供有状态的Pod使用，本地测试为了简单，直接使用hostpath来制作。选定k8s中的某个节点，例如，ctrlnode，执行下面的命令：给ctrlnode打上标签是为了后面在创建StatefulSet的时候，让Pod都调度到ctrlnode上。接下来创建PV以及Pod：创建成功之后，可以使用下面的命令进行验证：kubectl get pv,pvc,svc,sts,pod -n sts-test -owide可以看到的是3个Pod都绑定到了不同的PV，可以使用下面的命令进行验证：for i in 0 1 2; do kubectl exec nginx-sts-$i -n sts-test -c nettool -- curl localhost; done有状态的Pod会有数据数据写入到Pod挂载的Volume中，模拟这个写入，可以使用下面的命令将主机明写入到index.html中：for i in 0 1 2; do kubectl exec nginx-sts-$i -n sts-test -c nginx -- sh -c 'echo hello $(hostname) &gt; /usr/share/nginx/html/index.html'; done此时查看ctrlnode上的/mnt/k8s/hostpath/中的内容，也会被相应的修改。有状态的Pod重点在于Pod重建数据不丢失，所以即使现在删除3个Pod之后，重建出来的Pod还是会挂载原来的数据卷，也就是从nginx-sts-0中访问到的依然是hello nginx-sts-0：这是因为当把一个Pod，比如nginx-sts-0，删除之后，这个Pod对应的PVC和PV，并不会被删除，而这个Volume里已经写入的数据，也依然会保存在ctrlnode的/mnt/k8s/hostpath/下。Pod重建的时候，StatefulSet还为每一个Pod分配并创建一个同样编号的PVC，所以还是会使用www-nginx-sts-0这个PVC去申请存储并且和nginx-sts-0绑定，由于这个PVC并未被删除，所以直接绑定即可，数据还是原来的。通过这种方式，Kubernetes的StatefulSet就实现了对应用存储状态的管理，实现了存储持久化。
 滚动更新
如果我们指定StatefulSet的更新策略，默认就是：RollingUpdate，在发生更新时，它会以Pod编号相反的顺序进行，从最后一个Pod开始，逐一更新这个StatefulSet管理的每个Pod，而如果更新发生了错误，这次“滚动更新”就会停止。
例如，使用下面的命令更新nginx容器的镜像版本，命令的意思是，以补丁的方式（JSON格式的）修改一个API对象的指定字段，也就是在后面指定的spec/template/spec/containers/0/image：kubectl patch statefulset nginx-sts --type='json' -p='[&#123;&quot;op&quot;: &quot;replace&quot;, &quot;path&quot;: &quot;/spec/template/spec/containers/0/image&quot;, &quot;value&quot;:&quot;nginx:1.16.1&quot;&#125;]'从Pod的启动时间就可以看出谁时最后一个启动的： 现场清理
清理测试环境执行以下命令：kubectl delete ns --cascade sts-test
kubectl delete pv pv-hostpath-v1 pv-hostpath-v2 pv-hostpath-v3 DaemonSet
DaemonSet的主要作用在集群中的每个节点上都运行一个Pod，而且只有一个，当有新的节点加入Kubernetes集群后，该Pod会自动地在新节点上被创建出来；而当旧节点被删除后，它上面的Pod也相应地会被回收掉，通常用于网络插件的Agent组件、日志组件以及监控组件等。
下面是一个DS的示例，区别比较大的是它不用声明副本的数量，spec.template.spec.tolerations 是为了让它能够在控制节点上也运行：由于本地只有1个节点，运行成功之后，可以在本地看到如下的Pod：现场清理使用：kubectl delete ns ds-test --cascade Job
相较于Deployment，StatefulSet，DaemonSet处理在线任务的编排，Job 主要是处理离线任务，这种业务在计算完成后就直接退出了，而此时如果你依然用Deployment来管理这种业务的话，就会发现Pod会在计算结束后退出，然后被Deployment Controller不断地重启。
Job 中有几个比较重要的概念：restartPolicy，在Deployment中，restartPolicy只允许被设置为Always，在Job中只能被设置为Never或者OnFailure，因为离线计算的Pod永远都不应该被重启，否则又得重跑一边；
parallelism，用于控制一个Job在任意时间最多可以启动多少个Pod同时运行；
completions，定义的是Job至少要完成的Pod数目，即Job的最小完成数；
backoffLimit，在restartPolicy=Never时，如果Pod失败，会不断地有容器创建出来，在restartPolicy=OnFailure时，如果容器出错退出，Job Controller会不断滴重启Pod中的容器，那么这个重试不能一直进行，需要上限，这就是backoffLimit的意义；
activeDeadlineSeconds，用于设置Job的执行时间，一旦Job执行时间达到指定时间，其所有运行中的Pod都会被终止， 并且Job的状态更新为type: Failed及reason: DeadlineExceeded；
ttlSecondsAfterFinished，已完成Job（状态为 Complete 或 Failed）的清理使用该字段控制；下面是一个计算π值的Job：执行成功之后，可以通过下面的命令验证：kubectl get pod,job -n job-test -owide CronJob
CronJob相较于Job，就相当于 Deployment之于ReplicaSet，它是一个Job的控制器，使用类Unix Cron的格式定时创建Job，如下所示的例子：表示每5分钟创建一个Job执行，如下所示：kubectl get cronjob,job,pod -n cronjob-test -owide 参考链接Understanding ReplicaSet vs. StatefulSet vs. DaemonSet vs. Deployments
Kubernetes Service Account: What It Is and How to Use It
节点亲和性和反亲和性部署]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>pod</tag>
        <tag>deployment</tag>
        <tag>statefulset</tag>
        <tag>replicaset</tag>
        <tag>job</tag>
        <tag>cronjob</tag>
        <tag>daemonset</tag>
      </tags>
  </entry>
  <entry>
    <title>K8S 数据挂载</title>
    <url>/2024/01/17/K8S/k8s-data-mount/</url>
    <content><![CDATA[Pod中的容器它里面的文件在磁盘上是临时存放的，当容器崩溃或停止时，kubelet 会以干净的状态重新启动容器，在容器生命周期内创建或修改的所有文件都将丢失。另外Pod在运行期间，需要为它注入一些必要的配置信息，以满足其运行。在这些场景的要求下，卷 就应需而生，为了持久化存放容器里的数据，为容器运行提供配置。所有这些卷可以分为3类：持久卷（Persistent Volume）：和节点一样，属于集群资源，可以由管理员事先制备，或者使用存储类来动态制备，使用时通过PVC申请，就像其名字表述的一样，为了持久化数据；
投射卷（Projected Volumes）：为Pod运行注入必要的配置信息；
临时卷（Ephemeral Volume）：应用程序需要额外的存储，但并不关心数据在重启后是否仍然可用，随Pod而生，随Pod而灭。例如，Redis缓存服务经常受限于内存大小，而且可以将不常用的数据转移到比内存慢的存储中，对总体性能的影响并不大；这些卷以及它们的分类、涉及的概念如下：mindmap
卷
    投射卷
        Secret
        DownwardAPI
        Configmap
        ServiceAccountToken
    持久卷
        PV
        PVC
        StorageClass
    临时卷
        emptyDir
        CSI 临时卷
        通用临时卷 Secret
Secret 是一种包含少量敏感信息例如密码、令牌或密钥的对象，通过 Secret 我们就不用将一些机密数据硬编码到代码中了。K8S提供了一些内置的Secret类型，并且针对其中某些类型专门提供了kubectl命令进行管理，不同的类型对数据有不同的要求。
 Opaque
可以直接从命令创建创建任意数据的Secret，首先创建命名空间用于测试：kubectl create ns secret-test然后使用kubectl创建Secret：kubectl -n secret-test create secret generic db-user-pass --from-literal=username=admin --from-literal=password='S!B\*d$zDsb='或者从文件创建，默认键名为文件名，也可以自定义：echo -n 'admin' &gt; ./username.txt
echo -n 'S!B\*d$zDsb=' &gt; ./password.txt
kubectl -n secret-test create secret generic db-user-pass-v1 --from-file=./username.txt --from-file=./password.txt
kubectl -n secret-test create secret generic db-user-pass-v2 --from-file=user=./username.txt --from-file=pass=./password.txt也可以使用Yaml文件组织Secret对象，这个对象中的data字段内容必须使用base64编码，如果想提供明文数据，则需要将其写入stringData字段中。首先使用 base64 编码数据，``：然后使用下面的对象提交Secret查看已经创建的Secret对象：然后将创建的Secret挂载到Pod中，Secret不仅可以挂载到容器中的目录，还可以绑定到环境变量中：执行命令进入到容器查看挂载的密码文件： 基本身份认证
kubernetes.io/basic-auth 类型用来存放用于基本身份认证所需的凭据信息。 使用这种 Secret 类型时，Secret 的 data 字段必须包含以下两个键之一：username: 用于身份认证的用户名；
password: 用于身份认证的密码或令牌。以上两个键的键值都是 base64 编码的字符串。 当然你也可以使用 stringData 字段来提供明文形式的内容：不过StringData字段的内容只是作为输入，它会被编码合并到data字段中，而且通过kubectl命令是无法查看到明文，所以查看上面的对象，可以看到data中有4个字段： SSH 身份认证 Secret
kubernetes.io/ssh-auth 用来存放 SSH 身份认证中所需要的凭据。 使用这种 Secret 类型时，必须在其 data （或 stringData）字段中提供一个 ssh-privatekey 键值对。如下所示，创建 Secret 并且绑定到容器中：进入到容器中进行验证： TLS Secret
kubernetes.io/tls Secret 类型用来存放 TLS 场合通常要使用的证书及其相关密钥。当使用此类型的 Secret 时，Secret 配置中的 data （或 stringData）字段必须包含 tls.key 和 tls.crt 主键，而且可以通过kubectl命令直接创建tls类型的Secret。下面演示使用 mkcert 来生成证书，如果本地没有安装go，可以下载它的预编译版本： 清理现场
清理现场使用如下命令：kubectl delete ns --cascade secret-test ConfigMap
ConfigMap与 Secret 类似，区别是不需要加密，常用于应用的配置，可以从文件或者yaml对象文件进行创建。
首先，创建命名空间用于测试，方便后续清理现场：kubectl create ns configmap-test准备2个配置文件，存放于properties目录下：从目录创建ConfigMap，目录下的所有文件都将创建到ConfigMap中：kubectl -n configmap-test create configmap game-config1 --from-file=properties/从具体的文件创建ConfigMap，如果需要指定建明，则需要使用 --from-file=&lt;我的键名&gt;=&lt;文件路径&gt; 格式:kubectl -n configmap-test create configmap game-config2 --from-file=properties/ui1.properties可以同时从多个数据源创建ConfigMap：kubectl -n configmap-test create configmap game-config3 --from-file=properties/ui1.properties --from-file=properties/ui2.properties也可以使用 --from-env-file 从 env 文件进行创建，env文件是每行都是key=val的格式，而且注释和空行都将被忽略，上面的ui1.properties也是正确的env文件，但是每条配置多作为一个key：kubectl -n configmap-test create configmap game-config4 --from-env-file=properties/ui1.properties也可以从字面量进行创建：kubectl -n configmap-test create configmap game-config5 --from-literal=special.how=very --from-literal=special.type=charm创建Pod并且挂载上面创建的ConfigMap：进入到容器中进行验证：kubectl exec nettool -n configmap-test -it -c nettool -- /bin/bash清理现场：kubectl delete ns configmap-test --cascade DownwardAPI
通过 DownwardAPI 可以将Pod对象本身的信息传递给容器中的环境变量或者挂载到容器中的文件，主要可以通过fieldRef 以及 resourceFieldRef 进行获取，请看如下示例：提交成功之后，可以使用下面的命令进入容器进行验证：kubectl exec -n  downwardapi-test nettool -it -c nettool -- /bin/bash现场清理使用如下的命令：kubectl delete ns downwardapi-test --cascade 参考链接为 Pod 和容器管理资源
Pod容器资源API
数据卷描述
DownwardAPI ServiceAccountToken
当集群中的Pod想要和kube-apiserver交互时，需要通过认证，K8S通过ServiceAccount来标识应用的身份和权限控制，ServiceAccount是命名空间隔离的，当创建一个命名空间的时候，就会自动创建一个default的ServiceAccount，并且当我们在创建Pod的时候，如果没有指定ServiceAccountName，默认default，而ServiceAccountToken只是用来设置ServiceAccount对应Token的一些信息，如挂载路径，令牌的有效期等等。
 默认ServiceAccount
如下所示：执行上面的命令成功之后，查看已经创建的ServiceAccount 和 Pod:查看nettool这个Pod的详情，自动挂在了默认的default服务账号的token和以及访问ApiServer必须的证书在目录/var/run/secrets/kubernetes.io/serviceaccount中，在这个目录中还有证书以及命名空间等信息：可以使用这个token和证书访问kube-apiserver的API，在这个之前，在集群中最好创建一个Service指向ApiServer，如下所示：进入到Pod之后，访问 API，不过默认的default账号权限有限，甚至无法查看本明明空间内的Pod列表： 自定义ServiceAccount
首先使用如下的命令清理sa-test中的资源：kubectl delete ns --cascade sa-test然后创建下面的资源，相比默认场景，这里主要有以下改动：Role，具有Pod查看权限的pod-view-role角色；
ServiceAccount，自定义的pod-view-sa，将被用于和pod-view-role角色相关联；
RoleBinding，用于将pod-view-role角色的权限赋予pod-view-sa；
在Pod模板中，使用automountServiceAccountToken: false禁止默认挂载；
在Pod模板中，使用serviceAccountName: pod-view-sa表明Pod要关联的角色；
在Pod模板中，定义projected类型的pod-view-sa-token三合一资源，将证书、命名空间名称以及token挂载到容器的/var/run/secrets/kubernetes.io/sa/pod-view-sa-token目录中；创建成功以后，将会看到以下资源：进入到Pod中，同样查看Pod列表，如预期所料，访问成功： 清理现场
清理现场使用如下命令：kubectl delete ns --cascade sa-test 参考链接服务账号
投射卷API
为Pod配置服务账号
禁止ServiceAccount自动挂载 emptyDir
emptyDir 表示与Pod生命周期相同的临时目录，“临时（Ephemeral）”意味着对所存储的数据不提供长期可用性的保证。Pods通常可以使用临时性本地存储来实现缓冲区、保存日志等功能。kubelet可以为使用本地临时存储的Pods提供这种存储空间，允许后者使用emptyDir类型的卷将其挂载到容器中。 hostPath
hostPath 卷能将主机节点文件系统上的文件或目录挂载到Pod中，例如，在主机上创建目录 /tmp/test-hostpath：mkdir /tmp/test-hostpath然后将该目录挂再到容器中：进入容器中，在 /tmp-test-hostpath 写入任意文件 test.txt，然后销毁Pod：查看主机上的文件 /tmp/test-hostpath/text.txt，依然存在： 持久卷
持久卷通常用于有数据持久化需求的Pod，虽然上面的hostpath挂载也可以实现这种需求，但是hostpath数据没法迁移，不够安全，没法迁移，通过持久卷可使用的存储类型就比较广泛了。在持久化存储中，有几个比较重要的概念：PV（PersistentVolume）：集群概念，表示一块存储，可以预先创建好等着来用，也可以由存储类动态创建；
PVC（PersistentVolumeClaim）：用于描述存储需求，表示Pod需要什么类型的存储，多少空间等，只有当存在合适的PV来满足PVC的要求时，PVC才会和PV绑定，并被容器真正使用；合适意味着PVC的要求的类型和PV一样，要求的存储空间PV也能满足；
StorageClass：用于当作PV的模板，用于描述它能用什么插件创建出什么类型的PV，当用户创建的PVC没有预创建的PV满足时，就需要通过StorageClass来动态创建了；
回收策略，主要用于告知 PersistentVolume 在用户删除PVC时如何处理之前申请的存储空间，主要有Retain和Delete，表示手动回收和删除；
访问模式，表示卷以什么方式挂载到宿主机系统上，不同类型的PV支持的访问模式不同：ReadWriteOnce：卷可以被一个节点以读写方式挂载，也允许运行在同一节点上的多个 Pod 访问卷；
ReadOnlyMany：卷可以被多个节点以只读方式挂载；
ReadWriteMany：卷可以被多个节点以读写方式挂载；
ReadWriteOncePod：卷可以被单个 Pod 以读写方式挂载；持久卷类型，PV 持久卷是用插件的形式来实现的，但是这些类型并不是用户所能使用的存储类型的全集，因为还可以使用StorageClass动态创建PV，目前支持以下存储类型：csi - 容器存储接口 (CSI)
fc - Fibre Channel (FC) 存储
hostPath - HostPath 卷 （仅供单节点测试使用；不适用于多节点集群；请尝试使用 local 卷作为替代）
iscsi - iSCSI (SCSI over IP) 存储
local - 节点上挂载的本地存储设备
nfs - 网络文件系统 (NFS) 存储由于本地的测试条件有限，所以这里使用 hostpath 和 local 两种持久卷类型来做演示。
 hoatpath
hostpath 仅适用于本地单节点测试，我们可以将节点的一个目录作为PV，让Pod都调度到这个节点上来，就可以使用这个存储卷了。首先创建一个目录用于表示PV：为了让Pod能调度到这个和PV强绑定的节点上来，给节点打个标签 pvtype=hostpath：创建 hostPath 类型的 PV，下面的示例中，虽然本地并没有 manual 类型的 StorageClass，但是Kubernetes会根据PVC和PV的存储类名称进行匹配，所以不用担心：创建成功之后，使用如下的命令进行验证：接下来，创建PVC来描述存储需求，不同于PV属于集群的概念，PVC是有命名空间的：执行成功之后，使用下面的命令进行验证，可以看到PV处于绑定状态，也就是PVC的需求得到满足了：接下来就是创建Pod使用这个hostpath类型的PV了，这里的spec.affinity.nodeAffinity表明要把Pod调度到具有pvtype=hostpath的节点中去：进入容器的/hostpath/storage目录中，创建文件 text.txt：这个时候查看ctrlnode节点上的/mnt/k8s/pv-test/hostpath目录，存在text.txt文件。而且即使销毁Pod然后重建，只要依然使用这个PVC，它的数据依然是存在的，这就做到了数据的持久化：清理现场使用：kubectl delete ns --cascade  pv-hostpath-test
kubectl delete pv pv-hostpath
kubectl label nodes ctrlnode pvtype- local
local用于表示某个被挂载的本地存储设备，例如磁盘、分区或者目录，只能用作静态创建的持久卷，不支持动态配置。与 hostPath 卷相比，local 卷能够以持久和可移植的方式使用，而无需手动将 Pod 调度到节点，而 local可以让Pod自动去选择节点，核心含义就是首先让PV存在于具有特征的节点上，这样当PVC被和PV绑定时，PVC也具有了节点亲和性，当最后的使用者Pod出现时，要使用这个PVC就得被调度到满足条件的PV所在的节点上。
同样，为了演示，首先本地创建一个目录用于制备PV：给节点打个标签 pvtype=local：kubectl label nodes ctrlnode pvtype=local创建PV，并且使用nodeAffinity指定满足条件的节点：使用如下的命令验证是否创建成功：然后创建PVC，申请这个local类型的PV：创建成功之后，可以看到PV和PVC都是绑定状态了：同样创建一个Pod来使用这个PVC，与hostpath不同的时，这里不用再使用节点亲和性用来表示Pod要被调度到哪个节点了：进入到容器中，创建文件进行测试：在宿主机上的/mnt/k8s/pv-test/local中可以看到这个文件：清理现场使用如下的命令：kubectl delete ns --cascade pv-local-test
kubectl delete pv example-pv-local
kubectl label nodes ctrlnode pvtype-]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>Secret</tag>
        <tag>ConfigMap</tag>
        <tag>Downward API</tag>
        <tag>ServiceAccountToken</tag>
        <tag>持久卷</tag>
        <tag>投射卷</tag>
        <tag>临时卷</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes Service &amp; Ingress</title>
    <url>/2024/01/02/K8S/k8s-service/</url>
    <content><![CDATA[Service是Kubernetes中的资源类型，用来将一组Pod的应用作为网络服务公开。虽然每个Pod都有自己的IP，但是这个IP的生命周期与Pod生命周期一致，也就是说Pod销毁后这个IP也就无效了，而Service的IP（ClusterIP） 则是在创建之后便不会改变，Service 与 Pod 之前通过iptables和ipvs代理等手段关联。k8s一共提供了四种不同目的类型的Service，分别是ClusterIP、NodePort、LoadBalancer以及ExternalName，本来我们就来探索这四种服务的使用场景以及背后的使用原理。
k8s 集群中的每个节点都是运行一个kube-proxy，它用于实现流量从Service到Pod之间的转发。默认在 Linux 平台下，它使用 iptables 作为后端实现，通过监听Kubernetes控制平面，获知对 Service和EndpointSlice对象的添加和删除操作，对于每个Service，kube-proxy 会添加 iptables 规则，在这些这些规则的加持下，流向Service的流量会被重新路由到Service后端集合中的其中之一。
四种模式的基本工作原理如下图所示： 准备工作
为了验证这里面是如何工作的，我们先创建Pod，Service，然后一步步分析k8s和操作系统互相配合，是如何将数据包转发到对应Pod里面的服务中去。第一步，我这里有三个可用节点，所以创建一个具有3个Pod的nginx-deployment：kubectl apply -f https://k8s.io/examples/application/deployment-update.yaml
kubectl scale --current-replicas=2 --replicas=3 deployment/nginx-deployment然后我们使用下面的命令创建两个不同类型的Service：ClusterIP和NodePort，NodePort和ClusterIP不同的是，我们可以从集群外访问我们的服务：kubectl expose deploy nginx-deployment --port=8080 --target-port=80 --type=ClusterIP --name=nginx-deploy-clusterip-svc
kubectl expose deploy nginx-deployment --port=8081 --target-port=80 --type=NodePort --name=nginx-deploy-nodeport-svc在创建Service的时候，如果带了选择符，还会创建一个EndpointSlice集合，这个集合指向的是选择符选中的Pod集合，例如：：然后使用如下的命令创建一个Pod并且进入容器内进行验证：kubectl run mytools -it --rm --image=praqma/network-multitool --image-pull-policy=IfNotPresent --command -- /bin/bash在这个Pod中，可以使用curl 命令访问我们的服务，分别是 10.105.145.136:8080 和 10.102.231.147:8081。
 DNS
k8s集群创建的时候会创建一个kube-dns服务，用于对Service进行域名解析，每个Service都会被被自动分配一个 &lt;svc&gt;.&lt;namespace&gt;.svc.&lt;cluster-domain&gt; 格式的域名，在每个Pod中，也会存在关于域名解析的配置：这个文件中配置了多个search域，所以当我们写nginx-deploy-clusterip-svc、或者nginx-deploy-clusterip-svc.default，或者nginx-deploy-clusterip-svc.default.svc都是可以解析的：ndots:5 指的是如果域名中的.大于等于5个，则不走search域，目的是减少常规域名的解析次数。
 ClusterIP
ClusterIP是K8S中最基础的服务，只能用于集群内访问。我们来看当我们从mytools这个Pod访问我们的nginx-deploy-clusterip-svc时，它是怎么样一个过程：mytools被调度了node2上：从容器中发出去的报文出现在主机上时，一看系统的路由，也不知道如何处理，没有处理 10.109.146.68 的路由信息：所以就会流入默认网口enp0s1进行处理，按照我们对iptables的处理流程，这个包在处理之前会先触发NF_INET_PRE_ROUTING中的一系列钩子函数，对应于 iptables 中的 PREROUTING 链，而对于路由相关的信息都是在nat表中处理的，所以我们先来看下nat表中PREROUTING链的规则：在PREROUTING找了K8S自定义的链KUBE-SERVICES，这个链中存储的是关于Service的一些规则：然后对于目标地址为10.105.145.136的报文进入KUBE-SVC-ATSXPZA6MCLBTOSW处理，由于nginx-deploy-clusterip-svc有三个pod，所以做负载均衡，三个POD被访问的几率都是1/3：当匹配到某个POD时，进入到对应的 KUBE-SEP-*，然后通过DNAT转换，就把访问Service的请求转换到了具体的Pod中，而Pod在不同节点之间本来就是互通的，是有路由信息的：根据node2节点上的路由信息，会把发往10.244.0.4/16、10.244.1.2/16 网络的报文通过 flannel.1 发出去，而发往 10.244.2.2/16 的报文由于在本机上，所以通过 cni0 网口就可以处理。这部分不懂的可以看容器网络 - 跨主机容器通信以及Kubernetes CNI 网络。
在node2上的iptables规则中还能找到很多KUBE-MARK-MASQ相关的规则，这个链中的规则是用于做SNAT转换的，它的流程是这样的，在PREROUTING阶段使用Mark这个Target给要SNAT的包打上标记，在POSTROUTING阶段使用MASQUERADE做SNAT转换，MASQUERADE和SNAT这两个iptables的Target区别是，SNAT需要指定的具体的原地址，而MASQUERADE会动态获取报文发出去的网卡上的IP作为原地址。例如，当我们访问10.105.145.136的报文最终被路由到了node1，那么在从node2上的enp0s1网卡发送出去时，通过MASQUERADE将报文的原地址设置成node2上enp0s1网卡的地址。关于MASQUERADE的介绍可以看这里。
 NodePort
ClusterIP类型的服务只能在集群内访问，如果要在集群外访问我们的服务，最简单是创建一个对于NodePort类型的Service，这样我们就可以通过每个节点的“公网”IP进行访问，例如控制节点的IP是192.168.67.8，那么我们可以通过192.168.67.8:30673访问我们的服务：通过浏览器进行访问：同理，我们先到处 nat 表中的 PREROUTING 链中的所有规则：然后会在KUBE-SERVICES链中最后一条是和NodePort相关的规则，访问本地服务的链进入到KUBE-NODEPORTS链中的规则进行处理：NodePort链中的规则如下，只是简单跳转到了对应的NodePort服务的链中，对于30673端口的访问进入到了KUBE-EXT-5KZKXYM2F4JEGSLN链中：然后就是跳转到了对应的Service链中：到此就和ClusterIP类型的服务一样了： LoadBalancer
ClusterIP类型的Service在Pod间实现了负载均衡，NodePort提供了通过每个节点的公网IP访问集群服务的可能性，但是又带来了一个新的问题，这些服务没法在节点之间进行负载均衡，所以就出现了叫做LoadBalancer类型的服务，对NodePort类型的服务进行负载均衡，我们可以使用如下的命令创建一个该类型的服务：kubectl expose deploy nginx-deployment --port=8082 --target-port=80 --type=LoadBalancer --name=nginx-deploy-lb-svc但是这个时候查看新建的服务nginx-deploy-lb-svc，它的EXTERNAL-IP显示&lt;pengding&gt;，是因为集群中还没有一个LoadBalancer提供服务：安装METALLB作为LoadBalancer：kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.14.3/config/manifests/metallb-native.yaml然后使用如下命令为METALLB生成配置，下面的配置让它工作在二层协议，为其分配的地址和我们三个节点处在相同的网段，关于它更多的原理可以看这里：192.168.67.240-192.168.67.250 要和节点的公网IP处于同一个地址段，查看Service，它的EXTERNAL-IP已经被分配成了192.168.67.240：此时如果访问http://192.168.67.240:8082/是可以访问通的，因为LoadBlancer服务将这个IP地址的MAC信息通过ARP协议添加到了我们的Host上，而且这个地址对应的MAC信息和我们ctrlnode的公网IP的MAC地址完全一样，所以当从Host或者集群中的其他节点上进行访问的时候其实直接到了我们的ctrlnode进行处理：依然来看当这个请求到达了ctrlnode上的时候，它是如何被处理的。毫无疑问，它肯定会从nat表中的KUBE-SERVICES进入然后被处理：可以看到的是，LoadBlancer类型的服务既可以从集群内部通过ClusterIP访问，也可以从外部通过ExternalIP进行访问，当通过192.168.67.240这个IP进行访问的时候，这个请求下一步会进入到KUBE-EXT-BKP5P6G6IWL6KD3D这个链中进行处理：然后就开始在我们三个节点之间进行路由，和ClusterIP的处理方式一样了。
 无头服务
按照官方文档描述的，Headless Service 好像没什么用，无头服务本质上ClusterIP类型的，只是他的ClusterIP是None，所以它没有集群IP，因此kube-proxy是不会处理这里服务的。从类型上分，无头服务分为有选择符的和没有选择符的。
 带有选择符
对于有选择符的无头服务，K8S还是会创建对应的EndpointSlice对象，并且修改DNS记录，在查询对应的服务名称时，直接返回后端的EndpointSlice中的IP地址，而不是Service的ClusterIP。举个例子，我们有如下所示的Pod：我们使用如下的方式创建一个带选择符的无头服务：kubectl expose deploy nginx-deployment --target-port=80 --type=ClusterIP  --cluster-ip=None --name=nginx-deploy-headless-svc查看该服务详情，它的EndpointSlice集合中存在对应的Pod地址：如果此时使用DNS解析nginx-deploy-headless-svc，它返回的也是三个Pod的地址，使用nginx-deploy-headless-svc访问服务，就如同使用Pod的IP地址直接访问一样，不会通过iptables进行负载均衡： 没有选择符
对于没有选择服务的无头服务，常用于去访问外部服务，因为它没有选择符，所以不会自动创建EndpointSlice集合，需要手动创建，否则它没有实际的意义。假如我们现在像访问集群外部的服务，又不想在代码中硬编码该服务的地址，就可以创建一个没有选择符的无头服务，然后手动创建该服务指向的IP地址，在代码中使用服务名称进行访问。
例如，我们在主机上通过docker启动一个whoami服务：docker run -d -P --name whoami traefik/whoami启动之后可以通过下面的命令得到它在主机上发布的端口:现在我们使用下面的命令在k8s集群中创建一个名叫whoami的无头服务，以及一个同名的EndpointSlice集合，这里要注意的是，对于没有选择符的无头服务，它的port和targetPort必须相同，172.31.205.142 是我这个服务所在的公网地址：创建成功之后，我们就可以在k8s集群中实现通过名称放我们的whoami服务了： ExternalName
如果外部服务是通过IP访问的，我们可以使用不带选择符的无头服务在集群内配置名称进行访问。如果外部服务是以域名进行访问的，我们就可以创建ExternalName类型的Service仅进行访问外部服务。ExternalName本质上是在k8s集群内部的DNS中添加一条CNAME解析记录，CNAME可以把它看作是域名到域名的映射。
例如，对于我的博客，它的域名是blog.fudenglong.site，它本质上也是一个CNAME解析，它的值是gamelife1314.github.io，使用dig命令查询能得到下面的解析记录：现在我们在集群内部创建一个myblog服务，指向blog.fudenglong.site：然后使用 dig 命令在集群内部查询，可以看到myblog解析到了blog.fudenglong.site： Ingress
Loadbalancer类型的服务为每个Service都创建了一个负载均衡服务，这种做法成本高，实现麻烦，作为普通用户，应该更应该希望k8s能提供像nginx这样的反向代理功能，基于不同的Host，或者url规则，把请求转发到不同的后端服务中去，Ingress 就是用来提供这样的服务，可以把它看做是Service的Service，因为一个Ingress的后端对象是Service，不像Service，它的后端是Pod。
为了演示，除了本篇开始创建的nginx-deploy-clusterip-svc，再创建一个Service，使用如下的命令：kubectl create deployment whoami --image=traefik/whoami -r 3 --port=80
kubectl expose deployment whoami --port=8080 --target-port=80 --type=ClusterIP --name=whoami创建成功之后，使用如下的命令查看已创建的whoami：接下来，创建一个Ingress，需要注意的Ingress和Service必须在相同的命名空间内，默认是default：上面的ingressClassName指得是这个Ingress使用哪个IngressController，因为Ingress对象只是一份描述文件，它并没有实际的意义，需要IngressController对它解释并提供服务，而IngressController需要额外安装的，这里使用NginxIngress，安装如下所示：kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.2/deploy/static/provider/cloud/deploy.yaml等一切就绪的时候，去查看创建的default-ingress，它已经被分配了从集群外访问的外部地址192.168.67.241：现在，就可以使用我们自定义的域名访问服务了，只是要把自定义的域名解析到192.168.67.241，例如：curl --resolve nginx.svc.local:80:192.168.67.241 http://nginx.svc.local/
curl --resolve whoami.svc.local:80:192.168.67.241 http://whoami.svc.local/那这个192.168.67.241到底是谁分配的呢？在安装NginxIngress的时候，它其实还创建了一个LoadBalancer类型的service/ingress-nginx-controller，所以这个IP地址是我们集群内安装的负载均衡服务分配的，它就成了集群中NginxIngress的入口：到这里这个流程现在变得清楚了，通过192.168.67.241这个外部IP到达我们集群中之后，流程首先到ingress-nginx-controller这个Pod：这个Pod会将对Ingress对象的描述翻译成它能理解的/etc/nginx/nginx.conf：然后内部再将流量路由到nginx-deploy-clusterip-svc和whoami，整个过程如下图所示： 参考链接Understanding networking in Kubernetes
Kubernetes Services and Iptables
kubernetes - 虚拟IP和服务代理
Kubernetes Service iptables 网络通信验证
服务发现与负载均衡
Kubernetes LoadBalancer Service 与负载均衡器
在 Kubernetes 集群中使用 MetalLB 作为 LoadBalancer（下）- BGP
MetalLB服务和BGP路由器测试]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>Service</tag>
        <tag>NodePort</tag>
        <tag>Loadblance</tag>
        <tag>ExternalName</tag>
        <tag>Ingress</tag>
        <tag>MetaLB</tag>
      </tags>
  </entry>
  <entry>
    <title>K8S集群中部署MySQL</title>
    <url>/2025/07/19/K8S/mysql-deploy/</url>
    <content><![CDATA[本文描述如何在k8s集群中部署一个MySQL服务，前提请看K8S集群部署创建一个测试集群。如我本地，仅有一个控制节点： 创建hostpath目录
这里创建的目录将被用于PV卷创建，MySQL服务产生的数据也将保存在这个目录下。如果目录变更，请同步修改后续的PV卷的hostpath路径：mkdir -p /mnt/k8s/mysql-demo/mysql-data 为节点增加标签
为了让Pod能调度到这个和PV强绑定的节点上来，给节点打个标签pvtype=hostpath： 部署MySQL服务
将下面的模板保存为 mysql.yaml，然后从文件创建MySQL服务：执行命令： 集群内验证MySQL登录
上面的模板还创建了NodePort类型的MySQL服务，所以在集群之内进行登录。首先创建一个临时的客户端容器：kubectl run mytools -n mysql-demo -it --rm --image=mysql --image-pull-policy=IfNotPresent --command – /bin/bash然后通过mysql名字访问数据库：mysql -h mysql -P 3306 --user=root --password=123456 集群外验证MySQL登录
NodePort类型的服务可以从k8s集群外进行访问，这里在集群之外使用docker创建个MySQL客户端进行验证。首先查看MySQL服务的暴露在节点上的端口：这里使用docker创建的MySQL客户端和K8S集群就不在同一个网络了，是在集群之外访问，需要使用节点的IP地址：接下来使用docker创建一个临时的MySQL客户端容器：docker run --network host -it --rm  mysql bash]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>MySQL部署</tag>
      </tags>
  </entry>
  <entry>
    <title>使用kubeadm创建多节点集群</title>
    <url>/2023/12/17/K8S/kubeadm-deploy/</url>
    <content><![CDATA[本篇文章介绍使用 kubeadm 创建一个多节点的 K8S，使用 containerd 作为容器运行时，第一步，首先是准备 3 个虚拟机节点，使用 multipass 创建3台虚拟机，该镜像中自带 docker，无需再安装，使用如下命令创建：multipass launch --name ctrlnode -d 40G docker
multipass launch --name node1 -d 40G docker
multipass launch --name node2 -d 40G docker每个节点至少2GB内存，2个CPU，具体要求请看这里。创建成功之后，如下所示：VM 版本如下： 节点配置
在开始之前，三台节点做必要的设置。
 swap
首先，禁止 swap：sudo swapoff -a
sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab 防火墙
测试环境，直接关闭防火墙即可（Ubuntu）：sudo ufw disable 桥接流量
转发 IPv4 并让 iptables 看到桥接流量，这部分内容来源于这里：通过运行以下指令确认 br_netfilter 和 overlay 模块被加载：br_netfilter（Linux 内核中的一个模块，它主要用于管理网桥设备上的数据包过滤。 此模块允许在网桥设备上使用Netfilter（Linux内核的防火墙框架）的功能，例如iptables 和nftables。 它允许对网桥连接的两个网络段之间的数据包进行过滤。）
通过运行以下指令确认 net.bridge.bridge-nf-call-iptables、net.bridge.bridge-nf-call-ip6tables 和 net.ipv4.ip_forward 系统变量在你的 sysctl 配置中被设置为 1：sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward hostname
为各个节点设置合适的名称，并且做域名解析：sudo hostnamectl set-hostname &quot;ctrlnode&quot;
sudo hostnamectl set-hostname &quot;node1&quot;
sudo hostnamectl set-hostname &quot;node2&quot;在3个节点的 /etc/hosts 文件中加入下面的解析条目： containerd
这里选用 containerd 作为容器运行时，更多的容器运行时看这里。在使用 multipass 的 docker 模板创建的节点中，Docker 默认安装，作为 Docker 的一部分，continaerd 也会被安装。不过不管以哪种方式安装 containerd 之后，需要稍作配置，第一步生成默认配置：配置cgroup驱动 驱动，在 /etc/containerd/config.toml 中设置：然后重新启动：如果需要给 containerd 设置代理，用于拉取镜像。可以编辑文件 /etc/systemd/system/containerd.service.d/http-proxy.conf，加入自己的代理信息：然后重启：设置 crictl 的运行时，使用 containerd，官方文档请看这里： 安装K8S
官方阿里云官方安装请看这里：查看k8s可用版本：sudo apt-cache madison kubeadm安装指定版本：sudo apt install -y kubeadm=1.28.5-1.1 kubelet=1.28.5-1.1 kubectl=1.28.5-1.1锁定版本，不随 apt upgrade 更新：sudo apt-mark hold kubelet kubeadm kubectl
国内安装请看这里：每个节点上的kubelet会选择一个容器运行时用于Pod管理，可以使用下面的命令进行查看： 集群初始化
在集群初始化之前，我们可以先使用下面的命令在控制节点预先拉取镜像：kubeadm config images pull --kubernetes-version 1.28.5在控制节点上执行下面的命令，kubeadm 的使用文档请看这里：init 会执行一系列的检查，例如内核版本版本是否满足要求（3.10及以上），Cgroups模块是否启用，是否安装容器运行时，ip、mount 这样的工具是否安装，Kubernetes的工作端口10250/10251/10252端口是不是已经被占用等等，完整的工作流程请看这里。执行成功之后，将会得到下面这样的输出：如果要使用普通用户管理集群，需要执行下面的命令为普通用户创建kubectl命令运行所需要的配置：如果用 root 用户使用集群，只需要设置如下的环境变量：在加入新的节点之前，我们需要安装网络插件，这里以 flannel 为例：kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml在控制面节点初始化之后输出了其他 worker 节点加入的命令。如果忘记了，可以使用 kubeadm token create --print-join-command 重新生成加入命令：分别在 ndoe1 和 node2 执行之后，会有如下的输出：使用 kubectl get node 命令在控制节点上查看节点列表：如果节点 NotReady 可能是由于网络插件或者 kube-proxy 未启动，等它们就绪之后再去查看节点就 Ready 了。在节点上使用 crictl ps 查看相关容器是否启动：默认情况下，control-plane 所在节点被设置成了污点（Taint），不允许 Pod 调度到这类节点，例如:kubectl describe  node ctrlnode测试环境中，可以使用下面的命令清除污点，以便让 Pod 被允许调度到此类节点：kubectl taint nodes ctrlnode node-role.kubernetes.io/control-plane:NoSchedule-可以通过下面的命令给节点设置角色，例如，给 node1 和 node2 设置 worker 角色：kubectl label node node1 node-role.kubernetes.io/worker=worker
kubectl label node node2 node-role.kubernetes.io/worker=worker 部署应用
为了测试集群的可用性，部署一个 Deployment 测试，这里使用官方的无状态应用示例，并且将其扩展为3个Pod：kubectl apply -f https://k8s.io/examples/application/deployment-update.yaml
kubectl scale --current-replicas=2 --replicas=3 deployment/nginx-deployment等待部署成功，查看：可以使用如下的命令查看 pod 中有哪些容器：kubectl get pods nginx-deployment-848dd6cfb5-2gvg9 -o jsonpath={.spec.containers[*].name}使用如下的命令进入 pod 的容器中：kubectl exec nginx-deployment-848dd6cfb5-2gvg9 -n default  -it -c nginx – /bin/bash Dashboard
Dashboard 是基于网页的 Kubernetes 用户界面，可以使用 Dashboard 将容器应用部署到 Kubernetes 集群中，也可以对容器应用排错，还能管理集群资源，同时也展示了 Kubernetes 集群中的资源状态信息和所有报错信息。
执行下面的命令安装 Dashboard：kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml执行成功之后，你将会看到如下的输出：等待pod 启动成功之后，执行如下命令，将会看到创建成功的服务：kubectl get svc -n kubernetes-dashboard默认创建的服务是 ClusterIP 类型，没法通过集群外部进行访问，通过相面的命令将它修改为 NodePort 类型的：kubectl edit svc -n kubernetes-dashboard kubernetes-dashboard修改内容为，将 spec.type 从 ClusterIP 修改为 NodePort。修改成功之后，再次查看服务，类型更新为 NodePort，也分配了随机的节点端口 32688：使用 ctrlnode 的节点访问 https://192.168.67.6:30175/，登录页面打开，我们使用 Token 进行访问，使用下面的命令生成 Token：kubectl create token kubernetes-dashboard -n kubernetes-dashboard但是默认创建的 kubernetes-dashboard 只能访问 default 命名空间的服务，权限太小了。我们可以手创建新的 ServiceAccount，并且给它绑定 cluster-admin 这个角色：kubectl create serviceaccount cluster-admin-dashboard -n kubernetes-dashboard创建成功之后，使用如下的命令查看创建的 ServiceAccount：kubectl get serviceaccount -n kubernetes-dashboard然后给它绑定 cluster-admin 这个角色:使用下面的命令重新生成 Token：kubectl create token cluster-admin-dashboard -n kubernetes-dashboard退出使用新的Token重新登录之后，就可以看到所有的命名空间下的资源了： 参考文章使用kubeadm部署一套高可用k8s集群 for Ubuntu
Deploy Kubernetes Cluster on Ubuntu 20.04 with Containerd
Kubernetes Service Discovery
iptables — a comprehensive guide
A Deep Dive into Iptables and Netfilter Architecture
Kubernetes Service iptables 网络通信验证
Docker Overlay2 Cleanup: 5 Ways to Reclaim Disk Space
Use the OverlayFS storage driver
Details of the Kubernetes Cluster Network]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>kubeadm</tag>
        <tag>集群部署</tag>
      </tags>
  </entry>
  <entry>
    <title>【Leetcode-Rust】无重复字符的最长子串(0003)</title>
    <url>/2022/05/30/Leetcode-Rust/longest-substring-without-repeating-characters-0003/</url>
    <content><![CDATA[ 题目
给定一个字符串 s ，请你找出其中不含有重复字符的 最长子串 的长度。
 示例
示例 1：
输入: s = &quot;abcabcbb&quot;
输出: 3 
解释: 因为无重复字符的最长子串是 &quot;abc&quot;，所以其长度为 3。示例 2：
输入: s = &quot;bbbbb&quot;
输出: 1
解释: 因为无重复字符的最长子串是 &quot;b&quot;，所以其长度为 1。示例 3：
输入: s = &quot;pwwkew&quot;
输出: 3
解释: 因为无重复字符的最长子串是 &quot;wke&quot;，所以其长度为 3。 思路
使用滑动窗口，它的右边界不断的右移，只要没有重复的字符，就持续向右扩大窗口边界。一旦探测到出现了重复字符，就需要右边界先停下，然后缩小左边界，直到重复的字符移出了左边界，然后继续移动滑动窗口的右边界。以此类推，每次移动需要计算当前长度，并判断是否需要更新最大长度，最终最大的值就是题目中的所求。
]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>滑动窗口</tag>
      </tags>
  </entry>
  <entry>
    <title>【Leetcode-Rust】长度最小的子数组(0209)</title>
    <url>/2022/06/19/Leetcode-Rust/minimum-size-subarray-sum-0209/</url>
    <content><![CDATA[ 题目
给定一个含有 n 个正整数的数组和一个正整数 target。
找出该数组中满足其和 ≥ target 的长度最小的连续子数组 [numsl, numsl+1, ..., numsr-1, numsr]，并返回其长度。如果不存在符合条件的子数组，返回 0。
 示例
示例 1：
输入：target = 7, nums = [2,3,1,2,4,3]
输出：2
解释：子数组 [4,3] 是该条件下的长度最小的子数组。示例 2：
输入：target = 4, nums = [1,4,4]
输出：1示例 3：
输入：target = 11, nums = [1,1,1,1,1,1,1,1]
输出：0 思路
这一题的解题思路是用滑动窗口。在滑动窗口 [i,j] 之间不断往后移动，如果总和小于 s，就扩大右边界 right，不断加入右边的值，直到 sum &gt;= s，然后判断满足的子数组的长度，再缩小 left 左边界，直到 sum &lt; s，这时候右边界又可以往右移动，寻找下一个满足的子数组。
]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>滑动窗口</tag>
      </tags>
  </entry>
  <entry>
    <title>【Leetcode-Rust】重复的DNA序列(0187)</title>
    <url>/2022/06/11/Leetcode-Rust/repeated-dna-sequences-0187/</url>
    <content><![CDATA[ 题目
DNA 序列 由一系列核苷酸组成，缩写为 'A', 'C', 'G' 和 'T'.。
例如，&quot;ACGAATTCCG&quot; 是一个 DNA 序列，在研究 DNA 时，识别 DNA 中的重复序列非常有用。
给定一个表示 DNA 序列 的字符串 s ，返回所有在 DNA 分子中出现不止一次的 长度为 10 的序列(子字符串)。你可以按 任意顺序 返回答案。
 示例
示例 1：
输入：s = &quot;AAAAACCCCCAAAAACCCCCCAAAAAGGGTTT&quot;
输出：[&quot;AAAAACCCCC&quot;,&quot;CCCCCAAAAA&quot;]示例 2：
输入：s = &quot;AAAAAAAAAAAAA&quot;
输出：[&quot;AAAAAAAAAA&quot;]提示：
0 &lt;= s.length &lt;= 105
s[i]=='A'、'C'、'G' or 'T' 解法一
暴力解法，双层循环比较，结果可想而知，超时。 解法二
O(n) 的时间复杂度，一次遍历将长度为 10 的所有子串放在 map 中，并且计数，最后将出现次数大于 1 的子串找出来返回。
]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>滑动窗口</tag>
      </tags>
  </entry>
  <entry>
    <title>【Leetcode-Rust】串联所有单词的子串(0030)</title>
    <url>/2022/06/01/Leetcode-Rust/substring-with-concatenation-of-all-words-0030/</url>
    <content><![CDATA[ 题目
给定一个字符串 s 和一些 长度相同 的单词 words 。找出 s 中恰好可以由 words 中所有单词串联形成的子串的起始位置。
注意子串要与 words 中的单词完全匹配，中间不能有其他字符 ，但不需要考虑 words 中单词串联的顺序。
 示例
示例 1：
输入：s = &quot;barfoothefoobarman&quot;, words = [&quot;foo&quot;,&quot;bar&quot;]
输出：[0,9]
解释：
从索引 0 和 9 开始的子串分别是 &quot;barfoo&quot; 和 &quot;foobar&quot; 。
输出的顺序不重要, [9,0] 也是有效答案。示例 2：
输入：s = &quot;wordgoodgoodgoodbestword&quot;, words = [&quot;word&quot;,&quot;good&quot;,&quot;best&quot;,&quot;word&quot;]
输出：[]示例 3：
输入：s = &quot;barfoofoobarthefoobarman&quot;, words = [&quot;bar&quot;,&quot;foo&quot;,&quot;the&quot;]
输出：[6,9,12] 解法一
题目有两个要点：字符串数组里面的字符串长度都是一样的；
要求字符串数组中的字符串都要连续连在一起的，前后顺序可以是任意排列组合；假设，words 的长度是 n，words 中每个单词的长度是 w，所以我们每次可以从字符串 s 取 n * w 长度来判断它是否是 words 的自由排列组合。
在判断时，我们先将 words 中每个单词的数量放在一个计数器中，可以用 map 表示，例如：[&quot;aaa&quot;, &quot;bbb&quot;] 表示成 &#123;&quot;aaa&quot;: 1, &quot;bbb&quot;: 1&#125;；[&quot;aaa&quot;, &quot;aaa&quot;, &quot;ccc&quot;] 表示成 &#123;&quot;aaa&quot;: 2, &quot;ccc&quot;: 1&#125;；然后我们将 s 中每个 n * w 长度的子串每 w 个一组放在一个 map 中计数，最后和 words 的计数器比较是否相等，如果相等就是我们想要的子串。
]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>滑动窗口</tag>
      </tags>
  </entry>
  <entry>
    <title>【Leetcode-Rust】两数相加(0002)</title>
    <url>/2022/05/30/Leetcode-Rust/two-number-add-0002/</url>
    <content><![CDATA[ 题目
给你两个非空的链表，表示两个非负的整数。它们每位数字都是按照逆序的方式存储的，并且每个节点只能存储一位数字。
请你将两个数相加，并以相同形式返回一个表示和的链表。
你可以假设除了数字 0 之外，这两个数都不会以 0 开头。
 示例
示例 1：
输入：l1 = [2,4,3], l2 = [5,6,4]
输出：[7,0,8]
解释：342 + 465 = 807.示例 2：
输入：l1 = [0], l2 = [0]
输出：[0]示例 3：
输入：l1 = [9,9,9,9,9,9,9], l2 = [9,9,9,9]
输出：[8,9,9,9,0,0,0,1] 思路
2 个逆序的链表，要求从低位开始相加，得出结果也逆序输出，返回值是逆序结果链表的头结点，需要注意的是处理进位问题。
 代码 参考链接Add Two Numbers]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
  </entry>
  <entry>
    <title>【Leetcode-Rust】两数之和(0001)</title>
    <url>/2022/05/26/Leetcode-Rust/two-sum-0001/</url>
    <content><![CDATA[ 题目
Given an array of integers nums and an integer target, return indices of the two numbers such that they add up to target.
You may assume that each input would have exactly one solution, and you may not use the same element twice.
You can return the answer in any order.
给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target 的那两个整数，并返回它们的数组下标。你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。你可以按任意顺序返回答案。
在数组中找到 2 个数之和等于给定值的数字，结果返回 2 个数字在数组中的下标。
 示例
输入：nums = [2,7,11,15], target = 9
输出：[0,1]
解释：因为 nums[0] + nums[1] == 9 ，返回 [0, 1] 。输入：nums = [3,2,4], target = 6
输出：[1,2]输入：nums = [3,3], target = 6
输出：[0,1] 思路
这道题最优的做法时间复杂度是 O(n)。顺序扫描数组，对每一个元素，在 map 中找能组合给定值的另一半数字，如果找到了，直接返回 2 个数字的下标即可。如果找不到，就把这个数字存入 map 中，等待扫到另一半数字的时候，再取出来返回结果。
 代码 参考链接Two Sum]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
  </entry>
  <entry>
    <title>容器网络-单机容器通信</title>
    <url>/2023/12/09/Network/container-network-single-host/</url>
    <content><![CDATA[Docker 容器通过 Linux 提供的各种 namespace 技术，将运行中的容器封闭在一个沙箱中，看起来很像一个虚拟机，都拥有独立的网络栈，有独立的 IP 地址，但是这些同主机上的独立容器貌似天生互通，能通过各自的 IP 相互访问，这是如何做到的的？
如果我们想要实现两台独立主机之间互通，最简单的办法就是拿一根网线把它们连在一起；想要实现多台主机互通，这个时候就需要一台交换机了。
现在在不同的容器之间，想要实现互通，我们也可以借鉴交换机这种技术，毕竟容器看起来很像独立的主机。在 Linux 中，可以通过网桥（Bridge）模拟交换机，网桥工作是一个二层网络设备，工作在数据链路层，主要功能是能够根据MAC地址将数据包发送到网桥的不同端口上。
二层网络和三层网络的主要区别是，二层网络中可以仅靠MAC地址就实现互通，但是三层网络需要通过IP路由实现跨网络互通，这也能看出，二层网络的组网能力非常有限，一般只是小局域网，三层网络可以组建大型网络。
Docker 项目为了实现这种在相同主机上创建容器之间互通的目的，在主机上会创建一个名叫 docker0 的网桥，凡是连接在 docker0 上的容器，就可以通过它进行通信。要把一个容器插在网桥上，需要依赖 Veth Pair 这个虚拟设备了，它的特点是，它被创建出来之后，总是以两张虚拟网卡成对出现，并且从一张网卡发出的数据包，可以直接出现在与它对应的另一张网卡上，即使两张网卡在不同的 namespace 中。一旦一张虚拟网卡被插在了网桥设备上，它就会被降级成网桥的端口，丢失了处理数据包的能力，数据包会全部交由网桥进行处理。
如下是宿主机上 docker0 设备信息，172.17.0.1/16 是 Docker 默认的子网：接下来我们创建两个容器，来验证这种通信的流程，整个通信流程如下图所示： 创建容器
这里以 Ubuntu:22.04 为例，创建两个名为 ubuntu-1 和 ubuntu-2 的容器，创建容器之后，可以执行下面的命令安装 ifconfig、route 以及 ping 这些必要的命令。apt install -y iproute2 net-tools iputils-ping创建容器可以使用如下命令进行：docker run  --rm -it -d --name ubuntu-1 ubuntu:22.04
docker run  --rm -it -d --name ubuntu-2 ubuntu:22.04ubuntu-1ubuntu-2
上面的第二条路由信息表明凡是发往 172.17.0.0/16 网络的数据包都经过 eth0 网卡发送，通过二层网络直达目的主机。这个 eth0 也正是 Veth Pair 设备的一端，它的另一端在主机上，对应 ifindex 是 10972，这样就可以找到在主机上对应的 veth 设备了：怎么样证明他们插在了 docker0 网桥上呢？通过 brctl show 命令，Ubuntu 可以通过下面的命令进行安装：apt install bridge-utilsbrctl show 命令展示了插在 docker0 网桥上的设备，展示为 interface，表示一个端口： 容器通信
通过 ping 命令来验证 icmp 报文是通过 docker0 网桥进行转发的，在 ubuntu-1 发起 ping 命令肯定是可以正常达到的：为了抓住这个信息，我们需要借助 iptables 工具在发出 icmp 报文的时候记录下日志，iptables 控制内核模块在收发到数据包时根据创建的规则进行处理，我们这里只进行日志记录，可以在主机上执行如下命令：iptables -t raw -A OUTPUT -p icmp -j LOG
iptables -t raw -A PREROUTING -p icmp -j LOG查看创建的规则使用如下命令：如果要设置日志前缀，可以通过 --log-prefix 'xx prefix' 进行设置。 默认情况下，iptables 日志被发送到内核的消息缓冲区。要查看这些日志，需要配置 rsyslog 以读取消息缓冲区并将日志写入文件。可以通过编辑 syslog 配置文件来完成，该文件通常位于 /etc/syslog.conf 或 /etc/rsyslog.conf（Ubuntu），打开该文件添加如下配置：完成之后，需要重启 syslog 服务：一切就绪之后，再次从 ubuntu-1 之内发起 ping 请求，同时观察 /var/log/iptables.log 打印出来的日志消息：ping 报文从 ubuntu-1 的 eth0 发出去之后，从 vethb2e6fb3 流入，被 docker0 处理然后经 vethd08a547 到达 ubuntu-2 的 eth0，应答消息按照相反的路径返回。
由于发送消息的目的 IP 和源 IP 在同一网络，所以消息都是通过二层网络直达目的主机，因此对于 ubuntu-1 容器来说，在它的网络协议栈中，就需要 eth0 网卡发送 ARP 广播，来通过 IP 地址找到目的IP对应的 MAC 地址，这个 ARP 请求最终会被 docker0 接收并且广播到插在这个网桥上其他设备，ubuntu-2 收到之后应答对应的 MAC 地址给 ubuntu-1 容器，有了这个 MAC 地址，ubuntu-1 就可以把数据发送出去。ARP（Address Resolution Protocol），是通过三层的IP地址找到对应的二层MAC地址的协议在 ubuntu-1 容器中，可以根据查看已经学习到的 arp 记录： Veth Pair 设备
脱离容器，我们可以直接通过下面的命令我们可以手动创建 veth pair 设备分别加入两个命名空间，不创建网桥，就可以直接通信： 模拟容器通信
通过以下脚本创建两个命名空间，两对 Veth Pair 设备，以及网桥设备，模拟两个命名空间之内的通信：
示例脚本保存并且执行之后，将会输出如下的结果：]]></content>
      <categories>
        <category>Linux</category>
        <category>Network</category>
      </categories>
      <tags>
        <tag>容器网络</tag>
      </tags>
  </entry>
  <entry>
    <title>容器网络-跨主机容器通信</title>
    <url>/2023/12/12/Network/container-network-cross-host/</url>
    <content><![CDATA[单机场景下，相同主机上的容器会通过 Docker 默认创建的 docker0 网桥以及在启动容器时创建的 veth pair 设备实现互通。而对于跨主机容器通信，社区提供了很多种不同的方案，例如 weave、flannel，本篇文章将以 flannel 为例，实现跨主机容器通信，flannel 有多种后端实现，本文以 VXLAN 为例，动手实践，最终达到的效果如下图所示： 创建 node
首先在本地准备两台单独的虚拟机，并且安装 docker，这里我使用 multipass 直接创建两台虚拟机 docker1 和 docker2，命令如下：multipass launch --name docker1 -d 40G docker
multipass launch --name docker2 -d 40G docker最后面的 docker 是镜像名称，因此这不仅创建虚拟机，镜像中已经包含 docker，无需再手动安装。创建成功如下所示： 安装 etcd
flannel 通过 etcd 保存配置信息以及实现相互发现，为了方便测试，通过 docker 在 docker1 节点上启动一个 etcd 容器:docker run -it --env ALLOW_NONE_AUTHENTICATION=yes -d  --net=host  --name etcd bitnami/etcd这里的 --net=host 让这个容器直接使用 docker1 的网络空间，这样 etcd 服务在启动之后，直接监听在 docker1 上，让 docker2 节点也可以访问：随候使用 etcdctl 写入基础配置信息，这里我们以 vxlan 作为 flannel 的后端实现为例（flannel 没有在 Linux ARM 上实现 UDP），VXLAN（Virtual eXtensible Local Area Network） 全称是虚拟可扩展局域网，利用它可以通过三层的网络来搭建虚拟的二层网络，是一种 overlay 技术： 安装 flannel
从 flannel release 页面下载对应平台的预编译版本之后，启动运行。首先在 docker1 节点启动：flanneld 进程启动参数中，--public-ip 和 --iface 用于表示跨主机通信的是网络报文出口，相当于公网IP，他们二选一即可，为了示例，两者都展示。--etcd-prefix 指定我们存储在 etcd 中的配置前缀，--etcd-endpoints 指定 etcd 地址。flanneld 启动之后，从输出的日志中可以看到  从 etcd 读取配置，写入配置文件到 /run/flannel/subnet.env：并且创建 vetp 设备以及监听 4789 端口：然后在 docker2 节点上同样启动 flanneld 进程。启动命令：这同样在 docker2 节点上生成 flannel.88 配置文件以及 /run/flannel/subnet.env：从自动生成的配置文件可以看出，flanneld 为每个节点配置了不同的子网，docker1 节点：188.172.50.1/24，docker2 节点的 188.172.87.1/24。
然而在 docker2 上的 flanneld 进程启动之后，两个节点还会互相发现，互相添加对方的路由信息：
docker1docker2在 docker1 节点上会添加如下的路由信息：有了这条路由信息，操作系统就可以知道凡是发往 188.172.87.0/24 网络的 IP 包，都通过 flannel.88 发出，最后的网关地址是：188.172.87.0，除了添加这条路有信息，还会将 docker2 节点上的 flannel.88 设备对应的 MAC 地址添加在 docker1 节点上：有了这个信息，Linux 内核就可以进行二层网络的封包工作了，不用通过 ARP 进行学习。vxlan 是构建于三层网络之上的二层 overlay 网络，最终的数据还是要通过底层的网络发出去，上面两条信息还不足以在三层网络进行转发。为了在三层网络进行转发数据包，我们还需要知道对对端 veth 设备所在主机的 IP 地址，这也是为什么我们在启动 flanneld 进程通过 --public-ip 或者 --iface 设置该节点的“公网” ip 了。所以在 docker1 节点上的 FDB 数据库中查看到如下信息：
同样在 docker2 节点上会有发往 docker1 节点的路由信息：对端 docker1 节点上的 VETH 设备的 MAC 信息：将数据发往对端时的“公网” IP：到这里两台独立主机的 vxlan 网络就创建好了，我们还可以通过 etcdctl 命令查看它们各自在启动之后写入 etcd 的配置信息：将各自的公网IP以及 VETH 设备的 MAC 地址写入 etcd，这样就能互相配置了。
 配置 docker
为了让两台独立主机上的容器能够互相访问，我们还得让我们的 docker 网络加入这个 vxlan 网络，搭上这个便车，配置也很简单，就是配置 Dcoekr Daemon，设置 Docker 的网络和 flannel 为节点生成的子网保持一致，例如：
docker1docker2例如，docker1 节点上的子网信息如下：所以我们配置 Docker 的网络如下，配置成功之后，重启 Docker：配置成功之后，docker0 网桥的地址也会随之自动配置为该子网的第一个地址：
同样对于 docker2 节点，作如下配置： 创建 container
接下来我们在两个节点上各创建一个容器，测试网络是否能够互通，所需要的一些网络工具包可以用下面的命令进行安装：apt install -y iproute2 net-tools iputils-pingdocker1docker2
结果和预期一样，两个相互独立的子网下的容器 ubuntu1 和 ubuntu2 能够实现互通。
 过程详解
相比 flannel 的 UDP 后端实现，VXLAN 所有相关的解包和封装包的过程都是在内核处理，避免了频繁的用户态和内核态的相互切换。VXLAN 的覆盖网络的设计思想是：在现有的三层网络之上，“覆盖”一层虚拟的、由内核VXLAN模块负责维护的二层网络，使得连接在这个VXLAN二层网络上的“主机”（虚拟机或者容器都可以）之间，可以像在同一个局域网（LAN）里那样自由通信。当然，实际上，这些“主机”可能分布在不同的宿主机上，甚至是分布在不同的物理机房里。而为了能够在二层网络上打通“隧道”，VXLAN会在宿主机上设置一个特殊的网络设备作为“隧道”的两端。这个设备就叫作VTEP，即：VXLAN Tunnel End Point（虚拟隧道端点），就是上图中的 flannel.88 这个设备。
VTEP设备的封装和解封装的对象，是二层数据帧（Ethernet frame），而且这个工作的执行流程，全部是在内核里完成的（因为VXLAN本身就是Linux内核中的一个模块），整个通信的过程如文章开头的原理图所示。
当 ubunut-1 发出 ping 之后，这个目的地址是 188.172.87.3 的 IP 包，会先出现在 docker0 网桥，发现不在自己的网段内，它只能处理 188.172.50.1/24 网段内的包，因此内核会把这个请求进一步路由到本机 flannel.88 设备进行处理，这是因为 docker2 节点在启动的时候向 docker1 节点添加的那条路由信息，然后进一步发往 188.172.87.0 这个网关：188.172.87.0 是 docker2 节点上的 VTEP 设备的IP地址，我们将 docker1 节点上的 VTEP 设备和 docker2 节点上的 VTEP 设备分别称之为源VTEP设备和目的VTEP设备。既然 vxlan 工作在二层网络，它先要在这个报文转发到 188.172.87.0 这个网关，就需要知道这个网关的 MAC 地址，这个 MAC 地址在节点启动之后，相互发现加入对方 VETP 设备的 MAC，例如，对于 docker1 节点：这个目的 veth 设备的 IP 地址以及 MAC 地址都有了，现在就可以进行二层封包工作了。这个二层的数据帧格式如下：可以看到，Linux内核会把目的VTEP设备的MAC地址，填写在图中的Inner Ethernet Header字段，得到一个二层数据帧。需要注意的是，上述封包过程只是加一个二层头，不会改变原始IP包的内容。所以图中的Inner IP Header字段，依然是ubuntu2的IP地址，即188.172.87.3。
上面封装的这个二层数据帧并不能直接在二层网络里传输，VXLAN 是构建与底层网络之上的二层网络，它这个包要发出去，还是要借助底层的网络。所以，内核 的 vxlan 模块只会把它加上 vxlan 的投，而封装成为内部数据帧，让宿主机在外部网络之间传输的数据帧带上这个内部数据帧发出去。而这个VXLAN头里有一个重要的标志叫作VNI，它是VTEP设备识别某个数据帧是不是应该归自己处理的重要标识。而在flannel中，VNI的默认值是1，本次测试中，为了和默认值区分，设置成了 88，这也是为何，docker1 和 docker2 上的VTEP设备都叫作flannel.88的原因，这里的88，其实就是VNI的值。然后，Linux内核会把这个数据帧封装进一个 UDP 包里发出去。
既然是封装成 UDP 报文通过底层网络将我们的数据帧最后发出去，那得知道对端 docker2 节点的公网地址和监听的端口，公网地址和监听端口我们在启动 flannel 的时候已经提交到配置中心了，在 docker1 节点上的 Linux FDB（Fowarding Database） 数据库中通过目的 VETP 设备的 MAC 地址可以反查出 docker2 节点的公网地址。如下：有了这条信息，在二层网络进行UDP包的转发的所有信息就具备了。发往我们前面提到的目的VTEP设备（MAC地址是0a:2e:d0:15:07:4e）的二层数据帧，应该通过flannel.88设备，发往IP地址为192.168.65.4的主机，这个地址正是我们 docker2 节点上的 IP。
UDP包是一个四层数据包，所以Linux内核会在它前面加上一个IP头，即下图中的Outer IP Header，组成一个IP包。并且，在这个IP头里，会填上前面通过FDB查询出来的目的主机的IP地址，即docker2的IP地址192.168.65.4。然后，Linux内核再在这个IP包前面加上二层数据帧头，即下图中的Outer Ethernet Header，并把docker2节点公网IP的MAC地址填进去。这个MAC地址本身，是docker1的ARP自学习的内容，无需flnnael维护，如下是 docker1 节点上的 arp 记录信息：至此，封装出来的通过底层网络传递的数据帧如下所示：到现在为止，docker1 节点上的 flannel.88 设备就可以通过节点上的 enp0s1 网口将这个数据包发出去。显然，这个帧会经过宿主机网络来到docker2的enp0s1网卡。这时候，docker2的内核网络栈会发现这个数据帧里有VXLAN Header，并且VNI=88。所以Linux内核会对它进行拆包，拿到里面的内部数据帧，然后根据VNI的值，把它交给docker2上的flannel.88设备，而flannel.88 设备则会进一步拆包，取出目的容器的 IP 地址，根据这个目的容器的IP的地址，路由给 docker2 节点上的 docker0 网桥，这就到了节点上的容器网络了。
在 ubuntu1 容器中发起 ping 时，我们可以在 docker2 节点上使用如下的命令进行抓包：tcpdump -i enp0s1 -w enp0s1.pcap src host 192.168.65.3然后使用 Wireshark 打开该文件，如下图所示：每次 ping 请求封装的包可以分为上下两部分，一部分是底层网络的 UDP 报文，一部分构建于二层网络之上的 vxlan 报文。 在 UDP 报文中，我们可以看到该请求从 192.168.65.3(52:54:00:ec:05:3f) 发往 192.168.65.4(52:54:00:8b:81:1b)，UDP 监听的端口是 4789。在 vxlan 报文中，可以看到内部数据帧是从 docker1 上的 flannel.88(ba:a9:8c:00:1a:69) 发往 docker2 上的 flannel.88(0a:2e:d0:15:07:4e)，VNI 设备标识是 88，内部数据帧的源IP是 ubuntu1 的 188.172.50.3，目的地址是 ubuntu2 的 188.172.87.3。
 参考链接weave net
VXLAN 基础教程]]></content>
      <categories>
        <category>Linux</category>
        <category>Network</category>
      </categories>
      <tags>
        <tag>容器网络</tag>
      </tags>
  </entry>
  <entry>
    <title>深入理解 iptables</title>
    <url>/2023/12/25/Network/iptables-introduce-and-practice/</url>
    <content><![CDATA[iptables是Linux上重要的防火墙程序，它既是一个用户态的程序，也是一个内核的模块，通过向Linux内核netfilter框架注入钩子函数，以及自定义的规则，实现包过滤，修改，地址转换，日志记录等功能。在k8s生态中，作为kube-proxy的默认后端，实现流量在集群之内的的路由和转发，写这篇文章的最初原有也是想了解k8s是如何将访问到节点上的流量，路由到自定义的Service以及最终的pod内部。
 netfilter
在了解iptables之前，先认识下netfilter，它是Linux内核子系统，允许实现各种与网络相关的操作，它是网络相关操作领域的基础设施，基于此可以实现任何大多数网络包的诉求：包过滤，这可能是大多数场景下的诉求，也是iptables最多的使用场景，可以用来限制某些特征的包进入到本机，例如，指定ip范围，某类协议的；
NAT，负责转换网络数据包的源IP和目的IP；
数据包修改，地址转换只是数据包修改的一种，还可以修改数据包的TOS（Type Of Service，服务类型）、TTL指以及为数据包设置Mark标记等；Netfilter框架在Linux内核中提供了一堆钩子，当网络数据包通过内核中的协议栈时，它会遍历这些钩子。Netfilter允许使用这些钩子编写模块并注册回调函数，当钩子被触发时，回调函数将被调用。这些钩子被用在包处理的以下5个阶段：NF_INET_PRE_ROUTING：当数据包从网卡上收到还有路由之前，这类钩子函数就会被触发，然后内核判断这个数据包是否是发往当前主机的，根据条件，将触发以下两个钩子；
NF_INET_LOCAL_IN：当数据包决定路由到本机上的时候，就会触发这类钩子；
NF_INET_FORWARD：当数据包决定要继续转发的时候，这类钩子会被触发；
NF_INET_LOCAL_OUT：这类钩子函数会在本机生成数据包，发出去之前被调用；
NF_INET_POST_ROUTING：这类钩子函数主要用于从本机发出去的数据包，但是在发到网卡之前；为了清楚地了解Netfilter框架在协议栈内部是如何实现的，我们来看看内核源代码中是如何实现的，我们以linux v6.6版本NF_INET_PRE_ROUTING 阶段的钩子函数为例，了解下它的生效机制。当一个ipv4的包到达的时候，它的处理函数ip_rcv的实现逻辑如下：从上面的实现代码可以看到，收到包之后，NF_INET_PRE_ROUTING 阶段的钩子函数会被调用，我们继续看下NF_HOOK的实现：这个函数做两件事，调用 nf_hook 运行注入的钩子函数，如果通过该阶段的钩子函数，包没有被丢掉，那么就调用 okfn，这里 okfn 对应的是 ip_rcv_finish。所有5个阶段的钩子函数调用如下所示：阶段
文件
函数NF_INET_PRE_ROUTING
ip_input.c
ip_rcvNF_INET_LOCAL_IN
ip_input.c
ip_local_deliverNF_INET_FORWARD
ip_forward.c
ip_forwardNF_INET_LOCAL_OUT
ip_output.c
ip_local_outNF_INET_POST_ROUTING
ip_output.c
ip_output因此，netfilter 提供了一种可以介入到数据包处理的各种流程中的机制，通过它提供的入口，可以将用户注册的各种用于处理包的流程加入到内核中。那么，我们再来看下注册回调函数的流程，首先是 nf_register_net_hooks 和 nf_unregister_net_hooks 这个注册和去注册的函数：这里的 net 参数表明命名空间，如果不指定会取默认值。nf_hook_ops 描述一个 hook 操作：其中nf_hookfn表示一个钩子函数，hooknum 表示这个钩子函数生效的阶段，它是一个枚举值nf_inet_hooks： iptables
netfilter 提供了其他程序介入到内核数据包处理流程的框架，iptables提供了一种数据包过滤的方案实现，和 iptables 同类的还有 ip6tables 以及 arptables 用于不同的协议。最新的nftables 也是一个基于netfilter开发的包过滤系统，用于替换替换现有的 &#123;ip,ip6,arp,eb&#125;tables 命令，使用用户态的nft 命令作为其配置入口，虽然早在Linux kernel 3.13已经加入内核，但是到目前为止仍然不是很普及。
常听到的防火墙工具还有Deb发行版的UFW，旨在简化iptables防火墙配置，提供了一种用户友好的方式来创建基于IPv4或IPv6主机的防火墙，默认情况下，UFW处于禁用状态。以及Red Hat发行版本默认的firewalld，使用 nftables 作为其后端实现。
不过，到目前位置，最广泛使用的还是 iptables，可以使用 iptables-translate 将iptables 命令转换为 nft 命令：iptables 的处理流程图如下所示： table
iptables定义了 filter、nat、raw、mangle以及security5张表，每张表生效的 netfilter 阶段不同，iptables 将对应于 netfilter 不同阶段的规则保存在不同的链中。这5张表生效的阶段如下表所示：表生效阶段以及对应的链
filter
nat
mangle
raw
securityNF_INET_PRE_ROUTING &lt;-&gt; PREROUTING-100
-150
-300NF_INET_LOCAL_IN &lt;-&gt; INPUT 
0
100
-15050NF_INET_FORWARD &lt;-&gt; FORWARD
0-15050NF_INET_LOCAL_OUT &lt;-&gt; OUTPUT 
0
-100
-150
-300
50NF_INET_POST_ROUTING &lt;-&gt; POSTROUTING 100
-150上面横向看表示表示在netfilter对应的阶段，有哪些表里面的规则会生效，表里面的数字表示优先级，优先级较低的最先执行，纵向看表示表在哪些阶段生效，空值表示该表在当前阶段不生效。注册的表会写入内核文件 /proc/net/ip_tables_names：它们的作用分别是：filter：该表包含提供实际防火墙功能的规则，它允许用户决定是否允许数据包到达其目的地；
nat ：此表包含允许用户通过更改数据包的源地址和目标地址将数据包路由到NAT网络上的不同主机的规则，它通常用于允许访问无法直接访问的服务；
mangle：该表包含允许用户更改数据包标头和其他形式数据包更改的规则；
raw：该允许用户在内核开始跟踪其状态之前处理数据包，因此它一般最先被执行；
security：在filter表之后访问该表以实施强制访问控制网络规则，SELinux使用它在数据包上设置SELinux上下文标记；可以继续从内核代码中寻找这些表创建的逻辑，关于内核代码可以不用继续追究，我们只需要知道内核会在启动过程中把这些表创建好，如果感兴趣的可以继续阅读相关代码，security，filter，mangle，nat 以及 raw。
 chains
链是规则的集合，当一个数据到达的时候，就会触发注册对应netfilter阶段中不同表的钩子，然后遍历对应的链中的规则执行。规则是告诉系统如何处理数据包的语句，可以用规则阻止一种类型的数据包，或转发另一种类型的数据包，规则对应的处理动作称为Target。例如，对于下面这条规则：iptables -A INPUT -s 192.168.01 -p TCP -j DROP没有指定表的时候，默认是 filter。这条规则的意思就是匹配源IP为192.168.01包然后丢掉，INPUT指的是链，DROP 就是所谓的 Target。
iptables 中默认的链如下所示：PREROUTING：该链中的规则适用于刚到达网络接口的数据包；
INPUT：该链中的规则在数据包被传递给本地进程之前使用；
OUTPUT：这里的规则适用于刚刚由某个本地进程生成的数据包；
FORWARD：此处的规则适用于通过当前主机路由的任何数据包；
POSTROUTING：该链中的规则适用于即将通过网络接口发出去的数据包；用户可以基于自己的需要新创建链，使用 iptables -N 链名称。
 targets
target指定数据包应该被如何处理，常用的有ACCEPT、DROP或RETURN，以及来自它的扩展包中定义的DNAT、LOG、MASQUERADE、REJECT、SNAT、TRACE和TTL等等。ACCEPT：这意味着 iptables 接受该数据包；
DROP：iptables会丢弃这个数据包，对于任何尝试连接到系统的人来说，看起来就好像这个系统根本不存在一样；
REJECT：iptables拒绝该数据包。对于TCP，它发送一个connection reset数据包，对于UDP或ICMP，它发送一个destination host unreachable数据包，对于发送者来说目的地存在但是出错了；每条连应该有默认的Target，可以使用如下的方式查看或者更新链的默认 Target：Target 还分为终止型和非终止型，ACCEPT, REJECT, DROP 都是终止类型的，意味着在处理完匹配的包之后，后面的规则将不会被执行。而像 LOG、Mark 它们是非终止的，它们对匹配的包做一些体日志记录或者添加标记之后，继续执行下一条规则。
iptables可以用扩展的target模块，它们已经被包含在标准的发布包中。如果要看当前系统已经加载了哪些 target，可以查看内核文件 /proc/net/ip_tables_targets，例如：我们还可以手动加载内核模块，例如，这里加载 xt_AUDIT 扩展：iptables 的扩展信息可以通过 man iptables-extensions 查看，也可以通过查看在线文档。
 module
iptables可以使用扩展的数据包匹配模块，使用-m或--match选项，然后跟上匹配模块的名称，在这之后，根据具体模块的不同，会有各种额外的命令行选项可用。可以在一行中指定多个扩展匹配模块，并且在指定了模块后，可以使用-h或--help选项来获得该模块的特定帮助信息，扩展匹配模块按照规则中指定的顺序运行。
如果指定了-p或--protocol，当遇到未知选项时，iptables 将尝试加载与协议同名的模块，例如，如果指定了 --protocol icmp，当遇到选项 --icmp-type，就会自动加载 icmp 模块，相当于使用了 -p icmp -m icmp。
同样，扩展文档可以使用 man iptables-extensions 来查看，或者查看在线文档。
查看具体模块的帮助文档，可以在指定模块名称的情况下，使用 -h 查看，例如：iptables -m icmp --help。
内核已经加载的匹配模块我们可以查看 /proc/net/ip_tables_matches 文件，如果发现哪些没有加载，可以手动加载，也可以在使用时自动加载。和target不同的是，匹配模块的名称是小写，而target是大写。 rules
一条规则表达了匹配具有什么特征的包做什么动作，使用 iptables 命令创建规则的格式如下所示：sudo iptables [option] CHAIN_rule [-j target]下面是一个示例，表示接受来自192.168.0.27包：sudo iptables –A INPUT –s 192.168.0.27 –j ACCEPT
sudo iptables --append INPUT –-source 192.168.0.27 –-jump DROP根据日常的使用场景，举一些比较常用的例子。
 禁止来自某个IP的报文
REJECT 来自某个IP地址的报文：精确删除这条规则：可以更新这条规则，更换里面的 IP：-t filter 可以不用声明，默认就是这张表。
 添加规则到具体位置
首先需要需要打印出当前表中的规则序号，然后才能精准插入到某个位置：iptables --list --line-numbers这个命令会把规则的顺序打印出来：假设要阻止除了其中一个地址59.45.175.10之外的整个IP块59.45.175.0/24，由于iptables按序遍历规则并且处理，所以在最开始的位置将59.45.175.10加入白名单即可：现在 INPUT 链中的规则应该如下所示： 修改链的默认策略
如果链中没有任何规则匹配时对数据包执行的操作，默认链默认有一个接受策略，可以使用下面的方式更改默认策略：iptables --policy INPUT DROP 禁止访问某个端口
例如，可以禁止某个访问的IP登录我们的主机：可以使用multiport模块提供的匹配功能，禁止访问多个端口：可以使用如下的语法提供反向匹配，!表示除什么之外，这里表示除了22,80,443这几个端口，都禁止访问：禁止icmp请求：REJECT表现出来的就像这个主机存在但是回复了错误，但DROP表现的就像这个目的主机不存在一样，没有任何错误信息： TCP连接状态跟踪
如果通过INPUT链禁止了某个IP访问本机，那我们同样也访问了这个IP，因为即使我们的请求到达了对端，但是对端的响应在到达本机的途中，经过iptables时被丢掉了。但是可以通过conntrack模块解决这个问题，因为iptables是一个有状态的防火墙，可以使用这个模块跟踪一下任意状态：NEW：该状态表示连接的第一个数据包；
ESTABLISHED：此状态表示属于现有连接一部分的数据包，对于处于这种状态的连接，它应该已经收到来自其他主机的答复；
RELATED：此状态表示与另一个ESTABLISHED连接相关的连接。FTP数据连接就是一个例子——它们与已经建立的控制连接相关；
INVALID：这表示数据包没有正确的状态。这可能是由于多种原因造成的，例如系统内存不足或由于某些类型的ICMP流量所致；
UNTRACKED：raw表中具有NOTRACK目标的任何免于连接跟踪的数据包最终都会处于此状态；
DNAT：这是一个虚拟状态，表示包的目的地址已经被nat表中的规则更改；
SNAT：和 DNAT 一样，表示包的源地址已经被更改；因为，为了达到本节开始的目的，允许RELATED和ESTABLISHED状态的包到达本机： 常用防安全攻击规则
如果要阻止圣诞树攻击（TCP所有标志位被设置为1的数据包被称为圣诞树数据包（XMas Tree packet），之所以叫这个名是因为这些标志位就像圣诞树上灯一样全部被点亮），可以用下面这样的命令：为了阻止常见的无效数据包，例如同时设置了SYN和FIN的数据包，我们可以简单地查找同时设置了这两个数据包的数据包。执行此操作：还有阻止不以 SYN开头的新连接数据包： 速率限制
limit 通过令牌桶实现速率限制，它有两个主要参数，--limit-burst 充当缓冲区，是缓冲区大小，如果超过此缓冲区大小，则所有数据包都会被丢弃，但可以以--limit往这个桶里面放入令牌：例如限制每秒只能处理一个ICMP请求：iptables --append INPUT --protocol icmp --match limit --limit 1/sec --limit-burst 1 --jump ACCEPT可以使用recent模块实现一个动态限制，例如，我们可以限制某个IP在过去的180s内最多5次连接到本机，不过这通常需要两个命令配合完成： 本地端口重定向
例如，可以将访问本地80端口的包转发到8080端口： DNAT转换
例如，对于只监听了本地地址的服务，想通过本机公网地址访问，可以使用DNAT进行转换： 规则持久化
通过用户空间的 iptables 命令创建的规则或者链默认只存在于内存中，当系统重新启动就会丢失，如果要对已经创建的规则进行保存，首先可以手动调用 iptables-save 命令：sudo iptables-save &gt; /etc/iptables/rules.v4
sudo ip6tables-save &gt; /etc/iptables/rules.v6在想要恢复的时候，调用 iptables-restore 命令进行恢复：sudo iptables-restore &lt; /etc/iptables/rules.v4
sudo ip6tables-restore &lt; /etc/iptables/rules.v6如果想要自动进行 iptables 规则保存，需要安装 iptables-persistent 服务：sudo apt-get install iptables-persistent这将安装 netfilter-persistent.service 和 iptables.service 两个系统服务，他们之间是冲突的，只能启动一个：netfilter-persistent.service 会自动将最新的规则刷新到 /etc/iptables/rules.v4 文件，并且在系统启动时自动恢复。
 日志记录
如果希望将某些匹配的包记录到日志文件中，可以使用LOG这个Target，正好使用LOG验证下之前说明的iptables在不同阶段不同表的顺序。在使用之前，我们先需要开启rsyslog服务，并且将iptables的日志单独输出到一个文件中：然后重启rsyslog服务：systemctl restart rsyslog然后写入下面的规则，下面这些规则正好是本机产生的数据包发送出去的流程，其中的172.23.32.1是本次测试的目的地：然后发送一个icmp报文到达目的地：ping -c 1  172.23.32.1此时可以从日志文件/var/log/iptables.lo中获取到如下的信息，正好是iptables处理发包经过的表和链：同理，我们也可以使用如下的规则验证收报的的流程：ping之后会得到如下的日志信息，和我们的收报流程正好相符： 参考链接Illustrated introduction to Linux iptables
Iptables Tutorial: Securing VPS with Linux Firewall
A Deep Dive into Iptables and Netfilter Architecture
iptables — a comprehensive guide
What Is iptables and How to Use It?
Nftables - Packet flow and Netfilter hooks in detail
Write a Linux firewall from scratch based on Netfilter
3 ways to make iptables persistent
nftables 中文教程
Redhat - nftables 入门]]></content>
      <categories>
        <category>Linux</category>
        <category>Network</category>
      </categories>
      <tags>
        <tag>iptables</tag>
        <tag>netfilter</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 路由表</title>
    <url>/2023/12/08/Network/linux-routes/</url>
    <content><![CDATA[在学习 Linux 网络相关的知识时或者在定位网络相关的问题中，经常需要使用 route 命令查看路由表，本节主要记录该命令的输出及其含义。Linux 系统上一般有3张路由表，可以通过 ip rule 命令查看：路由表的配置可以通过 ip route list table &#123;name&#125; 输出，如果是查看 main 表，可以直接使用 route -n，例如：各字段主要说明如下：Destination：目标网络或目标主机；
Gateway：网关，连接两个不同网络的设备；
Genmask：目的地址的子网掩码。255.255.255.255 表示目的主机，0.0.0.0 表示默认路由，其他情况 Genmask 和 Destination 组成目标网络；
Flags：标识 U 表示路由生效，G 表示网关，H 表示目标地址是一个主机；
Metric：到目标地址的跳数；
Ref：路由被引用数；
Use: 路由被查询次数；
Iface：接口，去往目的地址所经出口；对于第一条路由，目标地址 0.0.0.0，表示没有明确指定的意思，既默认路由。路由匹配是按照掩码长短从长到端开始匹配，默认路由掩码也是 0.0.0.0，表示最后匹配；
对于中间三条路由，Gateway 都是 0.0.0.0，表示本条路由不经网关，网关是从一个网络进入另一个网络的边缘设备。换句话说，命中网关是 0.0.0.0 的报文，它的目标是可能是同一网络下的其它目标地址。这时候走的是二层直连，需要发起 ARP 请求换取 MAC 地址进行发送。这条路由通常是在网卡上配置 IP 时候自动生成的。在网卡上每绑定一个 IP，就相应地生成一条这样的记录。可以看到本条路由的 Flags 并没有 G 标志。
第五条路由，标志为 H，掩码是 255.255.255.255，表示目标地址是 10.244.186.193，直接发往 cali687d9beb32a，而这个设备的另一端是容器内的 eth0。这种情况也不需要网关，网关为 0.0.0.0。启用或者禁用 Linux 路由转发的方式如下：sysctl -w net.ipv4.ip_forward=1
sysctl -w net.ipv4.ip_forward=0或者echo 1 &gt; /proc/sys/net/ipv4/ip_forward
echo 0 &gt; /proc/sys/net/ipv4/ip_forward查看方式：sysctl net.ipv4.ip_forward或者cat /proc/sys/net/ipv4/ip_forward]]></content>
      <categories>
        <category>Linux</category>
        <category>Network</category>
      </categories>
      <tags>
        <tag>路由表</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 虚拟网络之MACVLAN &amp; IPVLAN</title>
    <url>/2024/03/08/Network/linux-macvlan/</url>
    <content><![CDATA[Macvlan 和 ipvlan 是 Linux 网络驱动程序，可将底层或主机接口直接暴露给主机中运行的虚拟机或容器。在运行裸机服务器时，主机联网可以很简单，只需几个以太网接口和一个默认网关即可提供外部连接。但是当在一台主机上运行多个虚拟机时，就需要在主机内和主机间提供虚拟机之间的连接。单个主机中的虚拟机数量平均不超过 15-20 个。在主机中运行容器时，单个主机中的容器数量很容易超过 100 个，这就需要有复杂的机制来实现容器之间的互联。容器或虚拟机之间的通信大致有两种方式，在底层网络中，通常使用网桥、macvlan、ipvlan将虚拟机或容器直接暴露于主机网络。但是在用于跨主机通信的overlay网络中，会使用 VXLAN 这样的技术进行额外的封装。
在安装 docekr 之后，会默认创建 docker0 这样的网桥，这也是docker默认的容器网络实现方式，连接同一个网桥上的容器，处于相同的网络之内，可以直接在二层实现网络互通，对于外部访问则通过网桥实现。而macvlan和 ipvlan允许单个物理接口创建出多个子接口，其中每个macvlan子都有唯一的MAC和IP地址，并直接暴露在底层网络中。macvlan 接口通常用于虚拟化应用，每个 macvlan 接口都连接到一个容器或虚拟机。macvlan 有4种类型（Private、VEPA、Bridge、Passthru），常用的类型是 Bridge，它允许单个主机中的实体在数据包不离开主机的情况下相互通信。对于外部连接，则使用底层网络，下图显示两个容器使用 macvlan 网桥相互通信并与外界通信，两个容器都将使用 macvlan 子接口直接接入底层网络。
ipvlan 与 macvlan 类似，区别在于每个子接口具有相同的 mac 地址，ipvlan 支持 L2 和 L3 模式，父接口只能选择其中一种工作模式，在 ipvlan l2 模式下，父接口作为交换机来转发子接口的数据，同一个网络的子接口可以通过父接口来转发数据，而如果想发送到其他网络，报文则会通过父接口的路由转发出去。L3 模式下，ipvlan 有点像路由器的功能，它在各个虚拟网络和主机网络之间进行不同网络报文的路由转发工作。只要父接口相同，即使虚拟机/容器不在同一个网络，也可以互相 ping 通对方，因为 ipvlan 会在中间做报文的转发工作。 MACVLAN
可以使用 ip 命令来创建 macvlan 设备：创建两个网络命名空间，将 macvlan 设备分别放入，模拟容器之间的通信，而且将它们的名字在两个命名空间之中都修改为了 eth0：然后设置IP地址并且启用，要注意的是设置的IP地址和eth0必须在同一网段内，例如，这里 eth0 的网络是 172.19.96.0/20：所以，可以将两个 macvlan 设备的地址分别设置为 172.28.248.10 和 172.28.248.9：测试命名空间之间的网络连通性：但是此时从主机无法访问命名空间的网络，从命名空间也无法访问主机网络：这个是 macvlan 网络的限制，解决方案参见这里，通过在主机上再创建一个macvlan子接口，通过它和 net1 和 net2 的网络打通：清理测试现场使用：ip netns delete net1
ip netns delete net2
ip link delete mynet-shim Docker Macvlan 网络
docker 默认的容器网络实现方式是通过docker0网桥将容器都连接起来，实现容器之间的互通，也可以通过 macvlan 实现容器网络。首先在 docker 中需要创建基于 macvlan 的网络，限定容器只能分配 172.28.244.0/22 之内的地址，并且保留地址 172.28.244.254：依然要注意的是这里的子网 172.28.240.0/20 必须和 eth0 同属一个网络内，或者必须是它的子集，eth0 的网络是 172.28.240.0/20。为避免IP冲突，通过指定 ip 的方式创建两个容器，镜像 ubuntu:local 是本地构建的添加了很多网络测试工具：docker run -itd --name ubuntu1 --ip=172.28.244.2 --network macvlan ubuntu:local
docker run -itd --name ubuntu2 --ip=172.28.244.3 --network macvlan ubuntu:local查看容器的 eth0 网口详细信息并测试网络连通性：和上面的示例一样，此时从Host访问荣日和和从容器访问Host都会失败：同样添加如下的设备用于打通主机和容器之间的网络，容器网络和主机网络的网络地址都是一样的，但是在添加路由时只限定了容器网络地址段的地址通过 mynet-shim 进行路由：然后进行测试网络连通正常： Docker多Macvalan网络
如果想在单个主机上创建多个 macvlan 网络时会创建失败，因为 Docker 的 Macvlan 网络会独占整个物理网卡：但是 macvlan 支持 VLAN，所以可以通过 VLAN 将 eth0 划分为不同的网络，然后基于 VLAN 再创建 macvlan 的网络。首先清除之前创建的 macvlan 网络：可以完全不执行这段命令，使用docker创建网络的命令能够自动创建vlan创建 VLAN，设置IP，并启用，如果对网络地址、子网、广播地址不会计算，可以点击这里：然后创建两个 Docker macvlan 网络，这里的父接口指定的是 eth0.10 不再是 eth0，实际上它是一个 VLAN，docker 能够自动识别并且创建vlan：基于两个不同的 macvlan 网络创建两个容器，发现他们之间并不互通，因为它们处于不同的 vlan：相同 vlan 之间的容器网络互通：
eth.10eth.20
但是不同 vlan 之间的网络相互隔离，不能互通：如果想要实现容器和主机的互通，可以使用如下的方法：测试主机到容器的网络连通性：如果还没有为 vlan 设置 IP 地址，执行如下的命令：此时系统的路由如下：再测试容器到主机的网络连通情况：清理现场使用如下方式，vlan 和 macvlan 设备会被自动删除：可以使用下面的命令验证是否有设备残留： ipvlan
ipvlan 主要有两种不同的模式：L2 和 L3。一个父接口只能选择一种模式，依附于它的所有虚拟接口都运行在这个模式下，不能混用模式。ipvlan L2 模式和 macvlan bridge 模式工作原理很相似，父接口作为交换机来转发子接口的数据，同一个网络的子接口可以通过父接口来转发数据，而如果想发送到其他网络，报文则会通过父接口的路由转发出去。L3 模式下，ipvlan 有点像路由器的功能，它在各个虚拟网络和主机网络之间进行不同网络报文的路由转发工作。只要父接口相同，即使虚拟机/容器不在同一个网络，也可以互相 ping 通对方，因为 ipvlan 会在中间做报文的转发工作。 L2
创建三个个 ipvlan 子接口，设置l2工作模式：创建三个命名空间，将新创建的子接口移入且重命名：为子接口设置IP地址，其中net1 和 net2 在同一个网络内，net3 属于其他网络：net1 和 net2 网络连通性正常：net1 和 net3 由于在不同的网络内，即使手动添加路由，网络也不能连通：此时从命名空间内也是无法访问到主机的：但是和主机的连通性可以通过在主机上创建另外一个ipvlan设备当做跳板：再次测试网络连通性，正常：清理现场使用如下方式： L3
创建两个 ipvlan 子接口：创建两个命名空间，将新创建的子接口移入且重命名：为两个子接口设置IP地址，而且他们不在同一个网络内：net1 和 net2 处于相同的网络，网络连通性正常：net1 和 net3 不在同一个命名空间内网络不能互通：但是 l3 模式下，可以通过设置默认路由的方式让两个网络互通：验证 net1 和 net3 之间的连通性：如果想要从命名空间内访问到主机，需要额外创建一个 ipvlan 设备用作跳板：测试从命名空间到达宿主机的网络连通性：清理现场： docker
创建基于 ipvlan 的容器网络：基于 ipvlan 网络创建两个容器：查看容器的 eth0 网口详细信息并测试网络连通性：清除现场： benchmark
使用 betperf 测试工具对容器三种组网方式的性能进行压测，测试机条件：12Core Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz 5.15.146.1-microsoft-standard-WSL2+bridgemacvlanipvlan启动 Server：docker run -it --rm --name perfserver alectolytic/netperf /usr/bin/netserver -D -p 4444启动客户端之前需要知道Server的IP地址：清理现场：docker stop perfserver
创建网络：docker network create -d macvlan --subnet=172.28.240.0/20 --gateway=172.28.240.1 --ip-range 172.28.244.0/22 --aux-address 'host=172.28.244.254' -o parent=eth0 macvlan启动 Server：docker run -it --rm --name perfserver --ip=172.28.244.2 --network macvlan alectolytic/netperf /usr/bin/netserver -D -p 4444启动客户端测试：清理现场：docker stop perfserver
docker network rm macvlan
创建网络：docker network create -d ipvlan --subnet=172.28.240.0/20 --gateway=172.28.240.1 --ip-range 172.28.244.0/22 -o parent=eth0 -o ipvlan_mode=l2 ipvlan_l2启动 Server：docker run -it --rm --name perfserver --ip=172.28.244.2 --network ipvlan_l2 alectolytic/netperf /usr/bin/netserver -D -p 4444启动客户端测试：清理现场：docker stop perfserver
docker network rm ipvlan_l2测试结果如下：容器组网方式
TCP_STREAM
UDP_STREAM
TCP_RR
TCP_CRR
UDP_RRbridge
14739.80 Mbit/s
6560.40 Mbit/s、6559.54 Mbit/s
14782.62次/s
6819.55次/s
15110.83次/smacvlan（bridge）
21311.05 Mbit/s
9805.24 Mbit/s、9801.57 Mbit/s
16331.71次/s
8798.79次/s
16847.11次/sipvlan（l2）
22691.55 Mbit/s
10500.90 Mbit/s、10488.34 Mbit/s
16573.58次/s
8875.21次/s
17010.19次/sipvlan（l3）
22535.93 Mbit/s
10598.59 Mbit/s、10592.38 Mbit/s
16412.51次/s
9049.53次/s
16898.77次/s指标介绍：TCP_STREAM：用来测试进行TCP批量传输时的网络性能，结果表示吞吐量大小；
UDP_STREAM：用来测试进行UDP批量传输时的网络性能。UDP_STREAM方式的结果中有两组数据，分别表示客户端发送和服务端接收的能力；
TCP_RR：TCP_RR方式的测试对象是多次TCP request和response的交易过程，但发生在同一个TCP连接中，这种模式常常出现在数据库应用中。数据库的client程序与server程序建立一个TCP连接以后，就在这个连接中传送数据库的多次交易过程；
TCP_CRR：TCP_CRR的测试对象是多次TCP request和response的交易过程，但为每次交易建立一个新的TCP连接。最典型的应用就是HTTP，每次HTTP交易是在一条单独的TCP连接中进行的。因此，由于需要不停地建立新的TCP连接，并且在交易结束后拆除TCP连接，交易率一定会受到很大的影响；
UDP_RR：使用UDP分组进行request/response的交易过程。由于没有TCP连接所带来的负担，所以相比TCP_RR交易率一定会有相应的提升； 网卡混杂模式
使用如下命令设置：取消设置： 参考链接https://sreeninet.wordpress.com/2016/05/29/macvlan-and-ipvlan/
https://wiki.archlinux.org/title/VLAN
https://hicu.be/docker-networking-macvlan-vlan-configuration
https://blog.oddbit.com/post/2018-03-12-using-docker-macvlan-networks/
https://cloud.tencent.com/developer/article/1432601
https://kiosk007.top/post/使用open-vswitch构建虚拟网络/
Netperf网络性能测试工具详解教程]]></content>
      <categories>
        <category>Linux</category>
        <category>Network</category>
      </categories>
      <tags>
        <tag>MACVLAN</tag>
        <tag>IPVLAN</tag>
        <tag>VLAN</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux tun 设备介绍</title>
    <url>/2024/02/04/Network/linux-tun-device/</url>
    <content><![CDATA[tun 是一种虚拟的3层虚拟网络设备，同时它也是一个字符设备，字符设备意味着可以把它当做一个文件，可以使用文件API操作这个设备，例如 open/read/write，由于它同时也是一个网络设备，所以它也可以像一个网卡一样，从内核网络协议栈中收发报文。所以从它架构上来看，tun 设备的一端连接着应用程序，一端连接着网络协议栈，如下图所示：从在系统中的表象来看，字符设备的文件类型是c，没有大小，但是有主次版本号：tun 设备的创建是通过打开/dev/net/tun这个文件，然后使用ioctl系统调用对其进行clone。也可以使用 ip 命令来实现tun设备的创建：ip tuntap add dev tun1 mod tun新创建的 tun1 设备位于 /sys/class/net/ 目录中：删除使用如下命令：ip tuntap del dev tun1 mod tun ICMP 示例
如前文所述，tun设备的使用需要打开/dev/net/tun并对其clone之后才能进行使用，所以通用的创建tun设备有如下的步骤：创建tun设备需要是root的用户，或者该应用程序需要具有CAP_NET_ADMIN权限，/dev/net/tun必须以读写方式打开，它是创建任何tun/tap虚拟接口的起点，因此也被称为克隆设备(clone device)。操作(open())后会返回一个文件描述符，但此时还无法与接口通信。下一步会使用一个特殊的ioctl()系统调用，该函数的入参为上一步得到的文件描述符，以及一个TUNSETIFF常数和一个指向描述虚拟接口的结构体指针。
tun_alloc 函数的两个参数中：dev：指的是创建的tun设备的名称，如果*dev为'\0'，则内核会尝试使用第一个对应类型的可用的接口，例如从tun0开始，如果tun0存在就为tun1；
flags：用于指定虚拟设备的类型，通常为IFF_TUN或者IFF_TAP，分别代表tun或者tap设备。除此之外，还有一个IFF_NO_PI标志，可以与IFF_TUN或IFF_TAP配合使用。IFF_NO_PI 会告诉内核不需要提供报文信息，即告诉内核仅需要提供&quot;纯&quot;IP报文，不需要其他字节。否则(不设置IFF_NO_PI)，会在报文开始处添加4个额外的字节(2字节的标识和2字节的协议)；如果要完整的处理到达tun设备的ICMP请求，需要手动回响应：完整的示例程序如下所示：
点击展开将完整的源代码保存成文件tun.c，使用如下的命令进行编译：gcc -o taptun tun.c打开终端运行编译生成的可执行程序taptun可执行程序。然后打开另外一个终端，查询创建的tun0设备：这个时候的tun0还未设置IP地址，可以使用如下的命令进行设置并启用：ip a a 10.1.1.2/24 dev tun0
ip l s tun0 up再次查看该设备，可以看到IP地址已经设置，并且处于启用状态：创建设置并且设置IP以后，可以看到操作系统会自动添加一条路由，表示发往 10.1.1.0/24 这个网段的所有报文都会经 tun0 设备发出：所以只要ping这个网段内的任一IP都会到达tun0设备，并且被我们的taptun应用程序收到并处理，例如：应用程序将会有如下的输出： 参考链接IP packets
IPv4 - Packet Structure
ICMP Explained and Packet Format
https://juejin.cn/post/7057833934947614750
https://blog.51cto.com/u_11299290/5107265
https://ctimbai.github.io/2019/03/01/tech/net/vnet/基于taptun写一个ICMP程序/
https://www.zhengwenfeng.com/pages/143447/#应用程序通过tun设备获取ping数据包
https://lxd.me/a-simple-vpn-tunnel-with-tun-device-demo-and-some-basic-concepts
https://www.rectcircle.cn/posts/linux-net-virual-05-tunnel/#tun-tap-虚拟设备
https://www.zhaohuabing.com/post/2020-02-24-linux-taptun/
https://www.luozhiyun.com/archives/684
https://blog.avdancedu.com/52f625ca/
https://www.xzcoder.com/posts/network/05-simple-vpn.html#程序测试]]></content>
      <categories>
        <category>Linux</category>
        <category>Network</category>
      </categories>
      <tags>
        <tag>tun</tag>
      </tags>
  </entry>
  <entry>
    <title>Nginx</title>
    <url>/2022/10/26/Nginx/Nginx/</url>
    <content><![CDATA[
 环境准备
以下使用 docker 准备学习环境。先拉取centos的最新镜像：docker image pull centos
创建一个数据卷用于存放容器中产生的文件：docker volume create centos
启动我们的容器：docker run -d -it -v centos:/workdir --name centos  centos /bin/bash
进入我们的容器：docker exec -it centos /bin/bash Nginx 的主要应用场景静态资源服务，即通过本地文件系统提供服务；
反向代理服务，提供缓存，负载均衡功能；
API服务，通过Openresty直接访问数据库； Nginx 的组成部分Nginx 二进制可执行文件；
Nginx.conf Nginx 配置文件，控制Nginx的行文；
access.log 访问日志，记录一条 http 请求信息；
error.log 错误日志； 热部署
为了便于演示，在编译Nginx的时候添加echo-nginx-module模块，记录一次编译（我所有的操作都是在目录 /workdir下）：源代码下载页面：http://nginx.org/en/download.html 先下载 1.14.1 版本，然后升级到 1.15.6 最新版；下载源代码并且解压，wget http://nginx.org/download/nginx-1.14.1.tar.gz，然后 tar -xzvf nginx-1.14.1.tar.gz下载 nginx-echo-module，wget https://github.com/openresty/echo-nginx-module/archive/master.zip -O nginx-echo-module.zip，并且解压：unzip nginx-echo-module.zip我们开始编译，./configure --prefix=/workdir/nginx --add-module=/workdir/echo-nginx-module-master结束之后，我们执行：make，这时候nginx已经编译好，在 objs 目录下，例如：首次编译，我们执行 make install 安装我们执行的目录：/workdir/nginx至此将看到如下的目录结构：修改Nginx的配置文件让其输出版本号，便于以后升级比较，vim nginx/cong/nginx.conf：利用我们添加的echo模块中包含的 echo 指令输出 Nginx的版本号。启动 Nginx （执行命令 ./nginx/sbin/nginx）之后，我们访问: http://localhost/version，将会看到：我们下载 1.15.6 版本，并且编译好，编译的时候依然带上echo 模块，但不要执行 make install，将会看到如下结构：由于热更新只是替换二进制文件，但是我们在操作之前先备份旧的二进制文件：cp ./nginx/sbin/nginx ./nginx/sbin/nginx.old使用新版的Nginx二进制文件替换掉当前正在使用中的：cp -f  nginx-1.15.6/objs/nginx ./nginx/sbin/nginx发送信号至正在运行的Nginx，告诉它我们要进行热部署，升级Nginx，kill -USR2 MasterPID这个时候会使用新的二进制文件新起一个master进程，并且将新的请求转到新的worker进程中处理，旧的master和worker虽然仍然存活，但已经不再监听相应的端口并且接受请求了，这个时候我们在查看版本号，就是升级之后的版本了：
[root@5b4bb2c41637 sbin]# curl http://localhost/version
1.15.6关闭老的 worker 进程，发送信号给旧的 MasterPID，kill -WINCH MasterPID：可以看到老的worker进程已经关闭了，但是此时老的master进程依然存在，是因为如果升级有问题，我们还可回退。回滚的时候，向老的 master 进程发送 HUP信号，向新的 master 发送 QUIT 信号。如果正常升级之后，应该给老的 master 进程发送 QUIT 信号，使其优雅退出。 nginx 命令行nginx -s quit 优雅退出进程
nginx -s stop 立即退出进程 nginx 常用配置学习
 配置静态资源访问服务器 记录 access 日志
使用 ngx_http_log_module 模块我们来配置记录访问日志： 开启 gzip 压缩
使用 ngx_http_gzip_module 提供的功能，对静态文件进行压缩 开启防盗链
使用 ngx_http_referer_module 提供的功能实现防盗链： 反向代理
使用 ngx_http_upstream_module 模块提供的 upstream 来配置上游服务器：指定某些路径配置反向代理，使用ngx_http_proxy_module提供的指令：
proxy_cache_path 配置缓存存储路径： 配置指令
 location
location 配置指令是由 ngx_http_core_module 模块提供，它的配置是下面这个样组的：它主要是用于根据请求 URL 设置配置，在解码以 ％XX 形式编码的文本，解析对相对路径组件 .和..的引用，并将两个或多个相邻斜杠/的可能压缩为单个斜杠之后，对规范化的URI执行匹配。
一个location 可以被一个前缀字符串定义或者一个正则表达式，正则表达式通过 ~*(大小写不敏感) 或者 ~(大小写敏感) 指定。为了找到与给定请求匹配的 location ，nginx 首先检查使用前缀字符串定义的 location，其中有最长匹配前缀的将被使用，然后按照他们在配置文件中出现的顺序检查正则表达式，正则表达式的搜索在第一个匹配时终止，并使用相应的配置。如果未找到与正则表达式的匹配，则使用先前记住的前缀位置的配置。
location 块是可以嵌套的，但是除了下面提到的。
对于不区分大小写的操作系统（如macOS和Cygwin），与前缀字符串匹配会忽略大小写（0.7.7）。
正则表达式可以包含捕获组，用于后续的其他指令。
如果最长匹配前缀位置具有“^〜”修饰符，则不检查正则表达式。
此外，使用=修饰符可以定义URI和位置的精确匹配。如果找到完全匹配，则搜索终止。例如，如果频繁发生/请求，则定义location = /将加速这些请求的处理，因为搜索在第一次比较之后立即终止。这样的 location 显然不能包含嵌套 location。
我们来通过一个例子说明情况：/ 请求将会匹配 A，/index.html 将会匹配 B，/documents/document.html 将会匹配 C，/images/1.gif 将会匹配 D，/documents/1.jpg 将会匹配 E。
@ 用于定义一个命名 location，这样的 location 不用于常规请求处理，而是用于请求重定向。它们不能嵌套，也不能包含嵌套 location。
匹配顺序是：先精确匹配，然后前缀匹配取最长匹配，然后是正则表达式；但是如果前缀匹配到 ^~ 则不会进行正则表达式匹配，如果匹配到的最长前缀前面没有 ^~ 则会继续按声明顺序进行正则表达式匹配，取匹配到的第一个正则表达式，否则匹配前缀匹配。
 路由重写
NGINX 通过 ngx_http_rewrite_module 模块支持URL重写，支持 if 条件判断，但不支持 else。
NGINX rewrite 指令执行顺序：执行 server 快的 rewrite 指令；
执行 location 匹配；
执行选定的 location 中的 rewrite 指令；如果其中某一步 URI 被重写，则重新执行循环 1-3，直到找到真实存在的文件，如果循环超过10次，则返回 500 错误。
 break 指令
break 的作用域为 server, location, if，用于停止当前虚拟主机的后续 rewrite 指令集： if 指令
语法：if(condition) &#123;...&#125;
默认值：无
作用域：server, location
对给定的条件 condition 进行判断。如果为真，大括号内的 rewrite 指令将被执行。if条件( condition )可以是如下任何内容：一个变量名；false如果这个变量是空字符串或者以0开始的字符串；
使用= ,!= 比较的一个变量和字符串
是用~， ~*与正则表达式匹配的变量，如果这个正则表达式中包含}，;则整个表达式需要用&quot; 或’ 包围
使用-f ，!-f 检查一个文件是否存在
使用-d, !-d 检查一个目录是否存在
使用-e ，!-e 检查一个文件、目录、符号链接是否存在
使用-x ， !-x 检查一个文件是否可执行 return 指令
语法：return code [text];
return code URL;
return URL;
默认值：无
作用域：server，location，if
停止处理并返回指定状态码(code)给客户端。非标准状态码 444 表示关闭连接且不给客户端发响应头。
从0.8.42版本起，return 支持响应URL重定向(对于301，302，303，307），或者文本响应。对于文本或者URL重定向可以包含变量。作为特殊情况，可以将重定向 URL 指定为此服务器的本地URI，在这种情况下，根据请求方案（$scheme）以及 server_name_in_redirect 和 port_in_redirect 指令形成完整重定向URL。
 rewrite 指令
语法：	rewrite regex replacement [flag];
作用域：server, location, if
如果指定的正则表达式匹配请求的URL，URL 将被改变为 replacement 中声明的字符串。rewrite 按照他们在配置文件出现的顺序执行，并且可以使用 [flag] 终止进一步处理。如果 replacement 是以 http://, https://, 或者 $scheme 开始，将不再继续处理，这个重定向将返回给客户端。
flag 参数可以是下列值之一：
last     : 停止处理后续 rewrite 指令集，然后对当前重写的新URI在 rewrite 指令集上重新查找；
break    : 停止处理后续rewrite指令集，并不在重新查找，但是当前 location 内剩余非 rewrite 语句和 location 外的的非 rewrite 语句可以执行；
redirect : 如果 replacement 不是以 http:// 或 https:// 开始，返回302临时重定向；
permanent: 返回 301 永久重定向。
例子：如果这些 rewrite 放到 /download/ location，如下所示, 那么应使用 break 而不是 last, 使用 last 将循环10次匹配，然后返回 500错误:对于重写后的URL（replacement）包含原请求的请求参数，原URL的?后的内容。如果不想带原请求的参数 ，可以在replacement后加一个问号。如下，我们加了一个自定义的参数user=$1,然后在结尾处放了一个问号?,把原请的参数去掉。 rewrite_log 指令
语法：rewrite_log on | off;
作用域：http, server, location, if
开启或关闭以 notice 级别打印 rewrite 处理日志到 error_log 文件。例子： set 指令
语法：set $variable value;
作用域：server, location, if
定义一个变量并赋值，值可以是文本，变量或者文本变量混合体。
 uninitialized_variable_warn 指令
语法：uninitialized_variable_warn on | off;
作用域：http, server, location, if
控制是否输出为初始化的变量到日志。
 参考阅读nginx 平滑升级
nginx rewrite指令
[ngx_http_rewrite_module 官方模块](http://nginx.org/en/docs/htt]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>【multipass】跨平台虚拟机</title>
    <url>/2022/11/13/Other/multipass/</url>
    <content><![CDATA[multipass 是一个很好用的虚拟机软件，基于它能够快速创建出需要的虚拟机环境。 帮助
下载安装之后，本地会有一个 multipass 命令，后续所有的操作都是基于此命令，例如，查看本地帮助： 镜像
使用 multipass find 我们可以查看有哪些可供选择的镜像： 运行
使用 multipass launch 命令能快速启动一个 Ubuntu 虚拟机，如果我们没有指定镜像，会选择 ubuntu 最新的 LTS 版本： 本地虚拟机
使用 multipass list 查看本地正在运行的虚拟机，这里的 primary 是默认的，ubuntu2204 是新创建的： 目录挂载
使用 multipass mount 命令可以将主机的目录挂载到虚拟机，虚拟机中的路径和挂载路径相同： 登录虚拟机
使用 multipass shell 进入虚拟机之后，查看我们挂在的目录，如果要切 root，直接使用 sudo su： 停止、删除
使用 multipass stop ubuntu2204，multipass delete ubuntu2204 以及 multipass purge 可以彻底删除我们创建的虚拟机。
我们可以在创建虚拟机的时候，可以指定更多的参数，例如，指定 CPU，内存，磁盘，目录挂在以及网路模式： 可用网络
可以使用 multipass network 查看我们可以使用的网络类型： 虚拟机信息
可以使用 multipass info 查看虚拟机的信息： 扩容虚拟机
虚拟机的磁盘大小在创建的时候就固定了，目前 multipass 没有提供扩容虚拟机磁盘的直接命令，但是总有大神会给出方案，例如这里的：https://github.com/canonical/multipass/issues/62#issuecomment-1093179387。
但是参考这个方案之前，要查看自己本地的驱动是什么：multipass get local.driver然后安装 qemu：brew install qemu安装之后，使用下面的命令进行 resize：新版本可以用下面的命令：multipass stop $&#123;name&#125;
multipass set local.$&#123;name&#125;.cpus=4
multipass set local.$&#123;name&#125;.disk=60G
multipass set local.$&#123;name&#125;.memory=7G 卸载虚拟机
MacOS:sudo sh &quot;/Library/Application Support/com.canonical.multipass/uninstall.sh&quot; 参考文章Rust Aya 开发 eBPF 程序]]></content>
      <tags>
        <tag>multipass</tag>
      </tags>
  </entry>
  <entry>
    <title>【Regex】正则表达式</title>
    <url>/2022/05/21/Other/regex-expression/</url>
    <content><![CDATA[一直以来，从 JavaScript，PHP，Python到Golang，然后还有linux系统中，无处不见正则表达式的身影，可是一致困扰在POSIX和PCRE的概念中，分不清这两个是个啥，今天就来翻翻正则表达式的老底，了解了解正则表达式的前世今生。
Regular Expression的Regular一般被译为正则、正规、常规。此处的Regular即是规则的意思，Regular Expression即描述某种规则的表达式之意。
正则表达式（英语：Regular Expression，在代码中常简写为regex、regexp或RE），是计算机科学的一个概念。正则表达式使用单个字符串来描述、匹配一系列匹配某个句法规则的字符串。在很多文本编辑器里，正则表达式通常被用来检索、替换那些匹配某个模式的文本。
许多程序设计语言都支持利用正则表达式进行字符串操作。例如，在Perl中就内建了一个功能强大的正则表达式引擎。正则表达式这个概念最初是由Unix中的工具软件（例如sed和grep）普及开的。正则表达式通常缩写成regex，单数有regexp、regex，复数有regexps、regexes、regexen。 历史
正则表示式这一概念最早可以追溯到20世纪40年代的两个神经物理学家Warren McCulloch与Walter Pitts，他们将神经系统中的神经元描述成小而简单的自动控制元。
紧接着，在50年代，数学家1950年代，数学家Stephen Kleene利用称之为正则集合的数学符号来描述此模型，并且建议使用一个简单的概念来表示，于是regular expressions就正式登上历史舞台了。
1968年，Ken Thompson发表了Regular Expression Search Algorithm, 紧接着大神Thompson根据这个论文实现了Unix上编辑器ed的前身qed。ed所支持的正则表示式并不比qed的高级，但是ed是第一个在非技术圈广泛传播的工具，ed有一个命令可以展示文本中符合给定正则表达式的行，这个命令是g/Regular Expression/p，在英文中读作**Global Regular Expression Print**，由于这个命令非常实用，所以后来有了grep、egrep这两个命令。
相比egrep，grep只支持很少的元符号，＊是支持的（但不能用于分组中），但是+、|与?是不支持的；而且，分组时需要加上反斜线转义，像\( ...\)这样才行，由于grep的缺陷性日渐明显，AT&amp;T的Alfred Aho实在受不了了，于是egrep诞生了，这里的e表示extended，加强版的意思，支持了+、|与?这三个元符号，并且可以在分组中使用*，分组可以直接写成(...)，同时用\1,\2...来引用分组。
在grep、egrep发展的同时，awk、lex、sed等程序也开始发展起来，而且每个程序所支持的正则表达式都或多或少的和其他的不一样，这应该算是正则表达式发展的混乱期，因为这些程序在不断的发展过程中，有时新增加的功能因为bug原因，在后期的版本中取消了该功能，例如，如果让grep支持元符号+的话，那么grep就不能表示字符+了，而且grep的老用户会对这很反感。
这种门派自居的时代混乱不堪，总得有人来统一吧。到了1986年，这个人终于来了，他就是**POSIX(Portable Operating System Interface)标准**，POSIX制定了不同操作系统之间都需要遵守的一套规则。当然了，正则表达式也包括其中，终于来个管事的，POSIX规范分为基本正则表达式BRE(Basic Regular Expressions)和扩展正则表达式ERE(Extended Regular Express，ERE)两个流派，所有的POSIX程序可以选择支持其中的一种，具体规范详见下表：从上图可以看出，有三个空白栏，那么是不是就意味这无法使用该功能了呢？答案是否定的，因为我们现在使用的linux发行版，都是集成GNU套件的，GNU是Gnu’s Not Unix的缩写，GNU在实现了POSIX标准的同时，做了一定的扩展，所以上面空白栏中的功能也能使用。下面一一讲解：BRE如何使用+、?呢？需要用\+、\?；
BRE如何使用|呢？需要用\|；
ERE如何使用\1、\2…\9这样的反引用？和BRE一样，就是\1、\2…\9；通过上面总结，可以发现：GNU中的ERE与BRE的功能相同，只是语法不同（BRE需要用\进行转义，才能表示特殊含义）。例如a&#123;1,2&#125;，在ERE表示的是a或aa，在BRE中表示的是a&#123;1,2&#125;这个字符串。为了能够在Linux下熟练使用文本处理工具，我们必须知道这些命令支持那种正则表达式。现对常见的命令总结如下：使用BRE语法的命令有：grep、ed、sed、vim
使用ERE语法的命令有：egrep、awk、emacs当然，这也不是绝对的，比如 sed 通过-r选项就可以使用ERE了，大家到时自己man一下就可以了。还值得一提的是POSIX还定义了一些shorthand，具体如下：[:alnum:]
[:alpha:]
[:cntrl:]
[:digit:]
[:graph:]
[:lower:]
[:print:]
[:punct:]
[:space:]
[:upper:]
[:xdigit:]在使用这些shorthand时有一个约束：必须在[]中使用，也就是说如果像匹配0-9的数字，需要这么写[[:alnum:]]，取反就是[^[:alnum:]]。shorhand 在BRE与EBE中的用法相同。
如果你对sed、awk比较熟悉，你会发现我们平常在变成语言中用的\d、\w在这些命令中不能用，原因很简单，因为POSIX规范根本没有定义这些shorthand，这些是由下面将要说的PCRE中定义的。
除了POSIX标准外，还有一个Perl分支，也就是我们现在熟知的PCRE（Perl兼容正则表达式，Perl Compatible Regular Expressions)，源自于Henry Spencer于1986年1月19日发布的regex，随着Perl语言的发展，Perl语言中的正则表达式功能越来越强悍，为了把Perl语言中正则的功能移植到其他语言中，PCRE就诞生了。现在的编程语言中的正则表达式，大部分都属于PCRE这个分支。
Perl语言第一版是由Larry Wall发布于1987年12月，Perl在发布之初，就因其强大的功能而一票走红，Perl的定位目标就是天天要使用的工具。
Perl比较显诸特征之一是与sed与awk兼容，这造就了Perl成为第一个通用性脚本语言。
随着Perl的不断发展，其支持的正则表达式的功能也越来越强大。其中影响较大的是于1994年10月发布的Perl 5，其增加了很多特性，比如non-capturing parentheses、lazy quantifiers、look-ahead、元符号\G等等。
正好这时也是 WWW 兴起的时候，而Perl就是为了文本处理而发明的，所以Perl基本上成了web开发的首选语言。Perl语言应用是如此广泛，以至于其他语言开始移植 Perl，最终Perl compatible（兼容）的PCRE诞生了，这其中包括了Tcl, Python, Microsoft’s .NET，Ruby，PHP，C/C++， Java等等。
前面说了shorthand在POSIX与PCRE是不同的，PCRE中我们常用的有如下这些：\w 表示[a-zA-Z]
\W 表示[^a-zA-Z]
\s 表示[ \t\r\n\f]
\S 表示[^ \t\r\n\f]
\d 表示[1-9]
\D 表示[^1-9]
\&lt; 表示一个单词的起始
\&gt; 表示一个单词的结尾 PCRE\, 将下一个字符标记为一个特殊字符(File Format Escape)、或一个原义字符（Identity Escape，有^$()*+?.[\&#123;|共计12个)、或一个向后引用(backreferences)、或一个八进制转义符。例如，n匹配字符n。\n匹配一个换行符。序列\\匹配\而\(则匹配(。^, 匹配输入字符串的开始位置。如果设置了RegExp对象的Multiline属性，^也匹配\n或\r之后的位置。$, 匹配输入字符串的结束位置。如果设置了RegExp对象的Multiline属性，$也匹配\n或\r之前的位置。*, 匹配前面的子表达式零次或多次。例如，zo*能匹配z、zo以及zoo。*等价于&#123;0,&#125;。+, 匹配前面的子表达式一次或多次。例如，zo+能匹配zo以及zoo，但不能匹配z。+等价于&#123;1,&#125;。?, 匹配前面的子表达式零次或一次。例如，do(es)?可以匹配do或does中的do。?等价于&#123;0,1&#125;。&#123;n&#125;, n是一个非负整数。匹配确定的n次。例如，o&#123;2&#125;不能匹配Bob中的o，但是能匹配food中的两个o。&#123;n,&#125;, n是一个非负整数。至少匹配n次。例如，o&#123;2,&#125;不能匹配Bob中的o，但能匹配foooood中的所有o。o&#123;1,&#125;等价于o+。o&#123;0,&#125;则等价于o*。&#123;m,n&#125;, m和n均为非负整数，其中n&lt;=m。最少匹配n次且最多匹配m次。例如，o&#123;1,3&#125;将匹配fooooood中的前三个o。o&#123;0,1&#125;等价于o?。请注意在逗号和两个数之间不能有空格。?, 非贪心量化（Non-greedy quantifiers）：当该字符紧跟在任何一个其他重复修饰符（*,+,?，&#123;n&#125;，&#123;n,&#125;，&#123;n,m&#125;）后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。例如，对于字符串oooo，o+?将匹配单个o，而o+将匹配所有o。., 匹配除\r \n之外的任何单个字符。要匹配包括\r \n在内的任何字符，请使用像(.|\r|\n)的模式。(pattern), 匹配pattern并获取这一匹配的子字符串。该子字符串用于向后引用。所获取的匹配可以从产生的Matches集合得到，在VBScript中使用SubMatches集合，在JScript中则使用$0…$9属性，要匹配圆括号字符，请使用\(或\)。(?:pattern), 匹配pattern但不获取匹配的子字符串，也就是说这是一个非获取匹配，不存储匹配的子字符串用于向后引用。这在使用或字符(|)来组合一个模式的各个部分是很有用。例如industr(?:y|ies)就是一个比industry|industries更简略的表达式。(?=pattern), 正向肯定预查（look ahead positive assert），在任何匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如，Windows(?=95|98|NT|2000)能匹配Windows2000中的Windows，但不能匹配Windows3.1中的Windows。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。(?!pattern), 正向否定预查(negative assert)，在任何不匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如Windows(?!95|98|NT|2000)能匹配Windows3.1中的Windows，但不能匹配Windows2000中的Windows。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。(?&lt;=pattern), 反向(look behind)肯定预查，与正向肯定预查类似，只是方向相反。例如，(?&lt;=95|98|NT|2000)Windows能匹配2000Windows中的Windows，但不能匹配3.1Windows中的Windows。(?&lt;!pattern), 反向否定预查，与正向否定预查类似，只是方向相反。例如(?&lt;!95|98|NT|2000)Windows能匹配3.1Windows中的Windows，但不能匹配2000Windows中的Windows。x|y, 匹配x或y。例如，z|food能匹配z或food。(?:z|f)ood则匹配zood或food。[xyz], 字符集合（character class）。匹配所包含的任意一个字符。例如，[abc]可以匹配plain中的a。特殊字符仅有反斜线\保持特殊含义，用于转义字符。其它特殊字符如*、+、各种括号等均作为普通字符。^如果出现在首位则表示不在字符集合；如果出现在字符串中间就仅作为普通字符。连字符 - 如果出现在字符串中间表示字符范围描述；如果如果出现在首位（或末尾）则仅作为普通字符。右方括号应转义出现，也可以作为首位字符出现。[^xyz], 排除型字符集合（negated character classes）。匹配未列出的任意字符。例如，[^abc]可以匹配plain中的plin。[a-z], 字符范围。匹配指定范围内的任意字符。例如，[a-z]可以匹配a到z范围内的任意小写字母字符。[^a-z], 排除型的字符范围。匹配任何不在指定范围内的任意字符。例如，[^a-z]可以匹配任何不在a到z范围内的任意字符。\b, 匹配一个单词边界，也就是指单词和空格间的位置。例如，er\b可以匹配never中的er，但不能匹配verb中的er。\B, 匹配非单词边界。er\B能匹配verb中的er，但不能匹配never中的er。\cx, 匹配由x指明的控制字符。例如，\cM匹配一个Control-M或回车符。x的值必须为A-Z或a-z之一。否则，将c视为一个原义的c字符。\d, 匹配一个数字字符。等价于[0-9]。注意Unicode正则表达式会匹配全角数字字符。\D, 匹配一个非数字字符。等价于[^0-9]。\f, 匹配一个换页符。等价于\x0c和\cL。\n, 匹配一个换行符。等价于\x0a和\cJ。\r, 匹配一个回车符。等价于\x0d和\cM。\s, 匹配任何空白字符，包括空格、制表符、换页符等等。等价于[ \f\n\r\t\v]。注意Unicode正则表达式会匹配全角空格符。\S, 匹配任何非空白字符。等价于[^ \f\n\r\t\v]。\t, 匹配一个制表符。等价于\x09和\cI。\v, 匹配一个垂直制表符。等价于\x0b和\cK。\w, 匹配包括下划线的任何单词字符。等价于[A-Za-z0-9_]。注意Unicode正则表达式会匹配中文字符。\W, 匹配任何非单词字符。等价于[^A-Za-z0-9_]。\ck, 匹配控制转义字符。k代表一个字符。等价于Ctrl-k。用于ECMA语法。\xnn, 十六进制转义字符序列。匹配两个十六进制数字nn表示的字符。例如，\x41匹配A。\x041则等价于\x04&amp;1。正则表达式中可以使用ASCII编码。\num, 向后引用（back-reference）一个子字符串（substring），该子字符串与正则表达式的第num个用括号围起来的捕捉群（capture group）子表达式（subexpression）匹配。其中num是从1开始的十进制正整数，其上限可能是9、31、99甚至无限。例如：(.)\1匹配两个连续的相同字符。\n, 标识一个八进制转义值或一个向后引用。如果\n之前至少n个获取的子表达式，则n为向后引用。否则，如果n为八进制数字（0-7），则n为一个八进制转义值。\nm, 3位八进制数字，标识一个八进制转义值或一个向后引用。如果\nm之前至少有nm个获得子表达式，则nm为向后引用。如果\nm之前至少有n个获取，则n为一个后跟文字m的向后引用。如果前面的条件都不满足，若n和m均为八进制数字（0-7），则\nm将匹配八进制转义值nm。\nml, 如果n为八进制数字（0-3），且m和l均为八进制数字（0-7），则匹配八进制转义值nml。\un, Unicode转义字符序列。其中n是一个用四个十六进制数字表示的Unicode字符。例如，\u00A9匹配版权符号（©）。 POSIX 优先权优先权
符号最高
\高
( )、(?: )、(?= )、[ ]中
*、+、?、&#123;n&#125;、&#123;n,&#125;、&#123;m,n&#125;低
^、$、中介字符次最低
串接，即相邻字符连接在一起最低
| 示例匹配至少同时包含大小写字母，数字以及符号中其中两个的密码字符串：^(?![A-Z]+$)(?![a-z]+$)(?!\d+$)(?!\W+$)\S&#123;8,16&#125;$
123131sdadad
#%sdad@#$dsd 参考阅读正则表达式
Regular_expression
正则表达式应用示例
正则表达式“派别”简述
POSIX Bracket Expressions
MSDN正则表达式语法介绍
正则表达式30分钟入门教程
GNU Regular Expression Extensions
RegExr: Learn, Build, &amp; Test RegEx
Linux/Unix工具与正则表达式的POSIX规范
Comparison of regular expression engines
各种语言或工具软件的不同风格的正则表达式文法规定
Different types of regular expressions Gnulib supports]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>regex</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】Foreign Function</title>
    <url>/2022/05/06/Rust/Rust-ffi/</url>
    <content><![CDATA[世界上的每个程序并非都是用 Rust 编写的，我们希望能够在我们的 Rust 程序中使用许多用其他语言实现的关键库和接口。Rust 的外部函数接口 (FFI) 允许 Rust 代码调用用 C 编写的函数，也可以是 C++。由于大多数操作系统都提供 C 接口，Rust 的外部函数接口允许立即访问各种低级功能。
在本章中，我们将编写一个与 libgit2 链接的程序，libgit2 是一个用于与 Git 版本控制系统一起工作的 C 库。首先，我们使用前一章中展示的 unsafe 特性展示直接从 Rust 使用 C 函数的例子，然后，我们将展示如何构建 libgit2 的安全接口，灵感来自开源 git2-rs。本文假设你熟悉 C 以及编译和链接 C 程序的机制，还假设熟悉 Git 版本控制系统。
现实中确实存在用于与许多其他语言进行通信的 Rust 包，包括 Python、JavaScript、Lua 和 Java。这里没有篇幅介绍它们，但归根结底，所有这些接口都是使用 C 外来函数接口构建的。 通用数据表示
Rust 和 C 的共同点是机器语言，所以为了预测 Rust 值在 C 代码中的样子，反之亦然，需要考虑它们的机器级表示。在该书中，强调了值是如何在内存中实际表示的，所以可能已经注意到 C 和 Rust 的数据世界有很多共同点：Rust 的 usize 和 C 的 size_t 是相同的，结构体在两种语言中基本上也是相同的。为了在 Rust 和 C 类型之间建立对应关系，我们将从基本类型开始，然后逐步发展到更复杂的类型。
鉴于其主要用作系统编程语言，C 对其类型的表示一直出人意料地松散，一个 int 通常为 32 位长，但可能更长，或短至 16 位。C char 可以有符号或无符号，等等。为了应对这种可变性，Rust 的 std::os::raw 模块定义了一组 Rust 类型，这些类型保证与某些 C 类型具有相同的表示形式，它们涵盖了原始整数和字符类型。如下图所示：除了 c_void，这里所有的 Rust 类型都是一些原始 Rust 类型的别名：例如，c_char 是 i8 或 u8；Rust 的 bool 等价于 C/C++ 的布尔值；Rust 的 32 位 char 类型不是 wchar_t 的类似物，wchar_t 的宽度和编码因实现而异。C 的 char32_t 类型更接近，但它的编码仍然不能保证是 Unicode；Rust 的原始 usize 和 isize 类型与 C 的 size_t 和 ptrdiff_t 具有相同的表示；C 和 C++ 指针和 C++ 引用对应于 Rust 的原始指针类型 *mut T 和 *const T；从技术上讲，C 标准允许实现使用 Rust 没有相应类型的表示：36 位整数、带符号值的符号和大小表示等。实际上，在 Rust 被移植到的每个平台上，每个常见的 C 整数类型在 Rust 中都有一个匹配项；要定义与 C 结构兼容的 Rust 结构类型，可以使用 #[repr(C)] 属性。将 #[repr(C)] 放在结构定义上方要求 Rust 在内存中排布结构体的字段，就像 C 编译器排布 C 结构类型一样。例如，libgit2 的 git2/errors.h 头文件定义了以下 C 结构体，以提供有关先前报告的错误的详细信息：可以定义具有相同表示的 Rust 类型，如下所示：#[repr(C)] 属性仅影响结构本身的布局，而不影响其各个字段的表示，因此要匹配 C 结构，每个字段也必须使用类 C 类型：*const c_char 对应于 char *，c_int 表示 int等等。
在这种特殊情况下，#[repr(C)] 属性可能不会改变 git_error 的布局。但是，尽管 C 和 C++ 保证结构的成员按照声明的顺序出现在内存中，每个成员都位于不同的地址，但 Rust 对字段重新排序以最小化结构的整体大小，并且零大小的类型不占用空间。#[repr(C)] 属性告诉 Rust 遵循 C 对给定类型的规则。
还可以使用 #[repr(C)] 来控制 C 风格枚举的表示：如果没有 #[repr(C)]，Rust 将使用单个字节来表示 git_error_code 枚举，使用#[repr(C)]，Rust 使用一个 C int 大小的值，就像 C 一样。
你也可以要求 Rust 给一个枚举与某个整数类型相同的表示。以 #[repr(i16)] 开始前面的定义会给你一个 16 位类型，它与以下 C++ 枚举具有相同的表示：如前所述，#[repr(C)] 也适用于联合体，#[repr(C)] 联合体的字段总是从联合体内存的第一位开始——索引是 0。
假设你有一个 C 结构体，它使用一个 union 来保存一些数据和一个 tag 值来指示应该使用 union 的哪个字段，类似于 Rust 枚举。Rust 代码可以通过将 #[repr(C)] 应用于枚举、结构和 union 类型，并使用 match 语句根据tag在更大的结构中选择union字段来与此结构体互操作：使用这种技术，即使是复杂的结构体也可以轻松地跨 FFI 边界使用。
在 Rust 和 C 之间传递字符串有点困难，C 将字符串表示为指向字符数组的指针，并且以空字符终止。另一方面，Rust 将字符串的长度显式存储在字符串的字段或胖引用 &amp;str 的第二个机器字，Rust 字符串不是以 null 结尾的。事实上，它们可能在其内容中包含空字符，就像任何其他字符一样。
这意味着不能将 Rust 字符串作为 C 字符串借用：如果将 C 代码指针传递给 Rust 字符串，它可能会将嵌入的空字符误认为字符串的结尾，或者在结尾处寻找终止的空字符不在那里。换个方向，你可以借用一个 C 字符串作为 Rust 的 &amp;str，只要它的内容是有效的 UTF-8。
这种情况有效地迫使 Rust 将 C 字符串视为完全不同于 String 和 &amp;str 的类型。在 std::ffi 模块中，CString 和 CStr 类型表示拥有和借用的以空值结尾的字节数组。与 String 和 str 相比，CString 和 CStr 上的方法相当有限，仅限于构造和转换为其他类型。
 定义外部函数和变量
extern 块声明了在其他库中定义的函数或变量，最终的 Rust 可执行文件将与之链接。例如，在大多数平台上，每个 Rust 程序都链接到标准 C 库，因此我们可以像这样告诉 Rust 库的 strlen 函数：这为 Rust 提供了函数的名称和类型，同时将定义留待稍后链接。
Rust 假设在 extern 块中声明的函数使用 C 约定来传递参数和接受返回值，它们被定义为不安全的函数。这些是 strlen 的正确选择：它确实是一个 C 函数，并且它在 C 中的规范要求向它传递一个指向正确终止字符串的有效指针，这是 Rust 无法强制执行的规约。（几乎任何接受原始指针的函数都必须是 unsafe：安全的 Rust 可以从任意整数构造原始指针，而解引用这样的指针将是未定义的行为。）
使用这个 extern 块，我们可以像调用任何其他 Rust 函数一样调用 strlen：CString::new 函数构建一个以 null 结尾的 C 字符串。它首先检查它的参数是否有嵌入的空字符，因为这些字符不能用 C 字符串表示，如果找到任何字符则返回一个错误。否则，它会在末尾添加一个空字节并返回一个拥有结果字符的 CString。
CString::new 的成本取决于你传递给它的类型，它接受任何实现了Into&lt;Vec&lt;u8&gt;的东西。传递一个&amp;str需要一个分配和一个拷贝，因为转换为Vec&lt;u8&gt;会建立一个堆分配的字符串拷贝给vector来拥有。但是通过值传递一个字符串只是消耗了字符串并接管了它的缓冲区，所以除非附加空字符迫使缓冲区被调整大小，否则转换根本就不需要复制文本或分配。
CString 取消对 CStr 的引用，其 as_ptr 方法返回指向字符串开头的 *const c_char，这是 strlen 期望的类型。在这个例子中，strlen 遍历字符串，找到 CString::new 放置在那里的空字符，并返回长度，作为字节数。
还可以在外部块中声明全局变量，POSIX 系统有一个名为 environ 的全局变量，它保存进程的环境变量的值。在 C 中，它被声明为：在 Rust 中可以这样做：在确保 environ 有第一个元素之后，代码调用 CStr::from_ptr 来构建一个借用它的 CStr。to_string_lossy 方法返回一个 Cow&lt;str&gt;：如果 C 字符串包含有效的 UTF-8，则 Cow 将其内容作为 &amp;str 借用，不包括终止的空字节。否则，to_string_lossy 会复制堆中的文本，用官方的 Unicode 替换字符 � 替换格式错误的 UTF-8 序列，并以此构建拥有所有权的 Cow。无论哪种方式，结果都会实现 Display，因此可以使用 &#123;&#125; 格式参数打印它。
 使用库中的函数
要使用特定库提供的函数，可以在 extern 块顶部放置一个 #[link] 属性，该属性命名库 Rust 应该链接可执行文件。例如，这里有一个程序调用 libgit2 的初始化和 shutdown 方法，但没有其他的：extern 块像以前一样声明了 extern 函数。 #[link(name =&quot;git2&quot;)] 属性在 crate 中留下一个注释，大意是当 Rust 创建最终的可执行文件或共享库时，它应该链接到 git2 库。Rust 使用系统链接器来构建可执行文件，在 Unix 上，这会在链接器命令行上传递参数 -lgit2，在 Windows 上，它通过 git2.LIB。
#[link] 属性也可以在库中使用，当你构建一个依赖于其他 crate 的程序时，Cargo 会从整个依赖图中收集链接注释，并将它们全部包含在最终链接中。
在此示例中，如果您想在自己的机器上进行操作，则需要自己构建 libgit2。 这里使用了 libgit2 版本 0.25.1。要编译 libgit2，需要安装 CMake 构建工具和 Python 语言，这里我们使用了 CMake 版本 3.8.0 和 Python 版本 2.7.13。
构建 libgit2 的完整说明可在其网站上找到，但它们非常简单，我们将在此处展示要点。在 Linux 上，假设已经将库的源代码解压缩到目录 /home/jimb/libgit2-0.25.1 中：
$ cd /home/jimb/libgit2-0.25.1
$ mkdir build
$ cd build
$ cmake ..
$ cmake --build .在 Linux 上，这会生成一个共享库 /home/jimb/libgit2-0.25.1/build/libgit2.so.0.25.1，其中包含指向它的通常嵌套的符号链接，包括一个名为 libgit2.so 的文件。在 macOS 上，结果相似，但库名为 libgit2.dylib。
在 Windows 上，事情也很简单，假设已将源代码解压缩到目录 C:\Users\JimB\libgit2-0.25.1。 在 Visual Studio 命令提示符下：
&gt; cd C:\Users\JimB\libgit2-0.25.1
&gt; mkdir build
&gt; cd build
&gt; cmake -A x64 ..
&gt; cmake --build .这些命令与在 Linux 上使用的命令相同，不同之处在于在第一次运行 CMake 时必须请求 64 位构建以匹配 Rust 编译器。(如果你已经安装了 32 位 Rust 工具链，那么你应该在第一个 cmake 命令中省略 -A x64 标志。）这会在目录 C:\Users\JimB\libgit2-0.25.1\build\Debug 生成一个名为 git2.LIB 和 git2.DLL 的文件。（除了 Windows 有很大不同的地方，其余说明均针对 Unix。）
在单独的目录中创建 Rust 程序：
$ cd /home/jimb
$ cargo new --bin git-toy
Created binary (application) `git-toy` package将之前的代码放在 src/main.rs 中，然后尝试构建它，Rust 不知道去哪里找这个 libgit2，所以就会：
$ cd git-toy
$ cargo run
Compiling git-toy v0.1.0 (/home/jimb/git-toy)
error: linking with `cc` failed: exit code: 1
|
= note: /usr/bin/ld: error: cannot find -lgit2
src/main.rs:11: error: undefined reference to 'git_libgit2_init'
src/main.rs:12: error: undefined reference to 'git_libgit2_shutdown'
collect2: error: ld returned 1 exit status
error: aborting due to previous error
error: could not compile `git-toy`.
To learn more, run the command again with --verbose.可以通过编写构建脚本告诉 Rust 在哪里搜索库，Rust 代码在构建时编译并运行 Cargo。构建脚本可以做各种各样的事情：动态生成代码，编译 C 代码以包含在 crate 中等等。在这种情况下，只需要在可执行文件的链接命令中添加一个库搜索路径。当 Cargo 运行构建脚本时，它会解析构建脚本的输出以获取此类信息，因此构建脚本只需将链接的文件位置信息打印到它的标准输出。
要创建构建脚本，请在与 Cargo.toml 文件相同的目录中添加一个名为 build.rs 的文件，其内容如下：这是 Linux 的正确路径，在 Windows 上，您可以将文本 native= 后面的路径更改为 C:\Users\JimB\libgit2-0.25.1\build\Debug。（为了让这个例子简单，我们偷工减料；在实际应用程序中，应该避免在构建脚本中使用绝对路径。我们在本节末尾引用了说明如何执行此操作的文档。）
现在几乎可以运行该程序了，在 macOS 上它可以立即工作，在 Linux 系统上，您可能会看到类似以下内容：
$ cargo run
    Compiling git-toy v0.1.0 (/tmp/rustbook-transcript-tests/git-toy)
    Finished dev [unoptimized + debuginfo] target(s)
    Running `target/debug/git-toy`
target/debug/git-toy: error while loading shared libraries:
libgit2.so.25: cannot open shared object file: No such file or directory这意味着，尽管 Cargo 成功地将可执行文件与库链接起来，但它不知道在运行时在哪里可以找到共享库。Windows 通过弹出一个对话框报告此故障。 在 Linux 上，必须设置 LD_LIBRARY_PATH 环境变量：
$ export LD_LIBRARY_PATH=/home/jimb/libgit2-0.25.1/build:$LD_LIBRARY_PATH
$ cargo run
    Finished dev [unoptimized + debuginfo] target(s) in 0.0 secs
    Running `target/debug/git-toy`在 MacOS 上可能需要设置  DYLD_LIBRARY_PATH，在 windows 上需要设置 PATH 环境变量：
&gt; set PATH=C:\Users\JimB\libgit2-0.25.1\build\Debug;%PATH%
&gt; cargo run
    Finished dev [unoptimized + debuginfo] target(s) in 0.0 secs
    Running `target/debug/git-toy`
&gt;自然，在已部署的应用程序中，希望避免为了查找库的代码而必须设置环境变量，一种替代方法是将 C 库静态链接到 crate 中。这会将库的目标文件与 crate 的 Rust 代码的目标文件和元数据一起复制到 crate 的 .rlib 文件中。
根据 Cargo 约定，提供对 C 库的访问的 crate 应命名为 LIB-sys，其中 LIB 是 C 库的名称，例如 libsqlite3-sys。一个 *-sys crate 应该只包含静态链接的库，和包含extern块以及类型定义的 Rust 模块。更高级别的接口则属于依赖于 *-sys 的 crate。这允许多个上游 crate 依赖于同一个 *-sys crate，假设有一个版本的 *-sys crate 可以满足每个人的需求。
有关 Cargo 支持构建脚本和与系统库链接的完整详细信息，请参阅在线 Cargo 文档。它展示了如何避免构建脚本中的绝对路径、控制编译标志、使用 pkg-config 等工具。git2-rs 也提供了很好的例子。
 libgit2 的原生接口
弄清楚如何正确使用 libgit2 分为两个问题：在 Rust 中使用 libgit2 函数需要什么？我们如何围绕它们构建一个安全的 Rust 接口？我们将一次一个地回答这些问题，在本节中，我们将编写一个程序，该程序本质上是一个巨大的不安全块，其中充满了非惯用的 Rust 代码，反映了混合语言中固有的类型系统和约定的冲突，我们将其称为原生接口，代码会很混乱，但它会让 Rust 代码使用 libgit2 必须执行的所有步骤变得清晰。
然后，在下一节中，我们将构建一个安全的 libgit2 接口，使用 Rust 的类型来执行 libgit2 强加给用户的规约。幸运的是，libgit2 是一个精心设计的 C 库，所以 Rust 的安全要求迫使我们提出的问题都有很好的答案，我们可以构建一个惯用的 Rust 接口，没有不安全的函数。
我们将编写的程序非常简单：它将路径作为命令行参数，在那里打开 Git 存储库，并打印出头部提交。对于原生接口，程序最终将需要比我们之前使用的更大的来自 libgit2 的函数和类型集合，因此将 extern 块移动到它自己的模块中是有意义的。我们将在 git-toy/src 中创建一个名为 raw.rs 的文件，其内容如下：这里的每个 item 都是根据 libgit2 自己的头文件中的声明。例如，libgit2-0.25.1/include/git2/repository.h 包含以下声明：此函数尝试在路径打开 Git 存储库。如果一切顺利，它会创建一个 git_repository 对象，并将指向它的指针存储在 out 指向的位置，等效的 Rust 声明如下：libgit2 公共头文件使用 typedef 定义了 git_repository，但它是不完整的结构体类型：由于这种类型的详细信息对库来说是私有的，因此公共头文件永远不会定义 struct git_repository，从而确保库的用户永远不能自己构建这种类型的实例。 Rust 中不完整结构类型的一种可能类似物是：这是一个结构体类型，包含一个没有元素的数组。 因为 _private 字段不是 pub，所以这种类型的值不能在这个模块之外构造，它完美地反映了只有 libgit2 应该构造的 C 类型，并且只能通过原始指针进行操作。
手工编写大的外部块可能是一件苦差事。如果您正在为复杂的 C 库创建 Rust 接口，可能想尝试使用 bindgen，它具有可以从构建脚本中使用的函数来解析 C 头文件并自动生成相应的 Rust 声明。
接下来我们将完全重写 main.rs。 首先，我们需要声明raw模块：根据 libgit2 的约定，易错函数返回一个整数代码，成功时为正数或者 0，失败时返回负数。如果发生错误，giterr_last 函数将返回一个指向 git_error 结构体的指针，该结构体提供有关出错的更多详细信息。libgit2 拥有这个结构，所以我们不需要自己释放它，但它可能会被我们进行的下一个库调用覆盖。适当的 Rust 接口将使用 Result，但在原始版本中，我们希望按原样使用 libgit2 函数，因此我们必须让自己的函数来处理错误：我们将用这个函数检查 libgit2 的调用结果，例如：这使用了之前使用的相同 CStr 方法：from_ptr 从 C 字符串构造 CStr，to_string_lossy 将其转换为 Rust 可以打印的东西。接下来，我们需要一个函数来打印commit：给定一个指向 git_commit 的指针，show_commit 调用 git_commit_author 和 git_commit_message 来检索它需要的信息。这两个函数遵循 libgit2 文档解释如下的约定：
If a function returns an object as a return value, that function is a getter and the object’s lifetime is tied to the parent object.在 Rust 术语中，author和message是从commit中借用的：show_commit 不需要自己释放它们，但在释放commit后它不能保留它们。由于这个 API 使用原生指针，Rust 不会为我们检查它们的生命周期。
前面的代码假定这些字段包含 UTF-8 文本，这并不总是正确的，Git 也允许其他编码，为简洁起见，我们将在此处忽略这些问题。
我们程序的main函数如下：这从处理路径参数和初始化库的代码开始，所有这些我们以前都见过。第一个新颖的代码是这样的：对 git_repository_open 的调用尝试在给定路径打开 Git 存储库。如果成功，它会为其分配一个新的 git_repository 对象并将 repo 设置为指向该对象。Rust 隐式地将引用强制转换为原始指针，因此在此处传递 &amp;mut repo 提供了调用所期望的 *mut *mut git_repository。
这显示了另一个正在使用的 libgit2 约定（来自 libgit2 文档）：
Objects which are returned via the first argument as a pointer-to-pointer are owned by the caller and it is responsible for freeing them.在 Rust 术语中，像 git_repository_open 这样的函数将新值的所有权传递给调用者。接下来，考虑查找存储库当前最新的 commit 对象hash 的代码：git_oid 类型存储一个对象标识符——一个 160 位的哈希码，Git 在内部（以及在其令人愉悦的用户界面中）使用它来识别提交、文件的单个版本等。对 git_reference_name_to_id 的调用会查找当前“HEAD”提交的对象标识符。
在 C 中，通过将指向变量的指针传递给填充其值的某个函数来初始化变量是完全正常的，这就是 git_reference_name_to_id 期望如何处理它的第一个参数。但是 Rust 不会让我们借用对未初始化变量的引用。我们可以用零初始化 oid，但这是一种浪费：存储在那里的任何值都将被简单地覆盖。
可以要求 Rust 给我们未初始化的内存，但是因为在任何时候读取未初始化的内存都是即时的未定义行为，Rust 提供了一个抽象，MaybeUninit，以简化它的使用。MaybeUninit&lt;T&gt; 告诉编译器为你的类型 T 留出足够的内存，但不要碰它，直到你说这样做是安全的。虽然此内存归 MaybeUninit 所有，但编译器还将避免某些优化，这些优化可能会导致未定义的行为，即使代码中没有对未初始化内存的任何显式访问。
MaybeUninit 提供了一个方法 as_mut_ptr()，它产生一个 *mut T 指向它包装的可能未初始化的内存。通过将该指针传递给初始化内存的外部函数，然后在 MaybeUninit 上调用 unsafe 方法 assume_init 以生成完全初始化的 T，可以避免未定义的行为，而不会产生初始化和立即丢弃值的额外开销。assume_init 是不安全的，因为在不确定内存是否实际初始化的情况下在 MaybeUninit 上调用它会立即导致未定义行为。
在这种情况下，它是安全的，因为 git_reference_name_to_id 初始化了 MaybeUninit 拥有的内存。我们也可以将 MaybeUninit 用于 repo 和 commit 变量，但由于这些只是单个字，我们只需将它们初始化为 null：这需要commit的对象标识符并查找实际的commit，成功时将一个 git_commit 指针存储在commit中。
main 函数的其余部分应该是不言自明的。它调用前面定义的 show_commit 函数，释放提交和存储库对象，并关闭库。
现在我们可以在手头的任何 Git 存储库上试用该程序：
$ cargo run /home/jimb/rbattle
    Finished dev [unoptimized + debuginfo] target(s) in 0.0 secs
        Running `target/debug/git-toy /home/jimb/rbattle`Jim Blandy &lt;jimb@red-bean.com&gt;Animate goop a bit. libgit2 的安全接口
libgit2 的原始接口是一个unsafe特性的完美示例：它当然可以正确使用，但 Rust 无法强制执行必须遵循的规则。为这样的库设计一个安全的 API 就是识别所有这些规则，然后找到将任何违反它们的行为转变为类型或借用检查错误的方法。
那么，这里是 libgit2 对程序使用功能的规则：在使用任何其他库函数之前，必须调用 git_libgit2_init，调用 git_libgit2_shutdown 后不能使用任何库函数；传递给 libgit2 函数的所有值都必须完全初始化，输出参数除外；当调用失败时，传递来保存调用结果的输出参数未初始化，不得使用它们的值；git_commit 对象指的是它派生自的 git_repository 对象，因此前者的寿命不能超过后者；类似地，git_signature 总是从给定的 git_commit 借来的，并且前者的寿命不能超过后者；与commit相关的消息以及作者的姓名和电子邮件地址都是从commit中借用的，在提交被释放后不得使用；一旦一个libgit2 对象被释放，它就不能再被使用；事实证明，可以通过 Rust 的类型系统或通过内部管理细节来构建 libgit2 的 Rust 接口来强制执行所有这些规则。在开始之前，让我们稍微重构一下项目。我们想要一个导出安全接口的 git模块，其中来自之前程序的原始接口是一个私有子模块。
整个源代码树将如下所示：
git-toy/
├── Cargo.toml
├── build.rs
└── src/
    ├── main.rs
    └── git/
        ├── mod.rs
        └── raw.rs我们将完全重写 main.rs，它应该以 git 模块的定义开始：然后我们创建 git 子目录，将 raw.rs 移入：
$ cd /home/jimb/git-toy
$ mkdir src/git
$ mv src/raw.rs src/git/raw.rs需要在 src/git/mod.rs 中声明 raw 模块：因为它不是 pub，所以这个子模块对main程序是不可见的。稍后我们需要使用 libc 中的一些函数，因此我们必须在 Cargo.toml 中添加依赖项。完整的文件现在显示：现在我们已经重构了我们的模块，让我们考虑错误处理。甚至libgit2的初始化函数也会返回一个错误码，所以我们需要先把它整理好才能开始。 一个惯用的 Rust 接口需要它自己的 Errortype 来捕获 libgit2 故障代码以及来自 giterr_last 的错误消息和类。正确的错误类型必须实现通常的Error、Display和Debug。然后，它需要自己的 Result 类型来使用这个 Error 类型。 以下是 src/git/mod.rs 中必要的定义：要检查原始库调用的结果，模块需要一个将 libgit2 返回代码转换为Result的函数：这个和原始版本中的 check 函数之间的主要区别在于，它构造了一个Error值，而不是打印Errir消息并立即退出。
现在我们已经准备好处理 libgit2 的初始化了。安全接口将提供一个代表开放 Git 存储库的 Repository 类型，以及用于解析引用、查找提交等的方法。继续 git/mod.rs，这里是 Repository 的定义：Repository 的 raw 字段不是公开的。由于只有此模块中的代码可以访问 raw::git_repository 指针，因此正确获取此模块应确保始终正确使用指针。
如果创建Repository的唯一方法是成功打开一个新的 Git 仓库，这将确保每个Repository都指向一个不同的 git_repository 对象：由于使用安全接口做任何事情的唯一方法是从 Repository 值开始，并且 Repository::open 以调用 ensure_initialized 开始，我们可以确信 ensure_initialized 将在任何 libgit2 函数之前被调用。其定义如下：std::sync::Once 类型有助于以线程安全的方式运行初始化代码。只有第一个调用 ONCE.call_once 的线程运行给定的闭包。此线程或任何其他线程的任何后续调用都会阻塞，直到第一个调用完成，然后立即返回，而无需再次运行闭包。闭包完成后，调用 ONCE.call_once 很便宜，只需要对存储在 ONCE 中的标志进行原子加载即可。
在前面的代码中，初始化闭包调用git_libgit2_init并检查结果。它稍作调整，只是使用 expect 来确保初始化成功，而不是试图将错误传播回给调用者。
为了确保程序调用 git_libgit2_shutdown，初始化闭包使用 C 库的 atexit 函数，该函数接受一个指向函数的指针以在进程退出之前调用。 Rust 闭包不能用作 C 函数指针：闭包是某种匿名类型的值，带有它捕获或引用的任何变量的值，C函数指针只是一个指针。但是，Rust fn 类型可以正常工作，只要将它们声明为 extern 以便 Rust 知道使用 C 调用约定。本地函数 shutdown 符合要求，并确保 libgit2 正确关闭。
在之前我们提到恐慌跨越语言边界是未定义的行为。从atexit 到shutdown 的调用就是这样一个边界，所以shutdown 不要panic 是很重要的。这就是为什么 shutdown 不能简单地使用 .expect 来处理从 raw::git_libgit2_shutdown 报告的错误。相反，它必须报告错误并终止进程本身。POSIX 禁止在 atexit 处理程序中调用 exit，因此 shutdown 调用 std::process::abort 以突然终止程序。
也许可以安排尽快调用 git_libgit2_shutdown ——比如说，当最后一个 Repository 值被删除时。但无论我们如何安排，调用 git_libgit2_shutdown 必须是安全 API 的职责。在调用它的那一刻，任何现存的 libgit2 对象都会变得不安全，因此安全的 API 不能直接暴露这个函数。
Repository的原始指针必须始终指向一个活动的 git_repository 对象。这意味着关闭存储库的唯一方法是删除拥有它的 Repository 值：通过仅在指向 raw::git_repository 的唯一指针即将消失时调用 git_repository_free，Repository 类型还确保指针在被释放后永远不会被使用。 Repository::open 方法使用一个名为 path_to_cstring 的私有函数，它有两个定义——一个用于类 Unix 系统，一个用于 Windows：libgit2 接口使这段代码有点棘手。在所有平台上，libgit2 都接受路径为以空字符结尾的 C 字符串。在 Windows 上，libgit2 假定这些 C 字符串保存有效的 UTF-8，并在内部将它们转换为 Windows 实际需要的 16 位路径。这通常有效，但并不理想。Windows 允许文件名不是有效的 Unicode，因此无法以 UTF-8 表示。如果你有这样的文件，就不可能把它的名字传给 libgit2。
在 Rust 中，文件系统路径的正确表示是 std::path::Path，它经过精心设计以处理可能出现在 Windows 或 POSIX 上的任何路径。这意味着 Windows 上的路径值无法传递给 libgit2，因为它们不是有效的 UTF-8。因此，尽管 path_to_cstring 的行为不太理想，但考虑到 libgit2 的接口，这实际上是我们能做的最好的事情。
刚刚显示的两个 path_to_cstring 定义依赖于对我们的Error类型的转换：?运算符尝试进行此类转换，并且 Windows 版本显式调用 .into()。这些转换是不起眼的：接下来，让我们弄清楚如何将 Git 引用解析为对象标识符。由于对象标识符只是一个 20 字节的哈希值，因此可以在安全 API 中公开它：我们将给 Repository 添加一个用于查找的方法：尽管 oid 在查找失败时未初始化，但此函数保证其调用者永远不会看到未初始化的值，只需遵循 Rust 的 Result 习惯用法：调用者要么得到一个带有正确初始化的 Oid 值的 Ok，要么得到一个 Err。
接下来，该模块需要一种从Git仓库中检索commit的方法。我们将定义一个 Commit 类型，如下所示：正如我们之前提到的，一个 git_commit 对象永远不能比它从中检索到的 git_repository 对象寿命长。Rust 的生命周期让代码准确地捕捉到了这条规则。
本文前面的 RefWithFlag 示例使用 PhantomData 字段告诉 Rust 将类型视为包含具有给定生命周期的引用，即使该类型显然不包含此类引用，Commit 类型需要做类似的事情。在这种情况下，_marker 字段的类型是 PhantomData&lt;&amp;'repo Repository&gt;，这表明 Rust 应该将 Commit&lt;'repo&gt; 视为它持有对某个 Repository 的生命周期 'repo 的引用。
查找Commit的方法如下：这如何将 Commit 的生命周期与 Repository 的生命周期联系起来？ 根据之前概述的规则，find_commit 的签名省略了所涉及的引用的生命周期（看这里）。如果我们要写出生命周期，完整的签名将显示为：这正是我们想要的：Rust 将返回的 Commit 视为从自身（即 Repository）借来的东西。当一个 Commit 被丢弃时，它必须释放它的 raw::git_commit：从Commit中，可以借用Signature（姓名和电子邮件地址）和提交消息的文本：一个 git_signature 对象总是从别处借用它的文本；特别是 git_commit_author 返回的Signature从 git_commit 借用了它们的文本。所以我们的安全 Signature 类型包含一个 PhantomData&lt;&amp;'text str&gt; 来告诉 Rust 表现得好像它包含一个 &amp;str 的生命周期为 'text.。就像以前一样，Commit::author 正确地将它返回的Signature的文本生命周期连接到Commit的生命周期，而我们不需要编写任何东西，Commit::message 方法对保存提交消息的 Option&lt;&amp;str&gt; 是同理的。
Signature 包括检索作者姓名和电子邮件地址的方法：上述方法依赖于私有实用函数 char_ptr_to_str：_owner 参数的值从未使用，但它有生命周期，如果显示声明是这样的：CStr::from_ptr 函数返回一个 &amp;CStr，它的生命周期是完全无界的，因为它是从一个解引用的原始指针中借来的。无限生命周期几乎总是不准确的，因此最好尽快约束它们。包含 _owner 参数会导致 Rust 将其生命周期归因于返回值的类型，因此调用者可以获得更准确的有界引用。
尽管 libgit2 的文档非常好，但从 libgit2 文档中不清楚 git_signature 的电子邮件和作者指针是否可以为空。作者在源代码中挖掘了一段时间，但无法以某种方式说服自己，最终决定 char_ptr_to_str 可能为空，以防万一。但是在 Rust 中，类型会立即回答这类问题：如果是 &amp;str，则可以指望字符串存​​在；如果是 Option&lt;&amp;str&gt;，则为可选。
最后，我们为我们需要的所有功能提供了安全接口。 src/main.rs 中的新 main 函数被精简了很多，看起来像真正的 Rust 代码：在本文中，我们已经从不提供安全保证的简单接口转变为安全 API，通过将任何违反后者规约的行为，改由 Rust 类型错误来包装本质上不安全的 API。 结果是 Rust 可以确保正确使用接口。在大多数情况下，我们让 Rust 强制执行的规则是 C 和 C++ 程序员最终强加给自己的那种规则。 让 Rust 感觉比 C 和 C++ 严格得多的原因不是规则如此陌生，而是这种执行是机械的和全面的。
 总结
Rust 不是一门简单的语言，它的目标是跨越两个截然不同的世界，它是一种现代编程语言，设计安全，具有闭包和迭代器等便利性，但它旨在让我们以最小的运行时开销控制运行它的机器的原始功能。
语言的轮廓由这些目标决定，Rust 设法用安全代码弥合了大部分差距。它的借用检查器和零成本抽象使我们尽可能接近裸机，而不会冒未定义行为的风险。当这还不够时，或者当想利用现有的 C 代码时，不安全的代码和外部函数接口已准备就绪。但同样，该语言不仅仅为我们提供这些不安全的功能，目标始终是使用不安全的特性来构建安全的 API，这就是我们对 libgit2 所做的。这也是 Rust 团队对 Box、Vec、其他集合、Chaneel等所做的事情：标准库充满了安全抽象，在幕后用一些不安全的代码实现。
具有 Rust 雄心壮志的语言，或许注定不会成为最简单的工具，但 Rust 是安全、快速、并发且有效的。使用它来构建大型、快速、安全、稳健的系统，充分利用它们所运行的硬件的全部功能，用它来让软件变得更好。
]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>Foreign Function</tag>
        <tag>ffi</tag>
        <tag>《Rust 程序设计》</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】运算符重载</title>
    <url>/2022/04/28/Rust/Rust-operator-overloading/</url>
    <content><![CDATA[我们可以为自定义的类型实现加减乘除操作，只要实现标准库的一些 Trait，这称之为运算符重载。下图是可以重载的运算符和需要对应实现的 Trait 列表： 算数和位运算符
在 Rust 中，表达式 a + b 实际上是 a.add(b) 的简写，调用 std::ops::Add 的方法，Rust 标准库数值类型都实现了这个 Trait。所有如果我们要实现类型之间的算数运算，只需要为这个类型实现相应的 Trait 即可。
假设我们需要为 num 中的 Complex&lt;T&gt; 实现 + 运算符：我们之前说过可以为一类类型添加方法，这样的话不至于为 Complex&lt;i32&gt; 和 Complex&lt;u64&gt; 都添加 + 运算符：虽然 Rust 不赞成支持混合类型的操作，但我们可以实现，这里要求 L 必须能和 R 实现加法操作： 一元操作符
Rust 有两个一元操作符 - 和 !，Rust 的所有带符号数字类型都实现了 std::ops::Neg，用于一元负数运算符 -。整数类型和 bool 实现 std::ops::Not，用于一元补码运算符 !。 ! 可以用于 bool 值也可以用于整数的按位取反。
std::ops::Neg 和 std::ops::Not 的定义如下：我们来实现对复数 Complex&lt;T&gt; 的 - 运算： 二元运算符
所有 Rust 的数值类型都实现了算数运算符，整数和 bool 类型实现了位运算符。所有这些 Trait 都有相同的形式，^ 运算符对应的 std::ops::BitXor 如下图所示： 复合赋值运算符
复合赋值表达式类似于 x += y 或 x &amp;= y：它接受两个操作数，对它们执行一些操作，如加法或按位与，并将结果存储回左操作数。在 Rust 中，复合赋值表达式的值始终是 ()，而不是存储的值。
许多语言都有这样的运算符，通常将它们定义为 x = x + y 或 x = x &amp; y 等表达式的简写，但是 Rust 没有采用这种方法。相反，x += y 是方法调用 x.add_assign(y) 的简写，其中 add_assign 是 std::ops::AddAssign 的唯一方法：Rust 的所有数字类型都实现了算术复合赋值运算符，Rust 的整数类型和 bool 实现了按位复合赋值运算符。我们来看一个对 Complex&lt;T&gt; 的假发复合赋值运算符：复合赋值运算符的内置Trait完全不同于相应二元运算符的内置Trait。实现 std::ops::Add 不会自动实现 std::ops::AddAssign。如果你想让 Rust 允许你的类型作为 += 运算符的左操作数，你必须自己实现 AddAssign。
 相等比较
Rust 的相等运算符 == 和 != 是调用 std::cmp::PartialEq 的 eq 和 ne 方法，这个 trait 的定义如下：因为 ne 有个默认实现，我们只需要实现 eq 方法，这里有个为 Complex&lt;T&gt; 的实现：PartialEq 的实现几乎总是如出一辙，每次都显示写出来显得很无聊，所以 Rust 经常会为我们自动派生这个 Trait 的实现：Rust 自动生成的实现本质上与我们的手写代码相同，依次比较类型的每个字段或元素，Rust 也可以为枚举类型派生 PartialEq 实现。自然地，该类型持有的每个值（或者在枚举的情况下可能持有）必须自己实现 PartialEq。
这里我们需要着重注意的是，这与算数运算符不同，eq 获取的是值的引用，这意味着比较 String，Vec 或者 HashMap 不会转移所有权：我们再来看看 Rhs: ?Sized 的约定，之前从未见过。这放宽了 Rust 通常要求类型参数必须是 Sized 类型的要求，让我们可以编写像 PartialEq&lt;str&gt; 或 PartialEq&lt;[T]&gt; 这样的 Trait。eq 和 ne 方法采用 &amp;Rhs 类型的参数，将某些东西与 &amp;str 或 &amp;[T] 进行比较是完全合理的。由于 str 实现了 PartialEq&lt;str&gt;，以下断言是等价的：在这里，Self 和 Rhs 都将是 unsized 类型 str，使得 ne 的 Self 和 rhs 参数都是 &amp;str 值。为什么 PartialEq? 叫做部分相等，因为从数学定义上来说，等价关系应该满足三个要求，对于任何值 x 和 y：如果 x == y 那么 y == x；如果 x == y，y == x 那么 x == z；x == x 永远成立；虽然最后一个足够简单，但最后一个正是出问题的地方。Rust 的 f32 和 f64 是 IEEE 标准浮点值，像 0.0 / 0.0 以及其他没有适当值的表达式必须产生 NaN，而且 NaN 不等于任何值包括自身：因此，虽然 Rust 的 == 运算符满足等价关系的前两个要求，但在 IEEE 浮点值上使用时显然不满足第三个要求，这称为部分等价关系。
如果你希望通用代码需要完全等价关系，则可以改为使用 std::cmp::Eq 作为边界，它表示完全等价关系：如果类型实现 Eq，则 x == x 对于该类型的每个值 x 都必须为真。在实践中，几乎所有实现 PartialEq 的类型也应该实现 Eq； f32 和 f64 是标准库中唯一属于 PartialEq 但不是 Eq 的类型。
标准库定义 Eq 是 PartialEq 的扩展，但是没有添加方法：如果你的类型实现了 PartialEq 也希望是 Eq，那么必须显示实现 Eq，即使不用实现任何新的函数：更简单的是我们可以使用派生 Eq 来实现：泛型类型的派生实现可能取决于类型参数，使用派生属性，Complex&lt;i32&gt; 将实现 Eq，因为 i32 可以，但是Complex&lt;f32&gt; 只会实现 PartialEq，因为 f32 没有实现 Eq。当自己实现 std::cmp::PartialEq 时，Rust 无法检查你的 eq 和 ne 是完全相等还是部分相等。
 有序比较
Rust 在 PartialOrd 中定义了 &lt; &gt; &lt;= &gt;= 的逻辑：这个 Trait 中唯一需要实现的是 partial_cmp 方法，根据它的返回结果，就确定了比较结果：但是如果 partial_cmp 返回 None，这意味着 self 和 other 相对于彼此是无序的：既不大于另一个，也不相等，在 Rust 中，只有 NaN 之间的比较才会有这样的结果。
像其他二元运算符一样，比较左右两种类型的值，左值必须实现 PartialOrd&lt;Right&gt;。 像 x &lt; y 或 x &gt;= y 这样的表达式是下面一些方法的简写：如果想始终确定两个值得大小关系，那么就需要使用更严格的 std::cmp::Ord：这里的 cmp 方法总是返回 Odering，说明两个值总是有顺序的，几乎所有实现 PartialOrd 的类型也实现了 Ord，除了 f32 和 f64。
 Index 和 IndexMut
索引运算符 [] 也是可以重载的，例如，a[i] 实际上是 *a.index(i)，如果这个表达式赋值给可变引用那家么实际上调用的是 *a.index_mut(i)，这俩方法分别代表的是std::ops::Index 和 std::ops::IndexMut，它们的实际定义如下：可以使用单个 usize 来索引切片，引用单个元素，因为切片实现 Index&lt;usize&gt;。但也可以可以使用像 a[i..j] 这样的表达式来引用子切片，因为它们也实现了 Index&lt;Range&lt;usize&gt;&gt;，这个表达式是简写为了：std::collections::HashMap 和 std::collections::BTreeMap 都实现了 Index&lt;&amp;str&gt;。
所以我们可以这样使用：从定义可以看出 IndexMut 扩展了 Index 并且增加了 index_mut 方法。当索引表达式出现在必要的上下文中时，Rust 会自动选择 index_mut。例如，假设我们编写以下代码：IndexMut 的一个限制是，根据设计，它必须返回对某个值的可变引用。这就是为什么你不能使用像 m[&quot;十&quot;] = 10; 这样的表达式的原因。因为向 HashMap 中插入一个值：该表需要首先为“十”创建一个 entry，并使用一些默认值，然后返回一个可变引用，但并非所有类型都具有简单的默认值，而且这里创建一个默认值并且立马丢掉，然后使用新值覆盖。
实现一个二维数组示例，存储图片的像素： 其他运算符
并非所有的运算符都可以重载，例如，用于错误检测的 ?，逻辑运算符 &amp;&amp; 和 ||，范围运算符 .. 和 ..=，借用运算符 &amp; 和赋值运算符 = 不能被重载。
解引用运算符 * 和字段(方法)运算符 . 是可以通过 std::ops::Deref 和 std::ops::DerefMut 重载的。
Rust 不支持重载函数调用运算符 f(x)，而是当你需要一个可调用的值时，用闭包来实现。
]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>《Rust 程序设计》</tag>
        <tag>运算符重载</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】anyhow &amp; thiserror</title>
    <url>/2022/05/11/Rust/anyhow-and-thiserror/</url>
    <content><![CDATA[Rust 中使用 std::result::Result 表示可能出错的操作，成功的时候是 Ok(T)，而出错的时候则是 Err(E)：通常情况下，E 是实现 std::error::Error 的错误类型：我们通常也需要在自己的代码中自定义错误，并且为之手动实现 std::error::Error，这个工作很麻烦，所以就有了 thiserror，自动帮我们生成实现的 std::error::Error 的代码。
而借助于 anyhow::Error，和与之对应的 Result&lt;T, anyhow::Error&gt;，等价于 anyhow::Result&lt;T&gt;，我们可以使用 ? 在可能失败的函数中传播任何实现了 std::error::Error 的错误。 thiserror
可以使用命令 cargo add thiserror 将它添加到自己的项目中，或者在 Cargo.toml 中添加如下的配置：thiserror 可以用于枚举或者结构体，例如，我们来看一个基本的例子： #[error]
如果使用 #[error(...)] 为结构体或者枚举生成自定义错误消息，这将为它们实现 Display：我们可以在错误中插入字段的简写，一共有四种形式：#[error(&quot;&#123;var&#125;&quot;)]   &lt;=&gt; write!(&quot;&#123;&#125;&quot;, self.var)
#[error(&quot;&#123;0&#125;&quot;)]     &lt;=&gt; write!(&quot;&#123;&#125;&quot;, self.0)
#[error(&quot;&#123;var:?&#125;&quot;)] &lt;=&gt; write!(&quot;&#123;:?&#125;&quot;, self.var)
#[error(&quot;&#123;0:?&#125;&quot;)]   &lt;=&gt; write!(&quot;&#123;:?&#125;&quot;, self.0)例如： #[from]
可以使用 #[from] 注解为错误类型实现 From，可以从其他错误生成： #[source]
可以使用 #[source] 属性，或者将字段命名为 source，可为自定义错误实现 source 方法，返回底层的错误类型：或者使用 #[source] 属性标记非 source 的字段，例如：这里是 err 字段：#[from] 和 #[source] 二选一即可，#[from] 也会为类型生成 .source() 方法，例如： #[backtrace]
只要在我们的错误结构体里面放个类型为 std::backtrace::Backtrace 的字段，就会自动实现 backtrace() 方法，可以看 #[from]。
另外，如果使用 #[backtrace] 标记 source（source字段，或者 #[source]，或者 #[from]），那么 backtrace() 方法会转发到 source 的 backtrace。
文档里面的例子（没理解，以后再来改）： #[error(transparent)]
可以通过 #[error(transparent)] 让 source 和 Display 直接使用底层的错误，这对于那些想处理任何的枚举来说是很有用的：
示例一示例二
 anyhow
anyhow::Error 是这个 crate 中最重要的结构体，它是动态错误类型的包装器，能从所有实现了 std::error::Error + Send + Sync + 'static 的错误转换而来，也能转换成 Box&lt;dyn std::error::Error + Send + Sync + 'static&gt;，它有以下特点：anyhow::Error 要求包裹的错误必须是 Send + Sync + 'static；
anyhow::Error 保证 backtrace 是可用的，就是底层的错误类型没有提供；
anyhow::Error 在内存中只占一个机器字而不是两个；如果我们要将 anyhow::Error 以文本形式展出来，可以有下面几种形式：可以使用 &#123;&#125; 或者 .to_string()，但是仅仅打印最外层错误或者上下文，而不是内层的错误；可以使用 &#123;:#&#125; 打印外层和底层错误；可以使用 &#123;:?&#125; 在调试模式打印错误以及调用栈；可以使用 &#123;:#?&#125; 以结构体样式打印错误，例如：另外，既然 anyhow::Error 包装了底层的错误，那就得提供找到内层错误的方法，这里是 downcast_ref： anyhow!
使用 anyhow! 这个宏可以生成 anyhow::Error类型的值，它可以接受字符串，格式化字符串作为参数，或者实现 std::error:Error 的错误作为参数。或者从实现了 std::error::Error 的错误转换而来：又或者： bail!
anyhow::bail 宏用于提前错误返回，它等价于 return Err(anyhow!($args...))，包含这个宏的函数的返回值必须是 Result&lt;_,anyhow::Error&gt;： anyhow::Context
anyhow::Context 为 anyhow::Result 类型提供了 context 方法，能在错误发生时提供更多的上下文信息：这段代码将输出：
Failed to detach the important thing
detach faield对于下面的代码也是输出：将输出：
Failed to read instrs from 
No such file or directory (os error 2)]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>anyhow</tag>
        <tag>thiserror</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】使用Cross进行跨平台编译</title>
    <url>/2023/02/26/Rust/cross/</url>
    <content><![CDATA[Rust 的编译速度和跨平台编译相比 Go 语言就要难用很多，但这也是语言特点，当你从中受益时，必然要付出一些代价，本文主要介绍如何实现跨平台编译，使用 cross 这个工具。
我的工作台是 Mac M2，想编译出 Linux 和 Windows 的可执行文件，使用的代码很简单，就是 Hello World 示例程序，这个不是重点。
使用 cross 首先当然是安装，按照官方的描述，可以使用下面的命令：然后是安装 docker 或者 podman，本文以 docker 为例，讲述使用过程中遇到的问题及其解决方案。cross 的使用很简单，例如，如果我要编译 target 为 aarch64-unknown-linux-gnu，执行： ghcr.io 镜像加速
cross 的工作原理是创建一个容器来构建我们的目标平台软件，但是它的镜像不是在 Dockerhub，所以说传统的镜像加速方法不能对它起作用，另外还有下面这些镜像仓库都不可以：gcr.io、k8s.gcr.io：谷歌镜像仓库；
quay.io ：Red Hat 镜像仓库；
ghcr.io ：GitHub 镜像仓库；例如，我要编译 target 为 aarch64-unknown-linux-gnu 以及 x86_64-pc-windows-gnu，就需要下载这两个镜像：ghcr.io/cross-rs/x86_64-pc-windows-gnu:edge；
ghcr.io/cross-rs/aarch64-unknown-linux-gnu:main所有可用的 target 可以在这里找到。
加速这些镜像的方法就是我们把他下载下来然后传到 Doclerhub，然后我们通过国内的公共镜像加速服务器就可以快速下载。当然自己搞这些太麻烦了，已经有大神做好了自动化，只需要在这里创建个issue，就可自动帮我们完成，例如，这是我创建的两个：https://github.com/togettoyou/hub-mirror/issues，执行完成之后，会在 Dockerhub 创建一个新的 Repo，例如：然后在 Cargo.toml 配置为我们新创建的镜像，例如： sh: 1: cargo: not found
当我将镜像好不容易拉到本地之后，以为可以顺利的编出我想要的软件时，没想到又遇到了错误：在一番查找之后，在 Github 中找到了解决方案：其实这个问题应该与我将 docker 装在虚拟中有关，但是这个解决方案可以从本质上解决问题，镜像中没有安装 rust 工具链。所以我又构建了新的镜像：构建命令为：然后又重新更新 Cargo.toml 为我新建的镜像：再去执行编译命令，终于成功了： x86_64-pc-windows-gnu
以同样的方式，我又编译出了 windows 上的可执行文件，下面是本地自建镜像的 Dockerfile 内容：如果自定义了 Dockerfile文件名，需要使用 -f 指定，构建镜像的命令为：Cargo.toml 配置使用自定义镜像：然后使用 cross 进行编译： 自建镜像
本文中涉及的 target 为 aarch64-unknown-linux-gnu 和 x86_64-pc-windows-gnu 的自建镜像已经上传到 Dockerhub，可以直接使用。]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>跨平台编译</tag>
        <tag>Cross</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】二进制体积减小</title>
    <url>/2023/12/05/Rust/decrease-binary-size/</url>
    <content><![CDATA[本篇文章介绍常用的二进制减小方案，某些场景下，对二进制文件的大小有比较严格的要求，尤其是某些便携嵌入式设备上。
 代码优化
编码阶段，我们可以从以下几点入手：减少使用泛型，考虑使用动态类型替换；但是动态调用相比静态展开有性能损失，需要做权衡；
合理使用宏；有些宏展开后会生成很多代码，如果不合理使用，例如，某些通用的 log 宏，助手宏，会展开生成很多代码导致二进制文件体积增加；
合理使用内联函数；一般我们使用内联函数加快代码执行的速度，但过多的内联函数也会导致二进制体积增加；例如对于泛型和动态类型，这两种方式实现的代码编译之后二进制大小是有差异的，print1 会根据不同类型的参数展开成不同的版本： 编译优化
常用的通过编译优化二进制文件大小的方式有：使用 release 进行编译，相当于设置 opt-level=3，这是 Cargo 默认的方式；
使用 -Cprefer-dynamic 告知 rust 动态依赖标准库；
codegen-units 通常用于被设置为大于0的数，用于在编译时将 crate 分割成不同的单元而让 LLVM 加速编译，但是该值越大意味着越差的代码性能，所以通常将该值设置成 1 牺牲编译时间，而获取较好的程序性能以及较小的代码尺寸；
对于生成的文件进行 strip，去掉 debug 信息；
动态依赖标准库，使用 RUSTFLAGS=&quot;-Cprefer-dynamic&quot; 编译参数，它会以动态方式依赖标准库，所以会将标准库内容从二进制文件中去除；
设置 panic 策略为 abort，出现 panic 时只终止进程，不展开堆栈，不能和第5点同时使用；
设置 lto 为 fat，不能和第5点同时使用；常规 release 模式下的编译设置：常用的命令，手动去除debug信息，以及加回的操作：
]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>编译优化</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】实现智能指针类型</title>
    <url>/2022/05/15/Rust/implement-smart-pointer/</url>
    <content><![CDATA[很多时候，我们需要实现一些自动优化的数据结构，在某些情况下是一种优化的数据结构和相应的算法，在其他情况下使用通用的结构和通用的算法。比如当一个 HashSet 的内容比较少的时候，可以用数组实现，但内容逐渐增多，再转换成用哈希表实现。如果我们想让使用者不用关心这些实现的细节，使用同样的接口就能享受到更好的性能，那么，就可以考虑用智能指针来统一它的行为。
我们来实现一个智能 String，Rust 下 String 在栈上占了 24 个字节，然后在堆上存放字符串实际的内容，对于一些比较短的字符串，这很浪费内存。
参考 Cow，我们可以用一个 enum 来处理：当字符串小于 N 字节时，我们直接用栈上的数组，否则使用 String。但是这个 N 不宜太大，否则当使用 String 时，会比目前的版本浪费内存。
当使用 enum 时，额外的 tag + 为了对齐而使用的 padding 会占用一些内存。因为 String 结构是 8 字节对齐的，我们的 enum 最小 8 + 24 = 32 个字节。
所以，可以设计一个数据结构，内部用1个字节表示字符串的长度，用 30 个字节表示字符串内容，再加上 1 个字节的 tag，正好也是 32 字节，可以和 String 放在一个 enum 里使用，我们暂且称这个 enum 叫 SmartString，它的结构如下图所示：这将输出：
Len: SmartString 32, InlineString: 31
s1: Inline(hello world), s2: Standard(&quot;这是一个超过了三十个字节的很长很长的字符串&quot;)
s1: hello world(11 bytes, 11 chars), s2: 这是一个超过了三十个字节的很长很长的字符串(63 bytes, 21 chars)]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>smart pointer</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】Mutex 使用示例</title>
    <url>/2022/05/15/Rust/mutex-multithre-share/</url>
    <content><![CDATA[使用 std::sync::Mutex 可以多线程共享可变数据，Mutex、RwLock 和原子类型，即使声明为 non-mut，这些类型也可以修改：
]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>mutex</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】幽灵数据（PhantomData）</title>
    <url>/2022/05/17/Rust/phantom-data/</url>
    <content><![CDATA[std::marker::PhantomData 是一个零大小的类型，用于标记一些类型，这些类型看起来拥有类型 T，但实际上并没有：Rust 并不希望在定义类型时，出现目前还没使用，但未来会被使用的泛型参数，例如未使用的生命周期参数以及未使用的类型。
PhantomData 最常见的用例可能是具有未使用的生命周期参数的结构体，例如，这儿有一个结构体 Slice，它有两个 *const T 类型的指针，可能指向某个地方的数组，我们期望 Slice 类型的值在生命周期 'a 内仅仅有效，但是如果像下面这样，'a 我们又无处安放：我们可以使用 PhantomData 告诉编译器就像 Slice 结构包含引用 &amp;'a T 一样来纠正这个问题：这反过来要求 T 类型中的任何引用在生命周期 'a 内都是有效的，初始化 Slice 时，仅需要为 phantom 字段提供值 PhantomData 即可： 示例一
我们现在想设计一个 User 和 Product 的结构体，它们都有数据为 u64 的 id 字段，但是我们不希望 user.id 和 product.id 可以比较：Identifier 中 phantom 字段的引入让 Identifier 在使用时具有了不同的静态类型，但 Identifier 中又实际没有使用类型 T。
 示例二
我们可以使用泛型结构体来实现对同一种类对象不同子类对象的区分，例如，我们的系统中要设计这样一个功能，将用户分为免费用户和付费用户，而且免费用户在体验免费功能之后，如果想升级成付费用户也是可以的。按照我们常规的思维，可能是定义两个结构体 FreeCustomer 以及 PaidCustomer，但是我们可以通过泛型结构体来实现，例如：不过，我们这里的 T 又无处安放，所以又不得不使用 PhantomData，它就像一个占位符，但是又没有大小，可以为我们持有在声明时使用不到的数据：运行测试案例，这将输出：
MichaelFu 正在使用免费功能一
MichaelFu 正在使用免费功能二
MichaelFu（0） 将花费 99.99 元升级到付费用户
MichaelFu 正在使用免费功能一
MichaelFu 正在使用免费功能二
MichaelFu 正在使用付费功能 注意
使用 PhantomData&lt;T&gt; 表示我们的结构体拥有 T 类型的数据，当我们的结构体删除的时候，可能会删除一个或者多个 T 类型的实例。
但是，如果我们的结构体实际上并不拥有类型 T 的数据，那么我们最好使用 PhantomData&lt;&amp;'a T&gt; 或者 PhantomData&lt;*const T&gt; 。
]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>phantom-data</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】代码片段</title>
    <url>/2022/05/12/Rust/some-useful-code/</url>
    <content><![CDATA[ 构造 Double Free
使用 unsafe 特性构造指向同一块内存的两个变量，导致 Double Free： Arc 无法 DerefMove但如果换成 Box 是可以的。
 参数生命周期继承
下面的代码中说明 'a 的生命周期要大于 'c，可以这样理解，如果一个引用的生命周期满足 'a，那么它必然可以满足 'c：或者我们可以给每个引用都声明一个单独的声明周期参数： 早期绑定、晚期绑定
可以阅读：https://dtolnay.github.io/rust-quiz/11
泛型参数可以是早期绑定或晚期绑定，当前（以及在可预见的将来）类型参数总是早期绑定，但生命周期参数可以是早期绑定或后绑定。
早期绑定参数由编译器在单态化期间确定，由于类型参数始终是早期绑定的，因此不能拥具有未解析类型参数的值。例如：但是这个对于生命周期却是允许的，因为生命周期 'a 的实际选择取决于它的调用方式，因此我们可以省略生命周期参数，它将在调用的地方确定：每次调用的生命周期甚至可能不同：
}
出于这个原因，我们不能指定生命周期直到它被调用，也不能让借用检查器去推断它：晚期绑定参数的想法与 Rust 的一个称为“高级Trait边界”（HRTB）的特性有很大的重叠，这是一种机制，用于表示trait参数的界限是后期界限。目前这仅限于生命周期参数，可以使用 for 关键字表达生命周期的HRTB，例如，对于上面的 m1：可以把它理解为这里有一个生命周期，但是我们目前还不需要知道它。
后期绑定生命周期总是无限的；没有语法来表示必须比其他生命周期更长的后期绑定生命周期：
}
除非开发人员明确使用 HRTB 作为语法，否则数据类型的生命周期总是提前绑定的。在函数上，生命周期默认为后期绑定，但在以下情况下可以提前绑定：生命周期在函数签名之外声明，例如在结构体的关联方法中，它可以来自结构体本身；生命周期参数以它必须超过的其他生命周期为界；通过这些规则，我们来看个例子：根据这些规则，签名 fn f&lt;'a&gt;() 具有后期绑定生命周期参数，而签名 fn g&lt;'a: 'a&gt;() 具有早期绑定生命周期参数（即使此处的约束无效）。
示例一（错误）示例二（通过）下面这段代码编译失败，原因很很直接，我们对 buf 存在两次可变借用，但是我们的第一次可变借用在获取 b1 之后就应该失效，只要 buf 存在，b1 和 b2 就应该保持有效。但是从 read_bytes 的实现中我们可以看出，它有一个后期绑定生命周期参数，返回值还和每次调用的可变借用必须具有相同生命周期，所以可变借用得保留到返回值最后一次使用位置。
但是我们将我们的 Buffer 改改，让它拥有一个具有 'a 的 buf，而且让 read_bytes 的返回值生命周期跟 buf 相同，这样就和它的调用者没关系了，生成 b1 和 b2 的可变借用在它们使用完就结束了，这里 read_bytes 的参数生命周期是早期绑定的，在编译期间就能但太态化。
]]></content>
      <categories>
        <category>rust</category>
      </categories>
  </entry>
  <entry>
    <title>【Rust】Crate 和 Module</title>
    <url>/2022/04/22/Rust/%E3%80%90Rust%E3%80%91Crate-%E5%92%8C-Module/</url>
    <content><![CDATA[ Crates
Rust 程序是由 crate 组成的，每个 crate 都是一个完整的的单元：单个库或可执行文件的所有源代码，以及任何相关的测试、示例、工具、配置和其他东西。可以使用 cargo build --verbose 查看项目中使用了哪些 crates。
通常项目的依赖都是配置在 Cargo.toml 文件中，例如：可以通过 cargo build，cargo install 或者 cargo add 下载依赖代码。一旦有了源代码，Cargo 就会编译所有的 crate。它为项目依赖图中的每个 crate 运行一次 rustc（Rust 编译器）。编译库时，Cargo 使用 --crate-type lib 选项。这告诉 rustc 不要寻找 main() 函数，而是生成一个 .rlib 文件，其中包含可用于创建二进制文件和其他 .rlib 文件的编译代码。例如：对于每个 rustc 命令，Cargo 都会传递 --extern 选项，给出 crate 将使用的每个库的文件名。这样，当 rustc 看到像 use num::bigint::BigInt; 这样的代码行时，它可以确定 num 是另一个 crate 的名称，并且通过 Cargo，可以在磁盘上找到已编译的 crate。Rust 编译器需要访问这些 .rlib 文件，因为它们包含库的编译代码， Rust 会将该代码静态链接到最终的可执行文件中。 .rlib 还包含类型信息，因此 Rust 可以检查我们在代码中使用的库功能是否确实存在，以及我们是否正确使用它们，它还包含 crate 的公共内联函数、泛型和宏的副本等。
如果编译程序时，Cargo 使用 --crate-type bin，结果将会生成目标平台的二进制可执行文件。 Edition
Rust 具有极强的兼容性保证，在 Rust 1.0 上编译的任何代码都必须在 Rust 1.50 上编译。但有时社区会遇到令人信服的扩展语言的提议，这会导致旧代码不再编译。例如，经过多次讨论，Rust 确定了一种支持异步编程的语法，将标识符 async 和 await 重新用作关键字。但是这种语言更改会破坏任何使用 async 或 await 作为变量名称的现有代码。
为了在不破坏现有代码的情况下发展，Rust 使用 Edition。Rust 2015 版与 Rust 1.0 兼容。2018 将 async 和 await 更改为关键字，简化了模块系统，并引入了与 2015 不兼容的各种其他语言更改。打开 Cargo.toml 我们会看到如下的 Edition 声明，默认是 2021：Rust 的编译器承诺始终接受该语言的所有现存版本，并且程序可以自由地混合使用不同版本编写的 crate，例如，2015 的 crate 依赖于 2018 的 crate 甚至可以，换句话说，一个 crate 的版本只影响其源代码的解释方式，代码编译完成之后，就没有所谓的 Edition 区分了，在学要使用语言的新功能时，我们只需要修改 Edition即可。
版本不会每年都发布，只有在 Rust 项目决定需要时才会发布，例如，没有 2020 版，将版本设置为 2020 会导致错误。Rust 版本指南 涵盖了每个版本中引入的更改，并提供了版本系统的良好背景，对于新代码，建议总是使用最新的版本，cargo new 默认在最新版本上创建新项目。如果有一个用旧版 Rust 编写的 crate，cargo fix 命令会帮助你自动将代码升级到新版本。
 Profile
配置文件提供了一种更改编译器设置的方法，影响优化和调试符号等内容。Cargo 有 4 个内置配置文件：dev、release、test 和 bench。如果未在命令行上指定配置文件，则会根据正在运行的命令自动选择配置文件。除了内置配置文件外，还可以指定自定义的用户定义配置文件。
可以使用 [profile] 在 Cargo.toml 中更改配置文件设置，在每个命名配置文件中，可以使用如下键/值对更改各个设置：cargo build 会使用 [profile.dev] 的配置，cargo build --release 会使用 [profile.release] 的配置，cargo test 使用 [profile.test] 中的配置。
更多详细的内容请看 Cargo Profiles。
 Module
crate 就是第三方模块，用于项目之间的代码共享，而 Module 是项目内的代码组织。它们充当 Rust 的命名空间、构成 Rust 程序或库的函数、类型、常量等的容器。一个模块如下所示：本例中，模块是 Spore 结构和两个函数的集合。pub 关键字使得标记的项公开，因此可以从模块外部访问它。
一个函数被标记为 pub(crate)，这意味着它在这个 crate 内的任何地方都可用，但不作为外部接口的一部分公开。它不能被其他 crate 使用，也不会出现在这个 crate 的文档中。被标记为 pub 的项目通常称为导出该项目，任何未标记为 pub 的内容都是私有的，只能在定义它的同一模块或任何子模块中使用： 模块嵌套
模块可以嵌套，一个模块可能仅仅是子模块的集合：如果希望嵌套模块中的项目对其他 crate 可见，必须将到达这个项的所有模块都标记为 pub。也可以指定 pub(super)，使项目仅对父模块可见，以及 pub(in &lt;path&gt;)，使其在特定父模块及其后代中可见。这对于深度嵌套的模块特别有用：通过这种方式，我们可以编写一个完整的程序，包含大量代码和整个模块层次结构，以我们想要的任何方式组织起来，而所有这些都在一个源文件中。
 模块和文件系统
如果将模块以单个文件形式组织，这种方式工作很痛苦，大型项目中往往需要拆分，将不同的功能的代码以不同的文件区分，使得代码在逻辑上，物理组织上都能很清晰。
 单文件模块
之前我们是在 spores 模块中使用括号将模块的内容包裹起来的，现在可以在单个源码文件中开发模块。我们在 main.rs 中声明如下模块：然后在 spores.rs 开发该模块的代码：公开和私有的原则和之前讲的是相同的，Rust 从不单独编译模块，即使它们在单独的文件中：当你构建一个 crate 时，会重新编译它的所有模块。当 Rust 看到一个模块时，例如上面的 mod spores; 时，它会检查 spores.rs 和 spores/mod.rs 是否存在，如果都存在或者都不存在，就会报错。
 模块目录（一）
但是当我们的模块中包含子模块时，就不能像 spores.rs 那样单独处理了，就像之前的 plant_structures 模块。如果，我们有下面这样的结构：在 main.rs，我们声明 plant_structures 模块，这会让 Rust 加载 plant_structures/mod.rs：然后，我们再声明子模块：这三个模块的内容存储在名为 leaves.rs、roots.rs 和 stems.rs 的单独文件中，和 plant_structures/mod.rs 同级。
 模块目录（二）
我们也可以使用文件和目录一起组成模块，如果之前的 stems 需要包含 xylem 和 phloem，我们选择保留 plant_structures/stems.rs，然后再添加一个 stems 目录：然后，我们可以在 stems.rs 中声明两个新模块：所以这里有三种模块组织方式：模块在他们自己的文件中；
模块在他们自己的目录中，带有 mod.rs；
模块在他们自己的文件中，带有包含子模块的补充目录； 导入
:: 操作符被用于访问其他模块的功能。我们可以直接使用其他模块中的功能而不实现导入，例如：std 指向标准库的顶层模块，mem 是其中的一个子模块，std::mem::swap 只是其中的一个导出函数。上面的这种使用访问方式有点冗长，另一种方式是将要使用的功能导入当前的模块，使用 use 将 std::mem 引入到当前模块，并且定义新的别 mem：我们可以写 use std::mem::swap; 导入 swap 函数本身而不是 mem 模块。但最好的方式是：导入类型、trait和模块（如 std::mem），然后使用相对路径访问其中的函数、常量和其他成员。例如：我们也可以使用 as 对导入的名称进行重命名：子模块不会自动导入父模块的内容，假设我们的 proteins/mod.rs 中内容是这样子的：那么模块 proteins/synthesis.rs 中如果不导入 AminoAcid 是不能直接使用的：而是，每个模块都是以一个空的状态开始的，必须手动导入它使用的任何内容（也不完全是空的，有预导入）：默认情况下，是从当前模块开始导入：self 是当模块的昵称，因此在 proteins/mod.rs 中可以这样写：也可以简化为：除了从顶层模块导入，从 self 当前模块导入或者从当前的子模块导入之外，还可以通过 super 或者 crate 关键字进行导入，其中 super 表示父模块，而 crate 表示当前模块的 crate。
使用相对于 crate 根目录的导入而不是相对于当前路径的导入，有助于在项目中移动代码。因为如果当前模块的路径发生更改，所有导入都不会中断。例如：之前看了从父模块导入子模块，但是如果从子模块导入父模块的内容，可以使用 super::。
如果你有一个模块和外部 crate 同名，在导入的时候就要注意了，否则会引起错误。例如，如果引用了 image，自己也有个 image 模块：解决这个问题的方法是使用绝对导入，导入以 :: 开始，例如，如果要导入第三方 image，可以这样写：引入内部的 image module 可以这样写： 预导入
之前说每个模块都以空的状态开始，但其实也不完全是空的，因为 Rust 有很多常用的类型，为了简化编程，Rust 会帮我们导入，不用我们显示导入。例如：Vec 和 Result。
自动导入的内容可以看这里，std::prelude。
 别名导出
use 只是将我们使用的内容从其他模块或者 crate导入并且在本模块起了个没别名，但是它也可以将导入的内容重新导出。例如：这意味着 Leaf 和 Root 是 plant_structures 模块中的公共内容，它们也仍然是 self::leaves::Leaf 和 self::roots::Root 的别名。
 结构体导出
module 可以包含用户定义的结构体类型，使用 struct 关键字引入，它和它的字段也可以由 pub 声明是否导出。一个简单的结构如下所示：结构体的所有字段，甚至私有字段，都可以在声明结构体的模块及其子模块中访问，在模块之外，只能访问导出字段。
 静态变量和常量
const 关键字引入了一个常量。 语法和 let 一样，只是它可能被标记为 pub，并且类型是必需的。此外，大写名称对于常量来说是常规的：static 关键字引入了一个静态项，和 const：常量有点像 C 中的 #define，值会被编译到使用的地方。静态变量是在程序开始运行之前设置并持续到退出的变量。在代码中使用常量作为 magic number 和字符串，对大量数据或任何需要借用常量值的引用的时候使用静态。
没有 mut 类型常量，静态变量可以标记为 mut，Rust 无法强制执行其关于对 mut 静态变量的独占访问的规则。因此，它们本质上是非线程安全的，安全代码根本不能使用它们，Rust 不鼓励全局可变状态： 开发 library 项目
如果想要将项目编译成一个 lib 而不是一个可执行文件，我们只需要三步：将 src/main.rs 重命名成 src/lib.js；添加 pub 关键字给 src/lib.js 中的导出内容；移除 src/main.rs 中的 main 函数；我们不需要更改 Cargo.toml 中的任何内容 默认情况下，cargo build 查看源目录中的文件并确定要构建的内容。当它看到文件 src/lib.rs 时，就知道需要去构建一个 lib。src/lib.rs 中的代码构成了库的根模块，使用我们的其他 crate 只能访问此根模块的公共项目。
 src/bin 目录
我们可以让一个项目是 lib，也可以让它同时编译成一个可执行程序，只是需要将 main 函数移到目录 sr/bin 中，而且可以有多个 main 函数，例如我的项目结构如下：各个文件的内容如下：
src/lib.rssrc/bin/mandelbrot.jssrc/bin/mandelbrot_v2/mandelbrot.jsCargo.toml
我们可以指定运行不同的 main 函数：
~/WORKDIR/rust/mandelbrot 20:25:13
$ cargo run --bin mandelbrot
    Finished dev [unoptimized + debuginfo] target(s) in 0.00s
    Running `target/debug/mandelbrot`
4057691201/1283082416~/WORKDIR/rust/mandelbrot 20:25:15
$ cargo run --bin mandelbrot_v2
  Compiling mandelbrot v0.1.0 (/Users/fudenglong/WORKDIR/rust/mandelbrot)
    Finished dev [unoptimized + debuginfo] target(s) in 0.15s
    Running `target/debug/mandelbrot_v2`
4057691201/1283082416 属性
Rust 程序中的任何项目都可以用属性进行修饰。属性是 Rust 用于向编译器编写杂项指令和建议的语法。例如，假设您收到以下警告：
libgit2.rs: warning: type `git_revspec` should have a camel case name
such as `GitRevspec`, #[warn(non_camel_case_types)] on by default但是你选择这个名字是有原因的，你希望屏蔽这个告警，可以通过在类型上添加 #[allow] 完成：条件编译是使用属性编写的另一个功能，即 #[cfg]：#[cfg] 常用的属性可以看 条件编译。
给函数添加 #[inline] 属性可以建议编译器根据情况决定是否内联函数。当一个 crate 中定义的函数或方法在另一个 crate 中被调用时，Rust 不会内联它，除非它是泛型的或显式标记为 #[inline]。Rust 还支持更直接的 #[inline(always)]，要求在每个调用点内联扩展函数，并支持 #[inline(never)]，要求永远不要内联函数。
一些属性，如 #[cfg] 和#[allow]，可以附加到整个模块并应用于其中的所有内容。其他的，如 #[test] 和#[inline]，必须附加到单个项目，每个属性都是可以指定参数进行定制，这里看完整的属性列表。
要将属性附加到整个 crate，请将其添加到 main.rs 或 lib.rs 文件的顶部，在任何内容之前，然后写 #! 而不是#，像这样：#! 通常只用于文件的开头，用于将属性附加到整个模块或 crate。某些属性总是使用 #! 语法，因为它们只能应用于整个 crate。 例如，#![feature] 属性用于打开 Rust 语言和库的不稳定特性，这些特性是实验性的，因此可能存在错误，或者将来可能会被更改或删除。
例如，Rust 为跟踪宏的扩展提供了实验性支持，比如 assert!，但是由于这种支持是实验性的，你只能通过(1) 安装 nightly 版本的 Rust；
(2) 来使用#![feature(trace_macros)] 明确使用 trace_macros； 单元测试
Rust 内置了一个单元测试框架，任何由 #[test] 标记的普通函数是测试函数：cargo test 用于运行项目中的所有测试函数：
$ cargo test
Compiling math_test v0.1.0 (file:///.../math_test)
Running target/release/math_test-e31ed91ae51ebf22
running 1 test
test math_works ... ok
test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out可以通过 cargo test TESTNAME 指定要运行的测试函数需要包含的关键字，以运行某些测试。
通常使用 asset! 和 asset_eq! 在测试中对结果进行断言，如果断言失败，程序就会 panic。asset! 和 asset_eq! 没有包含在 release 版本中，如果仅仅是构建 debug 版本，可以使用 debug_assert! 和 debug_assert_eq!。
为了测试错误情况，可以添加 #[should_panic] 给测试函数，这个例子中我们也使用了 #allow 允许我们无条件 panic：还可以从测试中返回 Result&lt;(), E&gt;：标有#[test] 的函数是会条件编译的。普通的 cargo build 或 cargo build --release 会跳过测试代码。但运行 cargo test 时，Cargo 会构建程序两次：一次以普通方式，一次来运行测试。这意味着单元测试可以与他们测试的代码一起使用，如果需要，可以访问内部实现细节，而且没有运行时成本。但是，它可能会导致一些警告。 例如：在省略了测试代码的构建中，roughly_equal 似乎没有被使用，Rust 会报错：
$ cargo build
Compiling math_test v0.1.0 (file:///.../math_test)
warning: function is never used: `roughly_equal`
--&gt; src/crates_unused_testing_function.rs:7:1
|
7 | / fn roughly_equal(a: f64, b: f64) -&gt; bool &#123;
8 | | (a - b).abs() &lt; 1e-6
9 | | &#125;
| |_^
|
= note: #[warn(dead_code)] on by default按照约定，当测试代码需要一些代码支持时，需要放进 tests 模块，并且使用 #[cfg(test)] 标记整个模块： 集成测试
我们可以在 src 目录同级创建一个 tests 目录，用于放我们的集成测试代码，集成测试将我们的库代码当做外部 crate 链接然后进行测试，因此集成测试也只能测试公共 API：cargo test 命令会同时运行集成测试和单元测试，如果只想运行 tests/unfurl.rs 中的集成测试代码，可以使用 cargo test --test unfurl。
 文档
cargo doc 命令可以生成 crate 的文档，文档中会包含库中 pub 内容的文档，文档就是添加到它们上面的注释。例如：当 Rust 看到三个斜线开头的注释时，就相当于使用 #[doc]，上面的例子等价于：除了 /// 样式的注释之外，还有 //!，被当做 #![doc]，经常用于模块或者 crate，例如 src/lib.rs 可能像下面这样：注释的内容会被当做 Markdown 格式，还可以包含 Html 标记。注释有个特色功能就是可以用 Rust 的模块组织路径去引用 Rust 定义的函数，结构体等。例如：还可以添加搜索别名，以便使用内置搜索功能更轻松地查找内容。在这个 crate 的文档中搜索 path 或 route 都能找到 VascularPath：还可以使用 backticks 在运行文本的中间设置一些代码，在输出中，这些片段将被格式化为固定宽度的字体。可以通过缩进4个空格来添加更大的代码示例：也可以使用 Markdown 格式的代码风格，有同样效果：还有很多注释类型，可以参考这里 注释。
 文档测试
当运行测试的时候，Rust 会检查所有出现在文档中的代码块，编译成一个独立的 crate，然后和我们的库链接并执行。下面是一个用 cargo new --lib ranges 创建的例子，把下面的代码的放入 ranges/src/lib.rs 中：使用 cargo doc --no-deps --open 应该能看到下面的文档：如果运行 cargo test 会看到如下的信息：
~/WORKDIR/rust/ranges ⌚ 9:57:08
$  cargo test               
    Finished test [unoptimized + debuginfo] target(s) in 0.00s
    Running unittests src/lib.rs (target/debug/deps/ranges-13060b2daf473d43)running 0 teststest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s  Doc-tests rangesrunning 2 tests
test src/lib.rs - overlap (line 5) ... ok
test src/lib.rs - overlap (line 10) ... oktest result: ok. 2 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.63s如果你将 cargo test --verbose，你会看到它使用 rustdoc --test 来运行这两个文档中的测试。rustdoc 将每个代码示例存储在一个单独的文件中，添加几行样例代码，以生成两个程序。 例如：doc test 背后的想法不是把所有的测试都放在文档中，而是确保文档中的代码能正常编译运行。一个代码示例将包含一些诸如导入类的东西，但是如果想在代码中隐藏，可以以 # 开头：生成的文档如下图所示，省略了 #  开头的导入：有时在文档中展示一个完整的示例程序会很有帮助，包括一个 main 函数。 rustdoc 将包含确切字符串 fn main 的任何代码块视为一个完整的程序，并且不会向其中添加任何内容。
如果我们想要实际编译代码块，但又不行让 rust 运行它，可以添加 no_run 标记：但是如果也不想编译，那么使用 ignore，而不是 no_run。如果代码块根本不是 Rust 代码，请使用语言的名称，如 c 或 sh，或 text（表示纯文本），它将任何它无法识别的注释视为表明代码块不是 Rust，这会禁用代码高亮和文档测试。
 依赖声明
关于依赖声明，详细请看 cargo 依赖声明。image = &quot;0.6.1&quot;：指定版本号，从 crates.io 下载依赖：image = &#123; git = &quot;https://github.com/Piston/image.git&quot;, rev = &quot;528f19c&quot; &#125;：指定版本号和原本下载路径；image = &#123; path = &quot;vendor/image&quot; &#125; 指定包含依赖源代码的相对目录； 依赖版本号
当我们在 Cargo.toml 文件中写入类似 image = &quot;0.13.0&quot; 的内容时，Cargo 对此的解释相当松散，它使用被认为与 0.13.0 版本兼容的最新版本的 image。兼容性规格改编自 语义化版本 2.0.0。以 0.0 开头的版本号非常原始，以至于 Cargo 从不认为它与任何其他版本兼容；以 0.x 开头的版本号（其中 x 非零）被认为与 0.x 系列中的其他点版本兼容。 我们指定了 image 版本 0.6.1，但如果可用，Cargo 将使用 0.6.3；一旦项目达到 1.0，由于新的主版本会破坏兼容性。因此，如果要求版本 2.0.1，Cargo 可能会使用 2.17.99，而不是 3.0；默认情况下，版本号是灵活的，否则使用哪个版本的问题很快就会变得过分约束。假设一个库 libA 使用 num = &quot;0.1.31&quot; 而另一个库 libB 使用 num = &quot;0.1.29&quot;。如果版本号需要完全匹配，则没有项目能够同时使用这两个库，允许 Cargo 使用任何兼容版本是一个更实用的默认设置。
尽管如此，不同的项目在依赖关系和版本控制方面有不同的需求。可以使用运算符指定确切的版本或版本范围：Cargo.toml
解释image = &quot;=0.10.0&quot;
完全匹配 0.10.0 版本image = &quot;&gt;=1.0.5&quot;
使用 1.0.5 或者更高的版本，甚至 2.9image = &quot;&gt;1.0.5 &lt;1.1.9&quot;
使用大于 1.0.5 但小于 1.1.9 的版本image = &quot;&lt;=2.7.10&quot;
小于 2.7.10 的任何版本*
任何版本 Cargo.lock
Cargo.toml 中的版本号很灵活，但我们不希望 Cargo 每次构建时都将我们升级到最新的库版本。因此，Cargo 有一个内置机制来防止这种情况。第一次构建项目时，Cargo 会输出一个 Cargo.lock 文件，该文件记录了它使用的每个 crate 的确切版本。以后的构建将参考这个文件并继续使用相同的版本。Cargo 仅在你告诉它时才升级到较新的版本，通过手动增加 Cargo.toml 文件中的版本号或运行 cargo update：
$ cargo update
Updating registry `https://github.com/rust-lang/crates.io-index`
Updating libc v0.2.7 -&gt; v0.2.11
Updating png v0.4.2 -&gt; v0.4.3cargo update 仅升级到与在 Cargo.toml 中指定的内容兼容的最新版本。如果你指定了 image = &quot;0.6.1&quot;，并且你想升级到 0.10.0 版本，你必须在 Cargo.toml 中改变它。下次构建时，Cargo 会更新到新版本的镜像库，并将新版本号存储在 Cargo.lock 中。前面的示例显示 Cargo 更新了 crates.io 上托管的两个 crate，存储在 Git 中的依赖项也会发生类似的情况。假设我们的 Cargo.toml 文件包含以下内容：
image = &#123; git = &quot;https://github.com/Piston/image.git&quot;, branch = &quot;master&quot; &#125;如果 cargo build 发现我们有一个 Cargo.lock 文件，它不会从 Git 存储库中提取新的更改。而是读取 Cargo.lock 并使用与上次相同的版本。但是 cargo update 将从 master 中提取，以便我们的下一个构建使用最新版本。
Cargo.lock 会自动生成，通常不会手动编辑它。如果项目是可执行文件，应该将 Cargo.lock 提交给版本控制。这样，每个人构建的项目都将始终获得相同的版本，Cargo.lock 文件的历史记录将记录你的依赖更新。
如果你的项目是一个普通的 Rust 库，不要提交 Cargo.lock。因为下游项目也拥有 Cargo.lock 文件，其中包含其整个依赖关系图的版本信息，他们会忽略依赖的库中的 Cargo.lock 文件。
在极少数情况下，项目如果是共享库（即输出是 .dll、.dylib 或 .so 文件），没有这样的下游项目，应该提交 Cargo.lock。
Cargo.toml 灵活的版本说明符使我们可以轻松地解决依赖之间的兼容性。 Cargo.lock 保证了构建一致性。
 发布到 crates.io
详情请看 发布到 crates.io。
 工作区间
详情请看 Cargo 工作空间。
]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>《Rust 程序设计》</tag>
        <tag>Crate</tag>
        <tag>Module</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】Rustup 介绍</title>
    <url>/2022/04/07/Rust/%E3%80%90Rust%E3%80%91Rustup%20%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[学习 rust 的第一步当然是安装，在 rust 中，工具链的安装，升级版本切换都是由 rustup 来完成的。rust 的工具链分布在三个不同的 channel ：stable，beta 和 nightly。
可以将 rustup 看做 rust 的版本管理器，方便我们在不同的 channel 之间进行切换。 在国内 rust 的相关网站是没有被 GFW 屏蔽的，但是访问速度还是很慢。好在国内有很多镜像源，例如，我这里使用的是中国科学技术大学的镜像，配置的话只需要添加两个环境变量：rustup 的安装我们依然使用官方的方式：curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh执行结束之后，应该能看到下面这样的信息，而且会默认安装 nightly（每日构建）版本：我们可以顺手配置以下 cargo 的镜像地址，参考自 中科大 Rust Crates 镜像使用帮助也推荐的字节跳动的 Rustup 镜像和 crates.io 镜像，具体请看 https://rsproxy.cn/。 概念
rustup 就是 rust 的包管理器，安装和管理 rust 的工具链，安装目录是：~/.cargo/bin。安装在 ~/.cargo/bin 中的 rustc 和 cargo 可执行文件其实是真实文件的代理，真正的文件在 ~/.rustup/toolchains/ 目录下，rustup 提供了在各个不同 channel 之间切换的能力。
关于 rustup 有很多术语，channel，toolchain，target，component 和 profile，它们的关系可以用下面的图表示： channel
rust 有三个不同的 channel 来发布版本：stable，beta 和 nightly。stable 和 beta 每六周发布一次， beta 就是下一个稳定版本，nightly 就是日版本。rustup 用于保持版本最新，并在它们之间轻松切换，当前版本信息请看 Rust Forge，发布模型请看 Appendix G - How Rust is Made and “Nightly Rust”。
我们经常使用 stable 作为我们的开发版本，但是 nightly 提供了提供了很多实验性的功能。切换 nightly 非常方便：安装：rustup toolchain install nightly
测试：rustup run nightly rustc --version
默认：rustup default nightly
更新： rustup update Toolchain
rustup 能够安装和处理不同的工具链，官方发布渠道最基本的跟踪：stable、beta 和 nightly；但是 rustup 也可以从官方存档、备用主机平台和本地构建中安装工具链。标准发布通道工具链名称具有以下形式：channel 是发布通道的名称，可以在后年跟上主次版本号，例如 1.42 或者 1.42.0，紧接着在后面可以跟一个发布日期，例如：nightly-2014-12-18。最后的是最主要的，需要填写安装目标机器的相关信息，例如：stable-x86_64-pc-windows-msvc。rustup toolchain install stable-x86_64-pc-windows-msvc出去方便考虑，某些编译信息可省略：rustup toolchain install stable-msvc对于开发者或者发烧友，可能会自己为 rust 增加新功能编译，那么可以编译自定义工具链，例如，克隆 rust-lang/rust 代码到 ~/rust，然后构建:rustup toolchain link myrust ~/rust/build/x86_64-unknown-linux-gnu/stage2/
rustup default myrustrust-lang/rust 项目中没有包含 cargo，从自定义的工具链中调用 cargo 是行不通的，rustup 会依次尝试 nightly，beta 或者 stable 中的 cargo。
 component
每个工具链都有一些 component，一些事必要的，例如 rustc，一些是可选的， 例如 clippy。rust componnet 被用于去管理 component。
component 可以随工具链一起安装，使用 --component，例如：rustup toolchain install nightly --component rust-docs也可以通过 rust component 命令添加到已安装的工具链中:rustup component add rust-docs可用的组件会随着版本变化，下面是一些可用的组件：rustc — Rust 编译器
cargo — 包管理器和构建工具；
rustfmt — 代码格式化工具；
rust-std — Rust 标准库，Rust 为许多平台都发布了二进制版本的标准库，有些平台还有完整的编译器；
rust-docs — Rust 文档 的本地副本，可以通过 rustup doc 在浏览器中打开；
rls — 用于IDE提供语言分析的后端能力；
clippy — 代码lint工具；
miri — 实验性的 Rust 解释器，可用于检查未定义的行为；
rust-src — Rust 标准库有代码的本地副本。可以被 RLS，Miri 或者 Cargo 的实验性 build-std 功能使用。
rust-analysis — 被 RLS 使用构建标准库的元数据信息；
rust-mingw — 包含了用于构建 x86_64-pc-windows-gnu 平台的 linker 和库；
llvm-tools-preview — 实验性组件，包含了一些列的 LLVM 工具；
rustc-dev — 该组件包含作为库的编译器。大多数用户不需要这个；它仅用于开发链接到编译器的工具，例如对 Clippy 进行修改。并非所有的组件在所有的工具链中都可用，关于组件的可用状态可以在 Rust 组件历史 这里找到。
对于 nightly 版本，当我们尝试更新的时候，可能有些组件没有一起发布，如果这个组件是必要的，rustup 会自动寻找一个历史版本，可以通过下面的方式改变这些行为：使用 --flag 强制 rustup toolchain install 安装最新的组件版本，即使没有；
使用 --profile 要求 rustup toolchain install 用不包含丢失组件的 profile。例如，--profile=minimal 应该总是可以的工作的；
安装一个包含需要组件的具体日版本，例如：rustup toolchain install nightly-2020-07-27。 Profile
profile 就是一组 component，目前可取的值有：minimal，default 和 complete。minimal：包含最少的组件，但是可以让编译器正常公共，例如：rustc，rust-std 和 cargo。如果不适用本地文档，在windows上推荐使用这个；default：除了包含 minimal 的组件之外，还包含：rust-docs，rustfmt，clippy。rustup 的默认行为；complete：包含了所有可用的组件，这永远不应该使用，因为它包含了元数据中曾经包含的所有组件。如果你需要某个额外的组件可以进行独立安装，例如 rls 和 miri。可以使用 rustup set profile 命令更高 rustup 的默认行为，例如 rustup set profile minimal。
 Proxy
rustup 包装了通用的 rust 工具， 它们被称为 Proxies 代表的命令由各种各样的 Component 提供。
The list of proxies is currently static in rustup and is as follows:rustc is the compiler for the Rust programming language, provided by the project itself and comes from the rustc component.rustdoc is a tool distributed in the rustc component which helps you to generate documentation for Rust projects.cargo is the Rust package manager which downloads your Rust package’s dependencies, compiles your packages, makes distributable packages, and uploads them to crates.io (the Rust community’s package registry). It comes from the cargo component.rust-lldb and rust-gdb are simple wrappers around the lldb and gdb debuggers respectively. The wrappers enable some pretty-printing of Rust values and add some convenience features to the debuggers by means of their scripting interfaces.rls is part of the Rust IDE integration tooling. It implements the language-server protocol to permit IDEs and editors such as Visual Studio Code, ViM, or Emacs, access to the semantics of the Rust code you are editing. It comes from the rls component.cargo-clippy and clippy-driver are related to the clippy linting tool which provides extra checks for common mistakes and stylistic choices and it comes from the clippy component.cargo-miri is an experimental interpreter for Rust’s mid-level intermediate representation (MIR) and it comes from the miri component. 常用操作如果要更新 rust 或者 rustup 可以使用下面的命令：$ rustup self update
info: checking for self-updates
info: downloading self-updates或者更新 rust：如果我们快速测试不同的 rust 版本，可以将 rustc 或者 cargo 的第一个参数指定为 +beta 的形式进行测试，例如:cargo +beta run如果要为目录指定 rust 版本，可以在目录下执行 rustup override set 命令，例如:rustup override set beta这会在配置文件 ~/.rustup/settings.toml，为目录指定 rust 版本:如果要为项目固定 rust 版本，可以在目录中放一个 rust-toolchain.toml，里面指定 rust 版本，例如:更多请看：https://rust-lang.github.io/rustup/overrides.html#the-toolchain-file 交叉编译
Rust 本身支持大量平台，对于很多平台 Rust 发布了标准库的二进制版本，一些平台还发布了全部的编译构建工具。当我们安装一个工具链的时候，rustup 仅仅会安装本平台下的标准库。为了编译到其他平台，我们必须安装特定平台的标准库，例如，对于 Android：然后我们可以使用 cargo build --target=arm-linux-androideabi 构建安卓平台的发布件。但是我们除了安装标准库之外，还需要交叉编译所需的其他工具，尤其是链接器。
 环境变量RUSTUP_HOME：rustup 根目录，默认是 ~/.rustup 或者 %USERPROFILE%/.rustup；
RUSTUP_TOOLCHAIN：默认：none。设置之后，会影响到所有的 rust 工具调用；
RUSTUP_DIST_SERVER：默认：https://static.rust-lang.org，下载 rust 相关静态资源，可以更改为镜像站点；
RUSTUP_UPDATE_ROOT：默认：https://static.rust-lang.org/rustup，rustup 自更新的站点，可以更新为镜像站点；
RUSTUP_NO_BACKTRACE：即使设置了 RUST_BACKTRACE，也禁用非紧急错误的调用栈。其他不常用的请看 https://rust-lang.github.io/rustup/environment-variables.html。
 代理
如果因网络问题不能下载或者下载较慢，可以设置代理，大多情况下设置 https_proxy 就够了。linix:export https_proxy=socks5://proxy.example.com:1080windows cmd：set https_proxy=socks5://proxy.example.com:1080windows powershell：$env:https_proxy=“socks5://proxy.example.com:1080” 示例命令
描述rustup default nightly
Set the default toolchain to the latest nightlyrustup set profile minimal
Set the default profilerustup target list
List all available targets for the active toolchainrustup target add arm-linux-androideabi
Install the Android targetrustup target remove arm-linux-androideabi
Remove the Android targetrustup run nightly rustc foo.rs
Run the nightly regardless of the active toolchainrustc +nightly foo.rs
Shorthand way to run a nightly compilerrustup run nightly bash
Run a shell configured for the nightly compilerrustup default stable-msvc
On Windows, use the MSVC toolchain instead of GNUrustup override set nightly-2015-04-01
For the current directory, use a nightly from a specific daterustup toolchain link my-toolchain &quot;C:\RustInstallation&quot;
Install a custom toolchain by symlinking an existing installationrustup show
Show which toolchain will be used in the current directoryrustup toolchain uninstall nightly
Uninstall a given toolchainrustup toolchain help
Show the help page for a subcommand (like toolchain)rustup man cargo
(Unix only) View the man page for a given command (like cargo) Cargo 插件cargo-clippy：代码 Lint 工具；
cargo-vet：crate 供应链检查； 参考文章Notes on cross-compiling Rust]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>rustup</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】Trait和泛型</title>
    <url>/2022/04/26/Rust/%E3%80%90Rust%E3%80%91Trait%E5%92%8C%E6%B3%9B%E5%9E%8B/</url>
    <content><![CDATA[编程中可能经常遇到要用相同的逻辑处理不同的类型，即使这个类型是还没出世的自定义类型。这种能力对于 Rust 来说并不新鲜，它被称为多态性，诞生于 1970 年代的编程语言技术，到现在为止仍然普遍。Rust 支持具有两个相关特性的多态性：Trait 和 泛型。
Trait 是 Rust 对接口或抽象基类的对照实现，它们看起来就像 Java 或 C# 中的接口：File，TcpStream 以及 Vec&lt;u8&gt; 都实现了 std::io::Write，这3个类型都提供了 .write()，.flush() 等等方法，我们可以使用 write 方法而不用关心它的实际类型：&amp;mut dyn Write 的意思是任何实现了 Write 的可变引用，我们可以调用 say_hello 并且给他传递这样一个引用：泛型函数就像 C++ 中模板函数，一个泛型函数或者类型可以用于许多不同类型的值：&lt;T: Ord&gt; 意思是 T 类型必须实现 Ord，这称为边界，因为它设置了 T 可能是哪些类型，编译器为实际使用的每种类型 T 生成自定义机器代码。 使用 Trait
Trait 代表了一种能力，这个类型能做哪些事情，例如：实现 std::io::Write 意味着可以调用 .write() 方法写入字节等；实现 std::iter::Iterator 可以产生一个序列值；实现 std::clone::Clone 可以在内存中 clone 自身；实现 std::fmt::Debug 可以使用 &#123;:?&#125; 打印；这 4 个 Trait 只是标准库中的一部分，许多标准类型都实现了他们，例如：std::fs::File 实现 Write，Range&lt;i32&gt;(0..10) 实现了 Iterator，有很多类型都实现了 Clone 和 Debug。
关于 Trait 方法有一个不寻常的规则：Trait 本身必须在范围内。否则，它的所有方法都会被隐藏：正常情况下，编译器会提示我们需要导入 std::io::Write：之所以要这样做，是因为了避免命名冲突，需要导入计划使用的 Trait，因为我们可能为类型实现了多种 Trait，它们都相同的方法名。但如果我们需要导入这两个名称冲突的方法，就需要使用完全限定方法调用，而 Clone 和 Iterator 能正常使用的原因是它们是预导入的。
 Trait 对象
在 Rust 中，一个变量的大小必须在编译时就能确定，而 Trait 可以被任何类型实现，所以它们的大小无法确认，类似下面的代码会编译失败：然而一个引用的大小时确定的，我们可以获取 Trait 的引用：Trait 类型的引用，如 writer，称为 Trait 对象。 Trait 对象指向某个值，它有生命周期，可以是可变引用或共享引用。Trait 对象的不同之处在于，它包含了一些关于所指对象类型的额外信息，当你调用 writer.write(data) 时，Rust 需要根据 *writer 的类型动态调用正确的 write 方法。Rust 不允许直接查询类型信息，也不支持从 Trait 对象向下转换，&amp;mut dyn 不能转换为 Vec&lt;u8&gt; 这样的具体类型。
在内存中，Trait 对象是一个胖指针，由一个指向值的指针和一个指向拥有该值类型方法表的指针组成，因此，每个Trait对象占用两个机器字，下图所示：C++ 也有这种运行时类型信息，它被称为虚拟表，vtable 是 Rust 的私有实现细节，这些是不可以直接访问的字段和数据结构。当调用Trait对象的方法时语言自动使用 vtable 去决定使用哪个类型。
Rust 在需要时会自动将普通引用转换为 Trait 对象， 这就是为什么我们能够在这个例子中将 &amp;mut local_file 传递给 say_hello：local_file 的类型是 &amp;mut File，say_hello 函数的参数类型是 &amp;mut dyn Write，由于 File 实现了 Write，所以允许自动转换。同样，Rust 也可以将 Box&lt;File&gt; 转换为 Box&lt;dyn Write&gt;：Box&lt;dyn Write&gt; 和 &amp;mut dyn Write 一样，是一个胖指针：它包含 writer 本身和 vtable 的地址。其他指针类型也是如此，例如 Rc&lt;dyn Write&gt;。
 泛型函数
首先来看一个普通函数和泛型函数的例子：&lt;W: Write&gt; 预示着这个函数是泛型的，W 是一个类型参数，意味着在整个函数体中，类型 W 是实现了 Write 的类型。约定上，类型参数使用单个大写字母表示，而 W 实际代表哪种类型取决于泛型函数的使用方式：当我们传递给 say_hello 函数 &amp;mut local_file，Rust 就会为 say_hello::&lt;File&gt;() 类型的机器代码，当使用 &amp;mut bytes 时，就会生成say_hello::&lt;Vec&lt;u8&gt;&gt;() 类型的代码。在这两种情况中，W 的类型都会由编译器自动推断，这叫做单态化（monomorphization）。
如果不嫌麻烦，可以显示写出 W 的类型：但是，如果你调用的泛型函数没有提供任何可供编译器进行类型推断的信息，就需要显示提供：有时候，一个类型可能需要具备多种能力，也就是它得实现多个 Trait，这个时候我们可以使用 + ：泛型函数也是可以拥有多个类型参数的，例如：但是这样写会让函数的签名变得很长，看起来不是很顺眼，所以可以使用 where 关键字达到同样的效果，只是将 M 和 R 的边界移动到了后边，让函数签名看起来更加清晰而已：泛型函数的参数有引用时，可能需要显示使用生命周期参数，这种情况需要把生命周期写在最前面：生命周期参数不会影响函数的机器代码生成，只有不同的类型 P 才会导致编译器生成不同的 nearest 版本。
即使结构体不是泛型，它的方法也可以是泛型的：类型别名也可以是泛型： 泛型 or Trait
Trait 解决的问题是像什么，它能代表一类对象，这一类对象都有相同的行为；而泛型解决的问题是解决重复编码，更像是一个代码模板，泛型类型可以使用 Trait 作为边界。
对于代码体积来说，由于泛型更像是代码模板，所以在编译时更具会对不同类型生成真正的代码，代码体积会增大，但是运行速度会更快，而 Trait 对象只有在实际运行时才能确定其真正的类型。
 定义实现 Trait
定义 Trait 相对比较简单，有两个必须的信息，名称和方法签名列表：如果要为类型实现 Trait，需要使用 impl TraitName for Type 的语法，这里只包含 Type 为 TraitName 实现的方法： Trait 默认方法
Trait 中可以不止包含方法签名列表，也可以包含方法的实现，如果类型没有重新实现方法，在调用的时候，会选择 Trait 的默认实现：Write 默认实现了 write_all 方法，在为自定义类型实现时，如果没有重新实现，就会选择这个 write_all 。
 Trait 实现限制
只要类型或者 Trait 是当前 crate 引入的，就可以：为其他任何类型实现当前 crate 中的 Trait；或者为当前 crate 中的类型实现任何 Trait；例如，我们可以为标准库 char 类型实现我们自定义的 IsEmoji，只要 IsEmoji 在作用域之内就可以使用： 方法扩展
还可以对某类已存在类型一次性扩展多个方法，通过一个 泛型impl块，这里，为所有实现了 Write 的类型添加 write_html 方法：例如，标准库中为所有实现了 From 的类型自动实现了 Into：要注意的是，当实现一个 Trait 的时候，Trait 或者类型必须要有是当前 crate 中，这称之为孤儿原则，它确保 Trait 实现是唯一的，所以不能为 u8 实现 Write，因为它两都是标准库中的。
 Trait 中的 Self
在 Trait 的方法定义中可以使用 Self 关键字，例如：在第一个 impl 中，Self 表示 CherryTree，在第二个 impl 中，Self 表示 Mammoth，而且 self 和 other 的类型必须匹配。但是如果 Trait 中包含了 Self，就和 Trait 对象不兼容，因为在编译时，Rust 不能确定 Trait 对象背后的实际类型，所以下面的代码会编译失败，因为 Rust 不知道 left 和 right 是否是相同类型：如果我们想要 splice 函数能够处理兼容处理不同类型，我们可以这样做： 子Trait
Trait 之间可以扩展，例如：这样每个想实现 Creature 的类型就必须实现 Visible，我们将 Creature 称作 Visible 的 子 Trait，或者将 Visible 称作 Creature 的 父Trait，但是子 Trait 不能继承 父Trait 的关联项。另外如果想调用 Trait 的方法，依然需要每个 Trait 都在作用域内。
其实 trait Creature: Visible 只是下面的简写： Trait 的关联函数
大多数面向对象语言中，接口是不可以包含静态方法或者构造函数的，但是 Rust 的 Trait 可以包含静态类型方法：new 和 from_slice 没有将 self 作为第一个参数，它们就像构造函数。每个实现 StringSet 的类型必须实现关联的静态方法。在非泛型代码中，这些函数可以使用 :: 调用=类型关联函数：在泛型代码中也是一样的，有区别的是，类型通常是一个类型变量，例如，S::new()：Trait 对象不支持类型关联的函数，如果你想使用 &amp;dyn StringSet，即 Trait 对象，你必须改变 Trait，给那些没有将 self 作为参数的关联函数添加边界 where Self: Sized：这个边界告诉Rust，Trait 对象可以不支持这个特定的关联函数。有了这些补充，虽然 StringSet 的 Trait对象仍然不支持new或from_slice，但可以创建它们并使用它们来调用.contains()和.add()。
 完全限定调用
当调用 &quot;hello&quot;.to_string() 的时候，Rust 会根据方法查找算法进行方法查找，这里的 to_string() 实际上引用到了 ToString Trait 的方法。下面的四种方法是等价的：其中最后一种称之为完全限定语法，通过这个语法，可以明确知道调用哪个方法，这在下面这些场景中非常有用：当两个方法有相同的名称时，调用就会有歧义，可以通过限定类型或者指定 Trait 来具体说明：当 self 参数类型不能推断时：当使用函数本身作为函数值时：在宏中调用 Trait 方法时； Trait 关联类型
Trait 内部也可以定义类型，用于类型之间相互交互，例如 std::iter::Iterator 和 std::ops::Mul这其中的 type Item; 是一个关联类型，每个实现 Iterator 的类型必须声明 Item 的具体类型，next 的返回值用了 Item 关联类型，这里写作 Self::Item 表明他不是一个普通类型，而是和每个实现 Iterator 的类型相关。
我们可以看到 std::env::Args 的实现，在这里的实现中，Item 的类型是 String：泛型代码也可以使用 Trait 的关联类型，在 collect_into_vector 的返回值中，我们必须使用 Vec&lt;I::Item&gt; 而不能是  Vec&lt;I：我们还可以指定关联类型的边界，如果不指定，我们可能会遇到问题，我们想打印出 Iterator 的每个值，但是编译器会提示我们 &lt;I as Iterator&gt;::Item 没有实现 Debug：鉴于此错误，我们要么指定 &lt;I as Iterator&gt;::Item 的边界，要么指定它的具体类型：或者后面这个语法可用于任何 Trait 名称可以使用的地方被使用，包括 Trait 对象类型： 泛型 Trait
Trait 也可以是泛型的，例如std::ops::Mul：这里的类型参数和在结构体或函数上的意思是一样的：Mul 是泛型 Trait，它的实例 Mul&lt;f64&gt;、Mul&lt;String&gt;、Mul&lt;Size&gt; 等都是不同的 Trait。
之前说我们实现 Trait 时，Trait 或者类型必须要有一个是当前 crate 中的。假设我们有自己的结构体 Number，我们完全可以为 f64 实现 Mul&lt;Number&gt;，以支持 f64 * Number，即使 Mul 和 f64 不是我们 crate 的，但是 Mul&lt;Number&gt; 是我们自己定义的： impl Trait
许多泛型类型的组合可能会使代码变得混乱，例如，使用标准库几个迭代器会使代码的返回类型变得异常复杂：我们可以使用 Trait 对象替换这个看起来很复杂的返回值类型：但是这个返回值每次都要在堆中重新申请内存，也是有代价的。因此，Rust 专门为这种情况提供了 impl Trait 这种语法，只指定它实现的一个或多个Trait，而无需动态调度或堆分配：但是我们不能通过这个实现在运行时动态返回不同类型的函数，错误是很明显的，Rust 需要在编译的时候就知道返回值的大小，并且分配大小正确的空间，这里返回三个不同类型，Rust 就不知道怎么做了：
查看错误示例正确的修改方法是：
查看正确示例更多可以查看 使用 dyn 返回 trait。需要注意的是，Rust 不允许 Trait 方法使用 impl Trait 返回值，只有自由函数和与类型关联的函数才能使用 impl Trait 返回。impl Trait 也可以用在接受泛型参数的函数中。例如，下面两个函数的实现等价：有一个重要的例外，使用泛型函数允许函数调用者声明泛型参数类型，例如：print::&lt;i32&gt;(42)，但是当使用 impl Trait 是不允许的。
每个 impl Trait 参数都分配有自己的匿名类型参数，因此参数是 impl Trait 仅限于简单的泛型函数，类型和参数之间没有关系的。
 关联常量
像结构体和枚举一样，Trait 也可以有关联的常量，例如：关联的常量可以只声明而不用给值：然后在实现的时候再定义这些值：这允许我们定义这样的泛型函数，以使用这些常量：请注意，关联常量不能与 Trait 对象一起使用，因为编译器依赖于有关实现的类型信息以便在编译时选择正确的值。即使是一个根本没有行为的简单 Trait，比如 Float，也可以提供足够的关于类型的信息，结合一些运算符，来实现常见的数学函数，比如 Fibonacci： 步步为营
假设我们写了一个函数用于求和两个 &amp;[i64] 的和，代码可能看起来是这个样子的，代码也可以正常运行：现在假设我们又想实现两个 &amp;[f64] 的和，我们可以第一步想到的是改成泛型函数：但这肯定不定，类型 N 必须支持 + 和 * 运算。另外由于 0 是整数，不是浮点数，当 N 代表 f64 是依然不对，所以我们可以改成这个样子，对 N 进行边界限定：由于看起来很丑陋，所以我们对它进行美化，但还是编译不过：因为 &amp;v1[N] 没有实现 Copy，v1[i] 会转移所有权：
    error[E0508]: cannot move out of type `[N]`, a non-copy slice
    --&gt; src/main.rs:11:25
    |
    11 |         total = total + v1[i] * v2[i];
    |                         ^^^^^
    |                         |
    |                         cannot move out of here
    |                         move occurs because `v1[_]` has type `N`, which does not implement the `Copy` trait    error[E0508]: cannot move out of type `[N]`, a non-copy slice
    --&gt; src/main.rs:11:33
    |
    11 |         total = total + v1[i] * v2[i];
    |                                 ^^^^^
    |                                 |
    |                                 cannot move out of here
    |                                 move occurs because `v2[_]` has type `N`, which does not implement the `Copy` trait所以我们接着改，这次改对了：虽然结局看起来不错，但是我们是跟着编译器提示把 N 的边界给找出来。就这个问题而言，我们可以使用 num 这个 crate，看起来很简洁： 注意事项
Rust 目前还不支持在 trait 里使用 impl trait 做返回值：]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>《Rust 程序设计》</tag>
        <tag>Trait</tag>
        <tag>泛型</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】unsafe 代码</title>
    <url>/2022/05/05/Rust/%E3%80%90Rust%E3%80%91Unsafe-%E4%BB%A3%E7%A0%81/</url>
    <content><![CDATA[系统编程的秘密乐趣在于，在每一种安全语言和精心设计的抽象之下，都存在着极其 unsafe 的机器语言和小技巧，我们也可以用 Rust 来写。
到目前为止，我们介绍的语言可确保程序通过类型、生命周期、边界检查等完全自动地避免内存错误和数据竞争，但是这种自动推断有其局限性，有许多有价值的技术手段是无法被 Rust 认可的。
unsafe 代码告诉 Rust，程序选择使用它无法保证安全的特性。通过将代码块或函数标记为  unsafe，可以获得调用标准库中的 unsafe 函数、解引用 unsafe 指针以及调用用其他语言（如 C 和 C++ ）编写的函数以及其他能力。
这种跳出安全 Rust 边界的能力使得在 Rust 中实现许多 Rust 最基本的功能成为可能，就像 C 和 C++ 用来实现自己的标准库一样。 unsafe 代码允许 Vec 有效地管理其缓冲区、 std::io 能直接和操作系统对话、以及提供并发原语的 std::thread 和 std::sync。
本节将 unsafe 功能的要点：Rust 的 unsafe 块在安全的 Rust 代码和使用 unsafe 特性的代码之间建立了界限；可以将函数标记为  unsafe，提醒调用者存他们必须遵守的额外规范以避免未定义的行为；裸指针及其方法允许不受限制地访问内存，并允许构建 Rust 类型系统原本禁止的数据结构。尽管 Rust 的引用是安全但受约束的，但正如任何 C 或 C++ 程序员所知道的，裸指针是一个强大而锋利的工具；了解未定义行为将帮助理解为什么它会产生比仅仅得到错误结果更严重的后果；unsafe 的 Trait，类似于 unsafe 的函数，强加了每个实现必须遵循的规约； unsafe 示例
下面这段程序在原书中说是运行会崩溃，但是在我自己的电脑上并未发生，就当它崩溃了吧。（我的 Rust 版本是 rustc 1.62.0-nightly ）该程序借用了对局部变量 a 的可变引用，将其转换为 *mut usize 类型的裸指针，然后使用 offset 方法在内存中生成一个指针，新指针等于 ptr + 3 * size_of::&lt;uszie&gt;()。按原书说这恰好是存储 main 的返回地址的地方（这其实得看 Rust 的调用规约了）。程序用一个常量覆盖了返回地址，这样从 main 中返回的行为就不确定了。导致这次崩溃的原因是程序对 unsafe 特性的错误使用，在这里就是滥用解引用裸指针的能力。
一个 unsafe 的特性是会有一个使用规约：但是 Rust 不能自动强制执行，所以必须遵循这些规约以避免未定义的行为。
unsafe 代码能跳过常规的类型检查和生命周期检查，但增加了更多的使用规约。通常， Rust 本身根本不知道这些规约，它们只是在该功能的文档中进行了解释。例如，裸指针类型有一个规约，禁止解引用已超出其原来范围的指针，此示例中的表达式 *ptr.offset(3) = ... 违反了此约定。但是， Rust 依然编译了程序：它的安全检查没有检测到这种违规行为。当使用 unsafe 的功能时，作为程序员，有责任检查代码是否符合他们的规约。
许多功能都有正确使用它们应该遵循的规则，但这些规则不是我们在这里所说的意义上的规约，除非可能的后果包括未定义的行为。未定义的行为是 Rust 坚信你的代码永远不会出现的行为，例如， Rust 假设你不会用其他东西覆盖函数调用的返回地址。通过 Rust 的安全检查并遵守非安全功能规约的代码不可能做这样的事情。由于该程序违反了裸指针规约，它的行为是未定义的，所以出错了。
如果代码出现了未定义的行为， Rust 就无法保证代码会执行到哪里了，也无法保证结局，更无法保证安全。可能报告出一对不相关的错误消息然后崩溃，或者系统的控制权让出给其他程序，而且不同的 Rust 版本之间也不保证一致，也不会存在告警。
规定只能在 unsafe 代码块或函数中使用 unsafe 的功能；我们将在接下来的部分中解释这两个。通过强制编写一个 unsafe 代码块或函数，这会提醒开发者在使用 unsafe 功能时应该格外小心， Rust 确保开发者知道需要遵循额外的规约。
 unsafe 代码块
Rust 的 unsafe 代码块和普通到的代码块看起来没什么两样，只是由一个 unsafe 关键字开始：如果块前面没有 unsafe 关键字， Rust 不让使用 from_utf8_unchecked，它是一个 unsafe 的函数。
与普通的 Rust 块一样， unsafe 代码块的值是其最终表达式的值，如果没有，则为 ()。前面显示的对 String::from_utf8_unchecked 的调用提供了块的值。
unsafe 代码块提供了 5 个编程能力：可以调用 unsafe 的函数，但是每个 unsafe 的函数都必须根据其用途指定自己的规约；可以解引用裸指针，安全代码可以传递裸指针并且比较它们，并通过从引用（甚至从整数）转换来创建它们，但只有 unsafe 代码才能真正使用它们来访问内存；可以访问联合体的字段，编译器无法确定它们是否包含代表它们类型的有效位模式；可以访问可变静态变量， Rust 无法确定线程何时使用可变静态变量，因此它们的规约要求确保所有访问都是同步的；可以访问通过 Rust 的外部函数接口声明的函数和变量。即使它们是不可变的，它们也被认为是 unsafe 的，因为它们对于用其他可能不遵守 Rust 安全规则的语言编写的代码是可见的；将 unsafe 的功能限制在 unsafe 代码块中并不能真正阻止我们要做的事情，这个限制的好处主要在于将开发者的注意力吸引到 Rust 无法保证安全的代码上：不会不小心使用了 unsafe 的特性，然后发现要为不知道的规约负责，肯定是开发者写的，出了事也要自己兜着，别怪 Rust ；一个 unsafe 的代码块会引起 commiter 的更多关注。一些项目甚至具有自动化来确保这一点，标记为 unsafe 的代码块可以引起特别关注；当考虑编写一个 unsafe 的块时，需要花点时间问问自己你的任务是否真的需要这样的措施。如果是为了性能，你是否有测量表明这实际上是一个瓶颈。也许有一个好方法可以在安全的 Rust 中完成同样的事情，不要为了那么一丁点的性能牺牲了整个程序的安全性。 高效的 ASCII
这里有一个 Ascii 类型，一个总是包含有效 ASCII 的 string 类型，使用了一个 unsafe 功能零成本转换成 String。这个模块的关键是 Ascii 类型的定义，类型本身被标记为 pub，以使其在 my_ascii 模块之外可见。但是该类型的 Vec&lt;u8&gt; 元素不是公共的，所以只有 my_ascii 模块可以构造一个 Ascii 值或引用它的元素。事实上，公共构造函数 Ascii::from_bytes 在构造一个 Ascii 之前仔细检查了可能出现的错误，确保 Ascii 值始终包含正确的 ASCII 文本，就像 String 的方法确保其内容是有效的 UTF-8 一样。
这种保证让我们可以非常有效地为 String 实现 From&lt;Ascii&gt;。 unsafe 函数 String::from_utf8_unchecked 接受一个字节 vector 并从中构建一个字符串，而不检查其内容是否是有效的 UTF-8 文本，函数的规约是让调用者对此负责。幸运的是， Ascii 类型强制执行的规则正是我们需要满足 from_utf8_unchecked 的规约。因为任何 ASCII 文本块也是有效的 UTF-8，因此 Ascii 的底层 Vec&lt;u8&gt; 可以立即用作字符串的缓冲区。
有了这些定义，我们可以写出如下的代码：但使用 Ascii 不需要 unsafe 代码块，这里已经使用 unsafe 的操作实现了一个安全的接口，并且只根据模块自己的代码而不是用户的行为来安排满足他们的规约。
Ascii 只不过是 Vec&lt;u8&gt; 的包装器，隐藏在一个模块中，该模块对其内容实施额外的规则。这种类型称为 newtype，是 Rust 中的一种常见模式。 Rust 的 String 类型的定义方式完全相同，只是它的内容被限制为 UTF-8，而不是 ASCII。下面是标准库中对 String 的定义：在机器层面上，去掉 Rust 类型， newtype 和它原本的类型在内存中有相同的表示，所以构造一个 newtype 根本不需要任何机器指令。在 Ascii::from_bytes 中，表达式 Ascii(bytes) 简单地认为 Vec&lt;u8&gt; 的表示方法现在持有一个 Ascii 值。类似地， String::from_utf8_unchecked 在内联时可能不需要机器指令： Vec&lt;u8&gt; 现在被认为是一个字符串。
 unsafe 函数
一个 unsafe 的函数定义看起来像一个普通的函数定义，前面有 unsafe 关键字。 unsafe 函数的主体自动被视为 unsafe 块。
只能在 unsafe 的块中调用 unsafe 的函数。这意味着将函数标记为 unsafe 会提醒调用者使用它们必须认真看文档以避免未定义的行为。
例如，这是我们之前介绍的 Ascii 类型的新构造函数，它从字节 vector 构建 Ascii，而不检查其内容是否为有效的 ASCII ：从使用场景来说，可能已经确定调用 Ascii::from_bytes_unchecked 的代码的 vector 仅包含 ASCII 字符，因此 Ascii::from_bytes 坚持执行的检查将是浪费时间。
但之前我们强调了 Ascii 的公共构造函数和方法的重要性，以确保 Ascii 值的格式正确，而 from_bytes_unchecked 制定规约将其传递给它的调用者来履行其义务。这个规约将函数标记为 unsafe 是完全正确的：尽管函数本身不执行 unsafe 的操作，但它的调用者必须遵循 Rust 无法自动强制执行的规约以避免未定义的行为。
我们可以不遵循 Ascii::from_bytes_unchecked 的规约，然后构造一个无效格式的 UTF-8 字符串：在某些版本的 Rust 中，在某些平台上，这个断言被观察到会失败 时，会出现以下有趣的错误信息（然而我自己测试并未出现）：
thread 'main' panicked at 'assertion failed: `(left == right)` 
left: `2097151` ,
right: `2097151` ', src/main.rs:42:5这两个数字在我们看来是相等的，但这不是 Rust 的错，而是之前 unsafe 代码的错。当我们说未定义行为会导致不可预测的结果时，这就是我们所指的那种情况。
从本质上讲， Rust 的类型检查器、借用检查器和其他静态检查是在检查程序，并试图证明程序中不存在未定义的行为。当 Rust 成功编译程序时，这意味着它成功地证明了代码是合理的。然而一个 unsafe 的块是这个证明中的一个缺口，这就相当于程序员对 Rust 口头说相信我的代码，不过口头承诺是否正确，可能取决于程序中影响 unsafe 块中发生的任何部分，而错误的后果可能出现在受 unsafe 块影响的任何地方。编写 unsafe 关键字相当于提醒你没有得到语言安全检查的全部保证。
如果有选择的话，你应该自然而然地倾向于创建没有隐含规约的安全接口。这些接口更容易操作，因为用户可以依靠 Rust 的安全检查来确保他们的代码不存在未定义的行为。即使你的实现使用了 unsafe 的特性，最好还是使用 Rust 的类型、生命周期和模块系统来满足它们的规约。
不幸的是，在很多地方遇到 unsafe 的函数是很正常的，这些函数的文档并没有对它们的规约进行解释。你应该根据你的经验和对代码行为的了解，自己推断出规则。
 unsafe block or unsafe fn
使用 unsafe 代码块还是 unsafe 函数，需要考虑：如果有可能以一种编译正常但仍导致未定义行为的方式滥用该函数，你必须将其标记为 unsafe。正确使用该函数的规则就是它的规约；规约的存在就是使该函数 unsafe 的原因；否则，该函数是安全的：对它的良好类型的调用都不会导致未定义的行为，它不应该被标记为 unsafe。该函数是否在其主体中使用了 unsafe 的特性并不重要，重要的是规约的存在。之前，我们展示了一个没有使用 unsafe 特征的 unsafe 函数，以及一个使用了 unsafe 特性的安全函数。不要因为在一个安全函数的主体中使用了 unsafe 的特征，就把它标记为 unsafe，这将使函数更难使用，并使读者感到困惑，他们会（正常情况下）期望在某处找到规约的解释。
 未定义行为
在介绍中，我们说过，未定义的行为是指 Rust 坚决认为你的代码不可能出现的行为。这是一个很奇怪的说法，尤其是我们从其他语言的经验中知道，这些行为确实会经常意外发生。为什么这个概念对规定 unsafe 代码的义务有帮助？
我们知道编译器是一种编程语言到另一种语言的翻译器。 Rust 编译器将一个 Rust 程序翻译成一个等效的机器语言程序。但是，如果说这种完全不同的语言的表示的程序是等价的，这意味着什么？
意味着两个程序在执行时总是有相同的可见行为，它们进行相同的系统调用，以相同的方式与外部库交互，等等。这有点像程序的图灵测试：如果你无法分辨你是在与原版还是译版互动，那么它们就是等价的。
现在考虑一下下面的代码：即使对 very_trustworthy 的定义一无所知，我们也可以看到它只接受对 i 的共享引用，所以这个调用不能改变 i 的值。由于传递给 println! 的值总是 1000， Rust 可以将这段代码翻译成机器语言，就像：这个转换后的版本具有与原版相同的行为，而且它的速度可能会快一点。但只有当我们同意这个版本与原始版本具有相同的意义时，考虑这个版本的性能才有意义。如果 very_trustworthy 被定义为以下情况呢？这段代码打破了共享引用的规则：它将 i 的值改为 20，尽管它不应该被修改，因为 i 是借用来共享的。结果，我们对调用者所做的转换现在有一个非常明显的效果：如果 Rust 转换代码，程序会打印 1000 ；如果它不理会代码并使用 i 的新值，它会打印 2000。在 very_trustworthy 中打破共享引用的规则意味着共享引用在其调用者中不会像预期的那样运行。
这类问题几乎出现在 Rust 可能尝试的每一种转换中。即使是将一个函数内联到它的调用位置，也假定当被调用者完成时，控制流将返回到调用站点。但是我们在这一章的开头举了一个甚至违反了这个假设的不良代码的例子。
对于 Rust 来说，除非它能相信语言的基本功能会按照设计的方式运行，否则基本上不可能评估对程序的转换是否保留了其意义。而他们是否能做到这一点，不仅取决于手头的代码，还取决于程序的其他可能遥远的部分。 为了对你的代码做任何事情，Rust 必须假设你的程序的其他部分是具有良好的行为。
Rust 定义了具有好行为的程序：禁止读未初始化的内存；程序不得创建无效的原始值：引用，Box 或者 fn 指针不能是 Null ；
bool 值只能是 0 或者 1 ；
枚举值只能使用有效的项；
char 必须是有效的 Unicode 码点；
str 必须是有效的 UTF-8；
胖指针必须具有有效的 vtables 或者 slice 长度；
不得使用 特殊类型 ! 的任何值；必须遵守引用规则，任何引用都不能比其引用的值活得更久；共享访问是只读访问；可变访问是独占访问；程序不得解引用空指针、不正确对齐的指针或悬空指针；程序不得使用指针访问与指针关联的分配之外的内存；程序必须没有数据争用，当两个线程在没有同步的情况下访问相同的内存位置时，如果至少其中一个访问是写入，就会发生数据竞争；The program must not unwind across a call made from another language, via the foreign function interface.程序必须遵守标准库函数的约定；由于我们还没有一个完整的 Rust unsafe 代码语义模型，这个列表可能会随着时间的推移而演变，但这些可能永远是被禁止的。
任何违反这些规则的行为都会构成未定义的行为，并使 Rust 优化程序并将其翻译成机器语言而变得不可信。
不使用 unsafe 特性的 Rust 代码保证在编译后遵循所有前面的规则。只有当使用 unsafe 功能时，这些规则才会成为必尽责任。
 unsafe Trait
unsafe trait 是具有规约的 trait，Rust 无法检查或强制实现者必须满足以避免未定义的行为。要实现 unsafe trait，必须将实现标记为 unsafe。由开发者来理解 trait 的 规约 并确保你的类型满足它。
将其类型变量与 unsafe trait 绑定的函数通常是使用 unsafe trait 本身的函数，并且仅通过依赖于 unsafe trait 的规约来满足它们的规约, trait 的不正确实现可能会导致此类函数表现出未定义的行为。
std::marker::Send 和 std::marker::Sync 是 unsafe trait 的经典示例。这些 trait 没有定义任何方法，因此对于任何类型都可以轻松实现。但是它们确实有规约：Send 要求实现者可以安全地移动到另一个线程，而 Sync 要求它们可以安全地通过共享引用在线程之间共享。例如，为不合适的类型实现 Send 将使 std::sync::Mutex 不能完全避免数据竞争。
举个简单的例子，Rust 标准库曾经包含一个 unsafe trait 的 core::nonzero::Zeroable，用于可以通过将所有字节设置为零来安全初始化的类型。显然，将 usize 归零很好，但是将 &amp;T 归零会返回一个空引用，如果解引用，这将导致崩溃。对于可归零的类型，可以进行一些优化：可以使用 std::ptr::write_bytes （ Rust 的 memset 等效项）快速初始化它们的数组，或者使用分配归零页面的操作系统调用。 （ Zeroable 是不稳定的，在 Rust 1.26 的 num 包中被转移到仅供内部使用，但它是一个很好的、简单的、真实的例子。） Zeroable 是一个典型的标记特征，没有方法或相关类型：合适类型的实现同样简单：使用这些定义，我们可以编写一个函数来快速分配一个给定长度的包含 Zeroable 类型的 vector ：该函数首先创建一个具有所需容量的空 Vec，然后调用 write_bytes 以用零填充未占用的缓冲区。（ write_bytes 函数将 len 视为 T 元素的数量，而不是字节的数量，所以这个调用确实填满了整个缓冲区。） vector 的 set_len 方法改变它的长度而不对缓冲区做任何事情； 这是不安全的，因为必须确保 vector 的缓冲区空间实际上包含正确初始化的 T 类型值。但这正是 T：Zeroable 界限所建立的：零字节块表示有效的 T 值，我们使用 set_len 是安全的。
这里我们可以写：显然，Zeroable 必须是一个不 unsafe trait，因为不尊重其规约的实现可能会导致未定义的行为：Rust 不知道 Zeroable 是什么意思，也不知道什么类型会实现它。与任何其他 unsafe 特性一样，由开发者来理解和遵守 unsafe trait 的规约。
 裸指针
Rust 中的裸指针是不受约束的指针，可以使用裸指针来形成 Rust 指针类型无法形成的各种结构，例如双向链表或任意对象图。但是由于裸指针非常灵活，Rust 无法判断是否安全地使用它们，因此只能在不安全的块中解引用。裸指针本质上等同于 C 或 C++ 指针，因此它们对于与用这些语言编写的代码进行交互也很有用。
这里有两种类型的裸指针：*mut T，指向 T 类型，并且允许对它指向的内容进行修改；
*const T，指向 T 类型，但是只允许读取它引用的内容；（记住，这里没有 *T 类型，必须总是声明 const 或者 mut。）
可以将一个普通引用转换成裸指针，并且使用 * 解引用：不像 box 和 Rust 引用，裸指针可能是空，类似于 C 里面的 NULL，或者 C++ 中的 nullptr ：这个例子没有 unsafe 代码块，因为创建裸指针，传递、比较都是安全的，仅解引用裸指针是不安全的。
指向 unsized 类型的裸指针是胖指针，就像对应的引用或 Box 类型一样。*const [u8] 指针包括长度和地址，并且像 *mut dyn std::io::Write 指针这样的 trait 对象携带 vtable。
尽管 Rust 在各种情况下隐式解引用安全指针类型，但裸指针解引用必须是显式的：. 运算符不会隐式解引用裸指针，必须写 (*raw).field 或者 (*raw).method(...) ；裸指针不实现 Deref，因此 deref 不适用于它们；诸如 == 和 &lt; 之类的运算符将裸指针作为地址进行比较：如果两个裸指针指向内存中的相同位置，则它们相等。类似地，对裸指针进行 hash 是以它们的地址为输入，而不是它们指向的内容；格式化 trait，如 std::fmt::Display 根本不处理裸指针，例外是 std::fmt::Debug 和 std::fmt::Pointer，它们将裸指针显示为十六进制地址，而不解引用它们；与 C 和 C++ 中的 + 运算符不同，Rust 的 + 不处理裸指针，但可以通过它们的 offset 和 wrapping_offset 方法，或者更方便的 add 、 sub 、 wrapping_add 和 wrapping_sub 方法来执行指针运算。 相反，offset_from 方法以字节为单位给出两个指针之间的偏移量：first 和 last 不需要显式转换，只需指定类型就足够了。 as 运算符允许引用和裸指针，或者两种裸指针类型之间的几乎所有可能的转换。但是，可能需要将复杂的转换分解为一系列更简单的步骤。 例如：以这种方式生成的引用具有不受约束的生命周期，它的生命周期没有限制，因为裸指针没有给 Rust 提供参考依据。还有就是 as 不能将裸指针转换为 Rust 的引用，这样的转换将是不安全的。而且，必须在 unsafe 代码块中解引用裸指针，然后借用结果值。
许多类型都有 as_ptr 和 as_mut_ptr 方法，它们返回指向其内容的裸指针。例如，数组切片和字符串返回指向它们的第一个元素的指针，并且一些迭代器返回指向它们将产生的下一个元素的指针。拥有像 Box、 Rc 和 Arc 这样的指针类型有 into_raw 和 from_raw 函数，它们可以在裸指针之间进行转换。其中一些方法的规约提出了难以置信的要求，因此在使用它们之前检查它们的文档。
允许将整数转换成裸指针，但通常是先把指针转换成整数，进行运算，然后转换成裸指针。
与 Rust 的引用不同，裸指针没有实现 Send 也没有实现 Sync。因此，默认情况下，任何包含裸指针的类型都不会实现这些 Trait。在线程之间发送或共享裸指针本身并没有什么不安全的。毕竟，无论它们走到哪里，都需要一个 unsafe 代码块来解引用它们。但是考虑到裸指针通常扮演的角色，语言设计者认为这种行为是最好的的默认设置。
 安全解引用裸指针
以下是一些安全使用裸指针的常识性指南：解引用空指针或悬空指针是未定义的行为，就像引用未初始化的内存或超出范围的值一样；解引用未针对其引用类型正确对齐的指针是未定义的行为；You may borrow values out of a dereferenced raw pointer only if doing so obeys the rules for reference safety: no reference may outlive its referent, shared access is read-only access, and mutable access is exclusive access.  (This rule is easy to violate by accident, since raw pointers are often used to create data structures with nonstandard sharing or ownership.)只有当裸指针是其类型有效值时，才可以使用它的引用。例如，必须确保取消引用 *const char 会产生正确的 Unicode 代码点；可以对裸指针使用 offset 和 wrapping_offset 方法，仅指向裸指针所指的变量或堆内存块中的字节，或指向超出该区域的第一个字节。如果通过将指针转换为整数、对整数进行算术然后将其转换回指针来进行指针运算，则结果必须是 offset 方法允许生成的指针，也就是遵循 offset 的规约；If you assign to a raw pointer’s referent, you must not violate the invariants of any type of which the referent is a part. For example, if you have a *mut u8 pointing to a byte of a String , you may only store values in that u8 that leave the String holding well-formed UTF-8 .除了借用规则之外，这些规则与在 C 或 C++ 中使用指针时必须遵循的规则基本相同。
The reason for not violating types’ invariants should be clear. Many of Rust’s standard  types use unsafe code in their implementation, but still provide safe interfaces on the  assumption that Rust’s safety checks, module system, and visibility rules will be respected. Using raw pointers to circumvent these protective measures can lead to  undefined behavior.
裸指针的完整、准确的约定不容易说明，并且可能随着语言的发展而改变，但是这里概述的原则可以让代码保持较为安全的状态。
 示例： RefWithFlag
下面是一个示例，说明如何利用裸指针实现的经典的位级 hack 并将其包装为完全安全的 Rust 类型。该模块定义了一个类型， RefWithFlag&lt;'a, T&gt;，它同时包含一个 &amp;'a T 和一个布尔值，就像元组 (&amp;'a T, bool) 一样，但仍然设法只占用一个机器字而不是两个，这种技术经常在垃圾收集器和虚拟机中使用，其中某些类型（例如，表示对象的类型）非常多，以至于在每个值中添加一个机器字都会大大增加内存使用：这段代码利用了许多类型必须放在内存中的偶数地址这一事实：由于偶数地址的最低有效位始终为零，我们可以在那里存储其他内容，然后只需通过屏蔽底部位即可重建原始地址。并非所有类型都符合条件，例如，类型 u8 和 (bool, [i8; 2]) 可以放在任何地址。但是我们可以在构造函数中检查类型的对齐方式拒绝那些不能使用的类型。
我们可以这样使用：构造函数 RefWithFlag::new 接受一个引用和一个 bool 值，断言引用的类型是合适的，然后将引用转换为裸指针和 usize。 usize 类型被定义为足够大，可以在我们编译的任何处理器上保存一个指针，因此将裸指针转换为 usize 并返回是明确定义的。一旦我们有了一个 usize，我们就知道它一定是偶数，我们也已将其转换为整数 0 或 1，所以我们可以使用 | 按位或运算符将其与 bool 运算。
get_flag 方法提取 RefWithFlag 的 bool 组件。这很简单：只需屏蔽底部位并检查它是否为非零。
get_ref 方法从 RefWithFlag 中提取引用。首先，它屏蔽了 usize 的底部位并将其转换为裸指针。as 运算符不会将裸指针转换为引用，但我们可以解引用裸指针并借用它。借用一个裸指针的引用对象会给你一个无限生命周期的引用：Rust 将给予引用任何生命周期会使其周围的代码检查的生命周期。但是，通常有一些特定的生命周期更准确，因此会发现更多错误。在这种情况下，由于 get_ref 的返回类型是 &amp;'a T，Rust 看到引用的生命周期与 RefWithFlag 的生命周期参数 'a 相同，这正是我们想要的：这就是我们开始引用的生命周期。
在内存中，RefWithFlag 看起来就像一个 usize：因为 PhantomData 是一个零大小的类型，behaviours_like 字段在结构中不占用空间。但是 PhantomData 是 Rust 知道如何处理使用 RefWithFlag 的代码中的生命周期所必需的。想象一下没有 behaves_like 字段的类型会是什么样子：在前面的章节中，指出任何包含引用的结构体都不能超过它们借用的值，以免引用变成悬空指针。该结构必须遵守适用于其字段的限制，这当然适用于 RefWithFlag：在我们刚刚查看的示例代码中，flagged  不能超过 vec，因为 flagged.get_ref() 返回对它的引用。但是我们简化的 RefWithFlag 类型根本不包含任何引用，并且从不使用它的生命周期参数 'a。 Rust 通过包含一个 PhantomData&lt;&amp;'a T&gt;  字段告诉 Rust  将 RefWithFlag&lt;'a, T&gt; 视为包含一个 &amp;'a T，而不会实际影响结构体的表示。
如果你省略了 behaves_like 字段， Rust 会认为 'a 和 T 没有使用，并建议使用 PhantomData。
RefWithFlag 使用与我们之前介绍的 Ascii 类型相同的策略来避免其 unsafe 块中的未定义行为。类型本身是 pub，但它的字段不是，这意味着只有 ref_with_flag 模块中的代码才能创建或查看 RefWithFlag 值，因此可确信 ptr_and_bit 字段构造是有效的。
 空指针
Rust 中的 null 裸指针是零地址，就像在 C 和 C++ 中一样。对于任何类型 T，std::ptr::null&lt;T&gt; 函数返回一个 *const T 空指针，而 std::ptr::null_mut&lt;T&gt; 返回一个 *mut T 空指针。
有几种方法可以检查裸指针是否为空，最简单的是 is_null 方法，但是 as_ref 方法可能更方便：它接受一个 *const T 指针并返回一个 Option&lt;&amp;'a T&gt;，将一个空指针变成一个 None。 同样， as_mut  方法将 *mut T 指针转换为 Option&lt;&amp;'a mut T&gt; 值。
 类型大小和对齐
任何 Sized 类型的值在内存中占用恒定数量的字节，并且进行内存对齐，按多少对齐由机器体系结构确定。例如，一个 (i32, i32) 元组占用 8 个字节，大多数处理器更喜欢将它放置在一个 4 的倍数的地址上。
调用 std::mem::size_of::&lt;T&gt;() 返回 T 类型值的大小，以字节为单位，而 std::mem::align_of::&lt;T&gt;() 返回其所需的对齐方式。 例如：任何类型的对齐方式始终是 2 的幂，一个类型的大小总是四舍五入到它的对齐的倍数，即使它在技术上可以容纳更少的空间。例如，即使像 (f32, u8) 这样的元组只需要 5 个字节， size_of::&lt;(f32, u8)&gt;() 也是 8，因为 align_of::&lt;(f32, u8)&gt;() 是 4。这确保如果有一个数组，则元素类型的大小始终反映一个元素与下一个元素之间的间距。
对于 unsize 类型，大小和对齐方式取决于手头的值。给定一个 unsize 值的引用， std::mem::size_of_val 和 std::mem::align_of_val 函数返回值的大小和对齐方式。这些函数可以对 Sized 和 unsized 类型的引用进行操作： 指针运算
Rust 将数组、切片或 vector 的元素布置为单个连续的内存块，如下图所示。元素是规则间隔的，因此如果每个元素占用 size 个字节，则第 i 个元素以第 i * sizeth 个字节开始。这样做的一个很好的结果是，如果你有两个指向数组元素的裸指针，比较指针会得到与比较元素索引相同的结果：如果 i &lt; j，那么指向第 i 个元素的裸指针小于指向第 j 的裸指针，这使得裸指针可用作数组遍历的边界。事实上，标准库对切片的简单迭代器最初是这样定义的：ptr 字段指向下一次迭代应该产生的元素，end 字段作为限制：当 ptr == end 时，迭代完成。数组这样布局的另一个好处是：如果 element_ptr 是指向某个数组的第 i 个元素的 *const T 或 *mut Traw  指针，则 element_ptr.offset(o) 是指向第 (i + o) 个元素的裸指针。它的定义等价于：std::mem::size_of::&lt;T&gt; 函数以字节为单位返回类型 T 的大小。由于根据定义， isize 大到足以容纳地址，因此您可以将基指针转换为 isize，对该值进行算术运算，然后将结果转换回指针。
使用 offset 生成超出该点或在数组开始之前的指针是未定义的行为，即使从未解引用它。为了优化， Rust 想假设当 i 为正时 ptr.offset(i) &gt; ptr，当 i 为负时 p tr.offset(i) &lt; ptr。这个假设似乎是安全的，但如果 offset 中的算术溢出，它可能不成立。如果 i 被限制在与 ptr 相同的数组中，则不会发生溢出：毕竟，数组本身不会溢出地址空间的边界。
如果确实需要将指针偏移到与它们关联的数组的限制之外，可以使用 wrapping_offset 方法，这等效于偏移量，但 Rust 不对 ptr.wrapping_offset(i) 和 ptr 本身的相对顺序做任何假设。当然，仍然不能解引用这些指针，除非它们在数组中。
 移入移出内存
如果正在实现一种管理自己内存的类型，将需要跟踪内存的哪些部分保存实时值以及哪些未初始化，就像 Rust 处理局部变量一样。考虑这段代码：这段代码运行之后，这两个变量的内存结构看起来如下图所示：赋值后， pot 未初始化， plate 是字符串的所有者。在机器级别，并没有指定 move 对源有什么作用，但实际上它通常什么都不做。赋值可能使 pot 仍然保留字符串的指针、容量和长度。但是将 pot 视为存在值将是灾难性的， Rust 确保不会这样做。
同样的注意事项也适用于管理自己内存的数据结构。假设运行以下代码：内存中，看起来的结构如下图所示：该 vector 有多余的容量再容纳一个元素，但它的内容是垃圾，可能是之前保存的内存。假设您随后运行此代码：将字符串推送到 vector 上会将未初始化的内存转换为新元素，如下图所示：该 vector 已初始化其空白空间以拥有该字符串并增加其长度以将其标记为新的活动元素。 vector 现在是字符串的所有者；可以引用它的第二个元素，删除 vector 会释放两个字符串， soba 现在未初始化。
最后，考虑当我们从 vector 中弹出一个值时会发生什么：现在，它的内存看起来如下图所示：变量 last 获得了字符串的所有权，该 vector 已减少其长度以指示用于保存字符串的空间现在未初始化。
就像之前的 pot 和 pasta 一样， soba 、 last 和 vector 的空闲空间可能都持有相同的位模式。但只有 last 被认为拥有该值，将其他两个位置中的任何一个视为可用都是错误的。
初始化值的真正定义是一个变量被视为可用。写入一个值的字节通常是初始化的必要步骤，但也只是因为这样做才会将变量视为可用。move 和 copy 对内存的影响是一样的，两者的区别在于，在 move 之后，源不再被视为可用的，而在 copy 之后，源和目标都是可用的。
Rust 会在编译时跟踪哪些局部变量处于可用状态，并阻止使用其值已移动到其他地方的变量。Vec、HashMap、Box 等类型动态跟踪它们的缓冲区。如果你实现一个类型来管理它自己的内存，你需要做同样的事情。
Rust 提供了两个基本操作来实现这些类型：std::ptr::read(src) ：将值移出 src 指向的位置，将所有权转移给调用者。 src 参数应该是一个 *const T 裸指针，其中 T 是一个 Sized 类型。调用此函数后， *src 的内容不受影响，但除非 T 实现了 Copy，否则必须确保程序将它们视为未初始化的内存。
这是 Vec::pop 背后的操作。弹出一个值调用 read 将值移出缓冲区，然后递减长度以将该空间标记为未初始化的容量。std::ptr::write(dest, value) ：将 value 移动到 dest 指向的位置，该位置在调用之前必须是未初始化的内存， dest 引用的变量现在拥有该 value。 在这里， dest 必须是一个 *mutT 裸指针并且 value 是一个实现了 Sized 的 T 类型。
这是 Vec::push 背后的操作。 push 一个 value 调用 write 将值移动到下一个可用空间，然后增加长度以将该空间标记为有效元素。两者都是自由函数，而不是裸指针类型的方法。不过请注意，不能使用 Rust 的任何安全指针类型来做这些事情。它们都要求始终初始化它们的所指对象，因此将未初始化的内存转换为值，反之亦然，它们是无法实现的，但是裸指针符合要求。
标准库还提供了将值数组从一个内存块移动到另一个内存块的函数：std::ptr::copy(src, dst, count) ：将内存中从 src 开始的有 count 个元素的数组移动到 dst 的内存，就像编写了一个读取和写入调用循环来一次移动一个一样。目标内存必须在调用之前未初始化，之后源内存保持未初始化。 src 和 dest 参数必须是 *const T 和 *mut T 裸指针，并且 count 必须是 usize ；ptr.copy_to(dst, count) ： copy 的简单易用版本，它将内存中从 ptr 开始的有 count 个元素的数组移动到 dst ；std::ptr::copy_nonoverlapping(src, dst, count) ：与相应的 copy 类似，只是它的规约进一步要求内存的源块和目标块不能重叠。这可能比调用 copy 稍微快一些；ptr.copy_to_nonoverlapping(dst, count) ：更方便的 copy_nonoverlapping 版本，例如 copy_to ；在 std::ptr 模块中还有另外两个读写函数系列：read_unaligned, write_unaligned ：这些函数类似于 read 和 write，除了指针不需要按照引用类型的通常要求进行对齐。这些函数可能比普通的读写函数慢；read_volatile, write_volatile ：这些函数相当于 C 或 C++ 中的 volatile 读写； 示例： GapBuffer
这是一个使用刚刚描述的裸指针函数的示例。假设正在编写一个文本编辑器，并且正在寻找一种类型来表示文本。可以选择 String 并使用 insert 和 remove 方法在用户键入时插入和删除字符。但是如果他们在一个大文件的开头编辑文本，这些方法可能会很昂贵：插入一个新字符需要将整个字符串的其余部分移到内存中的右侧，而删除则将其全部移回左侧。
Emacs 文本编辑器使用一种称为间隙缓冲区的简单数据结构，可以在恒定时间内插入和删除字符。 String 将其所有备用容量保留在文本的末尾，这使得 push 和 pop 比较轻量，而间隙缓冲区将其备用容量保留在文本中间，即进行编辑的位置，这种备用能力称为缺口。在间隙插入或删除元素很轻量：只需根据需要缩小或扩大间隙。可以通过将文本从间隙的一侧移动到另一侧来将间隙移动到喜欢的任何位置。当间隙为空时，将迁移到更大的缓冲区。
虽然间隙缓冲区中的插入和删除速度很快，但更改它们发生的位置需要将间隙移动到新位置，移动元素需要与移动距离成比例的时间。幸运的是，典型的编辑活动包括在缓冲区的一个邻域进行一系列更改，然后再开始在其他地方修改文本。
在本节中，我们将在 Rust 中实现一个间隙缓冲区。为了避免被 UTF-8 分散注意力，我们将让缓冲区直接存储 char 值，但如果我们以其他形式存储文本，操作原理将是相同的。
首先，我们将展示一个实际的间隙缓冲区。此代码创建一个 GapBuffer，在其中插入一些文本，然后将插入点移动到最后一个单词之前：运行代码之后，缓冲池可能如下如所示：插入是用新文本填补空白的问题，这段代码加了一个词 Onion ：插入之后如下图所示：这个就是我们的 GapBuffer 类型实现：GapBuffer 以一种奇怪的方式使用它的存储字段，它实际上从未在 vector 中存储任何元素或不完全存储。它只是调用 Vec::with_capacity(n) 来获得足够大的内存块来保存 n 个值，通过向量的 as_ptr 和 as_mut_ptr 方法获得指向该内存的裸指针，然后直接将缓冲区用于自己的目的，向量的长度始终保持为 0。 当 Vec 被丢弃时， Vec 不会尝试释放它的元素，因为它不知道它有任何元素，但它确实释放了内存块。 这就是 GapBuffer 想要的；它有自己的 Drop 实现，它知道活动元素的位置并正确删除它们。
GapBuffer 最简单的几个方法：继续实现这个 impl，实现返回一个指向指定索引的只读裸指针和指向指定索引的可变裸指针：要找到给定索引处的元素，必须考虑索引是落在间隙之前还是之后并适当调整：当我们开始在缓冲区的不同部分进行插入和删除时，我们需要将间隙移动到新位置。将间隙向右移动需要向左移动元素，反之亦然，就像水平仪中的气泡在流体流入另一个方向时向一个方向移动：该函数使用 std::ptr::copy 方法移动元素； copy 要求目标未初始化，而源未初始化，源和目标范围可能重叠，但 copy 可以正确处理这种情况。由于间隙是调用前未初始化的内存，并且函数调整间隙的位置以覆盖副本腾出的空间，因此满足 copy 函数的规约。
元素插入和移除相对简单。插入从新元素的间隙中占据一个空间，而删除将一个值移出并扩大间隙以覆盖它曾经占用的空间：与 Vec 使用 std::ptr::write 进行 push 和 std::ptr::read 进行 pop 的方式类似， GapBuffer 使用 write 插入和 read 删除。 就像 Vec 必须调整它的长度以保持初始化元素和备用容量之间的边界一样， GapBuffer 也会调整它的间隙。
当间隙被填满时， insert 方法必须增大缓冲区以获取更多可用空间。 expand_gap 方法处理这个问题：set_position 必须使用 copy 在间隙中来回移动元素，而 enlarge_gap 可以使用 copy_nonoverlapping，因为它将元素移动到全新的缓冲区。
将新 vector 移动到 self.storage 会删除旧 vector。由于它的长度为零，旧 vector 认为它没有元素可以丢弃并简单地释放它的缓冲区。 巧妙地， copy_nonoverlapping 让它的源未初始化，所以旧 vector 在这个信念上是正确的：所有元素现在都由新 vector 所有。
最后，我们需要确保删除 GapBuffer 会删除其所有元素：元素位于间隙之前和之后，因此我们遍历每个区域并使用 std::ptr::drop_in_place 函数删除每个区域。 drop_in_place 函数是一个行为类似于 drop(std::ptr::read(ptr)) 的实用程序，但不会将值移动到其调用者（因此适用于未调整大小的类型）。就像 enlarge_gap 一样，当向量 self.storage 被删除时，它的缓冲区实际上是未初始化的。
就像我们在本文中展示的其他类型一样， GapBuffer 确保它自己的不变量足以确保它使用的每个 unsafe 特性的规约都被遵循，因此它的任何公共方法都不需要标记为 unsafe， GapBuffer 实现了高效的接口但是这些没法使用安全代码做到。
完整的例子，请看 https://github.com/ProgrammingRust/examples/tree/master/gap-buffer。
 unsafe 中的 Panic
在 Rust 中， panic 通常不会导致未定义的行为； panic! 不是 unsafe 功能。但是当你决定使用 unsafe 代码时， panic 安全需要关注了。考虑上一节中的 GapBuffer::remove  方法：调用 read 将紧随间隙的元素移出了缓冲区，留下了未初始化的空间。在这一点上， GapBuffer 处于不一致的状态：我们破坏了所有在间隙外的元素必须被初始化的不变性。幸运的是，下一条语句扩大了间隙以覆盖这个空间，所以当我们返回时，不变性再次成立。
但是考虑一下，如果在调用 read 之后，但在调整为 self.gap.end 之前，这段代码试图使用一个可能会引起 panic 的功能–比如，对一个片断进行索引，那么会发生什么。下一次调用 remove 可能会尝试再次读取它；甚至简单地丢弃 GapBuffer 也会尝试放弃它。两者都是未定义的行为，因为它们访问了未初始化的内存。
一个类型的方法在做工作的时候，暂时放松该类型的不变性，然后在返回之前将一切恢复原状，这几乎是不可避免的。方法中间的错误可能会缩短清理过程，使类型处于不一致的状态。
如果类型只使用安全代码，那么这种不一致可能会使类型行为异常，但不会引入未定义的行为。但是使用 unsafe 特性的代码通常依靠其不变量来满足这些特性的规约，损坏的不变量会导致破坏规约，从而导致未定义的行为。在使用 unsafe 功能时，必须特别注意识别这些敏感的代码区域，其中不变量会暂时放松，并确保它们不做任何可能引起 panic 的事情。
 Union
Rust 提供了许多有用的抽象，但最终编写的软件还是在处理字节。 Union 是 Rust 处理这些字节并选择如何解释它们的最强大的功能之一。 例如，任何 32 位（ 4 个字节）的集合都可以被解释为整数或浮点数。任何一种解释都是有效的，尽管将数据解释为一个可能会导致无意义。
表示可以解释为整数或浮点数的字节集合的 Union 可以如下所示：这是一个具有两个字段 f 和 i 的 union，它们可以像结构体的字段一样被分配，但是在构造 union 时，与结构体不同，只可以选择其中一个。 结构体的字段指的是内存中的不同位置，而 union 的字段指的是同一位序列的不同解释。分配给不同的字段仅仅意味着根据适当的类型覆盖这些位中的一些或全部。这里， one 指的是单个 32 位内存跨度，它首先存储编码为简单整数的 1，然后存储 1.0 作为 IEEE 754 浮点数。一旦写入 f，之前写入 FloatOrInt 的值就会被覆盖：出于同样的原因， union 的大小由其最大的字段决定。例如，这个 union 的大小是 64 位，尽管 SmallOrLarge::s 只是一个布尔值：虽然构造 union 或给它的字段赋值是完全安全的，但从 union 的任何字段中读取总是不安全的：这是因为，与枚举不同， union 没有标签。编译器没有添加额外的位来区分变体。除非程序有一些额外的上下文，否则无法在运行时判断 SmallOrLarge 是要解释为 u64 还是 bool。
也没有内置保证给定字段的位模式有效。例如，写入 SmallOrLarge 值的 l 字段将覆盖其 s 字段，创建一个绝对没有任何用处的位模式，并且很可能不是有效的布尔值。因此，虽然写入 union 字段是安全的，但每个读取需要 unsafe。只有当 s 字段的位形成有效的布尔值时，才允许从 u.s 读取，否则，这是未定义的行为。
考虑到这些限制， union 可能是一种临时重新解释数据的有用方法，尤其是在对值的表示而不是值本身进行计算时。例如，前面提到的 FloatOrInt 类型可以很容易地用于打印出浮点数的各个位，尽管 f32 没有实现二进制格式化程序：尽管这些简单的示例几乎可以肯定在任何版本的编译器上都能按预期工作，但不能保证任何字段都从特定位置开始，除非在联合定义中添加一个属性，告诉编译器如何在内存中布局数据。 添加属性 #[repr(C)] 保证所有字段都从偏移量 0 开始，而不是编译器喜欢的任何位置。有了该保证，覆盖行为可用于提取单个位，例如整数的符号位：运行该程序输出：
1111111111111111111111111111111111111111111111111111111111111111 ([255, 255, 255, 255, 255, 255, 255, 255])
1 ([1, 0, 0, 0, 0, 0, 0, 0])
111111111111111111111111111111111111111111111111111111111111111 ([255, 255, 255, 255, 255, 255, 255, 127])
1000000000000000000000000000000000000000000000000000000000000000 ([0, 0, 0, 0, 0, 0, 0, 128])这里，符号位是最高有效字节的最高有效位。 因为 x86 处理器是 little-endian，所以这些字节的顺序是相反的；最重要的字节不是字节 [0]，而是字节 [7]。通常，这不是 Rust 代码必须处理的事情，但因为这段代码直接使用 i64  的内存表示，所以这些低级细节变得很重要。
因为 union 不知道如何删除它们的内容，所以它们的所有字段都必须是 Copy。但是，如果只是必须将 String 存储在 union  中，则有一种解决方法，请查阅 std::mem::ManuallyDrop 的标准库文档。
 匹配 Union
在 Rust union 上进行匹配就像在结构上进行匹配，只是每个模式都必须准确地指定一个字段：匹配联合变体而不指定匹配的值将始终成功。 下面如果 u 的最后更新字段是 u.i，则以下代码将导致未定义的行为： 借用 Union
借用 union 的一个字段会借用整个 union。这意味着，按照正常的借用规则，将一个字段借用为可变字段会排除对该字段或其他字段的任何额外借用，而将一个字段借用为不可变字段意味着在任何字段上都不能有可变借用。
Rust 不仅可以为自己的 unsafe 代码构建安全接口，还可以为用其他语言编写的代码构建安全接口。顾名思义， unsafe 虽然令人望而生畏，但小心使用它可以构建高性能代码，并保留 Rust 程序员享有的保障。
]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>《Rust 程序设计》</tag>
        <tag>unsafe</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】交叉编译</title>
    <url>/2022/04/08/Rust/%E3%80%90Rust%E3%80%91%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91/</url>
    <content><![CDATA[交叉编译就是跨平台编译，例如在 window 下编译程序的linux版本，或者在 x86_64 平台下编译 aarch64 版本。跨平台编译在Go语言中非常方便，得益于Go语言汇编器的设计。
 MacOS 交叉编译 Linux 程序
本文展示如何在 Apple M1 的平台下编译 Linux aarch64 的应用程序。Apple M1：linux aarch64：   
 安装 rust 标准库
在编译之前，我们需要在我们的工作平台，即 Mac 机器中，安装目的平台的标准库，我们可以通过 rustup target list 命令查看 rust 支持哪些平台架构，例如：安装特定平台标准库使用 rustup target add 命令即可:安装成功之后，通过 rustup show 命令查看本地已安装的工具链和标准库： 安装编译器
要编译 aarch64-linux-gnu 平台下的程序，就需要特定平台的编译器，这个项目中提供了MAC环境下用于交叉编译的工具，更多请看 https://github.com/messense/homebrew-macos-cross-toolchains。
使用 brew 安装非常简单，两条命令即可，耐心等待安装完成:经过这里之后，我们可以看到我们将所需要的 linux-aarch64 下的工具链都安装下来了： 交叉编译
使用 cargo 命令快速创建一个项目进行测试: 配置文件配置 Cargo
我们需要配置 cargo 编译时使用的链接器，在配置文件 .cargo/config 中添加如下配置:然后我们执行特定编译命令 cargo build -v --target aarch64-unknown-linux-gnu： 环境变量配置 Cargo
我们也可以使用环境变量配置所需要的链接器，环境变量的形式是：CARGO_TARGET_&lt;triple&gt;_LINKER，这里的 triple 就是我们目标 target，只不过要转换成大写，并且替换 - 为 _，例如:CARGO_TARGET_AARCH64_UNKNOWN_LINUX_GNU_LINKER=/opt/homebrew/bin/aarch64-unknown-linux-gnu-gcc  cargo build -v --target aarch64-unknown-linux-gnu 编译输出结果
在下面的目录下能找到编译之后的二进制文件：然后去linux下运行也是没有问题的： 其他场景
交叉编译的直接需求就是你得找到一款合适的编译器，能编译出特定平台架构下的二进制程序。macos-&gt;windows：Macos 平台linux和windows交叉编译器
linuxARM compiler for LinuxX86 System 参考文章Rust Cross-Compilation with Cargo and Rustup toolchain manager
如何在Mac上为Linux交叉编译Rust程序
Rust交叉编译Mac编译Linux/Windows平台
Macos 平台linux和windows交叉编译器]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>交叉编译</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】基础类型</title>
    <url>/2022/04/10/Rust/%E3%80%90Rust%E3%80%91%E5%9F%BA%E7%A1%80%E7%B1%BB%E5%9E%8B/</url>
    <content><![CDATA[下面是在 Rust 中会看到的类型的总结，展示了Rust的基本类型，标准库中一些非常常见的类型，以及一些用户定义类型的例子。Type
Description
Valuesi8, i16, i32, i64, i128 u8, u16, u32, u64, u128
给定宽度的有符号和无符号整数
42,-5i8, 0x400u16, 0o100i16, 20_922_789_888_000u64, b'*'isize, usize
有符号整数和无符号整数， 与计算机上的地址大小相同(32位或64位)
137, -0b0101_0010isize, 0xffff_fc00usizef32, f64
IEEE浮点数，单精度和双精度
1.61803, 3.14f32, 6.0221e23f64bool
Boolean
true，falsechar
Unicode字符，32位宽
'*', '\n', '字', '\x7f', '\u&#123;CA0&#125;'(char, u8, i32)
Tuple:允许混合类型
('%', 0x7f, -1)()
空元组
()struct S &#123; x: f32, y: f32 &#125;
字段带名称的复合结构
S &#123; x: 120.0, y: 209.0 &#125;struct T (i32, char);
Tuple-like struct
T(120, 'X')struct E;
Unit-like struct; has no fields
Eenum Attend &#123; OnTime, Late(u32) &#125;
枚举
Attend::Late(5), Attend::OnTimeBox&lt;Attend&gt;
Box:拥有指向堆中的值的指针
Box::new(Late(15))&amp;i32, &amp;mut i32
共享引用和可变引用:非拥有指针，不能比它们的引用活得更久
&amp;s.y, &amp;mut vString
动态大小的UTF-8字符串
&quot;ラーメン: ramen&quot;.to_string()&amp;str
Reference to str: non-owning pointer to UTF-8 text
&quot;そば: soba&quot;, &amp;s[0..12][f64; 4], [u8; 256]
数组，固定长度，元素同类型
[1.0, 0.0, 0.0, 1.0], [b' '; 256]Vec&lt;f64&gt;
变长Vector，元素同类型
vec![0.367, 2.718, 7.389]&amp;[u8],&amp;mut [u8]
对slice的引用:对数组或vector的一部分的引用，包括指针和长度
&amp;v[10..20], &amp;mut a[..]Option&lt;&amp;str&gt;
可选值，要么是 None，要么是 Some(v)
Some(&quot;Dr.&quot;), NoneResult&lt;u64, Error&gt;
可能失败的操作结果，成功就是 Ok(v)，失败则是：Err(e)
Ok(4096), Err(Error::last_os_error())&amp;dyn Any, &amp;mut dyn Read
Trait对象:引用任何实现了给定方法集的值
value as &amp;dyn Any,&amp;mut file as &amp;mut dyn Readfn(&amp;str) -&gt; bool
函数指针
str::is_empty(Closure types have no written form)
闭包
` 整数类型
固定宽度的数字类型可能会溢出或失去精度，但它们对于大多数应用程序来说已经足够了，并且可能比任意精度整数和有理素数等表示快数千倍。如果需要这些功能，可以使用 num。Rust 的类型名称中包含了他们代表的宽度和用途。大小
无符号整数
有符号整数
浮点数8
u8
i816
u16
i1632
u32
i32
f3264
u64
i64
f64128
u128
i128Machine word
usize
isizeRust 有符号数的范围如下：类型
范围i8
−27-2^7−27 ~ 27−12^7 - 127−1 (−128 ~ 127)i16
−215-2^{15}−215 ~ 215−12^{15}−1215−1 (−32,768 ~ 32,767)i32
−231-2^{31}−231 ~ 231−12^{31}−1231−1 (−2,147,483,648 ~ 2,147,483,647)i64
−263-2^{63}−263 ~ 263−12^{63}−1263−1  (−9,223,372,036,854,775,808 ~ 9,223,372,036,854,775,807)i128
−2127-2^{127}−2127 ~ 2127−12^{127}−12127−1 (roughly −1.7∗1038{-1.7} \ast 10^{38}−1.7∗1038 ~ 1.7∗10381.7 \ast 10^{38}1.7∗1038)isize
−231-2^{31}−231 ~ 231−12^{31}−1231−1, 或者 −263-2^{63}−263 ~ 263−12^{63}−1263−1Rust 无符号数的范围如下：类型
范围u8
0 ~ 28−12^8−128−1 (0 ~ 255)u16
0 ~ 216−12^{16}−1216−1 (0 ~ 65,535)u32
0 ~ 232−12^{32}−1232−1  (0 ~ 4,294,967,295)u64
0 ~ 264−12^{64}−1264−1  (0 ~ 18,446,744,073,709,551,615)u128
0 ~ 2128−12^{128}−12128−1 (0 ~ around 3.4∗10383.4 \ast 10^{38}3.4∗1038)usize
0 ~ 232−12^{32}−1232−1, 或者 0 ~ 264−12^{64}−1264−1usize和isize类型类似于C和C++中的size_t和ptrdiff_t，它们的大小和机器架构有关系，要么是 32位 要么是 64位。Rust要求数组索引为usize值，表示数组或vector大小或某些数据结构中元素数量计数的值通常也具有usize类型。
数字字面量可以用一个后缀表示它们的类型，例如：42u8，1729isize。如果没有类型后缀，Rust 会在赋值，函数调用或者比较的时候才确定其类型，也就是根据使用场景将它确定为合适的类型。最后，如果没有指定类型，并且多种类型也都可行，那么默认 i32，否则，就会报告错误。
数字字面量可以用前缀 0x，0o 或者 0b 表示 16进制，8进制 或者 2进制数值。
为了在表示长数字时更具可读性，可以在数字之间插入下划线 _。例如我们可将 u32 的最大值表示为 4_294_967_295。下划线的位置并不重要，例如，我们可以在表示16进制数字和2进制数字，以  0xffff_ffff 的形式进行分割，或者用 _ 分割数值和类型 127_u8。
在 Rust 中，可以将字符表示为 u8 类型，例如用 b'X' 表示字母 X，65 和 b'A' 是完全相等的。对于一些字符不能直接表示，需要转义：字符
字面量
等价数值单引号
b'\''
39u8反斜线
b'\\'
92u8换行键
b'\n'
10u8回车键
b'\r'
13u8水平制表符
b'\t'
9u8对于一些很难表示的字符，可以用16进制表示，形式为 b'\xHH'。例如，ASCII 码，27 代表的 ESC (Escape)，我们可以表示为 \x1b。
对于数值之间的类型转换，可以使用 as 操作符：标准库提供了很多整数操作方法，例如：更多可以去看每个标准库每个类型的方法，例如 i16。
真实编码情况下，我们编码的时候一般不会写类型后缀，但是像下面这样调用方面就会报错:原因是：
error[E0689]: can't call method `abs` on ambiguous numeric type `{integer}`这可能会有点令人困惑：所有有符号整数类型都有 abs方法，那么有什么问题呢？出于技术原因，Rust 想知道一个值在调用该类型自己的方法之前具有哪个整数类型。i32的默认值只适用于在所有方法调用解决后，类型仍然不明确的情况，所以在这里已经太晚了，没有帮助。解决方案是用后缀或使用特定类型的函数来阐明打算使用哪种类型：因为方法调用比一元操作符优先级高，所以我们需要将操作数用括号包括，否则 -4_i32.abs() 的结果将是 -4。
 溢出处理
当整数计算溢出时，debug 模式下，程序会奔溃。release 模式下，程序会一直运行，只是结果就不可期望了。对于下面的测试代码，我们使用两种不同的模式进行运行:使用 cargo run 命令时程序会崩溃（默认 debug），但使用 cargo run --release 时会一直运行。默认行为或许不是我们想要的，那么我们可以显示地表达我们的意图：checked 相关的方法会检查运算结果，如果数学上是正确的，那么就是会返回 Some(v)，否则，会返回 None：wrapping operations return the value equivalent to the mathematically correct result modulo the range of the value：Saturating 相关的操作在溢出时会用类型最大值表示结果：Overflowing 相关的操作会返回一个 tuple(result, overflowed)，其中 result 是 wrapping 将返回的内容，overflowed 指示是否发生了溢出：操作名称都以下面的前缀开始：checked_, wrapping_, saturating_, 或者 overflowing_，相关的操作有：Operation
Name suffix
ExampleAddition
add
100_i8.checked_add(27) == Some(127)Subtraction
sub
10_u8.checked_sub(11) == NoneMultiplication
mul
128_u8.saturating_mul(3) == 255Division
div
64_u16.wrapping_div(8) == 8Remainder
rem
(-32768_i16).wrapping_rem(-1) == 0Negation
neg
(-128_i8).checked_neg() == NoneAbsolute value
abs
(-32768_i16).wrapping_abs() == -32768Exponentiation
pow
3_u8.checked_pow(4) == Some(81)Bitwise left shift
shl
10_u32.wrapping_shl(34) == 40Bitwise right shift
shr
40_u64.wrapping_shr(66) == 10 浮点数
Rust提供IEEE单精度和双精度浮点类型。这些类型包括正负无穷大，不同的正负零值，以及非数字值。单双精度数值的范围如下：Type
Precision
Rangef32
单精度（最少6位小数）
Roughly –3.4∗1038{–3.4} \ast 10^{38}–3.4∗1038 ~ +3.4∗1038{+3.4} \ast 10 ^{38}+3.4∗1038f64
双精度 (最少15位小数)
Roughly –1.8∗10308{–1.8} \ast 10^{308}–1.8∗10308 ~ +1.8∗10308{+1.8} \ast 10^{308}+1.8∗10308Rust 的 f32 和 f64 对应于 C，C++ 中的 float 和 double（在支持IEEE浮点的实现中）以及 Java（始终使用IEEE浮点）。浮点数的一般形式如下图所示：整数部分之后浮点数的每个部分都是可选的，但分数部分、指数或类型后缀至少存在一个，以将其与整数文字区分开来。小数部分可能由一个单独的小数点组成，因此5.是一个有效的浮点常数。下面是一些示例：Literal
Type
Mathematical value-1.5625
Inferred
−(1916)−(1\frac{9}{16})−(1169​)2.
Inferred
20.25
Inferred
14\frac{1}{4}41​1e4
Inferred
10,00040f32
f32
409.109_383_56e-31f64
f64
Roughly 9.10938356∗10–319.10938356 \ast 10^{–31}9.10938356∗10–31f32和f64类型具有IEEE要求的特殊值的相关常量，如 INFINITY、NEG_INFINITY（负无穷大）、NAN（非数字值）以及MIN和MAX（最大和最小的有限值）：f32 和 f64 类型为数学计算关系提供了完整的方法补充；例如，2f64.sqrt()是2的双精度平方根。一些例子：同样，方法调用的优先级高于前缀运算符，因此请务必对否定值对方法调用进行校正括号。
std::f32::consts 和 std::f64::consts 模块提供了各种常用的数学常量，如E、PI和两个的平方根。
与C和C++不同，Rust几乎不隐式执行数字转换。如果函数期望f64类型参数，则传递i32值作为参数是错误的。事实上，Rust甚至不会隐式将i16值转换为i32值，即使每个i16值也是i32值。但始终可以使用 as 运算符写出显式转换：i as f64，或 x as i32。
缺乏隐式转换有时使Rust表达式比类似的C或C++代码更冗长。然而，隐式整数转换有可能导致意想不到的安全漏洞。根据经验，在 Rust 中显示写出数字转换提醒我们注意可能会发生的问题。
 Bool 类型
Rust 的 bool 类型具有 true 和 false 两个值。== 和 &lt; 等比较运算符产生 bool 结果：2 &lt; 5 的值为 true。
许多语言在需要布尔值的上下文中能使用其他类型进行自动隐式转换：C 和 C++ 隐式将字符、整数、浮点数和指针转换为布尔值，因此它们可以直接用作 if 或 while 语句中的条件。Python 允许在布尔上下文中设置字符串、列表、字典甚至集合，如果这些值是非空的，则将其视为 true。但是 rust 非常严格，对于 if 和 while 这样的控制结构，要求其条件语句必须为 bool 表达式，逻辑运算符&amp;&amp; 和 || 也是如此。所以必须写 if x != 0 &#123; ... &#125; 而不是 if x &#123; ... &#125;。
Rust 的 as 操作符可以将bool值转换为整形：但是反过来不行，as 不能将数字转化为 bool，所以，必须写显示的比较操作，例如：x != 0。虽然 bool 只需要 1 个 bit 来表示它，但 Rust 使用整个字节（8 bit）来表示内存中的 bool 值，因此可以创建指向它的指针，例如 &amp;true。
 字符类型
Rust 的字符类型 char 表示单个Unicode字符，为32位值。Rust 对单个字符使用 char 类型，但对字符串和文本流使用 UTF-8 编码。因此，字符串将其文本表示为 UTF-8 字节序列，而不是字符数组。字符字面量可以是任何用单引号括起来的Unicode 字符，如'8'，'!'，'中'。
根据个人喜好，如果喜欢，可以用16进制写出任何一个字符的 Unicode码点：如果字符的代码点在U+0000到U+007F的范围（也就是ASCII字符），那么我们可以将字符写为\xHH，其中HH是一个两位16进制数字。例如，字符文字*和\x2A是等价的，因为字符*的代码点是42，或16进制为2A；可以将任何 Unicode 字符写成 \u&#123;HHHHHH&#125;，其中 HHHHHH 是一个16进制数字，长度可达 6 位数，允许使用下划线分组。例如，字面字符\u&#123;CA0&#125;表示字符ಠ。char类型能表示的 Unicode 字符码点在 0x0000 ~ 0xD7FF 或者 xE000 ~ 0x10FFFF 之间。Rust 使用类型系统和动态检查来确保字符值始终在允许范围内。
Rust 永远不会在 char 和任何其他类型之间隐式转换。可以使用转换运算符将字符转换为整数类型；对于小于32位的类型，字符值的高位被截断：还有就是 u8是唯一可以直接通过as转换为char的类型，但u8以外的每个整数类型都包含不允许的Unicode代码点的值，因此这些转换需要运行时检查。标准库为此提供std::char::from_u32接受任何u32值并返回Option&lt;char&gt;：如果u32不是允许的Unicode代码点，则from_u32返回None；否则，它会返回Some(c)，其中c是char值。
标准库提供了一些关于字符的有用方法，可以查看标准库文档。例如： 元组类型
Tuple形式上是一个括号围起来的，逗号分割的多元素序列。例如 (&quot;Brazil&quot;, 1985)，它的类型是 (&amp;str, i32)，如果将它赋值给变量 t，可以通过 t.0 或者 t.1 访问元素。
在某种程度上，tuple 很像 array，都表示有序的值序列。有些编程语言中将他们统一在，但是在 rust 中，这完全是隔离开的。主要有两大区别：tuple 的元素类型可以不同，但是数组所有元素的类型都是相同的；
tuple 只能用常量作为索引，例如 t.4，不能用 t.i 或者 t[i] 去访问第 i 个元素；Rust 中，tuple 经常用于函数的多值返回，例如：返回值 (&amp;str, &amp;str) 是一个包含两个字符串slice的 tuple，可以通过模式匹配将他们赋值给不同的变量:这比下面的代码更具可读性：另一种常用的元组类型是零元组()，这一般被称为单位类型，因为它只有一个值，也写成 ()，虽然单位类型没有携带有意义的值，但某些场景仍然有意义。例如，我们可能有这样一个返回值 Result&lt;(), std::io::Error&gt;，它在成功时没有返回值，当出错时返回 std::io::Error。
还有就是，可以在 tuple 的最后一个元素后面添上逗号，但是还是同一个类型，例如 (&amp;str, i32,) 和 (&amp;str, i32) 是完全等价的。除此之外，Rust 在函数参数，数组，结构体或者枚举定义中都允许使用额外的逗号。
对于一元组，也就是只包含1个元素的 tuple，例如 (&quot;lonely hearts&quot;,)  它的类型是 (&amp;str,)，这里的逗号就是必须的，为了和括号表达式区分。
 指针类型
Rust 有几种代表内存地址的指针类型。
Rust和大多数具有 GC 功能的语言之间存在巨大差别。在Java中，如果类矩形包含一个类型位 Vector2D 的字段 upperLeft，那么 upperLeft 是对另一个单独创建的 Vector2D 对象的引用，在Java中，对象永远不会实际包含其他对象。
Rust 是不同的，该语言旨在帮助将内存分配保持在最低限度，对于值((0，0), (1440，900)) 存储为4个相邻整数。如果将其存储在局部变量中，则有一个4个整数宽的局部变量。
这会极大提高内存的效率，但因此，当Rust程序需要值来指向其他值时，它必须显式使用指针类型。好消息是安全 Rust 中使用的指针类型受到限制，以消除未定义的行为，因此在 Rust 中比在 C++ 中正确使用指针容易得多。
本节学习几种指针类型：reference，box 以及 unsafe pointer。
 引用
&amp;String 类型的值（发音为ref String）是对 String 值的引用，&amp;i32 是对 i32 的引用。
把引用看作是Rust的基本指针类型，是最容易入门的。在运行时，对i32 的引用是保存 i32 地址的单个机器字，该地址可能在堆栈上或堆栈中。表达式 &amp;x 产生对 x 的引用；在Rust术语中，我们说它借用了对 x 的引用。给定引用 r，表达式 *r 指的是r 指向的值。这些非常像C和C++中的 &amp; 和 * 运算符。
然而，与C指针不同，Rust引用永远不会为空，根本无法在安全的Rust 中生成空指针。与 C 不同，Rust 跟踪值的所有权和生命周期，因此在编译时排除了悬垂指针、重复释放等错误。
Rust 有两种形式的引用：&amp;T：可共享的，但不可变的引用，可以一次对给定值进行许多共享引用，但它们是只读的，不能修改它们指向的值，就像 C 中的 const T* 一样；&amp;mut T：可变的，但不可共享引用，可以读取和修改它指向的值，就像 C 中的 T* 一样。但只要该类型引用存在，就不会存在任何其他类型的该值引用；Rust的共享引用和可变引用其实就是多读单写，它可以由任何数量的 reader 共享，但 writer 始终只有一个，Rust 在编译时就会执行这种检查，也是 Rust 安全的核心。
 Boxes
在堆上申请内存的最简单方式是使用 Box::new：t 的类型是 (i32, &amp;str)，所以 b 的类型是 Box&lt;(i32, &amp;str)&gt;。Box::new 会在堆上申请最够多的内存以容纳 t。当 b 离开作用域时，它的内存会被理解回收，除非它被 move 到其他地方。
 原生指针
Rust 还具有原生指针类型*mut T和 *const T，原生指针就像 C++ 中的指针一样。使用原生指针不安全，因为Rust没有跟踪它指向的内容。例如，原生指针可能是空的，或者可能指向已释放或现在包含不同类型值的内存。
但是，只能在不安全的块中解引用原生指针，unsafe 代码块是Rust支持高级语言功能而加入的机制，其安全性由开发者保证。
 数组、Vector、slice
Rust有三种类型来表示内存中一个连续序列：[T; N]：表示N个值数组，每个值类型为T。数组的大小是在编译时确定的常量，是类型的一部分，无法在运行时变更数组大小；Vec&lt;T&gt;：称为T 的 vector，是 T 类型的动态分配、变长的值序列。vector的元素分配在堆上，因此可以通过增删元素调整vector大小；&amp;[T]、&amp;mut [T]：只读序列和可变序列，是对一系列元素的引用，这些元素是其他数组或者vector的一部分。可以将slice引用视为指向其第一个元素的指针，以及从该点开始可以访问的元素数量的计数。可变slice``&amp;mut [T]允许读取和修改元素，但无法共享；共享slice``&amp;[T]允许在多个reader之间共享访问权限，但不允许修改元素；给定这三种类型的值v，表达式v.len()给出了v中的元素数量，v[i]指的是v的第i个元素。第一个元素是v[0]，最后一个元素是v[v.len() - 1]。Rust 会检查 i 是否在这个范围内，不在就会panic。v 的长度可能是0，在这种情况下，任何索引尝试都会panic。i 必须是一个 usize 值，不能使用其他整数类型作为索引。
 数组
下面有几种不同的方式创建数组，最简单的是在方括号内写一系列值：如果要初始化一个 N 个 V 的数组，可以写作 [V; N]，例如，[true; 10000] 表示有 10000 个 true：由于Rust不会自动对内存进行初始化，因为不允许我们读未初始化的变量。所以如果我们想初始化一个缓冲池，可以像这样做：[0u8; 1024]。
数组的长度是其类型的一部分，在编译时是固定的。如果 n 是一个变量，则无法编写 [true; n] 来获取 n 个元素的数组。当需要一个长度在运行时有所不同的数组，请使用vector。
数组上看到的一些常用方法，例如，迭代、搜索、排序、填充、过滤等，其实都是作为slice上的方法提供的，而不是数组。但是，在搜索方法时，Rust 会隐式地将对数组的引用转换为slice，因此可以直接调用数组上的任何slice方法：在这里，排序方法实际上是在slice上定义的，但由于它需要引用做引参数，Rust 隐式生成一个引用整个数组的 &amp;mut [i32] slice,len 也类似。
 Vectors
Vec&lt;T&gt;是分配给堆上的T类型的大小可调整的数组。这里有几种创建 vector 的方式最简单的使用 vec! 宏，它给了一个特像创建数组字面量的方式；
vec![0; 100]，类似数组的初始化语法，将 vector 中的值都初始化相同的元素，vec! 宏类似于调用 Vec::new；
从迭代器创建；使用 collect时，通常需要提供该目的类型，因为它可以构建许多不同类型的集合，而不仅仅是vector。通过指定 v 的类型，我们明确了我们想要哪种集合。
和数组一样，可以在 vector 上使用slice方法，reverse 方法调用时会隐式转换为 &amp;mut [&amp;str] 类型：Vec 是 Rust 的基本类型，几乎在需要动态大小列表的地方都可以使用，因此还有许多其他方法来构建新 vector 或扩展现有 vector。Vec 实际上由三部分组成：指向堆内存的指针；
缓冲区的容量，最大能存储多少元素，超过就需要扩容，创建新的缓冲区，更改指针指向，复制当前所有的元素，释放旧的缓冲区；
当前实际存储的元素数量；vector扩容会导致程序性能下降，如果一开始就知道 vector 的大小，可以使用 Vec::with_capacity 创建指定大小的 vector，许多库函数使用Vec::with_capacity 创建新的 vector。len 方法返回了当前元素数量，capacity 返回 vector 的容量:最后打印的容量不能保证正好是4，但它至少是3，因为 vector 包含3个值。可以在 vector 中插入和删除元素，但这些操作会将受影响的所有元素向前或向后移动，因此如果 vector 很长，它们可能会变慢：可以使用 pop 方法删除最后一个元素并返回它。更准确地说，从Vec&lt;T&gt; 弹出一个值返回 Option&lt;T&gt;，因为如果vector已经为空，则返回 None，如果其最后一个元素是 v，则返回Some(v)：可以使用 for 循环迭代 vector：运行结果如下图:
~/WORKDIR/rust/mandelbrot ⌚ 10:10:03
$ cargo run Lisp Scheme C C++ Fortran
    Finished dev [unoptimized + debuginfo] target(s) in 0.00s
    Running `target/debug/mandelbrot Lisp Scheme C C++ Fortran`
Lisp, functional
Scheme, functional
C, imperative
C++, imperative
Fortran, imperative Slices
slice的类型是[T]，没有指定长度，是一个数组或者 vector 的一部分。由于slice可以是任何长度，slice不能直接存储在变量中或作为函数参数传递，参数或者变量的大小必须在编译时就能确定占用空间的大小，必须实现 Sized，因此slice总是通过引用传递。
slice的指针是一个胖指针，包含了两部分信息：指向的第一个元素地址和包含的元素数量。对于下面这两行代码，Rust 会自动转换 &amp;Vec&lt;f64&gt; 和 &amp;[f64; 4] 到 &amp;[f64]：内存分布图，可以展示为下面这样：普通指针是指向单个值，而 slice 是指向内存中一系列连续值。可以编写一个参数是slice的函数，这样既能处理数组，也能处理 vector：由于此函数将slice指针作为参数，因此可以将其应用于vector或数组，其实标准库中许多属于vector或数组的方法都是在slice上定义。例如，sort和reverse，实际上是slice类型[T]上的方法。
我们可以引用数组，vector或者已有slice的部分：与普通数组访问一样，Rust 检查索引是否有效。正常情况下，总是使用slice的指针，就像 &amp;[T] 或者 &amp;str。
 String
熟悉C++的程序员会记得有两种字符串类型，字符串字面量具有指针类型 const char *。标准库还提供了一个类 std::string，用于在运行时动态创建字符串Rust也有类似的设计。本节中，将展示编写字符串文字的所有方法，然后介绍Rust的两种字符串类型。
 字符串字面量
字符串文字以双引号括起来，可以使用转义符 \ 对特殊字符进行转义，字符串字面量中 &quot; 需要转义：字符串可以跨多行存在，该字符串文字中的换行符包含在字符串中，因此也包含在输出中。第二行开头的空格也是如此：如果字符串的一行以反斜杠 \ 结尾，则删除下一行的换行符和前缀空格：输出如下:
/Users/fudenglong/.cargo/bin/cargo run --color=always --package mandelbrot --bin mandelbrot
    Finished dev [unoptimized + debuginfo] target(s) in 0.00s
    Running `target/debug/mandelbrot`
It was a bright, cold day in April, and there were four of us—more or less.
It was a bright, cold day in April, and
        there were four of us—
        more or less.对于以 r 开头的原始字符串，其中的所有反斜杠和空格字符都逐字包含在字符串中，所以没法写转义字符：当然也有办法，例如，以 r###&quot;开始，和以 &quot;###结束。可以根据需要添加多个 # 符号： 字节序列
带有 b 前缀的字符串是一个字节字符串。这样的字符串是u8值（即字节）的slice，而不是Unicode文本：method 的类型是 &amp;[u8; 3]，是一个对拥有3个字节的数组的引用。他不能使用字符串的相关方法，只是看起来和字符串字面量比较像。
字节字符串可以使用我们展示的所有其他字符串语法：它们可以跨多行，使用转义序列，并使用反斜杠连接行。原始字节字符串以br开头。
字节字符串不能包含任意的Unicode字符，他们必须处理ASCII和\xHH转义序列。
 字符串内存表示
Rust字符串是Unicode字符的序列，但它们不会作为字符数组存储在内存中。相反，它们使用可变宽度编码UTF-8存储。字符串中的每个ASCII字符都存储在一个字节中，其他字符占用多个字节。
对于下面的示例：noodles：类型是 String，包含 Unicode 文本，拥有大小可变的缓冲区，能根据需要调整大小，在堆中分配内存；
oodles： 类型是 &amp;str，引用 UTF8 文本的一部分。在这里，它引用 noodles 的后6个字符。和其他的slice引用一样，&amp;str 是个胖指针，包含了第一个元素的地址和元素数量；
poodles：类型是 &amp;str，引用到预申请的文本，存储值只读内存中，也就是二进制文件的只读段中，poodles只是指向这段内存；它们的内存分布关系图如下：要注意的是 String 或者 &amp;str 的 len 方法返回的是字节的长度而不是字符的长度：改变 &amp;str 是不可能的：
错误示例如果要在运行时创建字符串，使用 String。类型 &amp;mut str 确实存在，但它不是很有用，因为UTF-8上的几乎任何操作都可以更改其整体字节长度，并且slice不能对它引用的值重新分配内存。事实上，&amp;mut str上唯一可用的操作是 make_ascii_uppercase 和 make_ascii_lowercase，根据定义，它们就地修改字符，只影响单个字节字符。
 String
&amp;str 非常像 &amp;[T]：指向数据的胖指针，String 类似于 Vec&lt;T&gt;。Vec&lt;T&gt;
&lt;String&gt;Automatically frees buffers
Yes
YesGrowable
Yes
Yes::new()and::with_capacity()type-associated functions
Yes
Yes.reserve() and .capacity() methods
Yes
Yes.push() and .pop() methods
Yes
YesRange syntaxv[start..stop]
Yes, returns &amp;[T]
Yes, returns &amp;str Automatic conversion
&amp;Vec&lt;T&gt; to &amp;[T]
&amp;String to &amp;str Inherits methods
From &amp;[T]
From &amp;str与Vec一样，每个字符串都有自己的堆内存缓冲区，不会与任何其他字符串共享。当字符串变量超出范围时，缓冲区会自动释放，除非字符串被移动。下面是几种创建 String 的方式：.to_string()：转换 &amp;str 为 String，转换时会复制字符串：format!()：格式化产生字符串，返回 String 类型的字符串字符串数组，slice或者 vector 有两个方法，.concat() 和 .join(sep) 产生新的 String： 字符串使用
字符串支持 ==，!=，&lt;，&lt;=，&gt; 以及 &gt;= 运算符等很多非常有用的方法，可以在这里 找到标准库中支持的方法。请记住，鉴于Unicode的性质，简单的逐个字符比较并不总是给出预期的答案。例如，Rust 字符串th\u&#123;e9&#125;和the\u&#123;301&#125; 都是 thé 的有效Unicode表示，thé 是法语单词tea。Unicode表示，它们应该以相同的方式显示和处理，但Rust将它们视为两个完全不同的字符串。同样，像&lt;这样的Rust的排序运算符使用基于字符代码点的简单词典顺序，这种排序有时只类似于用户语言和文化中用于文本的排序。
 其他 String
Rust保证字符串是有效的UTF-8。有时，程序真的需要能够处理无效的Unicode字符串。当Rust程序必须与其他不执行任何此类规则的系统互操作时，通常会发生这种情况。例如，在大多数操作系统中，很容易创建具有非Unicode文件名的文件。当Rust程序遇到这种文件名时，Rust的解决方案是为这些情况提供几种字符串类型：坚持使用String和&amp;str获取Unicode文本；
在处理文件名时，请使用std::path::PathBuf和&amp;Path；
在处理完二进制数据时，请使用Vec&lt;u8&gt;和&amp;[u8]；
在处理操作系统的环境变量名称和命令行参数时，请使用OsString和&amp;OsStr；
当与使用空终止字符串的C库互操作时，请使用std::ffi::CString和&amp;CStr； 类型别名
type 关键字可以像 C++ 中的 typedef 一样用于为现有类型声明新名称，我们在这里声明的字节类型是这种特殊 Vec 的缩写：
]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>《Rust 程序设计》</tag>
        <tag>基础类型</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】字符串和文本</title>
    <url>/2022/05/01/Rust/%E3%80%90Rust%E3%80%91%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%92%8C%E6%96%87%E6%9C%AC/</url>
    <content><![CDATA[Unicode 和 ASCII 匹配所有 ASCII 字符，从 0 到 0x7f。例如，都将字符 * 分配给码点 42。类似地，Unicode 将 0 到 0xff 分配给与 ISO/IEC 8859-1 字符集相同的字符，用于西欧语言的 8 位 ASCII 超集。Unicode 将此码点范围称为 Latin-1 代码块。
因为 Unicode 是 Latin-1 的超集，所以从 Latin-1 转换到 Unicode 是完全允许的：假设码点在 Latin-1 范围内，反向转换也很简单：Rust 中 String 和 str 类型都是使用 UTF-8 编码格式，它是一种变长编码，使用1到4个字节对字符进行编码。有效的 UTF-8 序列有两个限制。首先，对于任何给定码点，只有最短的编码被认为是有效的，也就是不能花费4个字节来编码一个适合3个字节的码点。 此规则确保给定代码点只有一个 UTF-8 编码。其次，有效的 UTF-8 不得编码为 0xd800 到 0xdfff 或超过 0x10ffff 的数字：这些数字要么保留用于非字符目的，要么完全超出 Unicode 的范围。 字符
Rust 中使用一个 32 位值存储 Unicode 码点，char 保证落在 0 到 0xd7ff 或 0xe000 到 0x10ffff 的范围内，所有用于创建和操作 char 值的方法都确保这个规则。char 类型实现了 Copy 和 Clone，以及用于比较、hash 和格式化的所有常用 Trait。
例如，通过 &amp;str 获得字符序列： 分类
下表是一些常用的字符类型的分类方法：下标是一些专门用于 ASCII 字符的方法：所有的 is_ascii_ 开头的方法在 u8 类型上都是可用：在使用这些函数来实现现有规范时要小心，因为分类可能不同。例如 is_whitespace 和 is_ascii_whitespace 在对某些字符的处理上有所不同：因为 is_ascii_whitespace 实现了 web 标准的空白字符，而 is_whitespace 实现了 Unicode 标准的字符。
 数字处理
下面是一些用于处理数字的方法：ch.to_digit(radix)：转换成 radix 进制数字，返回 Some(num)，num 是 u32 类型；std::char::from_digit(num, radix)：从数字转换成字符，返回 Some(ch)；ch.is_digit(radix)：判断字符是否是一个 ASCII 数字，等价于 ch.to_digit(radix) != None； 大小写转换ch.is_lowercase()、 ch.is_uppercase()：判断字符是否是一个小写或者大写字母；ch.to_lowercase()、ch.to_uppercase()：转换成小写或者大小可迭代字符序列，根据 Unicode 大小写转换算法；这些方法返回一个迭代器而不是单个字符，因为 Unicode 中不是一对一转换：为了方便，这些迭代器实现了 std::fmt::Display。 与数字之间的转换
使用 as 操作符可以将字符转换成整数，高位字节可能会被删除：u8 可以转换成 char，char 也实现了 From&lt;u8&gt;。但是更宽的字符可能代表无效的字符，所以必须使用 std::char::from_u32： String、str
Rust 的 String 和 str 类型保证只保存有效的 UTF-8。通过限制可以创建 String 和 str 值的方式以及可以对它们执行的操作来确保这一点，这样这些值在引入时有效并在使用它们时保持不变。他们所有的方法都保护了这一保证：对它们的任何安全操作都不会引入无效的 UTF-8，这简化了处理文本的代码。
Rust 将文本处理方法放置在 str 或 String 上，具体取决于该方法是否需要可调整大小的缓冲区或内容只是为了使用适当的文本。由于 String 解引用就是 &amp;str，因此在 str 上定义的每个方法也可以直接在 String 上使用。
String 被实现为 Vec&lt;u8&gt; 的包装器，以确保 vector 的内容总是有效的 UTF-8。
下表包含后续的解释中用到的词汇： 创建 StringString::new()：返回新的空字符串，没有堆内存申请；String::with_capacity(n)：返回新的，预申请 n 字节的字符串；str_slice.to_string()：重新申请一个新的 String，它的整个内容都是字符串切片，例如：&quot;literal text&quot;.to_string()；iter.collect()：通过连接迭代器 item 创建 String，例如：slice.to_owned()：Returns a copy of slice as a freshly allocated String. The str type cannot implement Clone: the trait would require clone on a &amp;str to return a str value, but str is unsized. However, &amp;str does implement ToOwned, which lets the implementer specify its owned equivalent. 简单操作
这些方法能获取字符串基本信息：slice.len()：字符串字节长度；slice.is_empty()：即 slice.len() == 0；slice[range]：返回给定部分的切片，有界和无界范围都可以，例如：不能通过括号单个索引字符，必须要先将字符串转换成 Unicode 字符序列，然后进行迭代：slice.split_at(i)：返回 (slice[..i], slice[i..]) 这样的 tuple；slice.is_char_boundary(i)：返回 true 如果 i 是一个字符的边界，这样他就可以作为 slice 的边界；自然地，可以比较切片的相等性、排序和散列。有序比较只是将字符串视为 Unicode 代码点序列，并按字典顺序比较它们。
 追加、插入string.push(ch)：插入单个字符 ch 到字符串；string.push_str(slice)：追加 slice 的全部内容；string.extend(iter)：将迭代器产生的所有 item 追加到 String，迭代器可以产生 char，str 或者 String，这些都被 String 实现：string.insert(i, ch)：插入一个单个的字符在 i 字节处，这会涉及字符串的向后移动；string.insert_str(i, slice)：在 i 字节处插入一个 slice；String 实现了 std::fmt::Write，这就意味着 write! 和 writeln! 可以被用来向 String 中追加格式化文本：因为 String 实现了 Add&lt;&amp;str&gt; 和 AddAssign&lt;&amp;str&gt;，所以你可以使用 + 和 +=：但是左操作数不能是 &amp;str，所以下面的写法是不可以的：而是应该这样写：但是，不鼓励从末尾向后构建字符串。字符串的行为方式与向量相同，当它需要更多容量时，它的缓冲区大小总是至少翻倍。这使重新复制开销与最终大小成正比。即便如此，使用  String::with_capacity 创建具有正确缓冲区大小的字符串可以完全避免调整大小，并且可以减少重新的内存分配。
 删除、替换
String 有一些删除文本的方法，这个不会影响字符串容量，如果需要可以使用  shrink_to_fit：string.clear()：重置 String 称为空的；string.truncate(n)：丢掉 n 字节后的所有字符如果原来的字符串就少于 n，不做任何操作；string.pop()：删除字符串中最后一个字符，返回 Option&lt;char&gt;；string.remove(i)：从 String 中删除 i 字节偏移的字符并且返回；string.drain(range)：删除指定范围的资费并且返回，后面的字符会前移：如果你仅仅是想去删除区间内的字符，可以立即丢掉返回的迭代器：string.replace_range(range, replacement)：用给定的替换字符串切片替换字符串中的给定范围。切片的长度不必与被替换的范围相同，但除非被替换的范围到达字符串的末尾，否则将需要移动范围末尾之后的所有字节： 搜索模式
当标准库函数需要搜索、匹配、拆分或修剪文本时，它接受几种不同的类型来表示要查找的内容：这些类型叫做 pattern，大多数操作都支持它们：标准库支持四种类型的模式：char 类型作为字符匹配的模式；String，&amp;str 或者 &amp;&amp;str 匹配等于它们表示的一个子串；FnMut(char) -&gt; bool 使用闭包匹配单个的字符；&amp;[char] 匹配任何出现在 char 列表中的字符，如果使用数组字面量，需要使用 as_ref 进行类型转换：而在库代码中，pattern 是任何实现了 std::str::pattern::Pattern 的类型，该类型目前还是实验性质，所以为避免引起兼容性问题，不要为自己的类型实现。
 搜索、替换
Rust 提供了几种方法用于slice模式搜索以及替换：slice.contains(pattern)：如果 slice 包含指定模式，返回 true；slice.starts_with(pattern), slice.ends_with(pattern)：slice 是否以某个 pattern 为前缀或者后缀；slice.find(pattern), slice.rfind(pattern)：返回 Some(i) 表示 slice 包含指定的模式，i 是偏移量，find 找到最后一个匹配的，而 rfind 找到最后一个匹配的：slice.replace(pattern, replacement)：替换所有匹配 pattern 子串：.replace() 在重叠匹配上的行为可能有点怪，在这里，模式&quot;aba&quot;有四个实例，但在替换第一个和第三个后，第二个和第四个不再匹配：slice.replacen(pattern, replacement, n)：和前者相同，但是至多替换 n 次； 文本迭代
标准库提供了几种迭代文本的方式，例如：大多数这些方法返回的迭代器是可反转的，也就是实现了 DoubleEndedIterator：slice.chars()：返回包含 slice 中所有字符的迭代器；slice.char_indices()：返回 slice 中所有字符的字节的偏移量；这个和 .chars().enumerate() 不等价。slice.bytes()：返回切片各个字节的迭代器：slice.lines()：以 \n 或者 \r\n 分割字符，返回一个 &amp;str 的迭代器；slice.split(pattern)：由匹配 pattern 的子串进行分割，如果模式是 &amp;str，返回的迭代器是不可反转的；slice.rsplit(pattern)：方法是相同的，只是从右至左扫描；slice.split_terminator(pattern), slice.rsplit_terminator(pattern)：模式被视为终止符，而不是分隔符，如果模式在切片的最后匹配，迭代器不会产生一个空切片，例如：slice.splitn(n, pattern), slice.rsplitn(n, pattern)：限定最左分割成 n 个 slice；slice.split_whitespace(), slice.split_ascii_whitespace()：通过 Unicode 定义的空格和 ASCII 空格来分割字符串：slice.matches(pattern)：返回切片中匹配 pattern 的迭代器，slice.rmatches(pattern) 是相同的，但从右往左迭代；slice.match_indices(pattern), slice.rmatch_indices(pattern)：返回 (offset, match) 对，offset 是匹配到的 match 开始字节偏移量； Trim
修剪字符串是从字符串的开头或结尾删除文本，通常是空格。slice.trim()：返回删除了前后空格的子串，slice.trim_start() 和 slice.trim_end() 仅删除前或后空格：slice.trim_matches(pattern)：删除 slice 前后匹配 pattern 的子串，trim_start_matches 和 trim_end_matches 仅作用于前面或者后面： 转换成其他类型
如果一个类型实现了 std::str::FromStr，那么它就提供了一个标准的方式可以从字符串生成它的值：所有常用的机器类型都实现了 FromStr：char 也实现了 FromStr，但是只针对哪些只包含一个字符的：std::net::IpAddr 也实现了 FromStr：字符串切片有一个 parse 方法，可以将切片解析为想要的任何类型，只要它实现了 FromStr，但是需要拼出所需的类型： 从其他类型转换
这有三种方式转换非文本值到字符串：对于实现了 std::fmt::Display 的类型，可以使用 format! 通过 &#123;&#125; 格式符来构建字符串：所有 Rust 的数字类型，字符以及字符串都实现了 Display，智能指针 Box&lt;T&gt;, Rc&lt;T&gt;, Arc&lt;T&gt; 在 T 实现 Display 时也会实现 Display，Vec 和 HashMap 没有实现 Display。如果一个类型实现了 Display，那么他就会自动实现 std::str::ToString，可以通过调用 .to_string() 达到目的：标准库里面的导出类型都实现了 std::fmt::Debug，可以通过 &#123;:?&#125; 格式声明生成字符串：对于任何实现了 Debug 的 T，Vec&lt;T&gt; 也实现了 Debug，所有 Rust 集合类型都有这样的实现。可以通过派生为自己的类型实现 Debug： 借用为其他类型切片和字符串实现 AsRef&lt;str&gt;、AsRef&lt;[u8]&gt;、AsRef&lt;Path&gt; 和 AsRef&lt;OsStr&gt;。许多标准库函数使用这些Trait作为其参数类型的界限，因此可以直接将切片和字符串传递给它们，即使它们真正想要的是其他类型，详细请查看 AsRef、AsMut；slice 和字符串也实现了 std::borrow::Borrow&lt;str&gt;，HashMap 和 BTreeMap 使用 Borrow 使 String 可以很好地作为表中的键工作，详细请查看 Borrow、BorrowMut。 转化为字节序列slice.as_bytes()：将 slice 转换为 &amp;[u8]，由于这不是一个可变引用，所以 slice 可以假设它的字节将保持有效的 UTF-8。string.into_bytes()：获取 String 的所有权，并且转换为 Vec&lt;u8&gt;，这是一种廉价的转换，因为它只是将字符串一直用作其缓冲区的 Vec&lt;u8&gt; 交出。由于字符串不再存在，因此无法再确保是正确的 UTF-8 编码，调用者可以随意修改 Vec&lt;u8&gt;。 从字节序列生成
这里有一些方法从字节序列转换成 String 或者 slice，取决于你如何处理错误：str::from_utf8(byte_slice)：以 &amp;[u8] 作为输入，返回 Result，如果正确将生成 Ok(&amp;str)；String::from_utf8(vec)：尝试去构建字符串从 Vec&lt;u8&gt;，如果转化成功，返回 Ok(String)，并且将 Vec 中缓冲区的所有权转移至 String，以至于没有额外的内存申请。如果转换失败，返回 Err(e)，e 的类型是 FromUtf8Error，可以调用 e.into_bytes() 获得原 vec 的所有权：String::from_utf8_lossy(byte_slice)：尝试从 &amp;[u8] 共享字节片构造字符串或 &amp;str。此转换始终成功，将任何无效的 UTF-8 替换为 Unicode 替换字符。返回值是一个 Cow&lt;str&gt;，如果它包含有效的 UTF-8，则直接从 byte_slice 借用 &amp;str，或者拥有一个新分配的字符串，其中替换字符替换了无效的字节。 因此，当 byte_slice 有效时，不会发生堆分配或复制。String::from_utf8_unchecked：如果知道 Vec&lt;u8&gt; 包含有效的 UTF-8，那么可以调用 unsafe 函数。这只是将 Vec&lt;u8&gt; 包装为一个字符串并返回它，根本不检查字节，开发者有责任确保你没有将无效的 UTF-8 引入系统，这就是为什么这个函数被标记为不安全的原因。str::from_utf8_unchecked：类似地，这需要一个 &amp;[u8] 并将其作为 &amp;str 返回，而不检查它是否包含有效的 UTF-8。 延迟分配
来看一个示例：这个函数要求返回一个 String，但是实际上它应该返回一个 String 或一个静态文本，我们没必要为静态文本 &amp;'static str 再次分配内存把它转换成 String 返回。这个时候应该使用 std::borrow::Cow，Cow&lt;'a, T&gt; 是一个有两种变体的枚举：Owned 和 Borrowed。 Borrowed 持有引用 &amp;'a T，Owned 能将持有的 &amp;str 转换为 String，&amp;[i32] 转换为 Vec&lt;i32&gt;，依此类推。无论是 Owned 还是 Borrowed，Cow&lt;'a, T&gt; 总能产生一个 &amp;T 供你使用。事实上，Cow&lt;'a, T&gt; 解引用 &amp;T 很像智能指针。由于 Cow 经常用于字符串，标准库对 Cow&lt;'a, str&gt; 有一些特殊的支持。它提供了来自 String 和 &amp;str 的 From 和 Into 转换，因此可以更简洁地编写 get_name：Cow 也实现了 Add&lt;&amp;'a str&gt;，Add&lt;Cow&lt;'a str&gt;&gt;，AddAsign&lt;&amp;'a str&gt;以及AddAssign&lt;Cow&lt;'a, str&gt;&gt; 所以可以使用 + 和 += 运算符： 实现 Default
String 是下了 std::default::Default 和 std::iter::Extend：返回空的字符串，以及追加字符，&amp;[str]，Cow&lt;.., str&gt;或者其他字符串。这与 Rust 的其他集合类型（如 Vec 和 HashMap）实现的特征组合相同，用于通用构造模式（如 collect 和 partition）。
&amp;str 也实现了 Default，返回空切片。
 格式化
Rust 的格式化工具被设计为开放式的。 可以通过实现 std::fmt 模块的格式化特征来扩展这些宏以支持自己的类型。可以使用 format_args！ 宏和 std::fmt::Arguments 类型以使自己的函数和宏支持格式化语言。
格式化宏总是借用对其参数的共享引用，他们从不获取所有权或改变它们。
&#123;...&#125; 叫做格式化参数，形式是：&#123;which:how&#125;，which 和 how 都可以省略，&#123;&#125; 是我们常用的格式。
which 用于指定应该使用模板后面的哪个参数，格式化参数中没有 &#123;&#125; 就会简单的从左到右按序取。
how 用来表示参数如何被格式化，填充多少、精度、数字基数等等。 如果 how 存在，则它前面的:是必需的。
下面是一些常用的例子： 文本格式化
对于 String 或者 &amp;str 类型，how 参数的值有几个部分，都是可选的：文本长度限制。如果声明，超过这个长度的文本就会被截断；最小字段宽度。在任何截断之后，如果你的参数比这个短，Rust 会在右边（默认）用空格（默认）填充它，以形成这个宽度的字段。如果省略，Rust 不会填充；对齐方式。可以通过 &lt; ^ &gt; 声明位左对齐，中对齐，右对齐；填充字符，如果省略，会自动使用空格；如果声明填充字符，必须声明对齐方式；文本格式化示例：Rust 的格式化程序假设每个字符占据一列，而不考虑组合字符、全角半角、零宽度空格或 Unicode 的其他现实。例如：尽管 Unicode 说这些字符串都等价于 thé，但 Rust 的格式化程序并不知道像 \u&#123;301&#125; 这样的字符，结合了重音符号需要特殊处理。 它正确地填充了第一个字符串，但假定第二个字符串是四列宽并且不添加任何填充。尽管很容易看出 Rust 在这种特定情况下如何改进，但所有 Unicode 脚本的真正多语言文本格式化是一项艰巨的任务，最好依靠平台的用户界面工具包来处理。有一个流行的包 unicode-width，可以处理这方面的某些方面。
就像 &amp;str 和 String，还可以传递带有文本引用的格式化宏智能指针类型，例如 Rc&lt;String&gt; 或 Cow&lt;'a, str&gt;。
由于文件名路径不一定是有效的 UTF-8，std::path::Path 不是一个文本类型；不能将 std::path::Path 直接传递给格式化宏。但是，Path 的 display 方法返回一个值，可以以适合平台的方式格式化它： 数值格式化
Rust 提供了用于格式化数字的方式：类似于文本的填充和对齐方式；
+ 显示有数值的正负号；
# 要求显示的前缀 0x、0b 或者 0o；
0 要求通过在数字中包含前导0来满足最小字段宽度，而不是通常的填充方法；
最小字段宽度。如果格式化后的数字至少没有这么宽，Rust 在左边（默认）用空格（默认）填充它，以形成一个给定宽度的字段；
浮点参数的精度，指示 Rust 应该在小数点后包含多少位。Rust 会根据需要进行四舍五入或零扩展，以准确生成这么多小数位数。如果省略了精度，Rust 会尝试使用尽可能少的数字来准确地表示该值，对于整数类型的参数，精度被忽略；
一个符号。对于整数类型，这可以是 b 表示二进制，o 表示八进制，或者 x 或 X 表示带有小写或大写字母的十六进制。如果包含 # 字符，则这些字符包括显式的 Rust 样式基数前缀、0b、0o、0x 或 0X。对于浮点类型，e 或 E 的基数要求科学记数法，具有归一化系数，使用 e 或 E 作为指数。如果你不指定任何符号，Rust 会以十进制格式格式化数字；下面是一些数字格式化的例子，示例 1234_i32：如最后两个示例所示，最小字段宽度适用于整个数字、符号、基数前缀等。负数总是包括它们的符号。 结果与“强制符号”示例中显示的结果类似。当要求前导零时，对齐和填充字符将被忽略，因为零会扩展数字以填充整个字段。
下面以 1234.5678 为例，演示浮点数格式化： 格式化其他类型
除了数字和字符串之外，你还可以格式化下面几种标注库类型：错误类型都可以直接格式化，便于将它们包含在错误消息中。每个错误类型都应该实现 std::error::Error，它扩展了默认的格式化std::fmt::Display。因此，任何实现 Error 的类型都可以格式化；可以格式化互联网协议地址类型，例如 std::net::IpAddr 和 std::net::SocketAddr；true 和 false 可以格式化，尽管这些通常不是直接呈现给最终用户的最佳字符串； 用于调试的格式化
为了帮助调试和记录，&#123;:?&#125; 参数以对程序员有帮助的方式格式化 Rust 标准库中的任何公共类型。可以使用它来调试 vector、切片、元组、哈希表、线程和数百种其他类型。
例如，你可这样写：这将输出：
&#123;&quot;Taipei&quot;: (25.0375167, 121.5637), &quot;Portland&quot;: (45.5237606, -122.6819273)&#125;可以使用 &#123;:#?&#125; 以更适合阅读的方式打印：
&#123;
    &quot;Taipei&quot;: (
        25.0375167,
        121.5637,
    ),
    &quot;Portland&quot;: (
        45.5237606,
        -122.6819273,
    ),
&#125;调试格式通常以十进制打印数字，但可以在问号前放置一个 x 或 X 来请求十六进制。前导0和字段宽度语法也可以接受。例如，可以编写：这将输出：
ordinary: [09, 15, 240]
hex: [09, 0f, f0]可以通过 #[derive(Debug)] 让自己的类型支持 &#123;:?&#125;：例如：这将输出：
Complex &#123; re: -0.5, im: 0.8660254037844386 &#125; 格式化指针
通常，如果将任何类型的指针传递给格式化宏——引用、Box、Rc——宏只会格式化引用的对象，指针本身并不重要。但是在调试时，有时查看指针会很有帮助：地址可以作为单个值的粗略“名称”，这在检查具有循环或共享的结构时会很有启发性。
&#123;:p&#125; 将引用和智能指针格式化为地址：这可能输出：
text: mazurka, mazurka, mazurka
pointers: 0x6000024ac2b0, 0x6000024ac2b0, 0x6000024ac2e0从结果可以看出 original 和 cloned 具有相同的地址，这也符合 Rc 的定义。
 通过索引或者名称引用参数
可以简单的通过索引来指定格式化参数使用哪个值，也就是指定开始所说的 which：也可以通过名称选择参数，有点像Python的关键字参数，例如：可以将命名参数，位置参数，索引参数混合起来使用，只是命名参数必须出现在最后。位置参数与参数从左到右配对，就好像索引和命名参数不存在一样： 动态宽度和精度
之前我们看到的宽度和精度都是固定值，也可以在运行时确定：1$ 告诉 format! 使用第二个参数作为宽度，宽度的类型必须是 usize，也可以使用命名参数：相同的方式处理文本长度限制：在文本长度或者浮点参数的位置，你还可以写 *，来使用下一个位置参数作为精度。例如：这将输出：
hello worl
hello worl 格式化自定义类型
格式化宏实际上是 std::fmt 中定义的一系列宏，可以通过自己实现这些特征中的一个或多个来使 Rust 的格式化宏格式化自己的类型。用于格式化的 Trait 都有相同的结构，仅仅是名字不同，以 std::fmt::Display 为例：fmt 方法的工作是生成有效的 self 表示并将其字符写入 dest。 除了作为输出流之外，dest 参数还携带从格式参数解析的详细信息，例如对齐方式和最小字段宽度。
下面是一个完整的实现用于 Complex 格式化输出：如果格式化参数中携带 #，我们以极坐标的形式显示负数，否则我们按照常规的方式展示。虽然 fmt 返回 Result，但是我们通常不用处理错误，只需向上传递，Formatter 还有很多其他有用的方法，alternate 只是其中一个。
 format_args!
可以使用 Rust 的 format_args 编写自己的函数和宏来接受类型为 std::fmt::Arguments 的参数。例如，假设程序需要在运行时记录状态消息，并且想使用 Rust 的文本格式化语言来生成它们，例如：在编译时，format_args! 宏解析模板字符串并根据参数类型检查它，如果有任何问题则报告错误。在运行时，它计算参数值并构建一个 Arguments ，其中包含格式化文本所需的所有信息：模板的预解析形式，以及对参数值的共享引用。
构造一个 Arguments 没有什么消耗：它只是收集一些指针，还没有进行格式化工作。这很重要：如果未启用日志记录，则将数字转换为十进制、填充值等所花费的任何时间都将被浪费。
File 类型实现了 std::io::Write 特征，其 write_fmt 方法接受 Argument 并进行格式化，它将结果写入底层流。
 正则表达式
regex 是 Rust 的官方正则表达式库，它提供通常的搜索和匹配功能。它对 Unicode 有很好的支持，但它也可以搜索字节字符串，尽管它不支持在其他正则表达式包中经常发现的某些功能，例如反向引用和环视模式，但这些简化允许正则表达式确保搜索时间与表达式的大小和正在搜索的文本长度呈线性关系。除其他外，这些保证使正则表达式可以安全使用，即使是在搜索不可信文本的不可信表达式中也是如此。
尽管 regex 不在 std 中，但它由 Rust 库团队维护。要使用正则表达式，请将以下行放在Cargo.toml 文件的 [dependencies] 部分中： 基本使用
Regex 值表示已解析的正则表达式可供使用。Regex::new 构造函数尝试将 &amp;str 解析为正则表达式，并返回一个结果：Regex::captures 方法在字符串中搜索第一个匹配项，并返回一个 regex::Captures 值，其中包含表达式中每个组的匹配信息：使用索引可能会发生 panic，可以使用 Captures::get，它返回一个 Option&lt;regex::Match&gt;，Match 包含了的那个的组匹配：find_iter 为文本中每个连续的非重叠匹配返回一个迭代器，返回相对于文本的开始和结束字节索引。例如：captures_iter 产生的 Captures 包含所有匹配组：这将输出：
28 -&gt; 33, 1.0.0
56 -&gt; 66, 1.0.1-beta
98 -&gt; 103, 1.2.4 懒惰构建 Regex
Regex::new 构造函数可能很昂贵：为 1,200 个字符的正则表达式构造 Regex 即使在快速机器上也需要一毫秒，即使是很小的表达式也需要数微秒，因此，最好将 Regex 构造排除在繁重的计算循环之外，而是应该构建一次正则表达式，然后重用同一个。
lazy_static 提供了一种比较好的方式用于延迟初始化静态值，这些值只有在第一次使用时才会被初始化，在 Cargo.toml 添加如下依赖：示例代码：该宏为一个名为 SEMVER 的静态变量的声明，但它的类型不完全是 Regex。 相反，它是实现 Deref&lt;Target=Regex&gt; 的宏生成类型，因此公开了与 Regex 相同的所有方法。第一次解引用 SEMVER 时会进行初始化，并保存该值以供以后使用。由于 SEMVER 是一个静态变量，而不仅仅是一个局部变量，因此初始化程序在每次程序执行时最多运行一次。
 Normalization
大多数用户会认为茶的法语单词 thé 是三个字符长。然而，Unicode 实际上有两种方式来表示这个文本：在composed形式中，thé 包含三个字符 t、h 和 é，其中 é 是单个 Unicode 字符，代码点为 0xe9。在decomposed形式中，thé 包含四个字符 t、h、e 和 \u&#123;301&#125;，其中 e 是纯 ASCII 字符，没有重音符号，代码点 0x301 是“组合重音符号”字符，它为它后面的任何字符添加一个尖锐的重音。Unicode 不认为 é 的组合形式或分解形式是“正确的”形式；相反，它认为它们都是相同抽象字符的等效表示。Unicode 表示两种表单都应该以相同的方式显示，并且允许使用文本输入法生成任何一种，因此用户通常不会知道他们正在查看或输入哪种表单。（Rust 允许直接在字符串文字中使用 Unicode 字符，因此如果不在乎获得哪种编码，可以简单地编写 thé。为了清楚起见，我们将使用 \u 转义。）
然而，考虑到 Rust 中 &amp;str 或 String 值，“th\u&#123;e9&#125;”和“the\u&#123;301&#125;”是完全不同的。它们有不同的长度，比较不相等，有不同的哈希值，并且相对于其他字符串有不同的顺序：显然，如果打算比较用户提供的文本或将其用作哈希表或 Btree 中的键，则需要首先将每个字符串放在某种规范形式中。
幸运的是，Unicode 指定了字符串的规范化形式。每当根据 Unicode 规则将两个字符串视为等效时，它们的规范化形式是逐字符相同的。当使用 UTF-8 编码时，它们是逐字节相同的。这意味着可以将规范化的字符串与 == 进行比较，将它们用作 HashMap 或 HashSet 中的键等。
未能规范化甚至会产生安全后果，例如，如果网站在某些情况下对用户名进行了规范化，但在其他情况下没有规范化用户名，最终可能会得到两个不同的用户，名为 bananasflambé，代码的某些部分将其视为同一个用户，但其他部分将其区别开来，从而导致一个人的权限被错误地扩展到另一个。当然，有很多方法可以避免此类问题，但历史表明也有很多方法可以避免。
 Normalization Forms
Unicode 定义了四种规范化形式，每一种都适用于不同的用途。 有两个问题需要回答：首先，更喜欢字符是尽可能组合还是尽可能分开？例如，越南语单词 Phở 的 composed 形式是三个字符串&quot;Ph\u&#123;1edf&#125;&quot;，其中声调符号̉和元音符号̛都应用于单个字符的基本字符&quot;o&quot;，Unicode 负责将拉丁小写字母 o 命名为上面带有角和钩的字符。
decomposed 形式将基本字母及其两个标记拆分为三个单独的 Unicode 字符：o、\u&#123;31b&#125;和 \u&#123;309&#125;，从而产生 Pho\u&#123;31b&#125;\u&#123;309&#125;。组合形式通常兼容性问题较少，因为它与大多数语言在 Unicode 建立之前用于其文本的表示形式更加匹配。它还可以很好地与 Rust 的 format! 工作。另一方面，decomposed 形式可能更适合显示文本或搜索，因为它使文本的详细结构更加明确。第二个问题是：如果两个字符序列表示相同的基本文本，但文本格式的方式不同，你想将它们视为等价还是保持不同？
Unicode 对普通数字 5、上标数字 ⁵（或 \u&#123;2075&#125;）和带圆圈的数字 ⑤（或\u&#123;2464&#125;）有单独的字符，但声明所有这三个是兼容性等价的。类似地，Unicode 有一个用于连字的单个字符 \u&#123;fb03&#125;，但声明它与三个字符序列 ffi 等效。
兼容性等价对搜索有意义：仅使用 ASCII 字符搜索&quot;difficult&quot;，应该匹配字符串&quot;di\u&#123;fb03&#125;cult&quot;。对后一个字符串应用兼容性分解会将连字替换为三个纯字母“ffi”，从而使搜索更容易。但是将文本规范化为兼容性等效形式可能会丢失基本信息，因此不应粗心地应用它。例如，在大多数情况下将2⁵存储为25是不正确的。Unicode 规范化形式 NFC 和规范化形式 NFD 使用每个字符的最大组合和最大分解形式，但不尝试统一兼容性等效序列。而NFKC 和 NFKD 规范化形式类似于 NFC 和 NFD，但将所有兼容性等价序列规范化为它们类的一些简单代表。
万维网联盟的建议对所有内容使用 NFC。 Unicode 标识符和模式语法建议在编程语言中使用 NFKC 作为标识符，并提供必要时调整格式的原则。
 unicode-normalization
Rust 的 unicode-normalization 提供了一个 trait，它向 &amp;str 添加方法以将文本置于四种规范化形式中的任何一种。要使用它，将以下行添加到 Cargo.toml 文件的 [dependencies] 部分：有了这个声明，&amp;str 有四个新方法，它们返回对特定规范化字符串形式的迭代器：Taking a normalized string and normalizing it again in the same form is guaranteed to return identical text.
Although any substring of a normalized string is itself normalized, the concatenation of two normalized strings is not necessarily normalized: for example, the second string might start with combining characters that should be placed before combining characters at the end of the first string.
As long as a text uses no unassigned code points when it is normalized, Unicode promises that its normalized form will not change in future versions of the standard. This means that normalized forms are generally safe to use in persistent storage, even as the Unicode standard evolves.
]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>《Rust 程序设计》</tag>
        <tag>String 和文本</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】宏</title>
    <url>/2022/05/04/Rust/%E3%80%90Rust%E3%80%91%E5%AE%8F/</url>
    <content><![CDATA[Rust 语言支持宏，如我们之前使用的 assert_eq!，println! 等。宏做了函数不能做的一些事情，例如，assert_eq! 当一个断言失败时，assert_eq! 生成包含断言的文件名和行号的错误消息，普通函数无法获取这些信息，但宏可以，因为它们的工作方式完全不同。
宏是一种简写，在编译期间，在检查类型和生成任何机器代码之前，每个宏调用都会被扩展。也就是说，它被一些 Rust 代码替换。assert_eq! 调用扩展为大致如下：panic! 也是一个宏，它本身扩展为更多的 Rust 代码。该代码使用到了另外两个宏：file!() 和 line!()。 一旦 crate 中的每个宏调用都被完全展开，Rust 就会进入下一个编译阶段。
在运行时，断言失败看起来像这样：
thread 'main' panicked at 'assertion failed: `(left == right)`, (left: `17`, right: `2`)', gcd.rs:7如果熟悉 C++，可能对宏有过一些不好的体验。但是 Rust 宏采用不同的方法，类似于 Scheme 的语法规则。与 C++ 宏相比，Rust 宏可以更好地与语言的其余部分集成，因此更不容易出错。宏调用总是标有感叹号 !，因此在阅读代码时它们会比较突出，所以不会意外调用它们。Rust 宏从不插入不匹配的括号或圆括号，并且 Rust 宏带有模式匹配，使得编写既可维护又易于使用的宏变得更加容易。
在本节中，我们将通过几个简单的例子来展示如何编写宏。但与 Rust 的大部分内容一样，理解宏需要下很大功夫。在这里将介绍一个很复杂的宏的设计，它可以将 JSON 文字直接嵌入到我们的程序中。但是宏的内容涵盖的非常多，因此这里将提供一些进一步研究的建议，包括我们在此处展示的高级技术，以及称为过程宏的更强大的工具。 宏基础
首先我们来看下 assert_eq! 的代码：macro_rules! 是在 Rust 中定义宏的主要方式。在此宏定义中的 assert_eq 之后没有!，! 仅在调用宏时，而不是在定义时。
并非所有的宏都以这种方式定义：如 file!、line! 和 macro_rules！ 它本身是内置在编译器中的，我们将在本章末尾讨论另一种方法，称为过程宏。但在大多数情况下，我们将专注于 macro_rules!，这是迄今为止自己编写宏最简单的方法。
用 macro_rules! 定义的宏完全通过模式匹配工作。宏的主体只是一系列规则：
( pattern1 ) =&gt; ( template1 );
( pattern2 ) =&gt; ( template2 );
...顺便说一句，可以使用方括号或花括号代替模板周围的圆括号；这对 Rust 没有任何影响。同样，当调用宏时，这些都是等价的：唯一的区别是花括号后面的分号通常是可选的。按照惯例，我们在调用 assert_eq! 时使用括号，为 vec! 使用方括号，为 macro_rules! 使用花括号。
现在我们已经展示了一个宏扩展的简单示例和生成它的定义，我们可以深入了解使其工作所需的细节：我们将准确解释 Rust 如何在程序中查找和扩展宏定义；我们将指出从宏模板生成代码的过程中固有的一些微妙之处；最后，我们将展示模式如何处理重复结构； 宏扩展
Rust 在编译前期就会将宏展开，编译器从头到尾读取源代码，将定义的宏进行展开，所以不能在定义之前使用宏。（相比之下，函数和其他项不必按任何特定顺序排列，可以调用直到稍后在 crate 中才定义的函数。）
当 Rust 展开一个 assert_eq 宏调用时，发生的事情很像计算匹配表达式。Rust 首先将参数与模式匹配，如下图所示：宏模式是 Rust 中的一种小型语言，它们本质上是用于匹配代码的正则表达式。但正则表达式是对字符进行操作，而模式则是对 token 进行操作–数字、名字、标点符号等等，这些都是Rust程序的组成部分。这意味着你可以在宏模式中自由地使用注释和空白，以使它们尽可能地可读。注释和空白不是标记，所以它们不会影响匹配。
正则表达式和宏模式之间的另一个重要区别是，在 Rust 中，小括号、大括号和圆括号总是以匹配对的形式出现。不仅在宏模式中，而且在整个语言中，在展开宏之前都会检查这些。
在这个例子中，我们的模式包含了 $left:expr 这个片段，它告诉 Rust 匹配一个表达式（在这个例子中，gcd(6, 10)）并将其命名为$left。然后 Rust 将模式中的逗号与 gcd 的参数后面的逗号进行匹配。就像正则表达式一样，模式中只有几个特殊的字符可以触发有趣的匹配行为，比如这个逗号，都必须逐字匹配，否则匹配失败。最后，Rust 匹配了表达式 2，并给它命名 $right。
这个模式中的两个代码片段都是 expr 类型的：期望匹配表达式。由于这个模式匹配了所有的参数，Rust 展开了相应的模板，如下图所示：Rust 将 $left 和 $right 替换成它在匹配过程中发现的代码片段。
在输出模板中包含片段类型是一个常见的错误：写$left:expr而不是只写$left。Rust不会立即发现这种错误。它把$left看作是一个替换，然后它把:expr和模板中的其他东西一样看待：要包含在宏的输出代码中的token。因此，在你调用宏之前，这些错误不会发生；然后它将产生假的输出，无法编译。如果你得到错误信息，如在这个范围内找不到expr类型： help: maybe you meant to use a path separator here。
宏模板与网络编程中常用的十几种模板语言并无太大区别。唯一不同的是，它的输出是 Rust 代码，这一点很重要。
 意外后果
将代码片段插入模板，与使用数值的常规代码有微妙的不同,这些差异起初并不总是很明显。我们一直在看的宏，assert_eq!，包含了一些略显奇怪的代码片段，其中的原因说明了宏编程的很多问题，让我们特别看看两个有趣的部分。
首先，为什么这个宏要创建变量 left_val 和 right_val，下面这样写为何不可以？要回答这个问题，请尝试在头脑中展开宏调用 assert_eq!(letters.pop(), Some('z'))。输出会是什么？当然，Rust 会把匹配的表达式插入到模板的多个地方。不过，在构建错误信息时重新计算这些表达式似乎是个坏主意，这不仅仅是因为它会花费两倍的时间：因为 letters.pop() 会从一个向量中移除一个值，所以在我们第二次调用时它会产生一个不同的值，这就是为什么真正的宏只计算一次$left和$right并存储它们的值。
接下来是第二个问题：为什么这个宏要借用 $left 和 $right 的值的引用，为什么不直接在变量中存储这些值，像这样？对于我们所考虑的特殊情况，即宏的参数是整数，这可以正常工作。但是，如果调用者将一个字符串变量作为 $left 或 $right 来传递，这段代码就会将该变量的值移出：因为我们不希望断言移动数值，所以这个宏借用了引用来代替，看一个个经典的 C++ 宏错误：大多数 C++ 程序员很熟悉这个原因，像 ADD_ONE(1)*10 或 ADD_ONE(1&lt;&lt;4) 这样不起眼的代码在这个宏下会产生非常意想不到的结果。要解决这个问题，需要在宏定义中加入更多的括号。这在 Rust 中是没有必要的，因为 Rust 的宏与语言的集成度更高。Rust 知道它是如何处理表达式的，所以当它把一个表达式粘贴到另一个表达式上时，它就会自动添加有效的括号。
 重复
标准的 vec! 有两种使用方式：它可以被像下面这样实现：这里有 3 个规则，我们将解释多个规则如何工作，然后挨着解释。
当 Rust 展开宏 vec![1, 2, 3]，它首先使用第一个规则匹配 1, 2, 3。但是第一条规则中的 $elem:expr ; $n:expr 匹配失败，1 是一个表达式，但是要求其之后应该是一个 ;，这里没有。所以 Rust 开始尝试第二条规则，如果所有规则尝试之后都没有匹配，就会报错。
第一条规则处理像 vec![0u8; 1000] 这样的用法。碰巧的是，有一个标准的碰巧有一个标准的函数，std::vec::from_elem，它正好做了这里所需要的事情，所以这条规则很简单。
第二条规则处理像 vec![&quot;udon&quot;, &quot;ramen&quot;, &quot;soba&quot;] 这样的用法，规则 $( $x:expr ),* 匹配 0 个或者多个有 , 分割的表达式。更一般地说，语法$( PATTERN ),* 用于匹配任何逗号分隔的列表，其中列表中的每一项都与 PATTERN 匹配。
* 是一个重复符号，类似于正则表达式中，表示重复 0 个或者多个，而 + 相同，只是只是重复 1 个或者多个。
下面是 Rust 支持的重复规则：示例中的 $x 不是一个单个的表达式，而是一个表达式列表，这个规则的模板也使用了重复的语法：这里也有标准的方法能够确切完成我们想要的工作，这里的代码创建了一个 boxed 数组，然后使用 [T]::into_vec 转换成一个 vector。第一点，&lt;[_]&gt;，是一种不寻常的写法，用来写 “某类型的切片” 类型，同时希望Rust能推断出元素的类型。普通标识符类型名称可以被用在表达式中，但是 fn()，&amp;str或者 [_] 必须由尖括号 &lt;&gt; 包裹。
重复出现在模板的最后，我们有 $($x),*，这个 $(...),* 与我们在模式中看到的语法相同。它遍历了我们为 $x 匹配的表达式列表，并将它们全部插入到模板中，用逗号分隔。
在这种情况下，重复输出看起来就像输入一样，但情况不一定是这样的，我们可以把规则写成这样。这里，模板中读取 $( v.push($x); )* 的部分为 $x 中的每个表达式插入了对 v.push() 的调用。一个宏匹配规则可以扩展到一连串的表达式，但这里我们只需要一个表达式，所以我们把 vector 的组装包在一个块中。
与 Rust 的其他部分不同，使用 $( ...),* 的模式不会自动支持可选的尾部逗号。然而，有一个标准的技巧来支持尾部逗号，那就是添加一个额外的规则，这就是我们的vec！宏的第三条规则的作用。我们使用 $( ...),+ , 来匹配一个带有额外逗号的列表。然后，在模板中，我们递归地调用 vec!，把多余的逗号留出来。这一次，第二条规则将被匹配。
 内建宏
Rust 编译器提供了几个宏，当定义自己的宏时，这些宏很有帮助。这些都不能单独使用 macro_rules! 来实，它们在 rustc 中是硬编码的。file!()、line!()、column!()：file!() 展开成一个字符串字面量，表示当前文件的名称；line!() 和 column!() 扩展成 u32 字面量表示当前的行号和列号；
如果一个宏调用另一个宏，而另一个宏又调用另一个宏，而且都在不同的文件中，最后一个宏调用 file!()、line!() 或 column!()，它将展开以指示第一个宏调用的位置。stringify!(...tokens...)：展开成一个包含给定标识的字符串字面量，assert! 宏使用它来生成一个错误信息，其中包括断言的代码。
参数中的宏调用不会被扩展：stringify!(line!()) 会扩展为字符串 &quot;line!()&quot;。 Rust 从标示中构造字符串，所以字符串中没有换行或注释。concat!(str0, str1, ...)：将它的参数连接起来，展开成一个字符串；Rust 还定义了一些查询环境变量的宏：cfg!(...)：展开为一个布尔值，如果当前的编译配置符合括号中的条件，则为真。例如，如果你在编译时启用了调试断言，cfg!(debug_assertions) 则为真。
这个宏支持的语法与 #[cfg(...)] 属性完全相同，但你得到的不是条件性编译，而是一个真或假的值。env!(&quot;VAR_NAME&quot;)：展开成一个字符串：在编译时指定的环境变量的值，如果这个变量不存在，就是一个编译错误。
除了 Cargo 在编译时设置了几个有趣的环境变量外，这将是相当无用的。例如，要获得 crate 的当前版本字符串，可以这样写。环境变量的完整列表可以看 Cargo Documentation。option_env!(&quot;VAR_NAME&quot;)：和 env! 大致相同，除了返回  Option&lt;&amp;'static str&gt;，所以如果设置的环境变量不存在，将返回 None；这里还有三个内建的宏可以将代码或者数据从另外的文件中包含进来：include!(&quot;file.rs&quot;)：展开成指定文件的内容，必须是有效的 Rust 代码；include_str!(&quot;file.txt&quot;)：展开成指定文件的静态文本，类型是 &amp;'static str，可以这样使用：如果文件不存在或者不是有效的 utf-8，就会有编译错误。include_bytes!(&quot;file.dat&quot;)：这是和之前的相同的，只是被当做二进制数据，不是 UTF-8 文本，结果是 &amp;'static [u8]；像所有的宏一样，这些都在编译时间处理，如果文件不存在那就编译失败，在所有的例子中，文件名称是一个相对路径，相对当前文件进行解析。
Rust 还提供了几个我们之前没有介绍过的方便的宏：todo!()、unimplemented!()：这些与 panic!() 等价，但表达了不同的意图。unimplemented!() 出现在 if 子句、匹配分支和其他尚未处理的情况中。todo!() 也是如此，但它传达的意思是，这段代码还没有写完；matches!(value, pattern)：将一个值与一个模式进行比较，如果匹配则返回真，否则返回假，这等同于写： 调试宏
调试一个宏可能是一个挑战，最大的问题是缺乏对宏扩展过程的了解。Rust 经常会展开所有的宏，发现某种错误，然后打印一条错误信息，但并不显示包含错误的完全展开的代码。
这里有三个工具可以帮助排除宏的故障。(这些功能都是不稳定的，但由于它们确实是被设计成在开发过程中使用，而不是在你要检查的代码中使用，所以在实践中这不是一个大问题)。
首先，也是最简单的，你可以要求 rustc 显示你的代码在扩展所有宏之后的样子。使用 cargo build --verbose 来查看 Cargo 是如何调用 rustc 的。 复制 rustc 的命令行，并添加 -Z unstable-options --pretty expanded 作为选项，完全展开的代码会被输出终端。不幸的是，这只有在代码没有语法错误的情况下才有效。
其次，Rust 提供了一个 log_syntax!() 宏，在编译时简单地将其参数打印到终端，可以用它来进行 println!-style 调试，这个宏需要 #![feature(log_syntax)]特性标志。
第三，可以要求 Rust 编译器将所有宏调用打印到终端，在代码中插入trace_macros!(true);。从那时起，每次 Rust 展开一个宏时，它都会打印出宏的名称和参数，例如：这将输出：
note: trace_macro
--&gt; src/main.rs:6:19
|
6 |     let numbers = vec![1, 2, 3];
|                   ^^^^^^^^^^^^^
|
= note: expanding `vec! &#123; 1, 2, 3 &#125;`
= note: to `$crate :: __rust_force_expr! (&lt; [_] &gt; :: into_vec(box [1, 2, 3]))`
= note: expanding `__rust_force_expr! &#123; &lt; [_] &gt; :: into_vec(box [1, 2, 3]) &#125;`
= note: to `&lt;[_]&gt;::into_vec(box [1, 2, 3])`    Finished dev [unoptimized + debuginfo] target(s) in 0.51s
    Running `target/debug/crosscompile`
total: 6编译器展示了每个宏展开前后调用的代码，trace_macros!(false); 会关闭这个 trace，所以 println!() 展开的内容不会打印出来。
 构建 json!
我们现在已经讨论了 macro_rules! 的核心功能! 在本节中，我们将逐步开发一个用于构建JSON 数据的宏。我们将用这个例子来说明宏的开发，介绍 macro_rules! 的其余部分，并提供一些建议以确保宏的行为符合要求。我们来看一个表示 JSON 数据的枚举：不幸的是，写出 Json 值的语法相当冗长。我们希望能用一种更类似 JSON 的语法来写这个：我们想要的是一个 json! 宏，它接受一个 JSON 值作为参数，并展开为一个像前面例子中的 Rust 表达式。
本节完整的代码可以看 https://github.com/ProgrammingRust/examples/tree/master/json-macro。
 片段类型
写入任何复杂宏的前提是指出如何匹配或解析所需的输入。
我们已经可以看到，这个宏会有几条规则，因为JSON数据中有几种不同的东西：对象、数组、数字，等等。事实上，我们可以猜测，我们将为每种JSON 类型制定一条规则。这并不完全正确，因为宏模式没有提供区分后三种情况的方法，但我们以后会看到如何处理这个问题。至少前三种情况显然是以不同的标记开始的，所以我们就从这些开始。第一条规则已经起作用了：为了增加对 JSON 数组的支持，我们可以尝试将元素匹配为 exprs：不幸的是，这并不符合所有的 JSON 数组，这里有一个测试，说明了这个问题。表达式 $( $element:expr ),* 表示一个逗号分割的 Rust 表达式，但是许多 JSON 值，特别是 JSON 对象，不是有效的 Rust 表达式，它们不匹配。所以这里的 &#123; &quot;pitch&quot;: 440.0 &#125; 匹配失败。
由于不是每一段你想匹配的代码都是表达式，Rust 支持其他几种片段类型，如下图所示：表中的大多数选项都严格执行 Rust 语法。expr 类型只匹配 Rust 表达式（不是 JSON 值），ty 只匹配 Rust 类型，以此类推。它们是不可扩展的：没有办法定义新的算术运算符或 expr 可以识别的新关键字，我们将无法使其中任何一个匹配任意的 JSON 数据。
最后两个，ident 和 tt，支持匹配看起来不像 Rust 代码的宏参数，ident 匹配任何标识符。tt 匹配一个单一的 token树：要么是一对提前匹配的括号，(...)，[...]，或 &#123;...&#125;，以及两者之间的一切，包括嵌套的标记树，或者不是括号的单一标记，如 1926 或 &quot;Knots&quot;。
token 树正是我们的 json! 宏所需要的，每个 JSON 值都是一个单一的标记树：数字、字符串、布尔值和 null 都是单一的标记，对象和数组则用括号表示，所以我们可以这样写模式。这个版本的 json! 宏可以匹配所有的 JSON 数据，现在我们只需要编写正确的Rust代码。
为了确保 Rust 能够在未来获得新的语法特性而不破坏你现在编写的任何宏，Rust 限制了紧随片段之后出现在模式中的标记。上表中的 &quot;Can be followed by...&quot; 列显示了哪些标记被允许。例如，模式 $x:expr ~ $y:expr 是一个错误，因为 ~ 在 expr 后面是不允许的。模式 $vars:pat =&gt; $handler:expr 是可以的，因为 $vars:pat 后面是箭头 =&gt;，是 pat 允许的标记之一，而$handler:expr 后面是空的，这也是允许的。
 宏中的递归
我们已经看到了一个宏调用自身的例子：我们对 vec! 的实现使用递归来支持尾部逗号。这里我们可以展示一个更重要的例子：json! 需要递归地调用自己。我们可以尝试在不使用递归的情况下支持 JSON 数组，像这样。但这并不可行，我们会把 JSON 数据（ $elemen 标记树）直接粘贴到 Rust 表达式中，它们是两种不同的语言。我们需要将数组的每个元素从 JSON 形式转换为 Rust 形式。例如：JSON 对象可以按照这种方式支持：编译器对宏施加了一个递归限制。默认情况下是 64 个调用。这对于 json 的正常使用是绰绰有余的，但复杂的递归宏有时会触及这个限制。可以通过在使用宏的 crate 顶部添加下面这个属性来调整它。至此 json! 宏已经接近完成，剩下的就是支持布尔值、数字和字符串值了。
 使用 Trait
在这里，我们需要支持 json!(true)、json!(1.0) 和 json!(&quot;yes&quot;)，将值转换为适当类型的 Json 值，但是宏并不擅长区分类型，我们可以想象一下写成这样：这种方法马上就被证明是错的，只有两个布尔值，但比这更多的数字，甚至更多的字符串。幸运的是，有一种标准的方法可以将各种类型的值转换为一种指定的类型：From，我们只需要为一些类型实现这个特性。事实上，所有12种数字类型都应该有非常相似的实现，所以写一个宏可能是有意义的，只是为了避免复制和粘贴。现在我们可以使用 Json::from(value) 来将任何支持的类型的值转换为 Json。在我们的宏中，它看起来会是这样的：把这个规则添加到我们的 json! 宏中，使它通过我们到目前为止所写的所有测试。把所有的部分组合起来，目前看起来是这样的：事实证明，这个宏出乎意料地支持在 JSON 数据中使用变量，甚至是任意的 Rust 表达式，这是一个方便的额外功能。因为 (width * 9.0 / 4.0) 是括号内的，它是一个单一的 token 树，所以宏在解析对象时成功地将其与 $value:tt 相匹配。
 Scoping and Hygiene
接下来介绍了 Rust 处理范围的两种方式：一种方式用于局部变量和参数，另一种方式用于其他所有内容。为了说明为什么这很重要，让我们重写解析 JSON 对象的规则（前面显示的 json! 宏中的第三条规则）以消除临时向量，我们可以这样写：现在我们不是通过使用 collect() 而是通过重复调用 .insert() 方法来填充 HashMap。这意味着我们需要将 map 存储在一个临时变量中，我们称之为fields。如果在调用 json! 的地方正好有个临时变量 fields 会如何？宏展开会将两处代码粘贴在一起，但是两处都使用的 fields 是不同的，就像：这里的宏正常工作，Rust 重命名变量。这个功能首先在 Scheme 宏中实现，称为hygiene，因此据说 Rust 具有 hygienic macros，理解宏 hygiene 的最简单方法是想象每次展开宏时，来自宏本身的扩展部分都被涂上不同的颜色。
然后，不同颜色的变量被视为具有不同的名称：注意，由宏调用者传入并粘贴到输出中的代码位，如 &quot;name&quot; 和 &quot;actor&quot;，保持其原始颜色（黑色），只有源自宏模板的 token 被换装。
现在有一个名为 fields 的变量（在调用者中声明）和一个名为 fields 的单独变量（由宏引入）。由于名字是不同的颜色，这两个变量不会被混淆。
如果一个宏真的需要引用调用者范围内的一个变量，调用者必须把这个变量的名字传给宏。
你可能已经注意到，随着宏的展开，许多其他标识符被涂上一种或多种颜色。例如，Box、HashMap 和 Json。尽管被涂上了颜色，Rust在识别这些类型名称时并没有遇到困难。这是因为 Rust 中的 hygiene 被限制在局部变量和参数上。当涉及到常量、类型、方法、模块、状态和宏名称时，Rust 是色盲的。
这意味着，如果我们的 json! 宏在一个模块中使用，而Box、HashMap或Json不在范围内，那么这个宏就不能工作。
首先，我们将考虑一种情况，即 Rust 的严格 hygiene 规定会妨碍我们的工作，而我们需要绕过它，假设我们有很多函数都包含这一行代码。假设我们改为用宏：正如所写，这不起作用。它需要宏中的名称 server_socket 来引用函数中声明的本地 server_socket，变量 req 反之亦然。但是hygiene 可以防止宏中的名称与其他范围内的名称冲突。
解决方案是将计划在宏代码内部和外部使用的任何标识符传递给宏：因为 req 和 server_socket 现在是由函数提供的，它们是该范围的正确&quot;颜色&quot;。
 宏的导入和导出
由于宏在编译的早期就被展开了，在 Rust 知道你项目的完整模块结构之前，编译器就有了导出和导入它们的特殊功能。
在一个模块中可见的宏在其子模块中自动可见，要将宏从模块向上导出到其父模块，请使用 #[macro_use] 属性。例如，假设我们的 lib.rs 看起来像这样：在 macros 模块中定义的所有宏都导入到 lib.rs 中，因此在包的其余部分中可见，包括在 client 和 server 中。
标有 #[macro_export] 的宏是自动发布的，可以像其他项目一样通过路径引用。
例如，lazy_static 提供了一个名为 lazy_static 的宏，它被标记为 #[macro_export]。要使用这个宏，你可以写：一旦被导入，他就可以像其他的任何导入一样使用：当然，实际做这些事情意味着你的宏可能被其他模块调用。因此，一个导出的宏不应该依赖于任何在范围内的东西。不知道在它被使用的地方会有什么在作用域内，即使是标准预导入的功能也会被屏蔽。
macro_rules 提供了特殊 $crate 来帮助解决这个问题。这与 crate 不同，crate 是一个关键词，可以在任何地方用于路径，而不仅仅是在宏中。$crate 的作用就像一个绝对路径，指向定义宏的 crate 的根模块。我们不能写成 Json，而写成 $crate::Json，即使 Json 没有被导入，它也能发挥作用。HashMap 可以改成 ::std::collections::HashMap 或者$crate::macros::HashMap 。在后一种情况下，我们必须重新导出 HashMap，因为 $crate 不能被用来访问 crate 的私有特性。
来看下我们最终版本的 json!：由于 .to_string() 方法是标准 ToString 的一部分，我们也用 $crate 来引用它，使用&quot;完全限定的方法调用&quot;语法：$crate::macros::ToString::to_string($key)。在我们的例子中，这对于宏的工作并不是严格必要的，因为 ToString 是在标准的预导入中。但是如果你要调用一个 Trait 的方法，而这个 Trait 在调用宏的时候可能不在范围内，那么完全限定的方法调用是最好的方式。
 语法错误
下面的宏只是看起来合理：假设我们这样调用：在我们看来，这显然与第二个模式相匹配。但是Rust首先尝试了第一条规则，试图用$msg:expr来匹配所有的输入。但是 user: &quot;jimb&quot; 不是一个表达式，所以我们得到了一个语法错误。Rust 拒绝把语法错误传递到下面–宏已经够难调试了。相反，它会被立即报告并停止编译。
如果一个模式中的任何其他标记不能匹配，Rust 就会进入下一个规则。只有语法错误是致命的，而且只在试图匹配片段时发生。
这里的问题并不难理解：我们正试图在错误的规则中匹配一个片段 $msg:expr。它不会被匹配，调用者其实想要匹配另一条规则，有两个简单的方法来避免这种情况。
首先，避免易混淆的规则。例如，我们可以改变宏，使每个模式以不同的标识符开始。当宏参数以 msg 开头时，将匹配规则 1。当它们以 user 开头时，将匹配规则2。无论哪种方式，我们都知道在尝试匹配片段之前我们已经获得了正确的规则。
避免虚假语法错误的另一种方法是首先放置更具体的规则，将 user: 规则放在第一个，就能解决了 complain! 的问题，因为导致语法错误的规则永远不会到达。
 不止 macro_rules!
宏模式可以解析比 JSON 更复杂的输入，但我们发现复杂性很快就会失控。
《Rust Macros小书》是一本优秀的高级 macro_rules! 编程手册。这本书清晰明了，而且比我们这里更详细地描述了宏展开的每一个方面。它还介绍了几种非常聪明的技术，将 macro_rules! 模式作为一种神秘的编程语言来使用，以解析复杂的输入。
Rust 1.15 引入了一个单独的机制，叫做过程宏，它支持扩展 #[derive] 属性以处理自定义派生，如下图所示，也支持创建自定义属性和新的宏，其调用方式与前面讨论的 macro_rules! 宏一样。实际上没有 IntoJson，但这并不重要：过程宏可以使用这个钩子来插入任何它想要的代码（在这种情况下，可能是 impl From&lt;Money&gt; for Json &#123; ... &#125;）。
过程宏是作为Rust的一个函数来实现的，而不是一个声明性的规则集。这个函数通过一个薄薄的抽象层与编译器交互，可以是任意复杂的。例如，diesel使用过程宏来连接数据库，并在编译时根据该数据库的模式生成代码。
由于过程宏与编译器内部相互作用，编写有效的宏需要对编译器的运行方式有所了解，可以在这里寻找你想要的。
也许，在阅读了这些内容之后，更不想用宏。另一个选择是使用构建脚本来生成 Rust 代码，Cargo 文档显示了如何一步一步地做到这一点。它包括编写一个程序来生成你想要的 Rust代码，在 Cargo.toml 中添加一行，作为构建过程的一部分来运行该程序，并使用 include! 来将生成的代码放入你的crate中。
]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>《Rust 程序设计》</tag>
        <tag>宏</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】常用 Trait</title>
    <url>/2022/04/29/Rust/%E3%80%90Rust%E3%80%91%E5%B8%B8%E7%94%A8-Trait/</url>
    <content><![CDATA[Rust 中的 Trait 可以分为三类：语言扩展 Trait：主要用于运算符重载，我们可以将常用的运算符使用在自己的类型之中，只要相应的 Trait 即可，例如 Eq，AddAssign，Dere，Drop 以及 From 和 Into 等；标记类型 Trait：这些 Trait 主要用于绑定泛型类型变量，以表达无法以其他方式捕获的约束，这些包括 Sized 和 Copy；剩下的主要是一些为解决常遇到的问题，例如：Default，AsRef，AsMut，Borrow，BorrowMut，TryFrom 和 TryInto； Drop
Rust 中当一个值离开作用域时就会对它的内存进行清理，但是所有权转移不会，这类似于 C++ 中的析构函数。在 Rust 中我们也可以对析构的过程进行自定义，只要实现 std::ops::Drop 即可，在值需要清理的时候会自动调用 drop 函数，不能显示调用：通常不需要实现 std::ops::Drop，除非定义了一个拥有 Rust 不知道的资源的类型。 例如，在 Unix 系统上，Rust 的标准库在内部使用以下类型来表示操作系统文件描述符：FileDesc 的 fd 字段只是程序完成时应该关闭的文件描述符的编号，c_int 是 i32 的别名。标准库为 FileDesc 实现 Drop 如下：这里，libc::close 是 C 库关闭函数的 Rust 名称，Rust 仅能在 unsafe 块中调用 C 函数。
如果一个类型实现了 Drop，它就不能实现 Copy，如果类型可 Copy，则意味着简单的逐字节复制足以生成该值的独立副本，但是在相同的数据上多次调用相同的 drop 方法通常是错误的。
标准库预包含的 drop 函数可以显示删除一个值： Sized
Sized 类型表明了它的内存在编译时确定的，该类型的所有值大小相等，Rust 中几乎所有类型大小确定，u64 占 8 个字节， (f32, f32, f32) 占 12 个字节，枚举也是大小确定的，它的大小能够容纳最大的项，对于 Vec&lt;T&gt;，尽管它拥有一个大小可变的堆内存，但就其自身而言，包含了指向堆的指针，容量和长度，所以它也是 Sized。
所有的 Sized 类型都实现了 std::marker::Sized，这个 Trait 没有任何方法和关联的类型，我们也不需要手动实现，Rust 会为所有适用的类型自动实现，Sized 类型唯一的用途是泛型的边界。
Rust 内部也有一些 unsized 类型，它们的值大小不一，例如 str，字符串 slice，它的值大小不确定，&quot;diminutive&quot; 和 &quot;big&quot; 都是 str 类型，但是它们分别占用 10 和 3 个字节。数组 slice，[T] 也是 unsized，一个共享引用 &amp;[u8] 可以指向任何大小的 [u8]。str 和 [T] 都表示一个变长的数据集合，大小不定。另外一种是 dyn Trait 类型，由于 Trait 可能指向多种类型，所以它的大小是不确定的，例如：但是 &amp;dyn Trait，包含指向实现 Trait 的值和一个指向拥有该值类型方法表的指针，所以它的大小是确定的，详细请看 Trait对象。
Rust 不能将 unsized 值存储到变量或者传递给参数，唯一能使用它们的方式是使用指针，例如：&amp;str 和 Box&lt;dyn Write&gt;，指向 unsized 值的指针是胖指针，包含了指向值的指针和 size 信息。
因为 unsized 类型限制比较多，所以大多数泛型都是 sized 类型，而且为了方便，Rust 隐式设置泛型是 Sized。例如，如果你写了 struct S&lt;T&gt; &#123;...&#125;，Rust 会自动加上 Sized 限制 struct S&lt;T: Sized&gt; &#123;...&#125;。如果不想这样做，可以显示设置 struct S&lt;T: ?Sized&gt;，?Sized 表明的意思是没必要是Sized，那也就是既可以是，也可以不是。因此，如果定义了泛型 struct S&lt;T: ?Sized&gt; &#123; b: Box&lt;T&gt; &#125;，Rust 允许我们为 str 和 dyn Write 实现该类型，例如，S&lt;str&gt; 和 S&lt;dyn Write&gt;，b 在这里包含了一个胖指针；以及 S&lt;i32&gt; 和 S&lt;String&gt;，b 包含一个普通指针。
除了 slice 和 Trait 之外，这里还有一种 unsized 类型。结构体的最后一个字段，也只能最后一个字段，可以是 unszied，这样的结构体也就是 unsized。我们看 Rc&lt;T&gt; 的实现中使用到的 RcBox&lt;T&gt; 类型的定义（该类型未导出）：我们可以将 RcBox 用于 Sized 类型，如：RcBox&lt;String&gt;，也可以用于 unszied 类型，例如：RcBox&lt;dyn std::fmt::Display&gt;，但是我们不能直接创建 RcBox&lt;dyn std::fmt::Display&gt;，而是先要创建一个实现了 Display 的类型，例如 RcBox&lt;String&gt;，然后再将 &amp;RcBox&lt;String&gt; 转换成 &amp;RcBox&lt;dyn Display&gt;，这个转换在传递给函数的时候还会隐式进行： Clone
std::clone::Clone 用于类型副本的创建，它的定义如下：Clone 扩展了 Sized，这意味着实现着都必须是 Sized，clone 方法构造了一个新的副本并且返回。
clone 值成本很高，体现在时间和内存上，例如，要克隆 Vec&lt;String&gt;，要复制其中的每个 String，所以 Rust 不会自动进行 clone，而是需要我们显示进行方法调用。这里有个例外就是 Rc&lt;T&gt; 和 Arc&lt;T&gt;，它们只是简单地增加引用计数。
clone_from 是根据 source 覆盖自身，工作过程就是先克隆 t，然后赋值给 *self，并且将 self 原来的值丢掉。这有时候成本很高，例如 s 和 t 都是 String，但是如果 s 的 buffer 有足够的容量容纳 t，只需要将 t 中的内容逐个复制，然后调整 s 的长度，所以 clone_from 尽可能使用优化实现。
如果 Clone 实现只是将 clone 应用于类型的每个字段或元素，然后从这些克隆中构造一个新值，并且 clone_from 的默认定义足够好，那么可以使用 #[derive(Clone )] 自动实现。
 Copy
赋值操作在大多数时候会将值移动并且让原来的值变成未初始化，但是，对于简单的值，赋值操作会自动生成产生一个副本。例如，People 未实现 Copy，所以会转移值的所有权，而简单整数则会赋值：但是我们可以通过 std::marker::Copy 告诉 Rust我们的类型是支持 Copy 的：Copy 只是一个标记，它扩展了 Clone，但没有任何方法：但是因为 Copy 是一种对语言具有特殊意义的标记 trait，Rust 只允许一个类型实现 Copy，前提是它可以按字节复制。拥有任何其他资源（如堆缓冲区或操作系统句柄）的类型无法实现 Copy。
实现了 Drop 的类型也不能 Copy，Rust 认为一个类型如果需要特殊清理，那么它就需要特殊复制。
 Deref、DerefMut
我们可以通过实现 std::ops::Deref 和 std::ops::DerefMut 来自定义 * 操作符的逻辑。这两个 trait 的定义如下：我们熟悉的 Box&lt;T&gt; 和 Rc&lt;T&gt; 就实现它们，以至于它们能变现的像内建的指针一样，例如 &amp;Box&lt;T&gt; 实际上返回的是 &amp;T。
Deref 和 DerefMut 的另一个重要功能是它们能够实现将 &amp;Self 引用自动转换为 &amp;Self::Target。这样，当我们使用 * 或者 . 运算符时发现类型不匹配，Rust 会为我们自动插入 deref 或者 deref_mut 调用，这在某些场景中很方便，例如：如果我们有 Rc&lt;String&gt; 的值 r，并且想使用 String::find，我们可以简单的调用 r.find('?') 而不是 (*r).find('?')，这个方调用隐式借用 r，&amp;Rc&lt;String&gt; 转换成了 &amp;String；我们可以使用 split_at 这些属于 String 的方法在 [str] 类型上，因为 String 实现了 Deref&lt;Target=str&gt;，所以我们可以从 &amp;String 直接转换成 &amp;str；我们可以将 &amp;Vec&lt;T&gt; 传递给参数是 &amp;[T] 的类型，因为 Vec&lt;T&gt; 实现了 Deref&lt;Target=T&gt;；如果有必要，Rust 可以连续应用 deref，例如我们可以将 &amp;Rc&lt;String&gt; 直接转换成 &amp;String，又可以直接转换成 &amp;str。例如：Deref 和 DerefMut 被设计用于实现智能指针类型，如 Box、Rc 和 Arc 以及 Vec&lt;T&gt; 和 Stirng 这种，不能仅仅为了这种隐式的自动转换而实现它。
deref 转换可能引起一些混乱，可以用来解决类型冲突，但是不能满足变量的边界。例如，下面的函数调用是可以进行的，&amp;Selector&lt;&amp;str&gt; 会转换成 &amp;str，Rust 发现传入的是 Selector&lt;&amp;str&gt;，但是要求的是 &amp;str，同时该类型实现了 Deref&lt;Target=str&gt;，所以就会将函数调用重写成 show_it(s.deref())：但是当我们使用泛型函数时，就会遇到问题，例如：Rust 提示我们的 Selector&lt;&amp;str&gt; 没有实现 Display，但我们的 &amp;str 确实可以。实际上因为传递了一个 &amp;Selector&lt;&amp;str&gt; 类型的参数，而函数的参数类型是 &amp;T，所以类型变量 T 必须是 Selector&lt;&amp;str&gt;。 然后，Rust 检查边界 T: Display 是否满足，因为它没有应用 deref 强制来满足类型变量的边界，所以这个检查失败。
    Compiling crosscompile v0.1.0 (/Users/fudenglong/WORKDIR/rust/crosscompile)
    error[E0277]: `Selector&lt;&amp;str&gt;` doesn't implement `std::fmt::Display`
    --&gt; src/main.rs:38:21
    |
    38 |     show_it_generic(&amp;s);
    |     --------------- ^^
    |     |               |
    |     |               `Selector&lt;&amp;str&gt;` cannot be formatted with the default formatter
    |     |               help: consider dereferencing here: `&amp;*s`
    |     required by a bound introduced by this call
    |
    = help: the trait `std::fmt::Display` is not implemented for `Selector&lt;&amp;str&gt;`
    = note: in format strings you may be able to use `{:?}` (or {:#?} for pretty-print) instead
    = note: required because of the requirements on the impl of `std::fmt::Display` for `&amp;Selector&lt;&amp;str&gt;`所以我们可以显示地告诉编译器怎么做：或者按照编译器提示： Default
有些类型有一个相当明显的默认值，例如 Vec 或者字符串是空，数字默认是0，而 Option 默认是 None，像这样的类型都实现了 std::default::Default：default 简单的返回了一个 Self 新值，String 的实现很直接：所有 Rust 的集合类型 Vec，HashMap，BinaryMap 等都实现了 Default，返回新的空的集合。如果类型 T 实现 Default，则标准库会自动为 Rc&lt;T&gt;、Arc&lt;T&gt;、Box&lt;T&gt;、Cell&lt;T&gt;、RefCell&lt;T&gt;、Cow&lt;T&gt;、Mutex&lt;T&gt;、 和 RwLock&lt;T&gt; 实现 Default。
如果一个tuple的所有元素类型都实现了默认值，那么tuple也会实现，默认为一个包含每个元素默认值的tuple。
Rust 不会为结构类型隐式实现 Default，但如果一个结构的所有字段都实现 Default，您可以使用 #[derive(Default)] 自动为该结构实现 Default。
 AsRef、AsMut
当一个类型实现 AsRef&lt;T&gt; 时，这意味着可以从中借用 &amp;T，实现AsMut&lt;T&gt; 可以借用 &amp;mut T，它们可以实现引用到引用之间的转换，不像 From 和 Into 用于值到值之间的转移，它们的定义如下：例如，Vec[T] 实现了 AsRef&lt;[T]&gt;，String 实现了 AsRef&lt;str&gt; 和 AsRef&lt;[u8]&gt;，AsRef 通常用于使函数在它们接受的参数类型中更加灵活。 例如， std::fs::File::open 函数声明如下：open 真正需要的是 &amp;Path，表示文件系统路径的类型。但是有了这个签名，open 接受任何它可以借用 &amp;Path 的东西——也就是说，任何实现 AsRef&lt;Path&gt; 的东西。这样的类型包括 String 和 str，操作系统接口字符串类型 OsString 和 OsStr，当然还有 PathBuf 和 Path；这是允许传递字符串文字以打开文件的原因：但是字符串文字是 &amp;str，但实现 AsRef&lt;Path&gt; 的类型是 str，没有 &amp;，Rust 不会尝试 deref 强制来满足类型变量的界限，幸运的是，标准库为所有实现了 AsRef&lt;U&gt; 的类型 T，自动为 &amp;T 实现了 AsRef&lt;U&gt;，查看这里： Borrow、BorrowMut
std::borrow::Borrow 类似于 AsRef：如果一个类型实现了 Borrow&lt;T&gt;，那么它的 borrow 方法有效地从它借用一个 &amp;T。但是 Borrow 施加了更多的限制：一个类型应该实现 Borrow&lt;T&gt; 只有当 &amp;T 的 hash 和它借用的值的 hash 相同时。（Rust 不强制执行这一点，它只是 Trait 的意图。）
这种区别在借用字符串时很重要，例如：String 实现 AsRef&lt;str&gt;、AsRef&lt;[u8]&gt; 和 AsRef&lt;Path&gt;，但这三种目标类型通常具有不同的哈希值。只有 &amp;str 切片保证和 String 有一样 hash 值，所以 String 只实现 Borrow&lt;str&gt;。
Borrow 的定义如下：Borrow 被设计出用于解决通用hash表和其他集合类型的场景，假设，我们有个 std::collections::HashMap&lt;String, i32&gt;，现在想实现查找方法，这可能是我们的第一版：这个实现中，意味着你必须传入和键值完全匹配的类型。这里，K 是 String，意思是调用 get 方法必须传入一个 String，有点浪费，再来修改：这有点好了，但是如果我们传入一个长岭的字符串，我们就得这样写，先申请一段内存将我们的文本放进去，然后传入，再然后丢掉：更好的方法是应该能传入和我们的 key 进行比较且能hash的值，这里 &amp;str 完全是可以的，所以，我们的最终版形成了：由于 String 实现了 Borrow&lt;str&gt; 和 Borrow&lt;String&gt;，因此这个最终版本的 get 允许您根据需要传递 &amp;String 或 &amp;str 作为键。并且所有标准库的关联集合类型都使用 Borrow 来决定哪些类型可以传递给它们的查找函数。
另外，标准库为所有类型实现了 impl&lt;T&gt; Borrow&lt;T&gt; for T，这确保 &amp;K 始终允许在 HashMap&lt;K, V&gt; 中查找条目时可用。
为方便起见，每个 &amp;mut T 类型也实现了 Borrow&lt;T&gt;，返回一个共享的像往常一样引用 &amp;T。
 From、Into
标准库中提供的 std::convert::From 和 std::convert::Into 用于不同类型值之间的转换，它们获取值的所有权并且转换成另一个类型的值，而 AsRef 用于引用到引用之间的转换。标准库自动实现了类型转换为自身的实现，例如：这两个 Trait 用于两个方向之间的转换，A into B 或者 B from A，例如，对于标注库的 std::net::Ipv4Addr：由于 from 和  into 是相对的，标准库对于任何实现了 From 的类型实现了 Into，例如： TryFrom、TryInto
std::convert::TryFrom 和 std::convert::TryInto 也用于数据类型之间的转换，只是它们可能失败：例如，如果我们将一个较大 i64 转换为 i32 时可能会发生溢出，我们可以使用 try_into() 根据结果进行判断： ToOwned
如果我们想要根据 &amp;str 或者 &amp;[i32] 生成 String 或者 Vec&lt;i32&gt;，由于 Clone 是不允许的，它只能返回相同类型的版本。所以 Rust 提供了 std::borrow::ToOwned：Borrow 和 AsRef 的区别是它的目的类型和当前类型的 hash 值一样，可以认为就是同一个东西。
 Cow
Cow（Clone-on-Write）是 Rust 中一个很有意思且很重要的数据结构。它就像 Option 一样，在返回数据的时候，提供了一种可能：要么返回一个借用的数据（只读），要么返回一个拥有所有权的数据（可写）。Cow 的合理使用能减少不必要的堆内存分配，例如，我们写一个替换 : 的程序，如果原文字符串中没有包含 :，就返回原来的字符串；如果包含，就替换为空格，返回一个 String：
]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>《Rust 程序设计》</tag>
        <tag>常用 Trait</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】实战突破</title>
    <url>/2021/09/05/Rust/%E3%80%90Rust%E3%80%91%E5%AE%9E%E6%88%98%E7%AA%81%E7%A0%B4/</url>
    <content><![CDATA[
Rust 是一门赋予每个人构建可靠且高效软件能力的语言。Rust 相比其他语言，具有显著的特点，尤其是：性能高；Rust 速度惊人且内存利用率极高。由于没有运行时和垃圾回收，它能够胜任对性能要求特别高的服务，可以在嵌入式设备上运行，还能轻松和其他语言集成。高可靠；Rust 丰富的类型系统和所有权模型保证了内存安全和线程安全，让您在编译期就能够消除各种各样的错误。极具生产力；Rust 拥有出色的文档、友好的编译器和清晰的错误提示信息， 还集成了一流的工具——包管理器和构建工具， 智能地自动补全和类型检验的多编辑器支持， 以及自动格式化代码等等。 表达式
 loop
不同于其他语言，rust 的 loop 循环是可以返回值的，因为 loop 循环是一个表达式，表达式可以求值，这样就可以作为赋值语句使用，如下示例： if let
由于 match 模式匹配必须要指出所有的可能性，所以在使用上不是很优雅，因此有了 if let，可以说它是 match 的语法糖，可以按需只匹配自己想要的。 while let
同 if let 类似，while let 可以简化代码的书写方式，使得呈现上更加优雅。
loop matchwhile let
 零类型
rust 中某些类型的是不占用任何内存的，享受 rust 为他们提供的优化，我们可以用标准库提供的 std::mem::size_of_val 函数进行测量。 match
rust提供match关键字用于模式匹配，类似于其他语言中的switch，不同的是match必须列出所有可能情况。
 示例不仅如此，match 还可以用于解构枚举enum，下面是一个复杂的例子：match 在匹配到第一个条件之后，不会再往下匹配： 卫语句
match 模式匹配可以加上 if条件语句来过滤分支，提供更加灵活的匹配方式： @ 绑定
match 提供了 @ 运算符用于将值绑定到变量： 解构
解构可以非常方便地从一个结构体或者元组中提取某个字段或者全部： 指针和引用
对指针来说，解构（destructure）和解引用（dereference）要区分开，因为这两者的概念 是不同的，和 C 那样的语言用法不一样。解引用使用 *
解构使用 &amp;、ref、和 ref mut&amp; 和 ref 都表示获取引用，只是一个出现在表达式左边一个出现在右边，当 &amp; 出现在右边的时候等价于 ref 出现在左边，&amp; 出现在左边的时候等价于 * 出现在右边：输出：参考：https://users.rust-lang.org/t/ref-keyword-versus/18818/2
 可反驳性
模式有两种形式：refutable（可反驳的）和 irrefutable（不可反驳的）。能匹配任何传递的可能值的模式被称为是不可反驳的（irrefutable），反之，对某些可能的值进行匹配会失败的模式被称为是可反驳的（refutable）。
举个例子，let x = 5; 中的 x 可以匹配任何值不会失败，所以称为不可反驳。if let Some(x) = a_value 中，如果 a_value 是 None，那么这个表达式就匹配不上，所以称为可反驳。
为什么有这么个模式？因为，函数参数，let，for 只能接收不可反驳的模式，也就是说只允许匹配成功，是一种确定性操作。而 if let，或者 while let 表达式被限制为只能接收可反驳的模式，也就是说他们允许出现匹配不上，即匹配失败的情况，再者说，他们的出现就是为了处理成功和失败这两种情况。下面的这段代码就会编译失败，因为没有处理 a_value 为 None 的情况，let 也处理不了：基于此，match 匹配分支必须使用可反驳模式，除了最后一个分支需要使用能匹配任何剩余值的不可反驳模式。Rust 允许我们在只有一个匹配分支的 match 中使用不可反驳模式，不过这么做不是特别有用，并可以被更简单的 let 语句替代。
 方法
方法通常用于和函数对比，和函数的区别是方法附着于对象，方法分为静态方法和实例方法，静态方法常用语构造对象，实例方法中通过关键字 self 来引用对象中的数据。
静态方法实例方法
 闭包
闭包是函数式编程中不可获取的一员，rust 对此也提供了支持，也叫 lambda，能够捕获环境中的变量，例如：|val| val + x 简单示例
这种超级简便的语法使得它在临时使用时非常方便，输入和返回值类型都可以自行推导，但是必须指定输入参数名称。在声明参数是，同函数不同，它是使用 || 而不是 () 将参数包裹起来；另外们对于单个表达式的闭包，&#123;&#125; 是可以省略的。 捕获变量
闭包会自动满足函数功能的要求，使得闭包不需要类型说明就可以工作。这允许变量捕获（capture）灵活地适应使用场合，既可移动（move）又可借用（borrow）变量。闭包可以通过：引用 &amp;T， 可变引用 &amp;mut T，值 T  自动捕获变量，也可以通过 move 强制获得变量的所有权： 作为入参
虽然闭包可以自动做类型推断，但是在编写函数以闭包作为参数时，还是得必须明确指定类型，可以通过以下三个之一来指定闭包捕获变量的类型，他们的受限程度依次递减：Fn：表示捕获方式为通过引用（&amp;T）的闭包
FnMut：表示捕获方式为通过可变引用（&amp;mut T）的闭包
FnOnce：表示捕获方式为通过值（T）的闭包 作为返回值
闭包可以作为输入参数，也可以作为返回值返回，由于闭包的类型是未知的，所以只有使用 impl Trait 才能返回一个闭包。除此之外，还必须使用 move 关键字，它表明所有的捕获都是通过值进行的。因为在函数退出时，任何通过引用的捕获都被丢弃，在闭包中留下无效的引用。 函数指针
函数指针是指向代码而非数据的指针。它们可以像函数一样被调用。与引用一样，函数指针被假定为不为空，因此如果想通过 FFI 传递函数指针并能够容纳空指针，需要使用所需的的类型 Option&lt;fn()&gt; 。
函数指针的类型是 fn，注意和 Fn 区分，后者是闭包实现的 trait 类型。 函数指针实现了所有三个闭包 trait（Fn、FnMut 和 FnOnce），所以总是可以在调用期望闭包的函数时传递函数指针作为参数。倾向于编写使用泛型和闭包 trait 的函数，这样它就能接受函数或闭包作为参数。Fn 系列 trait 由标准库提供，所有的闭包都实现了 Fn、FnMut 或 FnOnce 中的一个或多个。
我们可以将一个闭包转换为函数指针作为参数传入，但是仅限于没有捕获任何环境变量的闭包，这个从闭包和函数的概念上也能区分出来，闭包相对于函数，就是捕获了环境变量。没有捕获任何环境变量的闭包会被编译器重写为匿名独立函数。
闭包作为参数函数作为参数元组结构体作为参数闭包转换为函数闭包不能转换为函数在构造元组结构体时使用 () 语法进行初始化，很像是函数调用，实际上它们确实被实现为返回由参数构造的实例的函数，所以它们也被称为实现了闭包 trait 的函数指针。
没有捕获任何环境变量的闭包会被编译器重写为匿名独立函数。
闭包捕获环境变量之后，就不能再转换为函数了。这里有个例子：https://stackoverflow.com/questions/52696907/why-does-passing-a-closure-to-function-which-accepts-a-function-pointer-not-work?answertab=active#tab-top编译这段代码就会报错，帮我们指出闭包只有在没有捕获任何环境变量的情况下才能转换为函数，不得不说 rust 的编译器还是很友好： Trait
trait 用于定义共享的行为，trait 告诉 Rust 编译器某个特定类型拥有可能与其他类型共享的功能。可以通过 trait 以一种抽象的方式定义共享的行为，可以使用 trait bounds 指定泛型是任何拥有特定行为的类型。trait 定义是一种将方法签名组合起来的方法，目的是定义一个实现某些目的所必需的行为的集合，这里定义的方法可以只是签名说明而没有函数体。 默认类型和关联参数
rust 官方提供了一个 use std::ops::Add;，可以用于重载 + 运算符，定义如下：这里的 Output 被称作关联类型，用来决定 add 的返回值类型，在具体实现的时候指定具体类型。这里的 RHS=Self 语法表示：默认类型参数，RHS 是 right hand side 的缩写，用于定义 add 方法中的 rhs 参数。如果实现 Add trait 时不指定 RHS 的具体类型，RHS 的类型将是默认的 Self 类型，也就是在其上实现 Add 的类型。 完全限定语法
Rust 既不能避免一个 trait 与另一个 trait 拥有相同名称的方法，也不能阻止为同一类型同时实现这两个 trait。甚至直接在类型上实现开始已经有的同名方法也是可能的。下面的示例中通过在方法名称前面添加 trait 限定符，我们向 rust 指定我们需要哪个实现。像上面这种 fly 方法有一个 self 参数，即使有多个类型实现同一 trait，在使用 Trait::method(self)时，rust 可以根据 self 类型帮我们定位具体哪个类型的实现。然而，当遇到关联函数，即第一个参数不是 self 时，rust 就不能帮我们计算出该使用哪个类型了。下面的示例中使用完全限定语法消除歧义，该语法为：&lt;Type as Trait&gt;::function(receiver_if_method, next_arg, ...);
关联函数没有 receiver 自定义实现
实现 trait 时需要注意的一个限制是，只有当 trait 或者要实现 trait 的类型位于 crate 的本地作用域时，才能为该类型实现 trait，这个限制是被称为相干性（coherence） 的程序属性的一部分，或者更具体的说是孤儿规则（orphan rule）。这条规则确保了其他人编写的代码不会破坏你代码，反之亦然。没有这条规则的话，两个crate可以分别对相同类型实现相同的trait，而Rust将无从得知应该使用哪一个实现。 默认实现
默认实现指我们在定义 trait 方法时提供默认的实现行为，在为类型实现trait时，就可以不用再去实现它的方法了。默认实现的trait方法中还允许我们调用相同trait的其他方法，即使他们没有实现。 作为参数
我们可以将函数参数定义为实现了某个trait的类型，这样我们不用于去关心trait背后的具体类型，只在乎这些类型的行为。实现这一目标以多种不同的语法方式，它们是等价的，只是表现形式不同。
impltrait bound多个 trait bound如下，我们定义 notify 函数，指定 item 参数为实现了 Summary 的一个类型。
impl 看起来比较直观，它实际上是一个较长形式的语法糖，称之为 trait bound，所以前面的 impl Summary 等价于如下的形式：impl 形式在参数较少时比较方便，在参数较多时就看起来比较冗余，使用 trait bound 看起来就比较方便：
trait bound 可以理解为将 trait 绑定到某个泛型上，当需要将参数声明为实现了多个trait的类型时，可以使用 + ：使用过多的 trait bound 也有缺点。每个泛型有其自己的 trait bound，所以有多个泛型参数的函数在名称和参数列表之间会有很长的 trait bound 信息，这使得函数签名难以阅读。为此，Rust 有另一个在函数签名之后的 where 从句中指定 trait bound 的语法。 作为返回值
我们可以将函数的返回值定义为实现了某个trait的类型，例如我们指定 returns_summarizable 函数返回实现了 Summary 的类型：但是如果我们想从一个函数中返回多种实现了同一trait的类型，就不可以了，如下面这段代码就不能通过编译，因为rust需要在编译时期就确定函数返回值的大小。返回不同的类型，意味着函数的返回值大小是不确定的，这对于 rust 来说是不允许的。如果我们确实想这样做，我们可以使用 Box&lt;T&gt; 类型，这个类型将数据实际存储在堆上，保留该数据的指针，所以其大小是固定的，这样就实现了动态分发： 有条件地实现方法
有时候我们在为某一个泛型结构体实现方法的时候，首先需要它的类型实现某些trait。如下示例中，类型 Pair&lt;T&gt; 总是实现了 new 方法，不过只有那些为 T 类型实现了 PartialOrd trait （来允许比较） 和 Display trait （来启用打印）的 Pair&lt;T&gt; 才会实现 cmp_display 方法：也可以对任何实现了特定 trait 的类型有条件地实现 trait。对任何满足特定 trait bound 的类型实现 trait 被称为 blanket implementations，他们被广泛的用于 Rust 标准库中。例如，标准库为任何实现了 Display trait 的类型实现了 ToString trait。这个 impl 块看起来像这样：所以可以对任何实现了 Display trait 的类型调用由 ToString 定义的 to_string 方法。let s = 3.to_string(); 父 trait
在前面的例子中，我们演示过可以在 trait 的默认实现中使用相同trait的其他方法，即使该方法未实现。但是，我们有时也需要在当前trait中使用其他trait中的功能，这就形成了 trait 依赖，被依赖的trait的我们称之为当前trait的 父trait。
下面的例子中，OutlinePrint 在定义的默认方法 outline_print 调用了 fmt::Display 中的 to_string 方法： Copy、Clone
Copy 和 Clone 直接从字面意义上感觉没什么区别，它们最终都是产生了一个新的对象，但是这两个 trait 面向的对象不同，Copy 面向编译器，而 Clone 面向开发者。换句话说就是copy操作编译器帮我们做了，但是 clone 需要我们自己手动调用。
参考文章：https://stackoverflow.com/questions/31012923/what-is-the-difference-between-copy-and-clone?answertab=active#tab-top
https://doc.rust-lang.org/std/marker/trait.Copy.html#whats-the-difference-between-copy-and-clone
https://zhuanlan.zhihu.com/p/21730929
https://hashrust.com/blog/moves-copies-and-clones-in-rust/ Copy
Copy 的全称是 std::marker::Copy，它的内部其实什么方法都没有，但是实现它必须实现 Clone。一旦一个类型实现 Copy 意味着在任何需要的时候，我们可以简单的通过内存拷贝（C语言的按位拷贝memcpy）实现该类型的复制，而不会出现任何问题。在变量绑定、函数参数传递、函数返回值传递等场景下，它都是 copy 语义，而不再是默认的 move 语义pub trait Copy: Clone &#123; &#125;实现 Copy未实现Copyi32 实现了 Copy，所以我们在使用 let 表达式的时候，其实是复制而不是所有权转移。
实现 Copy 的基本类型： https://doc.rust-lang.org/std/marker/trait.Copy.html#implementors
String 没有实现 Copy，所以它在使用 let 表达式的时候，是所有权转移，下面的代码编译失败并不是所有的类型都可以实现 Copy 。Rust 规定，对于自定义类型，只有所有的成员都实现了 Copy ，这个类型才有资格实现 Copy。例如下面的类型：但是看下面的 PointList 类型，他就不能实现 Copy，因为 Vec&lt;T&gt; 没有实现 Copy。虽然 PointList 不能实现 Copy，但是是由于共享引用 &amp;T 可以 Copy，所以我们可以实现一个 PointListWrapper，包含 PointList 的一个引用，这样即使 PointList 不能 Copy，PointListWrapper 也可以 Copy。 Clone
Clone 的全称是 std::clone::Clone;，他定义了两个方法，其中 clone_from 默认实现。clone 方法一般用于基于语义的复制操作。所以，它做什么事情，跟具体类型的作用息息相关。比如对于 Box 类型，clone 就是执行的深拷贝，而对于 Rc 类型，clone 做的事情就是把引用计数值加1。你可以根据情况在 clone 函数中编写任意的逻辑。但是有一条规则需要注意：对于实现了 Copy 的类型，它的 clone 方法应该跟 Copy 语义相容，等同于按位拷贝。
实现了 Clone 的所有基本类型： https://doc.rust-lang.org/std/clone/trait.Clone.html#implementors
下面这段代码是编译通过的，可以看到，String 虽然未实现 Copy，但是它实现了 Clone。 Fn、FnMut、FnOnce
这三个 trait 位于 std::ops 模块中，其实是对函数调用运算符 () 的重载，区别在于 receiver 的类型，可以看到 Fn 的受限成都最高，FnOnce 最低：其中 Once 的意义， 正如闭包会捕获其环境 中描述的那样：FnOnce 消费从周围作用域捕获的变量，闭包周围的作用域被称为其环境，environment。为了消费捕获到的变量，闭包必须获取其所有权并在定义闭包时将其移动进闭包。其名称的 Once 部分代表了闭包不能多次获取相同变量的所有权的事实，所以它只能被调用一次。由于所有闭包都可以被调用至少一次，所以所有闭包都实现了 FnOnce 。 FnOnce
FnOnce 获取了 receiver 的所有权，如果一个类型仅仅实现了 FnOnce 它只可以被调用一次。FnOnce 由可能消耗捕获变量的闭包以及实现 FnMut 的所有类型自动实现。
由于 Fn 和 FnMut 都是 FnOnce 的 subtraits ，因此可以在需要 FnOnce 的地方使用 Fn 或 FnMut 的任何实例。如果我们在一个类函数类型参数使用场景中，如果我们期望只调用它一次，就使用 FnOnce 作为其类型，如果我们需要调用它多次是就使用 FnMut 作为其类型，如果我们还想要它不改变状态时，我们就用 Fn。
从 implementors 也可以看出，对于任何实现了 FnOnce 的类型 F，&amp;F 和 &amp;mut F 也自动实现 FnOnce。
闭包捕获非Copy类型，获取其所有权闭包捕获可Copy类型非Copy类型，获取所有权，但是并不消耗这个例子中，consume_and_return_x 捕获了 x 并获得了其所有权，并且在第一次调用时已经将 x 的所有权转移，所以无法再次调用。
当我们将前面例子中变量 x 的类型由 String 改为 i32，我们来看几个变种类型，改动很小。但是由于 i32 是可复制的，所以生成的闭包也是可复制的，还记得 Copy 的含义，当所有成员都实现 Copy 的时候，这个类型就可能实现 Copy。我们可以将上面示例中泛型参数 F 的类型声明为以下任何一种，就可以实现 func 多次调用，我们其实是在告诉编译器，可以通过 Copy 避免所有权的转移：F: FnOnce() -&gt; i32 + Copy
F: Copy + FnOnce() -&gt; i32
F: Copy + FnOnce() -&gt; i32 + Copy
下面的例子运行是没有问题的，consume_and_return_x 获取了变量 x 的所有权，因为 String 不可 Copy。但是我们在使用的时候并没有消耗它的所有权，所以是可以多次使用的。这个时候 consume_and_return_x 其实已经实现了 Fn。 FnMut
FnMut 实例可以被重复多次调用，并且可以改变环境变量。它被那些捕获了环境变量可变引用的闭包，所有Fn 的实现者，以及函数指针自动实现。对于任何实现了 FnMut 的类型 F，&amp;mut F 也实现了 FnMut。
另外，因为 FnOnce 是 FnMut 的 父trait，所以任何需要 FnOnce 的地方都可以传入 FnMut。当你需要对一个类似函数类型的参数限定为，可调用多次并且可改变内部状态时，可以使用 FnMut。 Fn
Fn 要和 函数指针 fn 区别，Fn 被那些仅捕获环境中变量不可变引用的闭包，或者不捕获任何东西的闭包，或者函数指针自动实现。需要 Fn或者FnMut 的地方，都可以传入 Fn。如果类型 F 实现 Fn，那么 &amp;F 也将自动实现 Fn。 Deref、DerefMut
Deref 允许我们重载解引用运算符 *，它包含一个 deref 方法：常规引用是一个指针类型，一种理解指针的方式是将其看成指向储存在其他某处值的箭头。下面的示例中创建了一个 i32 值的引用，接着使用解引用运算符来跟踪所引用的数据：定义我们自己的 MyBox 类型，实现 Deref，deref 方法体中写入了 &amp;self.0，这样 deref 返回了我希望通过 * 运算符访问的值的引用。没有 Deref trait 的话，编译器只会解引用 &amp; 引用类型。 隐式引用强制转换
隐式引用强制转换是 Rust 在函数或方法传参上的一种便利，这仅仅用在实现了 Deref 的 trait，隐式引用强制将这样一个类型转换为另一个类型或者引用。例如，&amp;String 转换为 &amp;str，因为 String 实现了 Deref 返回了 &amp;str。 隐式引用强制转换与可变性
类似于如何使用 Deref 重载不可变引用的 * 运算符，Rust 提供了 DerefMut 用于重载可变引用的 * 运算符。
Rust 在发现类型和 trait 实现满足三种情况时会自动进行引用强制转换：当 T: Deref&lt;Target=U&gt; 时从 &amp;T 到 &amp;U；
当 T: DerefMut&lt;Target=U&gt; 时从 &amp;mut T 到 &amp;mut U；
当 T: Deref&lt;Target=U&gt; 时从 &amp;mut T 到 &amp;U； Drop
Drop，其允许我们在值要离开作用域时执行一些代码。可以为任何类型提供 Drop 的实现，同时所指定的代码被用于释放类似于文件或网络连接的资源。在 Rust 中，可以指定每当值离开作用域时被执行的代码，编译器会自动插入这些代码。
指定在值离开作用域时应该执行的代码的方式是实现 Drop。Drop 要求实现一个叫做 drop 的方法，它获取一个 self 的可变引用。 错误
任何程序都不能完全正确地按照开发者的意愿去运行，总会遇到错误，例如打开文件时，文件不存在。Rust 将程序可能出现的错误分为可恢复错误（recoverable）和不可恢复错误（unrecoverable）。可恢复错误通常意味着意料之中的情况，我们可以选择向用户报告错误或者进行重试。不可恢复的错误往往意味着bug，比如数组访问越界。
Rust 中没有异常，如果遇到可恢复错误就返回 Result&lt;T, E&gt; 让开发者处理，遇到不可恢复的错误就 panic!。
 panic!，不可恢复错误
当程序遇到不可处理的异常时，选择 panic 未尝不可。可以通过宏 panic!，退出程序。
当程序 panic 时，程序默认会开始展开（unwinding），这意味着 Rust 会回溯栈并清理它遇到的每一个函数的数据，不过这个回溯并清理的过程有很多工作。另一种选择是直接终止（abort），这会不清理数据就退出程序，那么程序所使用的内存需要由操作系统来清理。如果你需要项目的最终二进制文件越小越好，panic 时通过在 Cargo.toml 的 [profile] 部分增加 panic = 'abort'，可以由展开切换为终止。例如，如果你想要在release模式中 panic 时直接终止：我们可以通过将 RUST_BACKTRACE 设置为一个非 0 的数值，用于在程序 panic 时得到程序的调用栈。这里还提示我们可以通过将 RUST_BACKTRACE 设置为 full，得到更详细的调用栈。 Result，可恢复错误
程序往往不会严重到不能执行，在出现异常情况时，返回一个错误大多是比较合适的处理方式。Rust 中经常通过枚举类型 Result 代表返回一个错误或者一个期望的值。如下面 Result 的定义所示，它被定义为一个泛型，在处理正确时返回 Ok(T)，出现错误时返回错误 Err(E)。我们来看一个打开文件的例子，目的是获得操作文件的句柄，在文件不存在时，我们创建新的文件，如果都失败或者其他未知错误，直接 panic：看着上面层层嵌套的 match，在感叹其强大的匹配功能的同时，也会感慨较深的代码嵌套不易阅读，我们尝试对其进行简化，其中 unwrap_or_else 接受一个闭包，它在前面的返回值没有问题时，直接返回；当遇到错误时，调用我们传入的闭包继续处理，期望返回我们需要的类型。 错误传播
当我们开发一个功能在遇到错误时，经常会选择向上传递错误，让调用者自由选择处理的方式，例如我们开发一个函数，读取指定的文件内容，我们可能会这样写：看到的是，我们使用 match 完成错误匹配，选择继续执行还是返回。但也展现出语法繁琐，所以就有了 ? 运算符。? 在遇到返回值 OK(value)，将取出 value 继续执行，如果遇到 Err，将会返回当前的错误。我们来改写上面的例子：match 表达式与问号运算符所做的有一点不同：? 运算符所使用的错误值被传递给了 from 函数，它定义于标准库的 From trait 中，其用来将错误从一种类型转换为另一种类型。当 ? 运算符调用 from 函数时，收到的错误类型被转换为由当前函数返回类型所指定的错误类型。这在当函数返回单个错误类型来代表所有可能失败的方式时很有用，即使其可能会因很多种原因失败。只要每一个错误类型都实现了 from 函数来定义如何将自身转换为返回的错误类型，? 运算符会自动处理这些转换。总结就是，? 将收集到错误值自动转换为要返回的错误类型。
另外，由于 main 函数是比较特殊的，它返回什么类型是由限制的，一般情况下它的返回值是 ()，但是为了方便，他也允许返回 Result&lt;(), E&gt;，因此，我们也可以在 main 中使用 ?： ? 运算符
? 除了可以用于 Result 类型之外，还可以用于 Option 类型。如果 x 是 Option，那么若 x 是 Some ，对 x? 表达式求值将返回底层值，否则无论函数是否正在执行都将终止且返回 None 。 Option
Option 自己实现了很多有用的方法，可以更快速的完成我们的代码编写。
mapand_thenmap 可以做的 Some -&gt; Some，None -&gt; None 的映射，可以串起来调用，我们来举一个煮饭的例子。map 中返回的是一个新的类型，当然这个类型可以是 Option，不过这将导致 Option 嵌套。
and_then 当 Option 是 None 时，返回 None。否则将 Some 中包裹的值传入闭包函数，这个闭包返回一个新的 Option。 定义错误类型
定义自己的错误类型在传递错误信息时是必要的，我们来看一个例子，将一个字符串数组中的第一个元素转换为数字并且乘以2。下面的代码中我们也定义了自己的 Result 类型，定义自己的错误类型需要实现 Error。 Box&lt;error::Error&gt;
当我们只关注错误信息，而不关注错误类型的时候，我们可以将错误装进 Box，我们对上面的例子稍加修改： 类型转换
Rust 使用 trait 解决类型之间的转换问题。最一般的转换会用到 From 和 Into 两个 trait。
 From、Into
From 定义怎么根据另一种类型生成自己，而在定义 From 之后，我们就自然的获得了 Into，因为它就是 From 倒过来，但是在使用 Into 的时候，我们得指明要转换的类型。 TryFrom、TryInto
类似于 From 和 Into，不过 TryFrom 和 TryInto 用于易出错的转换，他们的返回值类型是 Result 类型。 ToString、FromStr
在我们需要将类型转换成字符串类型时，我们只需实现 ToString，但是最好的是实现 fmt::Display，它会自动提供 to_string() 方法。
另外，我们也经常需要将字符串转换成我们需要的目标类型，只要目标类型实现了 FromStr，我们就可以使用字符串的 parse 方法解析，不过我们得提供要转换到的目标类型，或者使用涡轮鱼（turbo fish）语法。 泛型
泛型可以极大地降低代码重复度，我们可以定义泛型结构体，泛型函数，泛型方法，泛型枚举等。但是我们不用担心泛型的性能，Rust 通过在编译时进行泛型代码的单态化(monomorphization)来保证效率。单态化是一个通过填充编译时使用的具体类型，将通用代码转换为特定代码的过程。
枚举结构体和方法函数trait泛型枚举我们最常见的应该是：Option 和 Result。
也可以参考： https://doc.rust-lang.org/stable/rust-by-example/generics/gen_trait.html#traits 智能指针
指针是一个包含内存地址变量的通用概念，rust 中使用 &amp; 或者 ref 引用一个变量。智能指针是一类数据结构，他们的表现类似指针，但是也拥有额外的元数据和功能。在 Rust 中，普通引用和智能指针的一个额外的区别是引用是一类只借用数据的指针；相反，在大部分情况下，智能指针拥有他们指向的数据。
本节介绍几个常见的智能指针类型。
 Box 指向堆上的数据
Box&lt;T&gt; 将数据存储在堆上，留在栈上的仅仅是数据的指针，除此之外，box 没有性能损失。它们多用于如下场景：当在编译时不确定类型大小，又想在需要确切大小的上下文中使用时，例如，使用 Box&lt;dyn error:Error&gt; 动态分发；
当有大量数据并希望在转移所有权的时候，不发生数据拷贝；
当希望拥有一个值并只关心它的类型是否实现了特定 trait 而不是其具体类型的时候； 数据存储在堆上
如下示例，定义了变量 b，其值是一个指向被分配在堆上的值 5 的 Box。我们可以像数据是储存在栈上的那样访问 box 中的数据，正如任何拥有数据所有权的值那样，当像 b 这样的 box 在 main 的末尾离开作用域时，它将被释放。 创建递归类型
Rust 需要在编译时知道类型占用多少空间。一种无法在编译时知道大小的类型是 递归类型（recursive type），其值的一部分可以是相同类型的另一个值。我们探索一下 cons list，一个函数式编程语言中的常见类型，来展示这个（递归类型）概念。
cons list 的每一项都包含两个元素：当前项的值和下一项。其最后一项值包含一个叫做 Nil 的值且没有下一项。cons list 通过递归调用 cons 函数产生。代表递归的终止条件（base case）的规范名称是 Nil，它宣布列表的终止。
下面这段代码是不能编译通过的，编译提示我们这个类型大小无限大：另外编译器还提醒我们，不能直接存储一个值，而是应该存储一个指向这个值的指针，还提示我们应该用 Box&lt;List&gt;：
= help: insert indirection (e.g., a `Box`, `Rc`, or `&amp;`) at some point to
make `List` representable因为 Box&lt;T&gt; 是一个指针，我们总是知道它需要多少空间：指针的大小并不会根据其指向的数据量而改变，我们对上面的程序做出修改： Rc 引用计数
大部分情况下所有权是非常明确的：可以准确地知道哪个变量拥有某个值。然而，有些情况单个值可能会有多个所有者。例如，在图数据结构中，多个边可能指向相同的节点，而这个节点从概念上讲为所有指向它的边所拥有。节点直到没有任何边指向它之前都不应该被清理。
为了启用多所有权，Rust 有一个叫做 Rc&lt;T&gt; 的类型。其名称为 引用计数（reference counting）的缩写。引用计数意味着记录一个值引用的数量来知晓这个值是否仍在被使用。如果某个值有零个引用，就代表没有任何有效引用并可以被清理。
可以将其想象为客厅中的电视。当一个人进来看电视时，他打开电视。其他人也可以进来看电视。当最后一个人离开房间时，他关掉电视因为它不再被使用了。如果某人在其他人还在看的时候就关掉了电视，正在看电视的人肯定会抓狂的！
Rc&lt;T&gt; 用于当我们希望在堆上分配一些内存供程序的多个部分读取，而且无法在编译时确定程序的哪一部分会最后结束使用它的时候。如果确实知道哪部分是最后一个结束使用的话，就可以令其成为数据的所有者，正常的所有权规则就可以在编译时生效。Rc&lt;T&gt; 只能用于单线程场景 使用 Rc&lt;T&gt; 共享数据
我们继续看上面的例子，这一次，我们希望创建两个共享第三个列表所有权的列表，其概念将会看起来如下图所示：我们使用之前的 Box&lt;List&gt; 尝试时，发现编译失败：我们修改 List 的定义为使用 Rc&lt;T&gt; 代替 Box&lt;T&gt;，现在每一个 Cons 变量都包含一个值和一个指向 List 的 Rc&lt;T&gt;。当创建 b 时，不同于获取 a 的所有权，这里会克隆 a 所包含的 Rc&lt;List&gt;，这会将引用计数从 1 增加到 2 并允许 a 和 b 共享 Rc&lt;List&gt; 中数据的所有权。创建 c 时也会克隆 a，这会将引用计数从 2 增加为 3。每次调用 Rc::clone，Rc&lt;List&gt; 中数据的引用计数都会增加，直到有零个引用之前其数据都不会被清理。 Rc::strong_count
可以使用 Rc::strong_count 查看 Rc&lt;T&gt; 的引用计数值。这将输出：
count after creating a = 1
count after creating b = 2
count after creating c = 3
count after c goes out of scope = 2 RefCell
内部可变性（Interior mutability）是 Rust 中的一个设计模式，它允许你即使在有不可变引用时也可以改变数据，这通常是借用规则所不允许的。不同于 Rc&lt;T&gt;，RefCell&lt;T&gt; 代表其数据的唯一的所有权。我们之前学习的借用规则是这样的：在任意给定时刻，只能拥有一个可变引用或任意数量的不可变引用之一（而不是两者）。
引用必须总是有效的。对于引用和 Box&lt;T&gt;，借用规则的不可变性作用于编译时。对于 RefCell&lt;T&gt;，这些不可变性作用于运行时。对于引用，如果违反这些规则，会得到一个编译错误。而对于 RefCell&lt;T&gt;，如果违反这些规则程序会 panic 并退出。
在编译时检查借用规则的优势是这些错误将在开发过程的早期被捕获，同时对运行时没有性能影响，因为所有的分析都提前完成了。为此，在编译时检查借用规则是大部分情况的最佳选择，这也正是其为何是 Rust 的默认行为。相反在运行时检查借用规则的好处则是允许出现特定内存安全的场景，而它们在编译时检查中是不允许的。静态分析，正如 Rust 编译器，是天生保守的。
因为一些分析是不可能的，如果 Rust 编译器不能通过所有权规则编译，它可能会拒绝一个正确的程序；从这种角度考虑它是保守的。如果 Rust 接受不正确的程序，那么用户也就不会相信 Rust 所做的保证了。然而，如果 Rust 拒绝正确的程序，虽然会给程序员带来不便，但不会带来灾难。RefCell&lt;T&gt; 正是用于当你确信代码遵守借用规则，而编译器不能理解和确定的时候。
如下为选择 Box&lt;T&gt;，Rc&lt;T&gt; 或 RefCell&lt;T&gt; 的理由：Rc&lt;T&gt; 允许相同数据有多个所有者；Box&lt;T&gt; 和 RefCell&lt;T&gt; 有单一所有者。
Box&lt;T&gt; 允许在编译时执行不可变或可变借用检查；Rc&lt;T&gt; 仅允许在编译时执行不可变借用检查；RefCell&lt;T&gt; 允许在运行时执行不可变或可变借用检查。
因为 RefCell&lt;T&gt; 允许在运行时执行可变借用检查，所以我们可以在即便 RefCell&lt;T&gt; 自身是不可变的情况下修改其内部的值。RefCell&lt;T&gt; 只能用于单线程场景来看一个例子，我们定义了 Messenger 用于发送消息，真实场景可能是发送短信或者发送邮件，注意它的 receiver 是 &amp;ref；然后我们定义结构体 LimitTracker，它用来实现我们的业务功能，当调用它的 set_value 方法时，根据业务逻辑发送不同的消息。现在我们对 LimitTracker 的功能进行测试，但是肯定不能真正实现 Messenger，所以需要对其打桩，计划是对其进行 Mock，记录发送的消息，初步计划是这样的：不出意外，编译失败，不能对不可变引用做修改：按照编译器的提示，改成这样，依然编译失败，receiver 类型不匹配：然后我们引出我们今天的大招，RefCell，看下面的修改，我们使用 borrow_mut 和 borrow 分别在运行时进行可变借用和不可变借用： 结合 Rc&lt;T&gt; 和 RcCell&lt;T&gt;
Rc&lt;T&gt; 通过引用计数的方式可以让一个值有多个所有者，RcCell&lt;T&gt; 可以在运行时获取值的可变引用对其修改。下面的例子中，通过对 value 的修改，a，b，c 都改了。]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>rust基础</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】并发</title>
    <url>/2022/05/03/Rust/%E3%80%90Rust%E3%80%91%E5%B9%B6%E5%8F%91/</url>
    <content><![CDATA[Rust 提供了一种非常好的并发使用方法，它不强制所有程序采用单一风格，而是通过安全地支持多种风格，并由编译器强制执行。我们将介绍三种使用 Rust 线程的方法：Fork-join 并行；
通道（Chanel）；
共享可变状态；在此过程中，将使用到目前为止所学的有关 Rust 语言的所有内容，Rust 对引用、可变性和生命周期的关注在单线程程序中足够有价值，但在并发编程中，这些规则的真正意义变得显而易见。
 Fork-Join Parallelism
最简单的用于多线程的案例是处理互不相干的任务，例如，我们要处理大量的文档，可能会这样写：因为每个文档是被单独处理的，所以很容易分成线程来加速处理，如下图所示：这种模式称为 fork-join，fork 就是启动一个新线程，join 一个线程就是等待它完成，这种模式之所以具有吸引力，有以下原因：没有瓶颈，fork-join 中没有共享资源的锁定，唯一一次任何线程必须等待另一个线程是在最后。同时，每个线程都可以自由运行，这有助于保持较低的任务切换开销；性能提升明显，在最好的情况下，通过启动4个线程，我们可以在4分之一的时间内完成我们的工作，然而我们不应该期望达到这种理想加速。但是对于任何具有独立工作单元的 CPU 密集型程序都可以期待显着的提升；很容易保证序的正确性，只要线程真正隔离，fork-join 程序就是确定性的，无论线程速度如何变化，程序总是产生相同的结果，这是一个没有竞争条件的并发模型。 线程创建和等待
可以使用 std::thread::spawn 启动一个新线程：它接受一个参数，一个 FnOnce 闭包或函数，Rust 启动一个新线程来运行该闭包或函数的代码。新线程是一个真正的操作系统线程，具有自己的堆栈，就像 C++、C# 和 Java 中的线程一样。
下面是一个实现本节开始并行处理文档的例子：使用 .spawn() 启动一个新线程处理 worklist，它返回 std::thread::JoinHandle，我们使用 move 将 worklist 放进我们新建的闭包函数，这个代价是很低的，不涉及到内存的申请和释放，只是所有权的转移而已。
然后我们通过调用 JoinHandle 的 .join() 方法等待每个线程完成。等待线程完成通常是正确性所必需的，因为 Rust 程序在 main 返回时立即退出，即使其他线程仍在运行，这样未结束的线程就被杀死了。如果这不是想要的，确保在从 main 返回之前等待子线程完成。
 跨线程错误处理
我们再来看看 .join() 的方法的使用，它实际上为我们做了两件事：首先，handle.join() 返回一个 std::thread::Result 即使子线程发生 panic，这使得 Rust 中的线程比 C++ 中的线程更加健壮。在 C++ 中，越界数组访问是未定义的行为，并且无法保护系统的其余部分免受影响。在 Rust 中，panic 是安全的并且每个线程都是安全的，线程之间的边界充当panic的防火墙，panic不会自动从一个线程传播到依赖它的线程。而是一个线程中的 panic 会在其他线程中报告为错误结果，整个程序可以轻松恢复。
但是，在我们的程序中，我们没有处理任何错误。而是，我们立即在这个 Result 上使用 .unwrap()，断言它是 Ok 结果而不是 Err 结果。如果子线程确实 panic，那么这个断言就会失败，所以父线程也会 panic，我们明确地将panic从子线程传播到父线程。
其次，handle.join() 将子线程的返回值传递回父线程。我们传递给 spawn 的闭包的返回类型是 io::Result&lt;()&gt;，因为这是 process_files 返回的，这个返回值不会被丢弃。当子线程完成时，它的返回值被保存，并且 JoinHandle::join() 将该值传回给父线程。
在这个程序中，handle.join() 返回的完整类型是 std::thread::Result&lt;std::io::Result&lt;()&gt;&gt;。thread::Result 是 spawn/join API 的一部分，io::Result 是我们应用程序的一部分。
在我们的例子中，在展开 thread::Result 之后，我们在 io::Result 上使用 ? 运算符，将 I/O 错误从子线程显式传播到父线程。
所有这些似乎都相当复杂，但是 Rust 中只有一行代码。Java 和 C# 中的默认行为是将子线程中的异常转储到终端然后丢掉。在 C++ 中，默认设置是中止进程。在 Rust 中，错误是 Result（数据）而不是异常（控制流），它们像任何其他值一样跨线程传递。当使用低级线程 API 时，都需要编写对错误的处理，但 Rust 中只要处理 Result 即可。
 跨线程共享不可变数据
假设我们正在进行的分析需要一个包含大量英语单词和短语的数据库，需要对我们之前的方法进行修改：由于 glossary 比较大，所以我们通过引用传递，但是我们如何在多线程之间使用它，如果仅仅是下面这样处理，肯定会报错：编译错误：
error[E0621]: explicit lifetime required in the type of `glossary` --&gt; src/lib.rs:75:17
|
61 | glossary: &amp;GigabyteMap)
| ------------ help: add explicit lifetime `'static` to the
type of `glossary`: `&amp;'static BTreeMap&lt;String,
String&gt;`
...
75 | spawn(move || process_files(worklist, glossary))
| ^^^^^ lifetime `'static` required因为，spawn 启动独立线程，Rust 无法知道子线程将运行多长时间，因此它假设最坏的情况：它假设即使在父线程完成并且父线程中的所有值都消失后，子线程仍可能继续运行。显然，如果子线程要持续那么长时间，它运行的闭包也需要持续那么长时间，但是这个闭包有一个有限的生命周期：它依赖于glossary的引用。
Rust 拒绝此代码是正确的！我们编写此函数的方式是，一个线程可能会遇到 I/O 错误，导致 process_files_in_parallel 在其他线程完成之前退出，子线程最终可能会在主线程释放 glossary 后尝试使用它。似乎 spawn 过于开放，无法支持跨线程共享引用。我们之前的解决方案是使用move闭包将数据的所有权转移到新线程。这在这里行不通，因为我们有很多线程都需要使用相同的数据。一种安全的替代方法是为每个线程克隆整个词汇表，但由于它很大，我们希望避免这种情况。幸运的是，标准库提供了 std::sync::Arc。我们更改了glossary的类型：要并行运行分析，调用者必须传入一个 Arc&lt;GigabyteMap&gt;，这是一个指向已移动到堆中的 GigabyteMap 的智能指针，通过使用 Arc::new(giga_map) 创建。
当我们调用glossary.clone() 时，我们正在创建 Arc 智能指针的副本，而不是整个 GigabyteMap，这相当于增加引用计数。
通过此更改，程序可以编译并运行，因为它不再依赖于引用生命周期。只要任何线程拥有 Arc&lt;GigabyteMap&gt;，它就会使地图保持活动状态，即使父线程提前退出。也不存在任何数据竞争，因为 Arc 中的数据是不可变的。 Rayon
Rayon 提供了两种并发机制：rayon::join(fn1, fn2) 调用这两个函数并返回两个结果。.par_iter() 方法创建一个 ParallelIterator，一个带有 map、filter 和其他方法的值，很像 Rust 迭代器。在这两种情况下，Rayon 都会尽可能使用自己的工作线程池来分散工作。只需告诉 Rayon 可以并行完成哪些任务，Rayon 管理线程并尽其所能分配工作。
下图说明了对调用 giant_vector.par_iter().for_each(...) 的两种方式。 (a) Rayon 就像它为向量中的每个元素生成一个线程一样。 (b) 在幕后，Rayon 每个 CPU 核心有一个工作线程，效率更高，这个工作线程池由程序的所有线程共享。当数以千计的任务同时进入时，Rayon 会分工。使用 Rayon 编写的 process_files_in_parallel：在背后，Rayon 使用work-stealing技术动态平衡线程间的工作负载。Rayon 支持跨线程共享引用，任何发生在幕后的并行处理都保证在 reduce_with 返回时完成。
 Channel
通道是用于将值从一个线程发送到另一个线程的单向管道，换句话说，它是一个线程安全的队列。
下图说明了如何使用通道，它们有点像 Unix 管道：一端用于发送数据，另一端用于接收，两端通常由两个不同的线程拥有。但是 Unix 管道用于发送字节，而通道用于发送 Rust 值。sender.send(item) 将单个值放入通道，receiver.recv() 删除一个，所有权从发送线程转移到接收线程，如果通道为空，receiver.recv() 会阻塞，直到发送一个值。使用通道，线程可以通过相互传递值来进行通信。这是线程协同工作的一种非常简单的方式，无需使用锁定或共享内存。
这不是一项新技术，Erlang 已经有 30 年的隔离进程和消息传递了。Unix 管道已经存在了将近 50 年。我们倾向于认为管道提供了灵活性和可组合性，而不是并发性，但实际上，它们完成了上述所有工作。下图是 Unix 管道的示例，所有三个程序都可以同时运行。Rust 通道比 Unix 管道快。发送一个值会移动它而不是复制它，即使你正在移动包含许多兆字节数据的数据结构也是很快的。
 Send
接下来我们将使用通道来构建一个创建倒排索引的并发程序，倒排索引是搜索引擎的关键要素之一，每个搜索引擎都处理特定的文档集合，倒排索引是告诉哪些单词出现在哪里的数据库。
我们的程序结构为管道，如下图所示。管道只是使用通道的众多方式之一。我们将使用总共五个线程，每个线程执行不同的任务。每个线程在程序的生命周期内不断产生输出。例如，第一个线程只是将源文档从磁盘一个一个地读取到内存中。（我们需要一个线程来执行此操作，因为我们将在这里编写最简单的代码，使用 fs::read_to_string，这是一个阻塞 API，我们不希望 CPU 在磁盘工作时处于空闲状态。）这个阶段的输出是每个文档一个长字符串，所以这个线程通过一个字符串通道连接到下一个线程。
首先我们创建新线程处理文档，假设这里的 documents 是 Vec&lt;PathBuf&gt;：Channel 是 std::sync::mpsc 模块的一部分，首先来看创建通道的代码：.channel() 返回了一对值，发送通道和接收通道，我们将使用这个通道来发送每个文件的文本，所以我们有一个 Sender&lt;String&gt; 类型的发送者和一个 Receiver&lt;String&gt; 类型的接收者。我们可以通过编写 mpsc::channel::&lt;String&gt;() 明确地请求字符串通道。但是，我们让 Rust 的类型推断来解决这个问题。
我们使用 thread::spawn 创建了新线程，并且使用 move 将 sender的所有权转移给我们新建的线程：在成功读取到数据之后，我们使用将内容发送到通道中：sender.send(text) 将值文本移动到通道中。最终，它将再次转移到接收价值的人手中。无论文本包含 10 行文本还是 10MB 字节，此操作都会复制3个机器字（String 结构体的大小），相应的接收器 .recv() 调用也会复制3个机器字。
send 和 recv 方法都返回结果，但这些方法只有在通道的另一端被丢弃时才会失败。如果 Receiver 已被丢弃，则发送调用失败，否则该值将永远位于通道中但没有 Receiver，任何线程都无法接收它。同样，如果通道中没有等待的值并且 Sender 已被丢弃，则 recv 调用将失败，否则 recv 将永远等待但没有 Sender，任何线程都无法发送下一个值。
在我们的代码中，sender.send(text) 只有当接收者的线程提前退出时才会失败，这对于使用通道的代码很典型，无论这是故意发生的还是由于错误，我们的接收者线程都可以安静地自行关闭。
程序运行结束时返回 Ok(())，闭包返回的是 Result，如果线程遇到错误会立即返回，错误被存储在线程的 JoinHandle 中。
为方便起见，我们的程序将所有这些代码包装在一个函数中，该函数返回接收器（我们尚未使用）和新线程的 JoinHandle：这个函数启动新线程并且立即返回。
 Receiving
我们来创建第二个线程使用一个循环并且调用 .loop() 接收值：或者由于 Receiver 是可迭代类型，可以这样写：这两个循环是等价的，无论哪种方式，如果在控制到达循环顶部时通道恰好是空的，则接收线程将阻塞，直到其他线程发送一个值。当通道为空且 Sender 已被丢弃时，循环将正常退出。在我们的程序中，这会在读取线程退出时自然发生。该线程正在运行一个拥有变量 sender 的闭包，当闭包退出时，发送者被丢弃。现在我们可以为管道的第二阶段编写代码：此函数生成一个线程，该线程从一个通道（文本）接收字符串值并将 InMemoryIndex 值发送到另一个通道（发送方/接收方）。该线程的工作是获取在第一阶段加载的每个文件，并将每个文档变成一个小的单文件内存倒排索引。
这个线程的主循环很简单，索引文档的所有工作都由函数 InMemoryIndex::from_single_document 完成。我们不会在这里展示它的源代码，但它会在单词边界处拆分输入字符串，然后生成从单词到位置列表的映射。此阶段不执行 I/O，因此不必处理 io::Error。它返回 ()，而不是 io::Result&lt;()&gt;。
 Pipeline
其余3个阶段的设计相似，每个人都使用前一阶段创建的接收器。我们对管道其余部分的目标是将所有小索引合并到磁盘上的单个大索引文件中。我们发现最快的方法是分3个阶段，我们不会在这里展示代码，只展示这3个函数的类型签名。
首先，我们在内存中合并索引（第 3 阶段）：将这些大索引写入磁盘（第 4 阶段）：最后，如果我们有多个大文件，我们使用基于文件的合并算法将它们合并（第 5 阶段）：现在，我们将所有的代码整合在一起：和以前一样，我们使用 .join().unwrap() 将 panic 从子线程显式传播到主线程。这里唯一的另一个不寻常的事情是，没有立即使用 ? 马上，我们将 io::Result 值放在一边，直到我们加入所有四个线程。
该管道比单线程等效管道快 40%，有提升但是我们显然还没有使系统的 I/O 或所有 CPU 饱和。
因为管道就像制造工厂中的装配线：性能受到最慢阶段的吞吐量的限制。一条全新的、未经调整的装配线可能与单位生产一样慢，但装配线奖励有针对性的调整。在我们的案例中，测量表明第二阶段是瓶颈。我们的索引线程使用 .to_lowercase() 和 .is_alphanumeric()，因此它会花费大量时间在 Unicode 表中查找。索引下游的其他阶段大部分时间都在 Receiver::recv 中休眠，等待输入。
这意味着我们应该能够走得更快，随着我们解决瓶颈问题，并行度将会提高。既然知道如何使用通道并且我们的程序是由独立的代码片段组成的，那么很容易找到解决第一个瓶颈的方法。我们可以手动优化第二阶段的代码，就像任何其他代码一样，将工作分成两个或多个阶段，或一次运行多个文件索引线程。
 功能和性能
std::sync::mpsc 的 mpsc 部分代表多生产者单消费者，这是对 Rust 通道提供的通信类型的简洁描述。
我们示例程序中的通道将值从单个发送者传送到单个接收者，这是一个相当普遍的情况。但是 Rust 通道也支持多个发送者，以防你需要一个线程来处理来自多个客户端线程的请求，如下图所示：Sender&lt;T&gt; 实现了 Clone。要获得具有多个 Sender 的 Channel，只需创建一个常规 Channel 并根据需要多次克隆 Sender，可以将每个 Sender 移动到不同的线程。Receiver&lt;T&gt; 不能被克隆，所以如果你需要多个线程从同一个通道接收值，你需要一个 Mutex。
Rust 通道经过精心优化，首次创建通道时，Rust 使用特殊的“一次性”队列实现。如果只通过通道发送一个对象，则开销是最小的，如果发送第二个值，Rust 会切换到不同的队列实现。实际上，它正在为长期稳定做好准备，让通道准备好传输许多值，同时最大限度地减少分配开销。如果克隆 Sender，Rust 必须依靠另一种实现，当多个线程尝试同时发送值时，这种实现是安全的。但即使是这三种实现中最慢的也是无锁队列，所以发送或接收一个值至多是几个原子操作和一个堆分配，再加上移动本身。仅当队列为空并且接收线程因此需要使自己进入睡眠状态时才需要系统调用。当然，在这种情况下，通过Chaneel的流量无论如何都不会达到最大值。
尽管进行了所有优化工作，但应用程序很容易在通道性能方面犯一个错误：发送值的速度超过了接收和处理的速度。这会导致越来越多的积压值在渠道中累积。例如，在我们的程序中，我们发现文件读取线程（阶段 1）可以比文件索引线程（阶段 2）更快地加载文件。结果是数百兆字节的原始数据将从磁盘读取并立即填充到队列中。
这种不当行为会消耗内存并伤害局部性。更糟糕的是，发送线程继续运行，占用 CPU 和其他系统资源来发送更多的值，而这些资源正好在接收端最需要这些资源。
这里 Rust 再次从 Unix 管道中获取一个技巧，Unix 使用了一个优雅的技巧来提供一些背压，以便快速发送者被迫放慢速度：Unix 系统上的每个管道都有固定的大小，如果一个进程试图写入一个暂时已满的管道，系统会简单地阻止该进程 直到管道中有空间，Rust 也有类似的，称为同步通道：同步通道与常规通道完全相同，只是在创建它时，指定它可以保存多少个值。对于同步通道，sender.send(value) 可能是一个阻塞操作。毕竟，这个想法是阻塞并不总是坏事。在我们的示例程序中，将 start_file_reader_thread 中的通道更改为可容纳 32 个值的 sync_channel 将我们的基准数据集的内存使用量减少了三分之二，而不会降低吞吐量。
 Send、Sync
到目前为止，我们一直认为所有值都可以在线程之间自由移动和共享。这基本上是正确的，但 Rust 的完整线程安全取决于两个内置 Trait，std::marker::Send 和 std::marker::Sync。实现 Send 的类型可以安全地按值传递给另一个线程，它们可以跨线程移动；实现 Sync 的类型可以安全地通过非 mut 引用传递给另一个线程，它们可以跨线程共享；这里的安全指的是：没有数据竞争和其他未定义的行为，前面我们使用闭包将 Vec&lt;String&gt; 从父线程传递给每个子线程。我们当时没有指出，但这意味着 vector 及其字符串在父线程中分配，但在子线程中释放。Vec&lt;String&gt; 实现 Send 的事实是：Vec 和 String 内部使用的内存分配器是线程安全的。（如果要使用快速但非线程安全的分配器编写自己的 Vec 和 String 类型，则必须使用 非 Send 类型来实现它们，例如不安全的指针。Rust 会推断 NonThreadSafeVec 和 NonThreadSafeString 类型不是 Send 并将它们限制为单线程使用，但这比较少见。）
如下图所示，大多数类型都是 Send 和 Sync， 甚至不必使用 #[derive]，Rust 会自动处理。如果结构或枚举的字段为 Send，则结构或枚举为Send，如果其字段为Sync，则为Sync。有些类型是Send，但不是 Sync。这通常是有目的的，例如 mpsc::Receiver，它保证 mpsc 通道的接收端一次只被一个线程使用。
少数既不是 Send 也不是 Sync 的类型主要是那些以非线程安全的方式使用可变性的类型。例如，考虑 std::rc::Rc&lt;T&gt;，引用计数智能指针的类型。
如果 Rc&lt;String&gt; 是 Sync，允许线程通过共享引用共享单个 Rc，会发生什么？如果两个线程碰巧同时尝试克隆 Rc，如下图所示，我们就会发生数据竞争，因为两个线程都会增加共享引用计数。引用计数可能变得不准确，从而导致 use-afterfree 或 double free 行为。而且 Rust 是不会让这样的代码编译通过的：编译出错：
error[E0277]: `Rc&lt;String&gt;` cannot be sent between threads safely
  --&gt; src/main.rs:9:5
    |
9   |       thread::spawn(move || {
    |  _____^^^^^^^^^^^^^_-
    | |     |
    | |     `Rc&lt;String&gt;` cannot be sent between threads safely
10  | |         // error
11  | |         rc2.clone();
12  | |     });
    | |_____- within this `[closure@src/main.rs:9:19: 12:6]`
    |
    = help: within `[closure@src/main.rs:9:19: 12:6]`, the trait `Send` is not implemented for `Rc&lt;String&gt;`
    = note: required because it appears within the type `[closure@src/main.rs:9:19: 12:6]`
note: required by a bound in `spawn`
  --&gt; /Users/fudenglong/.rustup/toolchains/nightly-aarch64-apple-darwin/lib/rustlib/src/rust/library/std/src/thread/mod.rs:646:8
    |
646 |     F: Send + 'static,
    |        ^^^^ required by this bound in `spawn`可以看到 Send 和 Sync 帮助 Rust 加强线程安全，它们在跨线程边界传输数据的函数的类型签名中显示为边界。当生成一个线程时，传递的闭包必须是 Send，这意味着它包含的所有值都必须是 Send。类似地，如果想通过一个通道向另一个线程发送值，这些值必须是 Send。
 迭代 Pipeline
如果我们能使用迭代器的方法处理我们之前的倒排索引，就会显得很清晰，例如：因为 Trait 允许我们为标准库类型添加功能，所以我们可以这样做：简而言之，这就是 Rust 的特点：我们可以自由地为该语言中的几乎每个迭代器添加一个新方法。
 Beyond Pipelines
前面我们使用管道作为示例，因为管道是使用通道的一种很好的、​​明显的方式，每个人都理解他们。它们是具体的、实用的和确定性的。不过，通道不仅仅对管道有用。它们也是向同一进程中的其他线程提供任何异步服务的一种快速、简单的方法。
例如，假设想在自己的线程上进行日志记录，其他线程可以通过通道向日志线程发送日志消息；由于可以克隆通道的Sender，因此许多客户端线程可以拥有Sender，而接收者处理只有一个。日志记录线程可以在需要时轮换日志文件，它不必与其他线程进行任何协调。
到目前为止，已经介绍的工具——用于高度并行计算的 fork-join、用于松散连接组件的通道——对于广泛的应用程序来说已经足够了，但还不够。
 共享可变状态
如何在多个线程之间共享可变数据？可以通过创建一个新线程来解决此问题，该线程的全部工作是管理此可变数据，其他线程将通过通道与其通信。当然，这会花费一个线程，这会产生一些操作系统开销。另一种选择是使用 Rust 提供的工具来安全地共享可变数据，互斥锁、读/写锁、条件变量和原子整数。 什么是 Mutex？
互斥体（或锁）用于强制多个线程在访问某些数据时轮流进行，我们将在下一节介绍 Rust 的互斥锁。首先，回忆一下其他语言中的互斥锁是什么是有意义的。 C++ 中互斥锁的简单使用可能如下所示：调用 mutex.Acquire() 和 mutex.Release() 标记此代码中关键部分的开始和结束。对于程序中的每个互斥体，一次只能在临界区内运行一个线程。 如果一个线程处于临界区，则调用 mutex.Acquire() 的所有其他线程将阻塞，直到第一个线程到达 mutex.Release()。
我们说互斥体保护数据：在这种情况下，互斥体保护 waitingList。但是，程序员有责任确保每个线程在访问数据之前总是获取互斥锁，然后再释放它。
它们防止数据竞争，即竞争线程同时读取和写入相同内存的情况。即使不存在数据竞争，即使所有读取和写入都按程序顺序一一发生，如果没有互斥锁，不同线程的操作也可能以任意方式交错。
当然，所有这些实际上都是同一个原因：不受控制的竞争条件使编程变得棘手，而互斥锁就是为了解决这种混乱。然而，在大多数语言中，互斥锁很容易搞砸。 在 C++ 中，与大多数语言一样，数据和锁是独立的对象。但是即使有注释，编译器也不能在这里强制安全访问。当一段代码忽略获取互斥锁时，我们会得到未定义的行为。实际上，这意味着极难重现和修复的错误。即使在 Java 中，对象和互斥体之间存在一些概念上的关联，这种关系也不是很深。编译器不会尝试强制执行它，实际上，受锁保护的数据很少完全是关联对象的字段，它通常包含多个对象中的数据。
 Mutex&lt;T&gt;
其他语言的锁看起来不那么好有两点：一个是锁和数据独立，一个是编译器不能进行强制检查可能存在竞争的数据是否受锁保护。继续前面的例子，我们来看 Rust 的解决方案：不像 c++，数据是锁的一部分。创建一个新的 Mutex 看起来像创建一个新的 Box 或 Arc，但 Box 和 Arc 表示堆分配，Mutex 只是关于锁定。如果希望在堆中分配 Mutex，则必须像我们在这里通过对整个应用程序使用 Arc::new 和仅对受保护数据使用 Mutex::new 所做的那样。这些类型通常一起使用：Arc 可方便地跨线程共享事物，而 Mutex 可方便地用于跨线程共享的可变数据。
我们可以看下如何使用锁，唯一获取数据的方式是使用 self.waiting_list.lock()，它可以一直阻塞到数据可以获取。guard 的类型是 MutexGuard&lt;WaitingList&gt;，由于实现了 Deref，所以我们可以直接调用 guard.push(player)：guard 甚至允许我们借用对基础数据的直接引用。Rust 的生命周期系统确保这些引用不会超过 guard 本身。如果不持有锁，就无法访问 Mutex 中的数据。当 guard 离开作用域时，锁被释放，通常这发生在块的末尾，但也可以手动删除它： mut 和 Mutex
上面的例子中，我们的 join_waiting_list 方法的第一个参数竟然是 &amp;self：但是我们调用的 push 方法需要可变引用：互斥锁提供对内部数据的独占（mut）访问，即使许多线程可能对互斥锁本身具有共享（非mut）访问。Rust 的类型系统告诉我们 Mutex 做了什么。它动态地强制执行独占访问，这通常由 Rust 编译器在编译时静态完成，这其实类似于 内部可变性。
 Mutex 无法解决的问题
几乎可以肯定，Rust 互斥锁的设计会让你比以往任何时候都更系统、更明智地使用互斥锁。但是值得停下来思考一下 Rust 的安全保证可以和不能帮助什么。安全的 Rust 代码不能触发数据竞争，这是一种特定类型的错误，其中多个线程同时读取和写入相同的内存，从而产生毫无意义的结果。这很棒：数据竞争总是错误的，在真正的多线程程序中并不罕见。但是，使用互斥锁的线程会遇到 Rust 无法解决其他一些问题：有效的 Rust 程序不能有数据竞争，但它们仍然可以有其他竞争条件——程序的行为取决于线程之间的时间，因此可能因运行而异。一些竞争条件是良性的。有些表现为一般的脆弱性和难以修复的错误，以非结构化方式使用互斥锁会引发竞争条件；共享可变状态也会影响程序设计。通道在代码中充当抽象边界，便于分离隔离的组件以进行测试，互斥锁鼓励“仅添加方法”的工作方式，这可能导致相互关联的代码的整体块；最后，互斥锁并不像一开始看起来那么简单，正如接下来的两节将展示的那样； Deadlock
线程可以通过尝试获取它已经持有的锁来使自己死锁：假设第一次调用 self.waiting_list.lock() 成功，获得了锁。第二个调用看到锁被持有，所以它阻塞，等待它被释放。它将永远等待。等待线程是持有锁的线程。
换句话说，互斥锁中的锁不是递归锁。
这里的错误很明显。在实际程序中，两个 lock() 调用可能在两个不同的方法中，其中一个调用另一个。每个方法的代码，分开来看，看起来不错。还有其他方法可以导致死锁，涉及多个线程，每个线程一次获取多个互斥锁。 Rust 的借用系统无法做到避免死锁。最好的保护措施是将关键部分保持在较小的范围内：进入，完成工作，然后退出。
也有可能与渠道陷入僵局。例如，两个线程可能会阻塞，每个线程都在等待从另一个接收消息。然而，再一次，好的程序设计可以让你高度相信这在实践中不会发生。在管道中，就像我们的倒排索引构建器一样，数据流是非循环的。在这样的程序中，死锁的可能性与在 Unix shell 管道中一样。
 Poisoned Mutexes
Mutex::lock() 返回 Result 的原因与 JoinHandle::join() 所做的相同：如果另一个线程发生panic，则优雅地失败。当我们编写 handle.join().unwrap() 时，我们是在告诉 Rust 将 panic 从一个线程传播到另一个线程，mutex.lock().unwrap() 类似。
如果线程在持有 Mutex 时发生 panic，Rust 会将 Mutex 标记为 Poisoned。任何后续尝试锁定 Poisoned Mutex 都会得到错误结果。如果发生这种情况，我们的 .unwrap() 调用会告诉 Rust panic，将 panic 从另一个线程传播到这个线程。
有一个Poisoned互斥锁有多糟糕？毒药听起来很致命，但这种情况并不一定是致命的。panic是安全的，一个 panic 线程使程序的其余部分处于安全状态。
因此，互斥锁因 panic 而 Poisoned 原因并不是因为害怕未定义的行为。相反，担心的是一直在使用不变量进行编程。由于程序在没有完成它正在做的事情的情况下 panic 并退出了关键部分，可能已经更新了受保护数据的某些字段但没有更新其他字段，因此不变量现在可能已损坏。 Rust 会毒化互斥体，以防止其他线程无意中误入这种损坏的情况并使其变得更糟。但仍然可以锁定中毒的互斥体并访问其中的数据，完全强制互斥，请看 PoisonError::into_inne() 的文档。
 多消费者通道
我们前面提到，Rust 的通道是多生产者，单消费者。或者更具体地说，一个通道只有一个 Receiver。我们不能有一个线程池，其中许多线程使用单个 mpsc 通道作为共享工作列表。
然而，事实证明有一个非常简单的解决方法，只使用标准库片段。我们可以在 Receiver 周围添加一个 Mutex 并无论如何共享它。这是一个这样做的模块： 读写锁
互斥锁只有一个 .lock()，而std::sync::RwLock 有两种锁方法，.read() 和 .write()，RwLock::write 方法类似于 Mutex::lock。它等待对受保护数据的独占 mut 访问。RwLock::read 方法提供 non mut 访问，其优点是不必等待，因为许多线程可以安全地一次读取。使用互斥锁，在任何给定时刻，受保护的数据只有一个读取器或写入器（或没有）。使用std::sync::RwLock，它可以有一个 Writer 或多个 Reader，就像通常的 Rust 引用一样。多读单写是 Rust 借用系统的核心。
 条件变量
通常一个线程需要等到某个条件变为真：在服务器关闭期间，主线程可能需要等待，直到所有其他线程完成退出；当一个工作线程无事可做时，它需要等待，直到有一些数据要处理；实现分布式共识协议的线程可能需要等到一定数量的对等方做出响应；在 Rust 中，std::sync::Condvar 类型实现了条件变量，它有方法 .wait() 和 .notify_all()，.wait() 会阻塞到直到有其他线程调用 .notify_all() 或者 notify_one()。
当等待的条件到来时，可以使用 .notify_all() 或者 notify_one() 通知其他线程：为了进入休眠等待条件变为 true，可使用 Condvar::wait()：这个 while 循环是条件变量的标准习惯用法。 但是，Condvar::wait 的签名是不寻常的。它按值获取 MutexGuard 对象，使用它，并在成功时返回一个新的 MutexGuard。
 原子锁
std::sync::atomic 模块包含用于无锁并发编程的原子类型。这些类型与标准 C++ 原子基本相同，但有一些额外的：AtomicIsize 和 AtomicUsize 是对应于单线程 isize 和 usize 类型的共享整数类型；AtomicI8、AtomicI16、AtomicI32、AtomicI64 及其无符号变体（如 AtomicU8）是共享整数类型，对应于单线程类型 i8、i16 等。AtomicBool 是一个共享的布尔值；AtomicPtr&lt;T&gt; 是不安全指针类型 *mut T 的共享值；说多个线程可以一次读取和写入一个原子值而不会导致数据竞争。与通常的算术和逻辑运算符不同，原子类型公开了执行原子操作的方法、单独的加载、存储、交换和算术操作，这些操作作为一个单元安全发生，即使其他线程也在执行触及同一内存的原子操作。递增一个名为 atom 的 AtomicIsize 如下所示：这些方法可以编译成专门的机器语言指令。在 x86-64 架构上，此 .fetch_add() 调用编译为 lock incq 指令，其中普通的 n += 1 可能编译为普通的 incq 指令。Rust 编译器还必须放弃围绕原子操作的一些优化，因为与正常的加载或存储不同，它可以合法地立即影响其他线程或被其他线程影响。
参数 Ordering::SeqCst 是内存排序，内存排序类似于数据库中的事务隔离级别，内存顺序对于程序的正确性至关重要，而且它们很难理解和推理。令人高兴的是，选择顺序一致性（最严格的内存排序）的性能损失通常非常低——与将 SQL 数据库置于 SERIALIZABLE 模式的性能损失不同。因此，如有疑问，请使用 Ordering::SeqCst。 Rust 从标准 C++ 原子继承了其他几个内存排序，对存在的本质和因果关系有各种较弱的保证。
原子的一种简单用途是取消。 假设我们有一个线程正在执行一些长时间运行的计算，例如渲染视频，并且我们希望能够异步取消它。 问题是与我们希望它关闭的线程进行通信。 我们可以通过共享的 AtomicBool 做到这一点：这段代码创建了两个 Arc&lt;AtomicBool&gt; 智能指针，它们指向同一个堆分配的 AtomicBool，其初始值为 false。 第一个名为 cancel_flag，将留在主线程中。 第二个，worker_cancel_flag，将被移动到工作线程。
下面是工作线程中的示例：我们使用 load(Ordering::SeqCst) 来检查循环要不要继续，我们可以在主线程中取消工作线程继续执行任务：当然，还有其他方法可以实现这一点，这里的 AtomicBool 可以替换为 Mutex&lt;bool&gt; 或通道，主要区别在于原子具有最小的开销，原子操作从不使用系统调用，加载或存储通常编译为单个 CPU 指令。
原子是内部可变性的一种形式，例如 Mutex 或 RwLock，因此它们的方法通过共享（非 mut）引用来获取自身，这使得它们可用作简单的全局变量。
 全局变量
Rust 尽其所能阻止全局可变状态，用 const 声明的常量当然是不可变的。默认情况下，静态变量也是不可变的，因此没有办法获得一个 mut 引用。静态可以声明为 mut，但随后访问它是不安全的，Rust 对线程安全的坚持是所有这些规则的主要原因。
全局可变状态往往使程序的各个部分更紧密耦合，更难测试，也更难在以后更改。尽管如此，在某些情况下还是没有合理的替代方案，所以我们最好找到一种安全的方法来声明可变静态变量。
我们可以使用原子整数保证线程安全，例如：可以使用以下方式增加它：原子全局变量仅限于简单的整数和布尔值。尽管如此，创建任何其他类型的全局变量都相当于解决两个问题。
首先，变量必须以某种方式成为线程安全的，否则它就不能是全局的：为了安全起见，静态变量必须是 Sync 和 non-mut。但是 Rust 有用于安全共享变化值的类型：Mutex、RwLock 和原子类型，即使声明为非 mut，这些类型也可以修改。
其次，静态初始化器只能调用特别标记为 const 的函数，编译器可以在编译期间对其进行评估。换句话说，它们的输出是确定性的；它仅取决于它们的参数，而不取决于任何其他状态或 I/O。这样，编译器可以将该计算的结果作为编译时常量嵌入，这类似于 C++ constexpr。
Atomic 类型（AtomicUsize、AtomicBool 等）的构造函数都是 const 函数，这使我们能够更早地创建静态 AtomicUsize。其他一些类型，如 String、Ipv4Addr 和 Ipv6Addr，也有简单的构造函数，它们也是 const。
也可以通过简单地在函数的签名前加上 const 来定义自己的 const 函数。Rust 将 const 函数的功能限制为一小组操作，这些操作足够有用，但仍然不允许任何不确定的结果。const 函数不能将类型作为泛型参数，只能作为生命周期，并且不能分配内存或对原始指针进行操作，即使在不安全的块中也是如此。但是，我们可以使用算术运算、逻辑运算以及其他 const 函数。例如，我们可以创建方便的函数来简化静态和常量的定义并减少代码重复：但是我们不能写下面这样的函数：因为 Mutex::new 不是 const fn，而 AtomicUsize::new() 和 String::new() 是的。为了绕过这些限制，我们可以使用 lazy_static：或者使用 lazy_static：同样的技术适用于其他复杂的数据结构，如 HashMaps 和 Deques。 使用 lazy_static！ 对静态数据的每次访问都会产生很小的性能成本。 该实现使用 std::sync::Once，这是一种为一次性初始化而设计的低级同步原语。在幕后，每次访问惰性静态时，程序都会执行原子加载指令来检查初始化是否已经发生。
]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>《Rust 程序设计》</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】引用</title>
    <url>/2022/04/17/Rust/%E3%80%90Rust%E3%80%91%E5%BC%95%E7%94%A8/</url>
    <content><![CDATA[在 Rust 中，指针按是否有所有权属性可以分为两类，例如 Box&lt;T&gt;，String，或者 Vec 具有所有权属性的指针（owning pointers），可以说它们拥有指向的内存，当它们被删除时，指向的内存也会被被释放掉。但是，也有一种非所有权指针，叫做引用(references)，它们的存在不会影响指向值的生命周期，在 Rust 中创建引用的行为称之为对值的借用。
要注意的是，引用决不能超过其引用的值的生命周期。必须在代码中明确指出，任何引用都不可能超过它所指向的值的寿命。为了强调这一点，Rust 将创建对某个值的引用称为借用：你所借的东西，最终必须归还给它的所有者。
 引用值
在《【Rust】所有权》章节中，我们说到函数传值会转移值得所有权，for 循环也会，例如，对下面的代码，我们在将 table 传递给 show 函数之后，table 就处于未初始化状态：如果在 show 函数之后，我们再想使用 table 变量就会报错，例如：Rust 编译器提示变量 table 已经不可用，show 函数的调用已经转移 table 的所有权：
error[E0382]: borrow of moved value: `table`
--&gt; src/main.rs:24:16
|
13 |     let mut table = Table::new();
|         --------- move occurs because `table` has type `HashMap&lt;String, Vec&lt;String&gt;&gt;`, which does not implement the `Copy` trait
...
23 |     show(table);
|          ----- value moved here
24 |     assert_eq!(table[&quot;Gesualdo&quot;][0], &quot;many madrigals&quot;);
|                ^^^^^ value borrowed here after move正确处理这个问题的方法是使用引用，使用引用不会改变值的所有者，引用有两种类型：shared reference：可以读引用的值，但不能改变它。而且同时可以有多个shared reference。表达式 &amp;e 会生成 e 的shared reference。如果 e 的类型是 T，那么 &amp;e 的类型是 &amp;T，读作 ref T，shared reference是可以复制的；共享引用借用的值是只读的，在共享引用的整个生命周期中，它的引用对象或从该引用对象可到达的任何东西都不能被改变，就像加了读锁，被冻结了；mutable reference：可读可写所引用的值，不能拥有其他任何 shared reference 或者 mutable reference。表达式 &amp;mut e 生成 e 的 mutable reference。如果 e 的类型是 T，那么 &amp;mut e 的类型是 &amp;mut T，读作 ref mute T。 mutable reference是不可以复制的。可变引用借用的值只能通过该引用访问，在可变引用的整个生命周期中，没有其他可用路径可以到达其引用对象；因此，我们可以对上面的 show 函数作如下修改，就可以使得代码编译通过。在 show 函数中，table 的类型是 &amp;Table，那么 artist 和 works 的类型就是 &amp;String 和 &amp;Vec&lt;String&gt;，内部的 for 循环中 work 的类型也就变成了 &amp;String。现在，如果我们 table 中的值进行排序，shared reference 肯定不能满足要求，因为它不允许改变值，所以我们需要一个 mutable reference。可变借用使得 sort_works 有能力读和修改 works。当我们将一个值传递给函数时，可以说是将值的所有权转移给了函数，称之为按值传参。但是，如果我们将引用传给函数，我们可以称之为按引用传参，它没有改变值的所有权，只是借用了值。
 解引用
在 Rust 中，我们可以通过 &amp; 或者 &amp;mut 创建 shared reference 或者 mutable reference，在机器级别，它们就是个地址。解引用可以通过 * 操作符。如果每次访问引用指向的值，都需要 * 操作符，在访问结构体字段的时候，不难想象，体验有点糟糕。所在，在Rust中，可以通过.操作符隐式地解引用它的左操作数。除此之外，.操作符还可以隐式地从它的左操作数创建引用，因此下面两个操作使等价的： 引用更新
在 C++ 中，一旦一个引用被初始化，是不能更改其指向的。但是在 Rust 中是完全允许的，例如下面的代码中，一开始 r 借用了 x，后面又借用了 y： 引用的引用
在 C 语言中我们经常听到指向指针的指针，在 Rust 中也是允许的，如下所示，为了清晰，我们写出了每个变量的类型，实际上我们完全可以省略，由 Rust 来推断。然而，. 操作符可以一直向前寻找，直到找到最终的值。这些变量在内存中的分布如下图所示： 引用比较
同 . 操作符一样，比较运算符也有这样的效果，能连续解引用直到找到最终的值，例如：这在大多数情况下应该是我们想要的效果，但是如果我们确实想知道两个引用它们指向的内存地址是否相同，我们可以使用 std::ptr::eq，仅仅比较地址而不是指向的值：但是，无论如何，比较操作符左右两侧的操作数必须要有相同的类型，例如，下面的代码编译失败： 引用永不为空
Rust 中的引用永远不会为空。没有类似于C的NULL或C++的nullptr。引用没有默认初始值（因为任何变量在初始化之前，无论其类型如何，都不能使用），Rust 不会将整数转换为引用（安全代码中），因此无法将0转换为引用。
C 和 C++ 代码中使用空指针表示没有值，例如，malloc 函数要么返回一个指向内存块的指针，要么返回 null 表示内存申请失败。
在 Rust 中，如果你需要用一个值表示引用某个变量的内存，或者没有，可以使用 Option&lt;&amp;T&gt;。在机器层面，Rust将其表示为代表空指针的None或者Some(r)，其中r是&amp;T值，表示为非零地址，因此Option&lt;&amp;T&gt;与C或C++中的可空指针一样有效，但是它更安全：Option类型要求在使用它之前检查它是否为None。
 从任何表达式借用引用
在C、C++或者其他大多数语言中，我们都是从变量获取引用，也就是 &amp; 运算符后面一般都是紧跟某个变量。但是在 Rust 中，我们可以从任何表达式借用引用：这种情况下，Rust 会创建一个持有表达式值的匿名变量，然后再从匿名变量创建一个引用。匿名表达式的生命周期取决于我们怎么使用这个引用：如果我们是将这个引用用在赋值语句 let，结构体字段或者数组中，那么这个匿名变量的生命周期和我们 let 语句初始化的变量一样，例如上面的 r；否则，这个匿名变量在当前语句结束就会被释放掉，例如上面为 1009 创建的匿名变量在 assert_eq! 结束就会被丢掉； 胖指针
胖指针，即 fat pointers，指哪些不仅仅是包含了地址的指针，就像 &amp;[T]，引用自 slice 的指针除了包含首元素的地址之外，还包括 slice 的数量；
另一种胖指针是 trait 类型，详细请看 Trait 对象。
 引用安全性
截止到目前为止，我们看到的指针都和C中差不多，但是既然这样，我们又如何保证安全性呢？为了保证引用使用的安全性，Rust 为每个应用都会分配一个生命周期，更多请看【Rust】生命周期。
 引用局部变量
如果我们引用的是一个局部变量，并且我们的引用比局部变量的作用域更大，也就是局部变量释放了之后，我们的程序会如何，来看下面的示例：这段代码编译会失败的，编译器提示：我们引用的值没有引用活得久，因为 x 在内部的括号之后就被释放了，导致 r  成了一个悬垂指针：
error[E0597]: `x` does not live long enough
--&gt; src/main.rs:5:13
|
5 |         r = &amp;x;
|             ^^ borrowed value does not live long enough
6 |     }
|     - `x` dropped here while still borrowed
7 |     assert_eq!(*r, 1);
|     ----------------- borrow later used hereRust 编译器是如何确保每个引用都是有效的呢？ Rust 为每个引用都赋予了一个满足其使用范围的 生命周期。生命周期是程序的一部分，可以被安全地用于语句，表达式或者变量。但是生命周期完全是Rust编译时虚构的。在运行时，引用只不过是一个地址，其生命周期是其类型的一部分，没有运行时表示。
在上面的例子中，有三个生命周期，变量 x和 r 的生命周期是从它们初始化到编译器认为它们不再使用为止。第三个生命周期是一个引用类型，我们引用自x并且存储在 r 中。
正如我们上面看到的，生命周期有一个很明显的约束，就是它不能比它引用的值活的久。因为如果这里 x 出了内部的括号，就会被释放，所有来自于它的引用都会变成一个悬垂指针，所以，Rust 规定 约束1：值的生命周期必须大于它的引用的生命周期，上面的示例中，x的生命周期就小于它的引用的生命周期：还有另外一个约束，约束2：如果我们将引用存储在一个变量中，那么这个引用必须要覆盖这个变量的整个生命周期，从它的初始化到最后一次使用为止。上面示例中，x 引用的生命周期没有覆盖到r的使用范围：第一个约束限制了生命周期的上限，也就是它最大是多大；第二个约束限制了它的下限，也就是它最小应该是多少；Rust 的编译器必须能找到一个能满足所有约束的生命周期，也就是从上限开始到下限为止。然而遗憾的是，我们的示例中，没有这样的生命周期，所以编译失败：对于我们上面的示例，稍作修改，就可以找到满足的生命周期：此时 x 引用的生命周期满足我们的使用： 更新全局引用变量
当我们传递一个引用给函数时，Rust 如何保证安全使用呢？假设我们有一个函数 f，接受一个引用作为参数，并且把它存储在全局变量中，例如：Rust 的全局变量时静态创建的，贯穿应用程序的整个生命周期。像任何其他声明一样，Rust的模块系统控制静态变量在什么地方可见，所以它们仅仅是在生命周期里是全局的，而不是可见性。上面的代码是有一些问题的，没有遵循两个规则：所有的静态变量必须被初始化；可变的静态变量不是线程安全的，因为任何线程任何时候都可以访问静态变量，即使单线程也会引发某些未知的异常；出于这些原因，我们需要放在 unsafe 块中才能访问全局可变静态变量；根据这两个规则，我们将上面的代码改成下面这个样子：为了让代码更加完善，我们需要手动函数参数的生命周期，这里 'a 读作 tick A，我们将 &lt;'a&gt; 读作 for any lifetime 'a。所以下面的代码定义了一个接受具有任意生命周期 'a 参数 p 的函数 f：由于 STASH 的生命周期和应用程序一样，所以我们必须赋予它一个具有相同生命周期的引用，Rust 将这种生命周期称之为 'static lifetime，静态生命周期，所以如果参数的 p 的声明是 'a，是不允许的。编译器直接拒绝编译我们的代码：
error[E0312]: lifetime of reference outlives lifetime of borrowed content...
--&gt; src/main.rs:5:16
|
5 |        STASH = p;
|                ^
|
= note: ...the reference is valid for the static lifetime...
note: ...but the borrowed content is only valid for the lifetime `'a` as defined here编译器的提示很明显，f 需要一个具有静态生命周期的参数 p，因此我们现在可以将代码修改成如下的样子：从一开始的 f(p: &amp;i32) 到结束时的 f(p: &amp;'static i32)，如果不在函数的签名中反映该意图，我们就无法编写一个将引用固定在全局变量中的函数，我们必须指出引用的生命周期，满足约束2：如果我们将引用存储在一个变量中，那么这个引用必须要覆盖这个变量的整个生命周期，从它的初始化到最后一次使用为止。
]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>《Rust 程序设计》</tag>
        <tag>引用</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】异步编程</title>
    <url>/2022/05/03/Rust/%E3%80%90Rust%E3%80%91%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/</url>
    <content><![CDATA[如果我们正在开发一个聊天室，并且使用线程处理每个连接，我们的代码可能看起来像下面这个样子：对于每个新连接，这都会产生一个运行 serve 函数的新线程，该线程能够专注于管理单个连接的处理。
这很好用，但是如果突然用户达到成千上万时，线程堆栈增长到 100 KiB 或这更多时，这可能要花费几个GB的内存。线程对于在多个处理器之间分配工作是非常好的一种形式，但是它们的内存需求使得我们在使用时要非常小心。
不过可以使用 Rust 异步任务在单个线程或工作线程池上并发运行许多独立活动。异步任务类似于线程，但创建速度更快，并且内存开销比线程少一个数量级。在一个程序中同时运行数十万个异步任务是完全可行的。当然，应用程序可能仍会受到网络带宽、数据库速度、计算或工作固有内存要求等其他因素的限制，但内存开销远没有线程那么多。
一般来说，异步 Rust 代码看起来很像普通的多线程代码，除了涉及到的 I/O 操作，互斥锁等阻塞操作需要稍微的不同处理。之前代码的异步版本如下所示：这使用 async_std 的net和task模块，并在可能阻塞的调用之后添加 .await。但整体结构与基于线程的版本相同。
本节的目标不仅是帮助编写异步代码，而且还以足够详细的方式展示它的工作原理，以便可以预测它在应用程序中的表现，并了解它最有价值的地方。为了展示异步编程的机制，我们列出了涵盖所有核心概念的最小语言特性集：futures、异步函数、await 表达式、task 以及 block_on 和 spawn_local executor；然后我们介绍异步代码块和 spawn executor。这些对于完成实际工作至关重要，但从概念上讲，它们只是我们刚刚提到的功能的变体。在此过程中，我们会可能会遇到一些异步编程特有的问题，但是需要学习如何处理它们；为了展示所有这些部分的协同工作，我们浏览了聊天服务器和客户端的完整代码，前面的代码片段是其中的一部分；为了说明原始 futures 和 executors 是如何工作的，我们提供了 spawn_blocking 和 block_on 的简单但功能性的实现；最后，我们解释了 Pin 类型，它在异步接口中不时出现，以确保安全使用异步函数和 futures； 异步世界
来看一段示例代码，来看它背后会发生什么？它通过一个 TCP 连接到了 Web 服务器，然后发送 HTTP 请求：下图显示了该函数随时间的一个执行情况：此图显示了函数调用堆栈如何随着时间从左到右运行，每个函数调用都是一个方块，放置在其调用者的顶部。显然，cheapo_request 函数贯穿整个执行过程。它调用 Rust 标准库中的函数，例如 TcpStream::connect 和 TcpStream 的 write_all 和 read_to_string 实现。它们依次调用其他函数，但最终程序会进行系统调用，例如打开 TCP 连接读取或写入一些数据。
深灰色背景标记程序等待操作系统完成系统调用的时间，这里没有按时间比例回执，否则整个图表将是深灰色：实际上，该函数几乎将所有时间都花在等待操作系统上，前面代码的执行将是系统调用之间的窄条。
当这个函数在等待系统调用返回时，它的单线程被阻塞：在系统调用完成之前它不能做任何事情。一个线程的堆栈大小为数十或数百千字节并不罕见，因此，如果这是某个更大系统的一个片段，许多线程都在从事类似的工作，那么锁定这些线程的资源除了等待之外什么都不做可能会变的很浪费。
为了解决这个问题，线程需要能够在等待系统调用完成时承担其他工作，但如何做到这一点并不简单。例如，我们用来从套接字读取响应的函数的签名是：这个函数在工作完成或出错之前，此函数不会返回，此函数是同步的：调用者在操作完成后恢复执行。如果我们想在操作系统工作的同时将我们的线程用于其他事情，我们将需要一个新的 I/O 库来提供该函数的异步版本。
 Futures
Rust 为了实现异步编程引入了 std::future::Future：Future 表示可以测试是否完成的操作。Future 的 poll 方法从不等待操作完成：它总是立即返回。如果操作完成，poll 返回 Poll::Ready(output)，其中 output 是它的最终结果，否则，它返回待处理。如果 future 可以再次轮询，它将通过调用一个waker（一个在上下文中提供的回调函数） 来让我们知道。
所有现代操作系统都包含其系统调用的变体，我们可以使用这些变体来实现这种轮询接口。例如，在 Unix 和 Windows 上，如果将网络套接字设置为非阻塞模式，则如果它们会阻塞，则读取和写入会返回错误，必须稍后再试。
因此 read_to_string 的异步版本将具有大致如下的签名：这与我们之前展示的签名相同，除了返回类型：异步版本返回 Future&lt;Output = Result&lt;usize&gt;&gt;。需要轮询这个future，直到你得到一个 Ready(result) ，每次轮询时，都会尽可能读取，最终结果提供成功值或错误值，就像普通的 I/O 操作一样。这是一般模式：任何函数的异步版本都采用与同步版本相同的参数，但返回类型有一个 Future 包裹它。
调用这个版本的 read_to_string 实际上并没有读取任何内容；它的唯一职责是构建并返回一个在将来才能完成的工作。这个 future 必须包含执行请求所需的所有信息。例如，这个 read_to_string 返回的 future 必须记住调用它的输入流，以及它应该将传入数据附加到的 String。事实上，由于 future 持有引用 self 和 buf，read_to_string 的正确签名必须是：这增加了生命周期，以表明返回的 future 只能在 self 和 buf 借用的值期间存在。
async-std 提供所有 std 的 I/O 工具的异步版本，包括带有 read_to_string 方法的异步 async_std::io::Read。 async-std 紧跟 std 的设计，尽可能在自己的接口中重用 std 的类型，因此错误、结果、网络地址和大多数其他相关数据在两个世界之间是兼容的。熟悉 std 有助于使用 async-std，反之亦然。
Future 的规则之一是，一旦 future 返回 Poll::Ready，就假设它永远不会被再次轮询。一些 future 如果被过度轮询，就会永远返回 Poll::Pending。（但是，它们不得违反内存或线程安全，或以其他方式导致未定义的行为。） Future 上的 fuse 适配器方法将任何 future 转换为永远返回 Poll::Pending 的 future。但是所有通常的 futrue 消费方式都遵守这条规则，所以通常不需要 fuse。
轮询听起来效率低下，但不要担心，Rust 的异步架构经过精心设计，因此只要基本 I/O 函数（如 read_to_string）正确实现，只会在值得的时候轮询 future，每次调用 poll 时，某个地方应该返回 Ready，或者至少朝着那个目标取得进展。
但是使用 future 似乎是一个挑战：如果进行轮询时，得到 Poll::Pending 时你应该怎么做？给这个线程找点其他的活干，还得回头再来轮询 future。那么整个程序将变得乱七八糟，跟踪哪个 future 还没 Ready ，以及一旦 Ready 应该做什么，这就破坏了程序的简单性。
 Async、Await
我们更进一步，将 cheapo_request 写成异步函数：这和我们之前的版本目的相同，除了：函数以 async fn 开始，而不是 fn；使用了 async_std 提供的 TcpStream::connect，write_all 和 read_to_string 异步版本，这些都返回了他们所代表结果的 future；在每个返回 future 的调用之后，代码都会显示 .await。尽管这看起来像是对名为 await 的结构字段的引用，但它实际上是语言中内置的特殊语法，用于等待future准备好。await 表达式的计算结果是future的最终值。这就是函数从 connect、write_all 和 read_to_string 获取结果的方式；与普通函数不同，当您调用异步函数时，它会在主体开始执行之前立即返回。显然，调用的最终返回值还没有计算出来；你得到的是其最终值的future。因此，如果您执行此代码：那么 response 将是 std::io::Result&lt;String&gt; 的 future，cheapo_request 的主体尚未开始执行。你不需要调整异步函数的返回类型；Rust 自动将 async fn f(...) -&gt; T 视为返回 T 的 future 的函数，而不是直接返回 T。
异步函数返回的 future 包含了函数体运行所需的所有信息：函数的参数、局部变量的空间等等。就好像将调用的堆栈帧捕获为普通的 Rust 值一样。因此 response 必须保存 host、port、path 传递的值，因为 cheapo_request 的主体将需要这些值才能运行。
Future 的特定类型由编译器根据函数的主体和参数自动生成。这种类型没有名字；你只知道它实现了 Future&lt;Output=R&gt;，其中 R 是异步函数的返回类型。从这个意义上说，异步函数的 future 就像闭包：闭包也有匿名类型，由编译器生成，实现了 FnOnce、Fn 和 FnMut。
当你第一次轮询 cheapo_request 返回的 future 时，执行从函数体的顶部开始，一直运行到 TcpStream::connect 返回的 future 的第一个 await。await 表达式轮询连接的 future，如果它还没有准备好，那么它返回 Poll::Pending 给它自己的调用者：轮询 cheapo_request 的 future 不能继续超过第一个 await，直到对 TcpStream::connect 的 future 的轮询返回 Poll::Ready。因此，表达式 TcpStream::connect(...).await 的大致等价于：await 表达式获取 future 的所有权，然后对其进行轮询。如果它准备好了，那么 future 的最终值就是 await 表达式的值，然后继续执行。否则，它将 Poll::Pending 返回给它自己的调用者。
但至关重要的是，cheapo_request 的 future的下一次轮询不会再次从函数顶部开始：相反，它会在即将轮询 connect_future 的点恢复执行中间函数。在 futrue 准备好之前，不会进入异步函数的其余部分。
由于cheapo_request 的 future 继续被轮询，它将通过函数体从一个等待到下一个，只有当它等待的子 future 准备好时才会继续。因此，cheapo_request 的 future 必须轮询多少次取决于子 future 的行为和函数自己的控制流。cheapo_request 的 future跟踪下一次轮询应该恢复的点，以及恢复需要的所有本地状态——变量、参数、临时变量。
暂停执行中间函数然后稍后恢复的能力是异步函数所独有的。当一个普通函数返回时，它的堆栈帧就永远消失了。由于 await 表达式依赖于恢复的能力，只能在异步函数中使用它们。
 调用异步函数
从某种意义上说，异步函数只是推卸责任。确实，在异步函数中很容易获得 future 的值：只需等待它。但是异步函数本身返回一个future，所以现在调用者的工作就是以某种方式进行轮询。最终，有人必须实际等待一个值。
我们可以使用 async_std 的 task::block_on 函数从普通的同步函数（例如 main）调用 cheapo_request ，该函数接受一个 future 并轮询它，直到它产生一个值：由于 block_on 是一个同步函数，它产生异步函数的最终值，你可以把它看作是从异步世界到同步世界的适配器。但是它的阻塞特性也意味着你永远不应该在异步函数中使用 block_on：它会阻塞整个线程，直到值准备好。
下图展示了 main 的一种可能执行：上面的时间线简化视图显示了程序异步调用的抽象视图：cheapo_request 首先调用 TcpStream::connect 以获取套接字，然后在该套接字上调用 write_all 和 read_to_string，然后它返回，这与本节前面的 cheapo_request 同步版本的时间线非常相似。
但是这些异步调用中的每一个都是一个多步骤的过程：创建一个future，然后轮询它，直到它准备好，也许在这个过程中创建和轮询其他子 future，较低的时间线显示了实现此异步行为的实际同步调用，我们来看看这个异步函数的执行过程：首先，main 调用 cheapo_request，它返回其最终结果的 Future A。然后 main 将这个 Future 传递给 async_std::block_on，它会轮询它；轮询 Future A 允许 cheapo_request 的主体开始执行，它调用 TcpStream::connect 以获取套接字的Future B，然后等待。更准确地说，由于 TcpStream::connect 可能会遇到错误，因此 B 是 Result&lt;TcpStream, std::io::Error&gt; 的 future；Future B 被 await 轮询，由于网络连接尚未建立，B.poll 返回 Poll::Pending，但会在套接字准备好后安排唤醒调用任务；由于 Future B 尚未准备好，A.poll 将 Poll::Pending 返回给它自己的调用者 block_on；由于 block_on 无事可做，它进入睡眠状态，现在整个线程都被阻塞了；当 B 的连接准备好使用时，它会唤醒轮询它的任务，这会激发 block_on 的作用，并尝试再次轮询 Future A；轮询 A 导致 cheapo_request 在其第一次等待中恢复，并再次轮询 B；这一次，B 准备就绪：套接字创建完成，所以它返回 Poll::Ready(Ok(socket)) 给 A.poll；对 TcpStream::connect 的异步调用现已完成，TcpStream::connect(...).await 表达式的值因此是 Ok(socket)；cheapo_request 的主体的执行正常进行，使用format!构建请求字符串并将其传递给 socket.write_all；由于 socket.write_all 是一个异步函数，它返回其结果的 future C，cheapo_request 适当地等待；代码的其余部分是相似的，如上图所示，socket.read_to_string 的 future 在它准备好之前被轮询了4次；这些唤醒中的每一个都从套接字读取一些数据，但 read_to_string 被指定为一直读取到输入的末尾，这需要几个操作。
编写一个一遍又一遍地调用 poll 的循环听起来并不难，但是 async_std::task::block_on 的好处是它知道如何进入睡眠状态，直到 future 实际上值得再次轮询，而不是浪费处理器时间和电池寿命进行数十亿次毫无结果的轮询调用。由基本 I/O 函数，如 connect 和 read_to_string，返回的 future 保留由传递给 poll 的 Context 所提供的waker，并在 block_on 应该唤醒并再次尝试轮询时调用它。
与我们之前介绍的原始同步版本一样，cheapo_request 的这个异步版本几乎将所有时间都花在等待操作完成上。如果按比例绘制时间轴，则该图将几乎完全是深灰色。
通常可以只考虑简化的上部时间线：一些函数调用是同步的，另一些是异步的并且需要等待，但它们都只是函数调用。Rust 异步支持的成功取决于帮助程序员在实践中使用简化视图，而不会被来回的实现分心。
 创建异步任务
async_std::task::block_on 函数会阻塞到 future 的值准备好。但是在一个 future 上完全阻塞一个线程并不比同步调用好：本节的目标是让线程在等待时做其他工作。
为此，可以使用 async_std::task::spawn_local，这个函数接受一个 future 并将其添加到一个池中。因此，如果将一堆 future 传递给 spawn_local，然后将 block_on 应用于最终结果的 future，那么 block_on 就会轮询每个生成的 future，同时运行整个池，直到结果准备好。
要启用 spawn_local，必须启用 async-std 中的不稳定功能：spawn_local 函数是标准库用于启动线程的 std::thread::spawn 函数的异步实现：std::thread::spawn(c) 接受一个闭包 c 并启动一个运行它的线程，返回一个 std::thread::JoinHandle，其 join 方法等待线程完成并返回 c 的返回值；async_std::task::spawn_local(f) 获取 future f 并将其添加到池中，以便在当前线程调用 block_on 时进行轮询。spawn_local 返回它自己的 async_std::task::JoinHandle 类型，它本身就是一个future，你可以等待检索 f 的最终值。例如，假设我们要同时发出一整套 HTTP 请求。这是第一次尝试：这个函数对请求的每个元素调用 cheapo_request，将每个调用的 future 传递给 spawn_local，它将生成的 JoinHandles 收集到一个 vector 中，然后等待它们中的每一个完成。可以按任何顺序等待连接句柄：由于请求已经产生，因此只要该线程调用 block_on 并且没有其他的事情可做，就会对所有 handles 进行轮询，所有请求将同时运行。一旦完成，many_requests 会将结果返回给它的调用者。
前面的代码几乎是正确的，但是 Rust 认为 cheapo_request 的参数 host 不太对：
    error: `host` does not live long enough
    handles.push(task::spawn_local(cheapo_request(&amp;host, port, &amp;path)));
    ---------------^^^^^--------------
    | |
    | borrowed value does not
    | live long enough
    argument requires that `host` is borrowed for `'static`
    &#125;
    - `host` dropped here while still borrowedpath 也有类似的错误。自然，如果我们将引用传递给异步函数，它返回的future必须持有这些引用，因此 future 不能安全地比它们借用的值更长寿，这与适用于任何包含引用的值的限制相同。
问题是 spawn_local 不能确定你会在 host 和 path 被删除之前等待任务完成。事实上，spawn_local 只接受生命周期为'static 的 future，因为可以简单地忽略它返回的 JoinHandle，让任务在程序执行的其余部分继续运行。这并不是异步任务所独有的：如果你尝试使用 std::thread::spawn 来启动一个线程，该线程的闭包捕获了对局部变量的引用，你会得到类似的错误。
解决这个问题的一种方法是创建另一个异步函数，它接受所有权版本的参数：这个函数接受字符串而不是 &amp;str 引用，所以它的 future 拥有 host 和 path 字符串本身，它的生命周期是 'static 的。借用检查器可以看到它立即等待 cheapo_request 的 future，因此，如果这个 future 正在被轮询，它借用的 host 和 path 变量肯定仍然存在。
使用 cheapo_owning_request，可以像这样生成所有请求：也可以从 main 函数通过 block_on 调用 many_requests：此代码在对 block_on 的调用中同时运行所有 3 个请求，每个都有机会被运行，而且它们都在相同的调用线程上，下图显示了对 cheapo_request 的 3 个调用的一种可能执行：对 many_requests 的调用（为简单起见，未显示）产生了 3 个异步任务，我们将它们标记为 A、B 和 C。block_on 从轮询 A 开始，它开始连接到 example.com，一旦返回 Poll::Pending，block_on 就会将注意力转移到下一个任务上，轮询 B，最终轮询 C，每个都开始连接到各自的服务器。当所有可轮询的 future 都返回 Poll::Pending 时，block_on 进入睡眠状态，直到 3 个 TcpStream::connect 的 future 之一反馈连接已经准备好，可以再次轮询。
在本次执行中，服务器 en.wikipedia.org 的响应速度比其他服务器更快，因此该任务首先完成。当一个任务完成时，它会将其值保存在其 JoinHandle 中并将其标记为 Ready，以便 many_requests 在等待它时可以继续。最终，对 cheapo_request 的其他调用要么成功，要么返回错误，并且 many_requests 本身可以返回。最后，main 从 block_on 接收结果vector。
所有这些执行都发生在一个线程上，对 cheapo_request 的 3 个调用通过对它们的 future 的连续轮询相互交错。异步调用看起来像要等到函数运行完成，但这种异步调用是通过对 future 的 poll 方法一系列同步调用来实现的。每个单独的轮询调用快速返回，让出线程，以便另一个异步调用可以轮流。
我们终于实现了我们在本节开头设定的目标：让线程在等待 I/O 完成的同时承担其他工作，这样线程的资源就不会白白浪费。更好的是，这个目标是用看起来很像普通 Rust 代码的代码实现的：一些函数被标记为 async，一些函数调用后跟 .await，我们使用来自 async_std 的函数而不是 std，但除此之外，都是些普通的 Rust 代码。
异步任务和线程之间要记住的一个重要区别是，从一个异步任务切换到另一个异步任务只发生在 await 表达式中，此时正在等待的 future 返回 Poll::Pending。这意味着如果你在 cheapo_request 中放置一个长时间运行的计算，你传递给 spawn_local 的其他任务在它完成之前都没有机会运行。有了线程，这个问题就不会出现：操作系统可以在任何时候挂起任何线程并设置计时器以确保没有线程独占处理器，异步代码取决于共享线程的 future 的自愿合作。
 异步代码块
除了异步函数，Rust 还支持异步代码块。普通块语句返回其最后一个表达式的值，而异步代码块返回其最后一个表达式的值的 future ，你可以在异步代码块中使用 await 表达式。
async 块看起来像一个普通的块语句，前面有 async 关键字：这将使用future初始化 serve_one，当被轮询时，它会侦听并处理单个 TCP 连接。在轮询 serve_one 之前，代码块的主体不会开始执行，就像异步函数调用在轮询其future之前不会开始执行一样。
如果将 ? 操作符应用到异步代码块中的错误，它只是从块中返回，而不是从周围的函数中返回。例如，如果前面的绑定调用返回错误，则 ? 运算符将其作为 serve_one 的最终值返回。同样，return 表达式从 async 块返回，而不是包裹它的函数。
如果一个异步代码块引用了在周围代码中定义的变量，它的 future 会捕获它们的值，就像 move 闭包一样，可以使用 async move 启动块以获取捕获值的所有权，而不仅仅是持有对它们的引用。
异步代码块提供了一种简洁的方法来分离出希望异步运行的一段代码。例如，在上一节中，spawn_local 需要一个 静态 future，因此我们定义了 cheapo_owning_request 包装函数来为我们提供一个拥有其参数所有权的 future，然而只需从异步代码块中调用 cheapo_request，就可以获得相同的效果：由于这是一个 async move 代码块，它的 future 将拥有字符串值 host 和 path 的所有权，就像移动闭包一样。然后它传递对cheapo_request 的引用。借用检查器可以看到块的 await 表达式拥有 cheapo_request 的 future 所有权，因此对 host 和 path 的引用不能超过它们借用的捕获变量。async 代码块完成与 cheapo_owning_request 相同的事情，但代码更少。
如何指定异步代码块的返回值吗？初次使用我们可能会写出如下的代码：编译这段代码会遇到下面的错误：
    error: type annotations needed
    |
    | let future = async {
    | ------ consider giving `future` a type
    ...
    | input.read_line(&amp;mut line).await?;
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ cannot infer typeRust 无法判断异步代码块的返回类型应该是什么。read_line 方法返回 Result&lt;(), std::io:Error&gt;，但是因为 ? 运算符使用 From 将手头的错误类型转换为任何情况需要的类型，对于实现 From&lt;std::io::Error&gt; 的任何类型 E，异步代码块的返回类型可以是 Result&lt;(), E&gt;。Future 版本的 Rust 可以添加用于指示异步代码块的返回类型的语法，例如，确定返回类型：由于 Result 是一个泛型类型，它期望成功和错误类型作为其参数，因此我们可以在使用 Ok 或 Err 时指定这些类型参数，如上所示。
 构造异步函数
异步代码块为我们提供了另一种方法来获得与异步函数相同的效果，并且具有更多的灵活性。例如，我们可以将我们的 cheapo_request 示例编写为一个普通的同步函数，它返回一个异步代码块的future：当您调用此版本的函数时，它会立即返回异步代码块值的 future，这捕获了函数的参数，并且表现得就像异步函数返回的 future一样。由于我们没有使用 async fn 语法，我们需要在返回类型中写出 impl Future，但就调用者而言，这两个定义是相同函数签名的可互换实现。
当想在调用函数时立即进行一些计算，然后再创建其结果的 future 时，第二种方法可能很有用。例如，协调 cheapo_request 和spawn_local 的另一种方法是将它变成一个同步函数，返回一个'static future，捕获其参数的完全拥有的副本：此版本允许异步代码块将 host 和 path 捕获为拥有的字符串值，而不是 &amp;str 引用。由于 future 拥有它运行所需的所有数据，因此它在 'static 生命周期内有效。（我们在前面显示的签名中拼出了 + 'static，但 'static 是 -&gt; impl 返回类型的默认值，因此省略它不会有任何效果。）
由于这个版本的 cheapo_request 返回的是'static future，我们可以将它们直接传递给 spawn_local： 使用线程池
当单个线程无法完成较大的计算量时，可以使用 async_std::task::spawn 将 future 分派到一个工作线程池上，该线程池专用于轮询 future。
async_std::task::spawn 像 async_std::task::spawn_local 一样使用：与 spawn_local 一样，spawn 返回一个 JoinHandle 值，可以等待以获取 future 的最终值。但与 spawn_local 不同的是，future 不必等到你调用 block_on 才能被轮询，一旦线程池中的一个线程空闲，它将尝试轮询它。
在实践中，spawn 比 spawn_local 使用更广泛，它能够将工作负载分摊到不同的线程之上。
使用 spawn 时要记住的一件事是线程池试图保持忙碌，因此 future 会被首先访问它的线程轮询。异步调用可能在一个线程上开始执行，在await 表达式上阻塞，然后在另一个线程中恢复。因此，虽然将异步函数调用视为单个、连续的代码执行是一种合理的简化（实际上，异步函数和await 表达式的目的是鼓励你这样想），但调用可能实际上是由许多不同的线程来执行的。
如果使用的是线程本地存储，那么在 await 表达式之前放置的数据可能会被完全不同的东西替换，因为任务现在正在由池中的不同线程轮询，但也可以改用 async_std::task_local 来实现。
 Future 实现 Send
spawn 有一个限制 spawn_local 没有。由于 future 被发送到另一个线程运行，future 必须实现 Send。只有当它包含的所有值都是 Send 时，Future 才是 Send：所有函数参数、局部变量，甚至匿名临时值都必须可以安全移动到另一个线程。
和以前一样，这个要求并不是异步任务所独有的：如果你尝试使用 std::thread::spawn 来启动一个其闭包捕获 non-Send 值的线程，你会得到一个类似的错误。不同之处在于，虽然传递给 std::thread::spawn 的闭包保留在为运行它而创建的线程上，但在线程池上生成的 future 可以在它等待的任何时候从一个线程移动到另一个线程。
这个限制很容易被意外遇到，例如，下面的代码看起来很无辜：异步函数的 future 需要保存足够的信息，以便函数从 await 表达式继续。在这种情况下，reluctant 函数的 future 必须在等待之后使用字符串，所以 future 至少有时会包含一个 Rc&lt;String&gt; 值。由于 Rc 指针不能在线程之间安全地共享，future 本身不能被Send。由于 spawn 只接受 Send 的future，Rust 报错了：
    error: future cannot be sent between threads safely
    |
    | task::spawn(reluctant());
    | ^^^^^^^^^^^ future returned by `reluctant` is not `Send`
    |
    |
    | T: Future + Send + 'static,
    | ---- required by this bound in `async_std::task::spawn`
    |
    = help: within `impl Future`, the trait `Send` is not implemented
    for `Rc&lt;String&gt;`
    note: future is not `Send` as this value is used across an await
    |
    | let string = Rc::new(&quot;ref-counted string&quot;.to_string());
    | ------ has type `Rc&lt;String&gt;` which is not `Send`
    |
    | some_asynchronous_thing().await;
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    await occurs here, with `string` maybe used later
    ...
    | }
    | - `string` is later dropped here错误信息很长，但它有很多帮助信息：它解释了为什么需要 future 实现 Send：task::spawn 需要它；它解释了哪个值不是 Send：局部变量字符串，其类型为Rc&lt;String&gt;；它解释了为什么字符串会影响 future：它在指定的等待范围内；有两种方法可以解决此问题，一种是限制 non-Sennd 的范围，使其不覆盖任何 await 表达式，因此不需要保存在函数的 future ：另一种解决方案是简单地使用 std::sync::Arc 而不是 Rc。Arc 使用原子更新来管理它的引用计数，这使得它有点慢，但 Arc 指针是 Send。尽管最终将学会识别和避免 non-Send 类型，但起初它们可能会有点令人惊讶。例如，旧的 Rust 代码有时会使用这样的通用Result 类型：此 GenericError 类型使用 Box 对象来保存实现 std::error::Error 的任何类型的值。但它并没有对其施加任何进一步的限制：如果有人有一个实现 Error 的 non-Send 类型，他们可以将该类型的装箱值转换为 GenericError。由于这种可能性，GenericError 不是 Send，以下代码将不起作用：与前面的示例一样，来自编译器的错误消息将解释了发生了什么，并指出 Result 类型是罪魁祸首。由于 Rust 认为 some_fallible_thing 的结果存在于整个 match 语句中，包括 await 表达式，它确定 unfortunate 的future不是 Send。这个错误对 Rust 来说是过于谨慎了：虽然 GenericError 确实不能安全地发送到另一个线程，但 await 仅在结果为 Ok 时发生，因此当我们 await use_output 的 future 时，错误值实际上并不存在。理想的解决方案是使用更严格的通用错误类型：这个 trait 对象明确需要底层错误类型来实现 Send，如果你的 future 不是 Send 并且不能方便地做到这一点，那么仍然可以使用 spawn_local 在当前线程上运行它。当然，需要确保线程在某个时候调用了 block_on，让它有机会运行，但是这样的话，就不能负载分担了。
 yield_now、spawn_blocking
为了让 future 能够与其他任务很好地共享它的线程，它的 poll 方法应该总是尽可能快地返回。但是如果正在执行一个长时间的计算，可能需要很长时间才能到达下一个等待，这使得其他异步任务等待的时间比想要的要长。
避免这种情况的一种方法是偶尔等待某些东西。async_std::task::yield_now 函数返回一个为此设计的简单 future：第一次轮询 yield_now 时，它返回 Poll::Pending，但表示值得很快再次轮询。效果是异步​​调用让出了线程并让其他任务有机会运行，但调用将很快获得另一轮。yield_now 的 future 第二次被轮询，它返回 Poll::Ready(())，async 函数可以恢复执行。
然而，这种方法并不总是可行的。如果使用外部 crate 进行长时间运行的计算或调用 C 或 C++，则将代码更改为更加异步友好可能并不方便，或者可能很难确保通过计算的每条路径都一定会时不时地等待。
对于这种情况，您可以使用 async_std::task::spawn_blocking。这个函数接受一个闭包，启动它在自己的线程上运行，并返回代表其返回值的 future。异步代码可以等待那个 future，将其线程让给其他任务，直到计算准备好。通过将繁重的工作放在单独的线程上，可以让操作系统负责让它很好地共享处理器。
例如，假设我们需要根据我们存储在身份验证数据库中的散列版本检查用户提供的密码。为了安全起见，验证密码需要进行大量计算，这样即使攻击者获得了我们数据库的副本，他们也不能简单地尝试数万亿个可能的密码来查看是否匹配。argonautica 提供了一个专门为存储密码而设计的散列函数：一个正确生成的 argonautica 散列需要很长时间来验证。我们可以在异步应用程序中使用 argonautica，如下所示：如果密码与哈希、给定密钥、整个数据库的密钥匹配，则返回 Ok(true)。通过在传递给 spawn_blocking 的闭包中进行验证，我们将昂贵的计算推送到它自己的线程上，确保它不会影响我们对其他用户请求的响应。
 异步设计
在许多方面，Rust 的异步编程方法类似于其他语言所采用的方法。例如，JavaScript、C# 和 Rust 都具有带有 await 表达式的异步函数。所有这些语言都有代表不完整计算的值：Rust 称它们为 futures，JavaScript 称它们为 promises，C# 称它们为tasks，但它们都代表一个可能需要等待的值。
然而，Rust 对轮询的使用是不寻常的，在 JavaScript 和 C# 中，异步函数一被调用就开始运行，并且系统库中内置了一个全局事件循环，当它们等待的值可用时恢复暂停的异步函数调用。然而，在 Rust 中，异步调用什么都不做，除非你将它传递给像 block_on、spawn 或 spawn_local 这样的函数，该函数将轮询它并推动工作完成。这些称为`executor`的函数扮演着其他语言中全局事件循环的角色。
因为 Rust 让开发者选择一个 executor 来轮询 future，Rust 不需要系统中内置的全局事件循环。async-std 提供了到目前为止我们使用的 executor 函数，tokio 定义了自己的一组类似的 executor 函数，可以在同一个程序中使用多个 executor。
 异步 HTTP 客户端
下面是使用 surf 实现一个异步客户端，也可以选择 reqwest 这是对之前的 many_requests 的重写：使用单个 surf::Client 发出我们的所有请求，如果其中几个请求指向同一服务器，我们可以重用 HTTP 连接。并且不需要异步代码块：因为 recv_string 是一个异步方法，它返回一个实现了 Send + 'static 的 future，我们可以将它直接传递给 spawn。
 异步示例
本节实现一个简单的异步聊天服务器和客户端，能避免因单个客户端的网络连接速度很慢而影响其他客户端的场景，使用下面的命令创建我们的工程：cargo new --lib --vcs none  async-chat并且添加以下依赖：这个时候我们的目录看起来如下所示：
/Users/fudenglong/WORKDIR/rust/async-chat
├── Cargo.lock
├── Cargo.toml
└── src
|  └── lib.rs完整的代码请看 https://github.com/ProgrammingRust/async-chat。
 定义 Error 和 Result
我们增加一个新文件，src/utils.rs 包含我们的 Error 和 Result 类型：这些是通用错误类型。async_std、serde_json 和 tokio 都定义了自己的错误类型，但是它们都实现了标准库的 From，? 运算符可以自动将它们全部转换为 ChatError，可以将任何合适的错误类型转换为 Box&lt;dyn Error + Send + Sync + 'static&gt;。Send 和 Sync 边界确保如果分发到另一个线程的任务失败，它可以安全地将错误报告给主线程。
在实际应用中，考虑使用 anyhow，它提供了与这些类似的 Error 和 Result 类型。 anyhow 易于使用，并提供了一些不错的功能，超出了我们的 ChatError 和 ChatResult 可以提供的功能。
 Protocol
library crate 以这两种类型捕获了我们的整个聊天协议，在 src/lib.rs 中定义：FromClient 代表客户端可以发送到服务器的数据包：它可以请求加入一个房间并将消息发布到它已加入的任何房间。FromServer 表示服务器可以发回的内容：发布到某个组的消息和错误消息。使用引用计数的 Arc&lt;String&gt; 而不是普通的 String 有助于服务器在管理组和分发消息时避免复制字符串。
#[derive] 属性告诉 serde 为 FromClient 和 FromServer 生成其 Serialize 和 Deserialize 的实现。 这让我们可以调用 serde_json::to_string 将它们转换为 JSON 值，通过网络发送它们，最后调用 serde_json::from_str 将它们转换回 Rust 形式。
test_fromclient_json 单元测试说明了它是如何使用的。给定由 serde 派生的 Serialize 实现，我们可以调用 serde_json::to_string 将给定的 FromClient 值转换为这个 JSON：然后派生的 Deserialize 实现将其解析回等效的 FromClient 值。请注意，FromClient 中的 Arc 指针对序列化形式没有影响：引用计数的字符串直接显示为 JSON 对象成员值。
 获取用户输入
我们聊天客户端的首要职责是读取用户的命令，并将相应的数据包发送到服务器。我们将做最简单可行的事情：直接从标准输入读取行。我们新建一个可执行文件：src/bin/client.rs，包含我们的客户端代码：这会调用 async_std::io::stdin 来获取客户端标准输入的异步句柄，将其包装在 async_std::io::BufReader 中，然后调用 lines 逐行处理用户的输入。它尝试将每一行解析为对应于某个 FromClient 值的命令，如果成功，则将该值发送到服务器。如果用户输入了无法识别的命令，则 parse_command 会打印错误消息并返回 None，因此 send_commands 可以再次绕过循环。如果用户键入文件结束指示，则返回 None，并且 send_commands 返回。这与在普通同步程序中编写的代码非常相似，只是它使用了 async_std 版本的库功能。
异步 BufReader 的 lines 方法很有趣，它不能像标准库那样返回迭代器：Iterator::next 方法是一个普通的同步函数，所以调用 commands.next() 会阻塞线程，直到下一行准备好，相反，lines 返回一个 Result&lt;String&gt; 流。流是迭代器的异步模拟：它以异步友好的方式按需生成一系列值。这是来自 async_std::stream 模块的 Stream 的定义：可以将其视为 Iterator 和 Future 的混合体。与迭代器一样，Stream 具有关联的 Item 类型并使用 Option 来指示序列何时结束。但就像future一样，必须对流进行轮询：要获取下一项（或得知流已结束），必须调用 poll_next 直到它返回 Poll::Ready。流的 poll_next 实现应该总是快速返回，没有阻塞。如果一个流返回 Poll::Pending，它必须在值得通过 Context 再次轮询时通知调用者。
poll_next 方法很难直接使用，但通常不需要这样做。与迭代器一样，流具有广泛的实用方法集合，例如过滤器和映射。其中有一个 next 方法，它返回流的下一个 Option&lt;Self::Item&gt; 的future。可以调用 next 并等待它返回的future，而不是显式轮询流。
将这些部分放在一起，send_commands 通过使用 next 和 while let 循环流产生的值来消费输入流中的值：在它返回 Poll::Ready(None) 时就像在一个迭代器返回 None 之后在它上调用 next。与 futures 和 Iterator一样，流也有一个 fuse 方法来确保此类调用在需要时表现得可预测。使用流，必须包含导入：这是因为 Stream 的实用方法，如 next、map、filter 等，实际上并未在 Stream 本身上定义。相反，它们是一个单独的 StreamExt 的默认方法，它为所有 Streams 自动实现： 发包
为了在网络套接字上传输数据包，我们的客户端和服务器使用我们库 crate 的 utils 模块中的 send_as_json 函数，我们在 src/utils.rs 中增加以下内容：此函数将数据包的 JSON 表示构建为字符串，在末尾添加换行符，然后将其全部写入 outbound。
从它的 where 子句中，可以看到 send_as_json 非常灵活。要发送的数据包类型 P 可以是任何实现 serde::Serialize 的东西。输出流 S 可以是任何实现 async_std::io::Write 的东西，它是输出流的 std::io::Write 的异步版本。这足以让我们在异步 TcpStream 上发送 FromClient 和 FromServer 值。使用 write_all 方法需要对 S 进行 Unpin 约束。
send_as_json 不是将数据包直接序列化到 outbound，而是将其序列化为临时字符串，然后将其写入outbound。serde_json 确实提供了将值直接序列化到输出流的函数，但这些函数仅支持同步流。写入异步流需要对 serde_json 和 serde 进行根本更改，因为它们设计的Trait具有同步方法。
与流一样，async_std 的 I/O 许多方法实际上是在Ext Trait上定义的，因此请务必记住在使用它们时使用 async_std::prelude::*。
 收包
为了接收数据包，我们的服务器和客户端将使用 utils 模块中的这个函数从异步缓冲 TCP 套接字 async_std::io::BufReader&lt;TcpStream&gt; 接收 FromClient 和 FromServer 值，我们在 src/utils.rs 中继续增加以下函数：与 send_as_json 一样，此函数是泛型的：流类型 S 必须实现async_std::io::BufRead，它是std::io::BufRead 的异步模拟，表示缓冲的输入字节流；数据包类型 P 必须实现 DeserializeOwned，这是 serde 的 Deserialize 的更严格的变体。为了提高效率，Deserialize 可以生成 &amp;str 和 &amp;[u8] 值，这些值直接从它们被反序列化的缓冲区借用它们的内容，以避免复制数据。然而，在我们的例子中，这并不好：我们需要将反序列化的值返回给我们的调用者，所以它们必须能够比我们从中解析它们的缓冲区更长寿。实现 DeserializeOwned 的类型始终独立于反序列化的缓冲区。调用 inbound.lines() 给我们一个 std::io::Result&lt;String&gt; 值的流。然后，我们使用流的 map 适配器对每个项目应用闭包，处理错误并将每一行解析为 P 类型值的 JSON 形式。这为我们提供了 ChatResult&lt;P&gt; 值的流，我们直接返回，函数的返回类型是：这表明我们返回了一些异步生成一系列 ChatResult&lt;P&gt; 值的类型，但我们的调用者无法准确判断它是哪种类型。由于我们传递给 map 的闭包都是匿名类型，这是 receive_as_json 可能返回的最具体的类型。请注意，receive_as_json 本身并不是一个异步函数。它是一个返回异步值的普通函数。
要查看 receive_as_json 是如何使用的，这里是我们聊天客户端的 handle_replies 函数，来自 src/bin/client.rs，它从网络接收 FromServer 值流并将它们打印出来供用户查看（我们需要在 src/bin/client.rs 增加如下代码）:这个函数接受一个从服务器接收数据的套接字，在它周围包裹一个 async_std::io::BufReader，然后将它传递给 receive_as_json 以获取传入的 FromServer 值流。然后它使用 while let 循环来处理传入的回复，检查错误结果并打印每个服务器回复以供用户查看。
 Client 主函数
在 src/bin/client.rs 添加如下内容实现我们的主函数：从命令行获取服务器地址后，main 有一系列要调用的异步函数，因此它将函数的其余部分包装在一个异步块中，并将该块的future传递给 async_std::task::block_on 以运行。
建立连接后，我们希望 send_commands 和 handle_replies 函数串联运行，这样我们就可以在输入时看到其他人的消息到达。如果我们输入EOF或与服务器的连接断开，程序应该退出。
鉴于我们在本节其他地方所做的，你可能会期望这样的代码：但是由于我们等待两个连接句柄，这给了我们一个程序，一旦两个任务完成就退出。我们希望在任何一个完成后立即退出。future 的 race 方法完成了这一点。调用 from_server.race(to_server) 返回一个新的 future，该 future 会轮询 from_server 和 to_server 并在它们中的任何一个准备好后立即返回 Poll::Ready(v)。两个future 必须具有相同的输出类型：最终值是最先完成的future 的值，未完成的 future 被丢弃。
race方法以及许多其他方便的实用程序是在 async_std::prelude::FutureExt 特征上定义的，async_std::prelude 使我们可以看到它。
至于未实现的 parse_command() 及其剩余部分请看：github parse_command。
 Server 主函数
下面是完整的 Server main 函数的实现：服务器的主要功能类似于客户端的：它做一些设置，然后调用 block_on 来运行一个异步代码块来完成真正的工作。为了处理来自客户端的传入连接，它创建一个 TcpListener 套接字，其传入方法返回 std::io::Result&lt;TcpStream&gt; 值流。
对于每个传入的连接，我们生成一个运行 connection::serve 函数的异步任务。每个任务还接收到一个 GroupTable 值的引用，该值表示我们服务器的当前聊天组列表，由所有连接通过 Arc 引用计数指针共享。如果 connection::serve 返回错误，我们将消息记录到标准错误输出并让任务退出，其他连接继续照常运行。
 处理客户端连接
该部分的代码在 src/bin/server/connection.rs：这很像客户端的 handle_replies 函数：大部分代码是一个循环处理传入的 FromClient 流，由带有 receive_as_json 的缓冲 TCP 流构建。如果发生错误，我们会生成一个 FromServer::Error 数据包，将错误消息传回给客户端。
除了错误消息，客户端还希望从他们加入的聊天组接收消息，因此需要与每个组共享与客户端的连接。我们可以简单地给每个人一个 TcpStream 的克隆，但是如果其中两个源尝试同时向套接字写入一个数据包，它们的输出可能会交错，并且客户端最终会收到乱码的 JSON，我们需要处理对连接的安全并发访问。
Outbound 创建时，Outbound 值获取 TcpStream 的所有权并将其包装在 Mutex 中，以确保一次只有一个任务可以使用它。serve 函数将每个 Outbound 包装在 Arc 引用计数指针中，以便客户端加入的所有组都可以指向相同的共享 Outbound 实例。
对 Outbound::send 的调用首先获取锁，返回一个解除对内部 TcpStream 引用的保护值。我们使用 send_as_json 来传输数据包，最后我们调用 guard.flush() 以确保它不会在某个缓冲区中传输一半。
表达式 &amp;mut *guard 让我们可以解决 Rust 不会应用 deref 强制来满足 trait 边界的问题。相反，我们显式地取消引用互斥锁，然后借用一个可变引用到它所保护的 TcpStream，生成 send_as_json 需要的 &amp;mut TcpStream。
请注意，Outbound 使用 async_std::sync::Mutex 类型，而不是标准库的 Mutex，这有 3 个原因：首先，如果在持有互斥锁的情况下暂停任务，标准库的互斥锁可能会出现异常行为。如果已经运行该任务的线程选择了另一个尝试锁定同一个 Mutex 的任务，那么问题就来了：从 Mutex 的角度来看，已经拥有它的线程正在尝试再次锁定它。标准的 Mutex 不能处理这种情况，因此它会出现panic或死锁。由于 Outbound::send 在等待 send_as_json 和 guard.flush 的 future 时需要持有锁，所以它必须使用 async_std::sync::Mutex；其次，异步 Mutex 的 lock 方法返回的 guard 是 future，因此等待锁定 mutex 的任务会让出其线程供其他任务使用，直到 mutex 准备好。另一方面，标准互斥锁的lock方法在等待获取锁时锁定整个线程，由于前面的代码在通过网络传输数据包时持有互斥锁，这可能需要相当长的时间；最后，标准互斥锁只能由锁定它的同一线程解锁。为了强制执行这一点，标准互斥锁的保护类型没有实现 Send：它不能被传输到其他线程。这意味着持有这种保护的 future 本身并不实现 Send，并且不能传递给 spawn 以在线程池上运行；它只能与 block_on 或 spawn_local 一起运行。 async_std::sync::MutexGuard 实现了 Send，因此在衍生任务中使用它没有问题； 聊天组 Hash 表
通常在持有互斥锁时不需要等待任何东西，并且锁不会长时间持有。在这种情况下，标准库的 Mutex 会更加高效。我们的聊天服务器的 GroupTable 类型说明了这种情况。以下是 src/bin/server/group_table.rs 的完整内容：GroupTable 只是一个受互斥锁保护的哈希表，将聊天组名称映射到实际组，两者都使用引用计数指针进行管理。get 和 get_or_create 获取锁，执行一些哈希表操作，也许是一些分配，然后返回。
在 GroupTable 中，我们使用普通的旧 std::sync::Mutex。此模块中根本没有异步代码，因此无需避免等待。事实上，如果我们想在这里使用 async_std::sync::Mutex，我们需要将 get 和 get_or_create 变成异步函数，这会引入 future 创建、暂停和恢复的开销，但几乎没有什么好处：互斥锁仅被锁定执行一些 hash 操作，也许还有一些分配。
如果我们的聊天服务器发现自己拥有数百万用户，而 GroupTable 互斥锁确实成为了瓶颈，那么使其异步无法解决这个问题。使用某种专门用于并发访问的集合类型而不是 HashMap 可能会更好，例如 dashmap。
 聊天组
group::Group 类型代表一个聊天组。该类型只需要支持 connection::serve 调用的两种方法：join（添加新成员），post（发布消息），发布的每条消息都需要分发给所有成员。
这就是我们解决前面提到的背压挑战的地方，这要求：如果一名成员无法跟上发布到群组的消息（例如，如果他们的网络连接速度较慢），则群组中的其他成员不应受到影响；即使成员落后，他们也应该有办法重新加入对话并继续以某种方式参与；用于缓冲消息的内存不应无限制地增长；因为在实现多对多通信模式时这些挑战很常见，所以 tokio 提供了一种广播通道类型，它实现了一组合理的权衡。tokio 广播通道是一个值队列（在我们的例子中是聊天消息），它允许任意数量的不同线程或任务发送和接收值。它被称为广播通道，因为每个消费者都会获得自己发送的每个值的副本，值类型必须实现 Clone。
通常，广播通道会在队列中保留一条消息，直到每个消费者都得到他们的副本。但是如果队列的长度超过了通道创建时指定的最大容量，那么最旧的消息就会被丢弃。任何跟不上的消费者在下次尝试获取下一条消息时都会收到错误消息，但是它们可以继续从当前队列最旧的消息开始获取。有两个发送者将消息入队，四个接收者将消息出队——或者更准确地说，是从队列中复制消息。接收者 B 仍有 14 条消息要接收，接收者 C 有 7 条消息，接收者 D 已完全赶上。接收者 A 落后了，11 条消息在它看到之前就被丢弃了。它下一次接收消息的尝试将失败，返回一个指示该情况的错误，并且它将被赶到队列的当前末尾。
我们的聊天服务器将每个聊天组表示为一个带有 Arc&lt;String&gt; 值的广播通道：向该组发布消息会将其广播给所有当前成员。下面是 group::Group 类型的定义，在 src/bin/server/group.rs 中定义：Group 结构体包含聊天组的名称，以及表示广播通道发送端的 broadcast::Sender。Group::new 方法调用 broadcast::channel 创建一个最大容量为 1000 条消息的广播通道。通道函数返回发送者和接收者，但此时我们不需要接收者，因为该组还没有任何成员。
要将新成员添加到组中，Group::join 方法会调用发送者的 subscribe 方法来为通道创建新的接收者。然后它生成一个新的异步任务来监视该接收者的消息并将它们写回客户端，在 handle_subscribe 函数中。
有了这些细节，Group::post 方法就很简单了：它只是将消息发送到广播通道。由于通道携带的值是 Arc&lt;String&gt; 值，因此为每个接收者提供自己的消息副本只会增加消息的引用计数，而无需任何副本或堆分配。一旦所有订阅者都发送了消息，引用计数就会下降到零，消息就会被释放。
至于 handle_subscriber，虽然细节不同，但这个函数的形式很熟悉：它是一个循环，从广播通道接收消息并通过共享的 Outbound 值将它们传输回客户端。如果循环跟不上广播通道，它会收到一个滞后错误，并报告给客户端。
如果将数据包发送回客户端完全失败，可能是因为连接已关闭，handle_subscriber 退出其循环并返回，导致异步任务退出。这会删除广播通道的接收者，从通道中取消订阅。这样，当一个连接断开，并且在它加入的组向它发送消息时，太会从组中被删除。
我们的聊天组永远不会关闭，因为我们永远不会从组表中删除组，但只是为了完整性，handle_subscriber 已准备好通过退出任务来处理已关闭的错误。
请注意，我们正在为每个客户端的每个组成员创建一个新的异步任务。这是可行的，因为异步任务使用的内存比线程少得多，而且在进程中从一个异步任务切换到另一个异步任务非常高效。
这就是聊天服务器的完整代码。它有点简陋，在 async_std、tokio 和 futures 中还有很多有价值的特性，理想情况下，这个扩展示例设法说明了异步生态系统的一些特性如何协同工作：任务、流、异步 I/O、通道和两种风格的互斥锁。
 实现执行器
聊天服务器展示了我们如何使用诸如 TcpListener 和广播通道之类的异步原语编写代码，并使用诸如 block_on 和 spawn 之类的executor 来驱动它们的执行，现在我们可以看看这些东西是如何实现的。关键问题是，当 future 返回 Poll::Pending 时，它如何与 executor 协调以在正确的时间再次对其进行轮询？想想当我们从聊天客户端的 main 函数中运行这样的代码时会发生什么：第一次 block_on 轮询异步块的 future 时，网络连接几乎肯定没有立即准备好，所以 block_on 进入睡眠状态。但是什么时候应该醒来？不知何故，一旦网络连接准备好，TcpStream 需要告诉 block_on 它应该再次尝试轮询异步块的future，因为它知道这一次，等待将完成，并且异步块的执行可以进行。
当像 block_on 这样的 executor 轮询 future 时，它必须传入一个称为 waker 的回调。如果 future 还没有准备好，Future 的规则说它现在必须返回 Poll::Pending，并安排 waker 稍后被调用，如果 future 值得再次轮询。因此，Future 的实现通常看起来像这样：换句话说，如果 future 的值已经准备好，则返回它。否则，将 Context 的 waker 的克隆存储在某处，并返回 Poll::Pending。当future 值得再次轮询时，future 必须通过调用它的 waker 来通知最后一个轮询它的 executor：理想情况下，executor 和 future 轮流轮询和唤醒：executor 轮询 future 并进入睡眠状态，然后 future 调用 waker，因此 executor 唤醒并再次轮询future。
异步函数和异步代码块的 future 不处理 waker 本身，它们只是将获得的上下文传递给他们等待的子 future ，将保存和调用 waker 的义务委托给他们。在我们的聊天客户端中，异步代码块 future 的第一次轮询只是在它等待 TcpStream::connect 的future时传递上下文，随后的类似地将其上下文传递到接下来等待的任何future。
TcpStream::connect 的future句柄被轮询，如前面的示例所示：它将waker交给一个辅助线程，该线程等待连接准备好然后调用它。
Waker 实现了 Clone 和 Send，因此 Future 可以随时创建自己的 Waker 副本，并根据需要将其发送到其他线程。Waker::wake 方法使用waker。
executor 对 future 进行过度轮询是无害的，只是效率低下。然而，Futures 应该小心，只有在轮询会取得实际进展时才调用waker：虚假唤醒和轮询的循环可能会阻止 executor 完全休眠，从而可能使处理器对其他任务的响应能力降低。
现在我们已经展示了 executor 和原始 future 如何通信，我们将自己实现原始 future，然后介绍 block_on 执行器的实现。
 调用 Waker
在本节前面，我们描述了 spawn_blocking 函数，它启动新的线程运行给定闭包并返回其返回值的 future。我们现在拥有了我们自己实现 spawn_blocking 所需的所有部分。为了简单起见，我们的版本为每个闭包创建一个新线程，而不是像 async_std 的版本那样使用线程池。
虽然 spawn_blocking 返回一个 future，但我们不会将它写成异步 fn。相反，它将是一个普通的同步函数，它返回一个结构 SpawnBlocking，我们将在其上自己实现 Future。
我们的 spawn_blocking 的签名如下：由于我们需要将闭包发送到另一个线程并带回返回值，因此闭包 F 及其返回值 T 都必须实现 Send。 而且由于我们不知道线程将运行多长时间，因此它们也必须是 'static 的，这些与 std::thread::spawn 本身施加的界限相同，SpawnBlocking&lt;T&gt; 是闭包返回值的future，这是它的定义：Shared 结构体必须充当 future 和运行闭包的线程之间的集合点，因此它由 Arc 拥有并由 Mutex 保护（这里可以使用同步互斥锁） 轮询 future 检查值是否存在，如果不存在，则将 Waker 保存在 waker 中。运行闭包的线程将其返回值保存在 value 中，然后调用 waker（如果存在）。
这是 spawn_blocking 的完整定义：创建 Shared 值后，这会产生一个线程来运行闭包，将结果存储在 Shared 的 value 字段中，并调用唤醒器（如果有）。我们可以为 SpawnBlocking 实现 Future，如下所示：轮询 SpawnBlocking 检查闭包的值是否已准备就绪，如果是，则获取所有权并返回它。否则，future 仍然处于未就绪状态，因此它会在 future 的 Waker 字段中保存上下文唤醒器的克隆。一旦 Future 返回 Poll::Ready，你就不应该再次轮询它。使用Future的常用方式，如 await 和 block_on，都遵守这条规则。
 实现 block_on
在本节中，我们将编写自己的 block_on 版本。它会比 async_std 的版本简单很多。例如，它不支持 spawn_local、任务局部变量或嵌套调用，但是运行我们的聊天客户端和服务器就足够了。
这是代码：首先来看：crossbeam 的 Parker 类型是一个简单的阻塞原语：调用 parker.park() 会阻塞线程，直到其他人在相应的 Unparker 上调用 .unpark()，可以通过调用 parker.unparker() 预先获得它。 如果你 unpark 一个未 parked 的线程，它的下一次 park() 调用会立即返回，而不会阻塞。这里的 block_on 将使用 Parker 在 future 未准备好时等待，我们传递给 futures 的唤醒器将 unpark 它。waker_fn 函数，来自同名的 crate，从给定的闭包创建一个 Waker。在这里，我们创建了一个 Waker，当被调用时，它会调用闭包 move || unparker.unpark()。可以仅使用标准库创建唤醒器，但 waker_fn 更方便一些。给定一个持有 F 类型的 future 变量，pin 宏获得future的所有权并声明一个同名的新变量，其类型为 Pin&lt;&amp;mut F&gt; 并借用 future，这为我们提供了 poll 方法所需的 Pin&lt;&amp;mut Self&gt;，将在下一节中解释的原因，异步函数和块的 future 必须通过 Pin 引用，然后才能被轮询。最后，轮询循环非常简单。传递一个带有我们唤醒器的上下文，我们轮询future，直到它返回 Poll::Ready。 如果它返回 Poll::Pending，我们将暂停线程，该线程会一直阻塞，直到调用 Waker，然后我们再试一次。as_mut 调用让我们可以在不放弃所有权的情况下轮询 future，我们将在下一节中对此进行更多解释。
 Pinning
尽管异步函数和异步代码块对于编写清晰的异步代码是必不可少的，但处理它们的 future 需要小心。Pin 类型帮助 Rust 确保它们被安全使用。
在本节中，我们将展示为什么不能像普通的 Rust 值那样自由地处理异步函数调用和块的 future。然后，将展示 Pin 如何充当指针的&quot;seal of approval&quot;，可以依靠这些指针来安全地管理此类 future。最后，展示一些使用 Pin 值的方法。
 Future 的两个生命阶段
我们来看下面代码的实现：这将打开到给定地址的 TCP 连接，并以字符串形式返回服务器想要发送的任何内容。标记为❶、❷和❸的点是恢复点，即异步函数代码中可能暂停执行的点。
一旦你向下面这样调用，而不等待其结果：现在 response 是一个 future，准备通过给定的参数执行 fetch_string，在内存中，future 如下图所示:由于我们刚刚创建了这个 future，它说执行应该从函数体顶部的恢复点 ❶ 开始。在这种状态下，future 需要处理的唯一值是函数参数。现在假设你轮询了几次响应，它到达了函数体中的这一点：进一步假设 read_to_string 的结果还没有准备好，所以 poll 返回 Poll::Pending。此时，future看起来如下图所示：future 必须始终保存下一次轮询时恢复执行所需的所有信息，在这种情况下是：恢复点❸，表示应在等待轮询read_to_string 的future恢复执行；在该恢复点处于活动状态的变量：socket 和 buf。address 的值将来不再存在，因为函数不再需要它；read_to_string future，await表达式正在轮询中；请注意，对 read_to_string 的调用借用了对 socket 和 buf 的引用。在同步函数中，所有局部变量都存在于堆栈中，但在异步函数中，在等待期间处于活动状态的局部变量必须位于 future，因此当再次轮询时它们将可用，借用此类变量的引用会借用future的一部分。
但是，Rust 要求在借用值时不要移动它们，假设要将这个 future 移动到一个新位置：Rust 无法找到所有活动的引用并相应地调整它们，在还未初始化的响应中，引用继续指向它们的旧位置，而不是指向新位置的 socket 和 buf。它们变成了悬空指针，如下图所示。防止借用值被移动通常是借用检查器的责任。借用检查器将变量视为所有权树的根，但与存储在堆栈中的变量不同，如果future本身移动，存储在future中的变量也会移动。异步函数的 future 是借用检查器的盲点，如果 Rust 想要保持其内存安全承诺，它必须以某种方式做到。
Rust 对这个问题的解决方案基于这样的见解，即 future 在首次创建时始终可以安全移动，并且只有在轮询时才会变得不安全。刚刚通过调用异步函数创建的 future 只包含一个恢复点和参数值。这些仅在尚未开始执行的异步函数主体的范围内，只有轮询future才能借用其内容。
由此可见，每一个 futue 都有两个生命阶段：第一阶段从创建 future 开始。因为函数体还没有开始执行，所以它的任何部分都不可能被借用，在这个时间点，它可以安全地移动；第二阶段在第一次轮询 future 时开始。一旦函数的主体开始执行，它可以借用存储在future的变量的引用，然后await，留下 future 的那部分借用。从第一次 poll 开始，我们必须假设 future 可能不安全；第一个生命阶段的灵活性让我们可以将 futures 传递给 block_on 和 spawn 并调用诸如 race 和 fuse 之类的适配器方法，所有这些都通过值来获取 futures。事实上，即使是最初创建 future 的异步函数调用也必须将其返回给调用者，这也是一个 move 操作。
要进入它的第二个生命阶段，必须对 future 进行poll。poll 方法要求将 future 作为 Pin&lt;&amp;mut Self&gt; 值传递。Pin 是指针类型（如 &amp;mut Self）的包装器，它限制指针的使用方式，确保它们的所指对象（如 Self）不能再次移动。因此，必须先生成一个指向未来的 Pin 包装指针，然后才能对其进行轮询。
那么，这就是 Rust 保证 futures 安全的策略：future 在被轮询之前不会变得危险；在构建指向它的 Pin-wrapped 指针之前，无法轮询future，一旦你做到了，future 就不能被 move。
一个你不能移动的值 听起来是不可能的：在 Rust 中 move 无处不在，我们将在下一节中准确解释 Pin 如何保护 future。
尽管本节讨论了异步函数，但这里的所有内容也适用于异步代码块。一个新创建的异步代码块的 future 只是从周围的代码中捕获它将使用的变量，就像一个闭包。只有轮询 future 才能创建对其内容的引用，使其无法安全移动。
请记住，这种移动的脆弱性仅限于编译器为异步函数和代码块的 future 生成的特殊实现。如果为自己的类型手动实现 Future，future在它们被轮询之前和之后移动都是完全安全的。在任何手写的 poll 中，借用检查器确保在 poll 返回时，借用的任何对 self 部分的引用都已消失。只是因为异步函数和块有能力在函数调用过程中暂停执行，并且正在进行借用，所以我们必须小心处理它们的 future 。
 Pinned Pointers
Pin 类型是指向 future 的指针的包装器，它限制如何使用指针来确保future 一旦被轮询就不能移动。对于不介意被移动的future，可以取消这些限制，但它们对于安全地轮询异步函数和块的 future 至关重要。
指针是指任何实现 Deref 的类型，也可能是 DerefMut。包裹在指针周围的 Pin 称为固定指，例如 Pin&lt;&amp;mut T&gt; 和 Pin&lt;Box&lt;T&gt;&gt;。标准库中 Pin 的定义很简单：请注意，指针字段不是 pub。这意味着构造或使用 Pin 的唯一方法是通过类型提供的精心选择的方法。给定异步函数或代码块的future，只有几种方法可以获得指向它的固定指针：pin!，来自 futures-lite 的宏，用一个Pin&lt;&amp;mut T&gt; 类型的新变量屏蔽了一个 T 类型的变量。新变量指向原始值，原始值值已移动到堆栈上的匿名临时位置。当新变量超出范围时，该值将被删除。在前面的 block_on 实现中用了 pin! 固定我们想要轮询的future。标准库的 Box::pin 构造函数获取任何类型 T 的值的所有权，将其移动到堆中，并返回 Pin&lt;Box&lt;T&gt;&gt;；Pin&lt;Box&lt;T&gt;&gt; 实现了 From&lt;Box&lt;T&gt;&gt;，因此Pin::from(boxed) 获得 boxed 的所有权，并返回一个指向堆上相同 T 的 pinned box；获得指向这些 future 的固定指针的每一种方法都需要放弃对 future 的所有权，并且没有办法将其收回。当然，固定指针本身可以以任何你喜欢的方式移动，但是移动指针并不会移动它的所指对象。因此，拥有指向 future 的固定指针可以证明已经永久放弃了移动该 future 的能力，但因此它可以被安全地轮询。
一旦你固定了一个 future，如果你想对其进行轮询，所有 Pin&lt;pointer to T&gt; 类型都有一个 as_mut 方法，该方法解引用指针并返回轮询所需的 Pin&lt;&amp;mut T&gt;。as_mut 方法还可以帮助在不放弃所有权的情况下轮询future，前面的 block_on 实现中使用了它：在这里，pin! 宏已将 future 重新声明为 Pin&lt;&amp;mut F&gt;，因此我们可以将其传递给 poll。但是可变引用不是 Copy，因此 Pin&lt;&amp;mut F&gt; 也不能是 Copy，这意味着直接调用 future.poll() 将获得future的所有权，从而为循环的下一次迭代留下一个未初始化的变量。为了避免这种情况，我们调用 future.as_mut() 为每次循环迭代重新借用一个新的 Pin&lt;&amp;mut F&gt;。
没有办法获得对 pinned future 的 &amp;mut 引用：如果你想，可以使用 std::mem::replace 或 std::mem::swap 将其移出并放置一个不同的future。
我们不必担心在普通异步代码中 pinned future 的原因是，获取future值的最常见方法是通过await或传递给执行器，它们都拥有future 的所有权并在内部将它固定。例如，我们的 block_on 实现获得了future的所有权并使用了 pin！来生成轮询所需的 Pin&lt;&amp;mut F&gt;，await 表达式也拥有future的所有权，并使用类似于 pin! 的内部宏。
 UnPin
但是，并非所有 future 都需要这种谨慎处理。对于普通类型的 Future 的任何手写实现，例如前面提到的 SpawnBlocking 类型，对构造和使用pinned pointer的限制是不必要的。这种类型实现了 Unpin 标记特性：Rust 中的几乎所有类型都使用编译器中的特殊支持自动实现 Unpin。异步函数和代码块的future例外。对于 Unpin 类型，Pin 没有任何限制。可以使用 Pin::new 从普通指针创建一个固定指针，然后使用 Pin::into_inner 将指针取出。Pin 本身传递指针自己的 Deref 和 DerefMut 实现。
比如String实现了Unpin，那么我们可以这样写：即使在创建了 Pin&lt;&amp;mut String&gt; 之后，我们也可以完全可变地访问字符串，并且一旦 Pin 被 into_inner 消耗并且可变引用消失，我们就可以将其移动到新变量中。因此，对于 Unpin 类型（几乎是所有类型）而言，Pin 是指向该类型的指针的无聊包装器。
这意味着当为自己的 Unpin 类型实现 Future 时，poll 实现可以将 self 视为 &amp;mut Self，而不是 Pin&lt;&amp;mut Self&gt;。
得知 Pin&lt;&amp;mut F&gt; 和 Pin&lt;Box&lt;F&gt;&gt; 实现了 Unpin，即使 F 没有实现，这可能会令人惊讶。因为即使 F 一旦被轮询就不能安全移动，指向它的指针总是可以安全移动，无论是否轮询。
这对于了解何时要将异步函数或代码块的 future 传递给只接受 Unpin futures 的函数很有用，Pin&lt;Box&lt;F&gt;&gt; 是 Unpin，即使 F 不是，因此将 Box::pin 应用于异步函数或代码块future会给你一个未来您可以在任何地方使用，但要以堆分配为代价。
有多种使用 Pin 的不安全方法可以让您对指针及其目标执行任何喜欢的操作，即使对于不是 Unpin 的目标类型也是如此。
 何时使用异步
异步代码比多线程代码更难编写，因为必须使用正确的 I/O 和同步原语，手动分解长时间运行的计算或将它们分离到其他线程上，并处理多线程代码中不会出现的其他细节，例如 pinning。那么异步代码提供了哪些具体优势呢？
经常听到的两种说法经不起仔细检查：异步代码非常适合 I/O，这并不完全正确。如果的应用程序花费时间等待 I/O，使其异步不会使 I/O 运行得更快。当今普遍使用的异步 I/O 接口没有什么比同步接口更高效，无论哪种方式，操作系统都有相同的工作要做。（事实上​​，未准备好的异步 I/O 操作必须稍后再试一次，因此需要两次系统调用才能完成，而不是一次。）异步代码比多线程代码更容易编写。在 JavaScript 和 Python 等语言中，这很可能是真的。在那些语言中，程序员使用 async/await 作为表现良好的并发形式：有一个执行线程，并且中断只发生在 await 表达式中。当任务切换仅在我们明确许可的情况下发生时，更容易理解您的代码。
但是这个论点并没有延续到 Rust，线程没有那么麻烦。一旦程序编译完成，它就没有数据竞争了。非确定性行为仅限于同步功能，如互斥锁、通道、原子等，这些功能旨在应对这种情况。因此，异步代码没有独特的优势，这在所有安全的 Rust 代码中都很清楚。
当然，当与线程结合使用时，Rust 的异步支持真的很出色，放弃它会很可惜。那么，异步代码的真正优势是什么？异步任务可以使用更少的内存。在 Linux 上，线程的内存使用量从 20 KiB 开始，包括用户和内核空间。Futures 可以小得多：我们的聊天服务器的 futures 大小只有几百字节，并且随着 Rust 编译器的改进而变得越来越小；异步任务的创建速度更快。在 Linux 上，创建一个线程大约需要 15 µs。生成一个异步任务大约需要 300 ns，大约是五十分之一的时间；异步任务之间的上下文切换比操作系统线程之间的切换要快，0.2 µs vs 1.7 µs。但是，这些是每个任务的最佳情况数字：如果切换是由于 I/O 准备就绪，则两种成本都会增加至 1.7 µs。切换是在不同处理器内核上的线程还是任务之间切换也有很大的不同：内核之间的通信非常慢；这给了我们一个关于异步代码可以解决什么样的问题的提示。例如，异步服务器每个任务可能使用更少的内存，因此能够处理更多的同时连接。（这可能是异步代码以“适合 I/O”而闻名的地方。）或者，如果您的设计自然地组织为许多相互通信的独立任务，那么每个任务的成本低、创建时间短，并且快速上下文切换都是重要的优势。这就是为什么聊天服务器是异步编程的经典示例，但多人游戏和网络路由器也可能是很好的用途。
在其他情况下，使用异步的情况不太清楚。如果程序有一个线程池正在执行大量计算或处于空闲状态等待 I/O 完成，那么前面列出的优点可能不会对其性能产生很大影响。而是必须优化计算，找到一个更快的网络连接，或者做一些实际影响限制因素的事情。
]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>《Rust 程序设计》</tag>
        <tag>异步编程</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】所有权</title>
    <url>/2022/04/12/Rust/%E3%80%90Rust%E3%80%91%E6%89%80%E6%9C%89%E6%9D%83/</url>
    <content><![CDATA[在编程语言的内存使用中，我们经常遇到什么时候释放内存以及如何确定访问的内存是否已被释放等问题。对于内存管理方式，存在着两大阵营：一种是以 Python，JavaScript， Ruby，Java， C#，以及 Go 等为代表的拥有垃圾回收器的语言，垃圾回收器在对象不再被访问时，会释放对象所持有的内存。这种方式对开发者友好，因为我们不用太多关心内存的申请和释放，但是这意味着将对象释放的权利交给了垃圾回收器，对于理解什么时候释放内存会是一个较大的挑战。另一种是以 C 和 C++ 为代表的语言，它们将内存的申请和回收完全交给了开发者，这造成过很多致命的问题，悬垂指针，访问已释放内存以及多重释放等问题；Rust旨在既安全又高效，因此这两种方案都不能接受，但如果有更好的方案，估计早就有人做了。Rust 通过限制程序使用指针的方式打破了这种非得妥协的僵局。Rust的做法激进，但这成了它成功的基础，尽管有诸多限制，但使用起来依然足够灵活。 所有权
在 Rust 中，所有权的概念根植于语言自身并且由编译器在编译时检查。每个值都有一个决定其生死的所有者，当这个所有者被释放（在 Rust 中，称为 Drop）时，它所拥有的值占用的的内存也会被释放。
每个变量都有一个值，当变量离开它的作用域时，就会被 drop，它拥有的值也会被从内存中释放。变量 padovan 的类型是 Vec&lt;i32&gt;，在内存中，它的值看起来像下面这样，padovan 的指针，容量和长度分配在函数 print_padovan 的栈帧上，只有 vector 的缓冲池是在堆上分配的：Rust 的 Box 类型是所有权的另一个代表。Box&lt;T&gt; 是存储在堆上的 T 类型值的指针。调用 Box::new(v) 分配一些堆空间，将值v移动到其中，并返回包含指向堆内存指针的 Box。由于Box拥有它指向的空间，当 Box 离开作用域时，它也会释放相应的堆内存。例如：当程序调用 Box::new 时，它会在堆上为两个f64值的元组分配空间，将(0.625，0.5)移动到该空间中，并返回指向它的指针。当程序运行到assert_eq!时，栈帧如下图所示：来看一个结构体的例子，结构体字段也可以是 String，Array 或者 Vector 等：composers 的类型是 Vec&lt;Person&gt;，它在内存中的表示如下图所示：这里有很多所有权关系，但每个关系都非常简单：composers 拥有一个 vector，vector 拥有它的元素，每个元素都是 Person 结构体，每个结构体都拥有自己的字段，name 字段拥有其文本。当composers离开作用域时，程序会释放掉所有堆上分配的内存。
从上面的示例来看，每个值都有一个所有者，所有者离开作用域值被释放。为了对开发友好，Rust 的所有权概念有一些变通：值的所有者可以进行转移；简单的整数，浮点数，字符这些类型不受所有者规则约束，它们在参数传递，重新赋值时会进行拷贝，它们实现了 Copy；标准库提供了引用计数类型 Rc 和 Arc，允许值在某些规则下可以有多个所有者；可以借用值的引用，引用不改变值的所有者； 所有权转移
在 Rust 中，赋值类操作，比如传递值给变量，或者从函数返回都不会复制值，仅仅是把值的所有权从一个变量转向另一个变量。来看一个例子说明值的所有权是如何转移的，而且在不同的语言中都是如何处理，我们对比 Python，C++ 以及 Rust：
RustPythonC++
当 s 初始化的时候，我们看到的是s拥有这个值，它的值的所有者：但是在将 s 赋值给 t 之后，我们看到值的所有权转移了：但是在将 s 赋值给 t 之后，值得所有权从 s 转移到了 t，成了 vector 新的主人，这段代码在运行时会报如下的错误:
error[E0382]: use of moved value: `s`
--&gt; src/main.rs:5:12
|
3 |     let s = vec![&quot;udon&quot;.to_string(), &quot;ramen&quot;.to_string(), &quot;soba&quot;.to_string()];
|         - move occurs because `s` has type `Vec&lt;String&gt;`, which does not implement the `Copy` trait
4 |     let t= s;
|            - value moved here
5 |     let u= s;
|            ^ value used here after move所以说这里将 s 赋值给 t，操作使很轻量的，没有内存的复制，只是值的所有权的转移。如果我们要实现内存的复制，我们需要对值进行 clone：对于类似的代码，我们可以对比在python语言中，s初始化的时候，和值s赋值给t和u时的内存布局：Python 的实现是将指针从s复制到t和u，并且更新列表对象的引用计数。我们来看 C++ 中的代码：s 新创建的时候，内存布局如下图所示:在将 s 赋值给 t 和 u 之后如下图所示，可见C++实现了内存的复制:在通过 let 语句将值赋值给已经初始化的变量时，变量先前拥有的值将会被释放掉，例如：但是如果在给s重新赋值之前，将原先拥有的Govinda转移给另外的变量t，再赋值 Siddhartha 时，s 是未初始化状态，所以就不会释放任何值：除了赋值之外，函数参数传递，从函数返回值以及构建结构体或者 tuple，都会涉及到所有权的转移。下面这段代码展示了这几种情况：从函数返回值：Vec::new() 构造了一个新的 vector 并且返回，不是指向 vector 的指针，而是 vector 本身。它的所有权从 Vec::new  转移给了变量 composers。类似，to_string 也返回了一个新的 String；构造结构体或者tuple：Person 的 name 字段使用 to_string 方法返回了一个 String，因此这个结构体现在拥有这个 String 的所有权；传值到函数：整个 Person 结构体，传递给了 vector 的 push 方法，vector 拥有了 Person 的所有权，间接拥有了 Palestrina 的所有权；当一个变量拥有的值转移到其他变量，或者函数之后，原先的变量就会变得未初始化，在重新初始化之前是不能使用的。
在控制流中要尤其注意： 所有权转移和索引
move 会让值的原所有者变得未初始化，因为它的所有者换人了，但不是所有类型的值都会这样。
例如，这段代码无法正常编译：试图运行此段代码会遇到下面的错误:
--&gt; src/main.rs:9:17
|
9 |     let third = v[2]; // error: Cannot move out of index of Vec
|                 ^^^^
|                 |
|                 move occurs because value has type `String`, which does not implement the `Copy` trait
|                 help: consider borrowing here: `&amp;v[2]`理解这里为什么不能编译其实也很简单，站在编程语言的角度，如果允许这样做，那么 vector 就需要记录哪些元素是活着的，哪些元素被 move 而变得未初始化。根据错误提示，我们可以用一个引用。但是如果我们确实想获取 vector 中一些元素的所有权，我们可以使用一些方法：类似 Vec 的集合类方法也提供了用于消费它们中的元素的方法，当我们直接将 vector 传递给 for 语句时，实际上我们已经将 v 的所有权转移了，v 处于未初始化状态，下面这段代码也是不能编译的。根据编译器提示是由于隐式调用了 into_iter 方法，vector 的所有权被转移，v 已经变成未初始化状态：
error[E0382]: borrow of moved value: `v`
--&gt; src/main.rs:11:22
    |
2   |     let v = vec![
    |         - move occurs because `v` has type `Vec&lt;String&gt;`, which does not implement the `Copy` trait
...
7   |     for mut s in v {
    |                  - `v` moved due to this implicit call to `.into_iter()`
...
11  |     println!(&quot;{:?}&quot;, v);
    |                      ^ value borrowed here after move
    |for 循环运行过程中，它会获取 vector 的所有权，并且在每次迭代的过程中将它赋值给 s。 Copy 类型的所有权转移
本节到目前为止，所展示的所有权转移示例示例涉及 vector、字符串等这些类型可能会占用大量内存的类型，并且复制成本高昂，通过 move 转移值的所有权会使操作成本低廉。但对于整数或字符等更简单的类型，这种出于成本的考虑就没有必要了。我们来看下面这段代码就能看到他们之间的差别：字符串类型会执行所有权转移的策略，而对于简单类型，则是采取复制策略：实际上，在处理 Copy 类型时，是复制值而不是 move，标准的 Copy 类型包括了所有的整数，浮点数，char，bool 类型以及大小固定的数组或者tuple，或者说可以按 bit 复制的类型都能被 Copy，String 由于包含一个堆中的缓冲池，所以不允许 Copy，Box&lt;T&gt; 类似。而 File类型包含了一个操作系统的文件句柄，所以也不能 Copy。还有例如 MutexGuard 互斥锁类型，复制是没有意义的，并且只能由一个线程持有。
根据经验，当值被删除时需要做一些特殊事情的任何类型都不能复制：Vec 需要释放其元素，File 需要关闭句柄，MutexGuard 需要解锁，这种类型的位按bit复制将会导致谁拥有原始的资源不清晰。
默认情况下，自定义的类型是不能复制的，所以我们自己定义的结构体或者枚举都不满足复制条件。例如下面这段代码会编译失败：原因是 Label 不能 Copy，在调用 print 函数的时候，l 拥有的值已经被转移，在调用结束之后被释放掉：
error[E0382]: borrow of moved value: `l`
--&gt; src/main.rs:13:40
|
11 |     let l = Label { number: 3 };
|         - move occurs because `l` has type `Label`, which does not implement the `Copy` trait
12 |     print(l);
|           - value moved here
13 |     println!(&quot;My label number is: {}&quot;, l.number);
|                                        ^^^^^^^^ value borrowed here after move
|但是这个设计看起来很蠢，因为我们结构体里面的都是基本类型。如果我们想这样做，并且结构体内部所有字段都是可复制的，那么我们可以通过 #[derive(Copy, Clone)] 来标记我们的结构体，这样就上面的代码就可以编译通过了：但是如果我们的结构体内部包含 String 字段，还是会编译失败，原因是 String 类型没有实现 Copy，不能复制：error[E0204]: the trait `Copy` may not be implemented for this type
--&gt; src/main.rs:2:14
|
2 |     #[derive(Copy, Clone)]
|              ^^^^
3 |     struct Label {
4 |         name: String,
|         ------------ this field does not implement `Copy`
|复制类型更灵活，因为他不会导致值原来的所有者处于未初始化状态。但是这对于一个类型的开发者来说恰好相反，更希望类型的负影响更小，而且 Copy 类型可以包含的类型非常有限，非复制类型可以使用堆分配内存并且拥有其他类型。
 Rc 和 Arc：共享所有权
尽管在 Rust 中，大多数情况下，每个值都拥有唯一的所有者，但是在某些情况下，我们可能希望某个值在所有人都不用的情况下再去释放它。为了应对这种情况，Rust 提供了 Rc 和 Arc 两种引用计数类型。Rc 和 Arc(Atomic Reference Count) 的唯一区别是，Arc 是线程安全的，支持多线程，但是性能有影响，所以，如果不需要线程共享，应该使用 Rc。
我们来看下面这个示例，和 Python 很像，对于任何类型 T，Rc&lt;T&gt; 和 Arc&lt;T&gt; 的值是一个指向堆内存的指针和一个引用计数。clone 操作不会复制 T，而是简单地创建一个指针指向堆中的内存，并且增加引用计数。这段代码的内存布局如下图所示，这里的 s，t，u 都指向了相同的内存块，当它们的最后一个离开作用域时，堆中的内存被释放掉：可以直接使用 T 类型的方法，这里我们可以用 String 的方法：但是 Rc&lt;T&gt; 持有的指针是不可变的，所以我们不能更改所包含的字符串：这段代码在编译时会出现错误：
error[E0596]: cannot borrow data in an `Rc` as mutable
--&gt; src/main.rs:11:5
|
11 |     s.push_str(&quot; noodles&quot;);
|     ^^^^^^^^^^^^^^^^^^^^^^ cannot borrow as mutable
|
= help: trait `DerefMut` is required to modify through a dereference, but it is not implemented for `Rc&lt;String&gt;`这是因为 Rust 的内存安全策略是：共享可读和可修改只能同时存在一个，而 Rc 就是为了多人共享而存在。
]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>《Rust 程序设计》</tag>
        <tag>所有权</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】枚举和模式匹配</title>
    <url>/2022/04/25/Rust/%E3%80%90Rust%E3%80%91%E6%9E%9A%E4%B8%BE%E5%92%8C%E6%A8%A1%E5%BC%8F%E5%8C%B9%E9%85%8D/</url>
    <content><![CDATA[在 Rust 中，枚举也可以包含数据，甚至是不同类型的数据。例如，Rust 的 Result&lt;String, io::Error&gt; 类型是一个枚举，这样的值要么是包含字符串的 Ok值，要么是包含 io::Error 的 Err 值。
只要 value 只有一种可能，枚举就很有用。使用它们的代价是你必须安全地访问数据，使用模式匹配就可以完成。Rust 模式有点像正则表达式，它们用于检测一个值是否是想要的，他们也可以将结构体或tuple中的多个字段提取到局部变量中。
 枚举
来看一个标准库中枚举示例 std::cmp::Ordering，它有三种可能的值：Ordering::Less， Ordering::Equal 和 Ordering::Greater，称为变量或者构造函数：我们在使用的时候可以直接导入：如果导入当前模块的枚举的构造函数可以使用 self：在内存中，C 风格的枚举值存储为整数，默认情况下，Rust 使用可以容纳它们的最小内置整数类型来存储 C 风格的枚举，大多是 1 字节，从 0 开始，但是也可以指定：但是像上面的 404，1 byte 就不能容纳了：可以使用 #[repr] 属性覆盖 Rust 的选择，就像上面的 Ordering。
允许转换一个 C 风格的枚举值为整数，但是不能从整数转换为枚举值：与 C 和 C++ 不同，Rust 保证枚举值只是枚举声明中拼写的值之一。从整数类型到枚举类型的未经检查的强制转换可能会破坏此保证，因此是不允许的。可以编写自己的转换函数：或者使用 enum_primitive。
像结构体一样，可以让 enum 自动派生内置 trait，实现比较等运算符：与其他语言不同的是，Enums 可以有自己的方法，就像结构体： 枚举数据
枚举值可以带带参数，第一种就像 tuple结构体，这些枚举值就像构造函数一样可以创建枚举变量：第二种枚举值就像结构体，参数可命名：总之，Rust 有 3 种枚举，与 3 种 struct 相呼应，没有数据的枚举对应于类似 unit 结构体。单个枚举可以同时拥有这3种类型： 内存表示
在内存中，带有数据的枚举被存储为一个小的整数标签，加上足够的内存来保存最大变体的所有字段。tag 字段供 Rust 内部使用，它告诉哪个构造函数创建了该值以及它具有哪些字段。然而，Rust 没有对枚举布局做出任何承诺，以便为未来的优化敞开大门。在某些情况下，打包枚举的效率可能比图中所示的要高。
 Json 示例
我们来看如何在代码中表示 JSON 数据，JSON 一共有 6 中数据类型：NULL，Boolean(bool)，Number(f64)，String(String)，Array(Vec&lt;Json&gt;)，和 Object(Box&lt;HashMap&lt;String, Json&gt;&gt;)：关于 json 解析，可以查看 serde_json，crates.io 上最流行的库。
代表 Object 的 HashMap 周围的 Box 仅用于使所有 Json 值更紧凑，在内存中，Json 类型的值占用了 4 个机器字。 String 和 Vec 值是3个字节，Rust 增加了1个标记字节。Null 和 Boolean 值中没有足够的数据来用完所有空间，但所有 Json 值必须具有相同的大小，多余的空间未被使用。下图展示了 Json 值在内存中的布局，Box&lt;HashMap&gt; 是一个字：它只是一个指向堆分配数据的指针，我们通过 Box 使 Json 更加紧凑。 泛型枚举
枚举也可以是泛型的，这里有两个常用的例子 Option 和 Result，和结构体的语法比较相似：当类型 T 是引用、Box 或其他智能指针类型时，Rust 可以消除 Option&lt;T&gt; 的 tag 字段。 由于这些指针类型都不允许为零，Rust 可以将 Option&lt;Box&lt;i32&gt;&gt; 表示为单个机器字：0 表示无，非零表示 Some 指针。这使得此类 Option 类型非常类似于可能为空的 C 或 C++ 指针值。不同之处在于，Rust 的类型系统要求在使用其内容之前检查选项是否为 Some，这就避免了解引用空指针。
只需几行代码即可构建通用数据结构：这几行代码定义了一个可以存储任意数量的 T 类型值的 BinaryTree，每个 BinaryTree 要么为空要么不为空。如果是空的，那么什么数据都不包，如果不为空，那么它有一个 Box，包含一个指向堆数据的指针。
每个 TreeNode 值包含一个实际元素，以及另外两个 BinaryTree 值。这意味着树可以包含子树，因此 NonEmpty 树可以有任意数量的后代。BinaryTree&lt;&amp;str&gt; 类型值的示意图如下图所示。与 Option&lt;Box&lt;T&gt;&gt; 一样，Rust 消除了 tag 字段，因此 BinaryTree 值只是一个机器字。构建这样一棵树可以用如下代码完成：大树可以由小树构成：枚举的缺点是访问里面的数据必须使用 match 模式匹配。
 模式匹配
假设有一个 RoughTime 值，需要访问值内的 TimeUnit 和 u32 字段。Rust 不允许直接 rough_time.0 和 rough_time.1 直接访问它们，因为值可能是 RoughTime::JustNow，必须使用 match：匹配枚举、结构体或元组就像 Rust 正在做一个简单扫描一样，依次检查每个 pattern 是否匹配。一个模式包含一些表示符，就像 count 和 units，匹配之后，枚举值内容都会被移动会复制到这些局部变量中，这些局部变量只能在当前模式中使用。
Rust 的模式匹配除了匹配枚举值，还能匹配很多类型的数据，如下表所示： 字面量、变量、通配符
数值，字符，bool，字符串都可以用于模式匹配，例如：这里的 n 和 other 都用于匹配其他的情况，可以使用 _ 捕获剩余所有情况：要注意的是，Rust 中，必须为 match 列出所有可能情况，_ 通常用来处理剩余的情况。
 tuple、结构体匹配
tuple模式匹配元组，当你想要在单个匹配中获取多条数据时，它们很有用：结构体模式使用花括号，就像结构体表达式一样。 它们包含每个字段的子模式：在这个例子中，如果第一个模式匹配上，那么 balloon.location.y 将存储在 height 中。像 Point &#123; x: x, y: y &#125; 这样的模式在匹配结构体时很常见，冗余的名称在视觉上很混乱，所以 Rust 有一个简写：Point &#123;x, y&#125;， 意思是一样的。这种模式仍然将 Point 的 x 字段存储在新的本地 x 中，并将其 y 字段存储在新的本地 y 中。
即使使用简写，当我们只关心几个字段时，匹配一个大型结构也很麻烦：为了避免这个，可以使用 .. 去告诉 Rust 不要关心剩余的字段： 数组、切片匹配
模式可以匹配数组，例如：切片模式类似数组，不同的是切片具有可变长度，因此切片模式不仅匹配值，还要匹配长度，.. 用于匹配任意数量的元素： ref 和 &amp;
匹配不可复制的值会转移所有权，例如下面这段代码编译失败：在这里，字段 account.name 和 account.language 被移动到局部变量 name 和 language 中，的其余部分被删除，这就是为什么我们不能在之后借用它。如果 name 和 language 都是可复制的值，Rust 会复制字段而不是移动它们，这段代码就可以了。但是如果这些是字符串，就需要一种借用匹配值而不是移动它们的模式，ref 关键字就是这样做的：现在局部变量 name 和 language 是对 account 中相应字段的引用，由于 account 只是被借用而不是被消耗，因此可以继续对其调用方法。可以使用 ref mut 借用 mut 引用：模式 Ok(ref mut line) 匹配任何成功结果，并借用 mut 引用存储在其中的成功值。
之前我们都是匹配的值，现在假如我们要匹配一个引用，假设 sphere.center() 返回 Point3d 的地址，例如 &amp;Point3d &#123; x: 0.0, y: 0.0, z: 0.0 &#125;，我们就得这样做：要记住的是，模式和表达式是自然对立的。表达式 (x, y) 将两个值组合成一个新的元组，但模式 (x, y) 则相反，它匹配一个元组并分解这两个值，&amp; 也一样，在表达式中，&amp; 创建一个引用，在一个模式中， &amp; 匹配一个引用。
匹配引用遵循我们所期望的所有规则，无法通过共享引用获得 mut 访问权限。当我们匹配 &amp;Point3d &#123; x, y, z &#125; 时，变量 x、y 和 z 接收坐标的副本，而原始 Point3d 值保持不变。它之所以有效，是因为这些字段是可复制的。如果我们在具有不可复制字段的结构上尝试同样的事情，我们会得到一个错误：但是我们可以使用 ref 获得对他的引用：让我们再看一个 &amp; 模式的例子。假设我们对字符串中的字符有一个迭代器 chars，并且它有一个方法 chars.peek()，它返回一个 Option&lt;&amp;char&gt;：对下一个字符的引用。程序可以使用 &amp; 模式来获取指向的字符： 条件模式
可以在 pattern 和 =&gt; 之间使用 if CONDITION 来决定是否匹配，例如：：如果匹配成功，但是条件未达到，就会继续匹配下一个。
 匹配多种可能
竖线 | 可用于在单个匹配中组合多个模式：在表达式中，| 是按位或运算符，但在这里它更像正则表达式中的 |，chars.peek() 匹配任何三种模式之一都会返回 true。另外可以使用 ..= 匹配整个范围的值，范围模式包括开始和结束值，所以 '0' ..= '9' 匹配所有 ASCII 数字：Rust 目前不允许在模式中使用 0..100 这样的不包含结束符的范围。
 @ 绑定
使用 x @ pattern 在匹配成功时会创建一个变量，将匹配到的整个值 copy 进去或者移动所有权，看这样一个示例代码：第一个例子，解构 Shape::Rect 然后又构建了一个，我们可以使用 @ 来完成这个目的：@ 也用于范围绑定： 模式的其他用途
模式匹配除了应用于 match，也可以应用与 tuple，struct 以及 HashMap 解构：还可以应用于我们之前学习到的 if let 和 while let 模式：]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>《Rust 程序设计》</tag>
        <tag>枚举</tag>
        <tag>模式匹配</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】生命周期</title>
    <url>/2021/09/14/Rust/%E3%80%90Rust%E3%80%91%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/</url>
    <content><![CDATA[Rust 中的每一个引用都有其生命周期（lifetime），也就是引用保持有效的作用域。大部分时候生命周期是隐含并可以推断的，正如大部分时候类型也是可以推断的一样。但有些时候，Rust 需要我们使用泛型生命周期参数来注明他们的关系，这样就能确保运行时实际使用的引用绝对是有效的。 避免悬垂应用
rust 的编译器拥有一个借用检查器，通过比较作用域来确保所有的借用是否有效。如下的示例中，这段代码是不能工作的，'a 和 'b 被称作生命周期注解，很明显看出变量 r 的生命周期大于 x，那么如果在 x 生命周期结束的时候，r 依然保留对 x 的引用，就会引发程序异常，所以 rust 拒绝这段代码的编译，根据编译器的提示，因为变量 x 获得不够长，编译通过借用检查器，就能有效地避免悬垂指针。 生命周期注解语法
生命周期注解并不改变任何引用的生命周期的长短。与当函数签名中指定了泛型类型参数后就可以接受任何类型一样，当指定了泛型生命周期后函数也能接受任何生命周期的引用。生命周期注解描述了多个引用生命周期相互的关系，而不影响其生命周期。
生命周期注解有着一个不太常见的语法：生命周期参数名称必须以撇号（'）开头，其名称通常全是小写，类似于泛型其名称非常短。'a 是大多数人默认使用的名称。生命周期参数注解位于引用的 &amp; 之后，并有一个空格来将引用类型与生命周期注解分隔开。 函数签名中的生命周期注解
来看个例子，编写一个函数，根据两个字符串的长度，返回较长的那一个，意想不到的是编译错误了，因为就这段代码来说，两个分支都有可能进入，但是rust要保证引用的有效性，就得比较两个参数的生命周期，他们的生命周期只有相同的时候才是有效的，rust 的编译器也提示我们添加生命周期注解：
代码编译错误
改进之后，给函数的参数添加生命周期注解之后，函数编译通过，我们指定两个参数 s1 和 s2 的生命周期是相同的：当我们传入的两个参数的生命周期不同的时候，因为 string2 没有 string1 活得长，当我们最后要打印的时候，string2 已经不存在了，所以编译器是会拒绝编译的。
代码编译错误
如果将打印位置放在 &#123;&#125; 内，是没有问题的，返回值的作用小于参数的作用域，result &lt; string2 &lt; string1。
 结构体中的生命周期注解
结构体包含引用时，需要为结构体添加一个生命周期注解。这个结构体有一个字段，part，它存放了一个字符串 slice，这是一个引用。类似于泛型参数类型，必须在结构体名称后面的尖括号中添加泛型生命周期参数，以便在结构体定义中使用生命周期参数。这个注解意味着 ImportantExcerpt 的实例不能比其 part 字段中的引用存在的更久，也就是说ImportantExcerpt 的实例的生命周期范围小于part 字段中的引用。 生命周期省略
每一个引用都有一个生命周期，我们需要为那些使用了引用的函数或结构体指定生命周期。但是如果每一个有引用参数的函数都需要声明参数周期，那将是惨绝人寰的编程体验。但是像下面这样的代码编译确实没有任何问题的：在早期版本（pre-1.0）的 Rust 中，这的确是不能编译的。每一个引用都必须有明确的生命周期。那时的函数签名将会写成这样：fn first_word&lt;'a&gt;(s: &amp;'a str) -&gt; &amp;'a str {在rust开发团队编写了很多 rust 代码之后，发现总是重复地写着相同的生命周期注解，为了让生活更美好，抽象出了 生命周期省略规则（lifetime elision rules），只要我们编写的代码符合这些规则，就不用写生命周期注解了。
函数或方法的参数的生命周期被称为输入生命周期（input lifetimes），而返回值的生命周期被称为输出生命周期（output lifetimes）。编译器采用三条规则来判断引用何时不需要明确的注解。第一条规则适用于输入生命周期，后两条规则适用于输出生命周期。如果编译器检查完这三条规则后仍然存在没有计算出生命周期的引用，编译器将会停止并生成错误。这些规则适用于 fn 定义，以及 impl 块。
 Rule1
每一个是引用的参数都有它自己的生命周期。换句话说就是，有一个引用参数的函数有一个生命周期参数：fn foo&lt;'a&gt;(x: &amp;'a i32)，有两个引用参数的函数有两个不同的生命周期参数，fn foo&lt;'a, 'b&gt;(x: &amp;'a i32, y: &amp;'b i32)，依此类推。
 Rule2
第二条规则是如果只有一个输入生命周期参数，那么它被赋予所有输出生命周期参数：fn foo&lt;'a&gt;(x: &amp;'a i32) -&gt; &amp;'a i32。
 Rule3
如果方法有多个输入生命周期参数并且其中一个参数是 &amp;self 或 &amp;mut self, 那么所有输出生命周期参数被赋予 self 的生命周期。这条规则使得方法更容易读写，因为只需更少的符号。
 规则使用示例
对于我们本节开头的示例，我们应用规则1之后得到：fn first_word&lt;'a&gt;(s: &amp;'a str) -&gt; &amp;str {接着我们应用规则2，这样编译器就能懂了，我们也就不用写了：fn first_word&lt;'a&gt;(s: &amp;'a str) -&gt; &amp;'a str {但是对于比较字符串长度的函数：fn longest(x: &amp;str, y: &amp;str) -&gt; &amp;str {我们在应用规则1之后得到：fn longest&lt;'a, 'b&gt;(x: &amp;'a str, y: &amp;'b str) -&gt; &amp;str {但是在应用规则2的时候，发现不适用，这样对于输出参数的生命周期，编译器不能推断出来，只能报错，由开发者指定。
 方法中的生命周期注解
当为带有生命周期的结构体实现方法时，其语法依然类似泛型类型参数的语法。声明和使用生命周期参数的位置依赖于生命周期参数是否同结构体字段或方法参数和返回值相关。
实现方法时结构体字段的生命周期必须总是在 impl 关键字之后声明并在结构体名称之后被使用，因为这些生命周期是结构体类型的一部分。
impl 块里的方法签名中，引用可能与结构体字段中的引用相关联，也可能是独立的。另外，生命周期省略规则也经常让我们无需在方法签名中使用生命周期注解。
如下示例，这里有一个方法 level。其唯一的参数是 self 的引用，而且返回值只是一个 i32，并不引用任何值：impl 之后和类型名称之后的生命周期参数是必要的，不过因为第一条生命周期规则我们并不必须标注 self 引用的生命周期。下面是一个适用于第三条生命周期省略规则的例子：这里有两个输入生命周期，所以 Rust 应用第一条生命周期省略规则并给予 &amp;self 和 announcement 他们各自的生命周期。接着，因为其中一个参数是 &amp;self，返回值类型被赋予了 &amp;self 的生命周期，这样所有的生命周期都被计算出来了。
 静态生命周期
这里有一种特殊的生命周期值得讨论：'static，其生命周期能够存活于整个程序期间。所有的字符串字面值都拥有 'static 生命周期，我们也可以选择像下面这样标注出来：这个字符串的文本被直接储存在程序的二进制文件中而这个文件总是可用的。因此所有的字符串字面值都是 'static 的。
 结合泛型参数、Trait Bound
如下是一个在同一函数中指定泛型类型参数、trait bounds 和生命周期的语法： HRTB (higher ranked trait bounds)
HRTB，中文名为高阶生命周期参数，可以用来实现动态生命周期，举几个例子说明情况。
 示例一
假如我们有下面这样的示例：
错误示例正确示例第一次调用 f(&amp;x) 时生命周期 'a 等于变量 x 的生命周期；而在第二次调用 f(&amp;y) 时，生命周期 'a 又等于了变量 y 的生命周期；而变量 x 和变量 y 的生命周期显然是不同的。因此无法用一个静态的生命周期来描述 'a ，我们希望的是，闭包 f 在具体调用时绑定具体的生命周期，比如调用 f(&amp;x) 时绑定的是 x 的生命周期，而调用 f(&amp;y) 时绑定的是 y 的生命周期。
这里我们使用 for&lt;'b&gt; Fn(&amp;'b i32) 表示 f 参数的声明周期应该在具体调用的时候和它的入参绑定： 示例二
错误示例正确示例这里不能运行的原因是，我们传入 b.do_sth 的生命周期太短了，'a 的生命周期要求是和 main 函数中 &amp;2usize 生命周期一样长： 示例三
对于下面的闭包 f，编译器不能直接推断出它的生命周期如何，因为没有声明周期参数，返回的 x 引用可能是局部变量的：
}
由于我们无法直接对 f 的参数使用生命周期参数，所以退而求其次，我们限定 f 的生命周期在其调用的时候和它的参数绑定就可以了：或者我们使用下面的方式定义 generate 函数也是可以的，限定传入 F 的参数和返回值都具有相同的生命周期 'a： 示例四
]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>生命周期</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】表达式</title>
    <url>/2022/04/20/Rust/%E3%80%90Rust%E3%80%91%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url>
    <content><![CDATA[Rust 被称作表达式语言，在C中，if 和switch 是语句，它们不会产生值，也不能在表达式中间使用。在Rust中，if 和 match可以产生值。例如：这解释了为什么Rust没有C的三元运算符(expr1: Expr2: expr3)，在 C 中，它类似 if 语句，而在 Rust 中，if 完全可以代替。另外大多数控制流在 C 中是语句，而在 Rust 中是表达式（语句都会以 ; 结束，而表达式没有）。下面是 Rust 中所有支持的表达式列表：下面的运算符都是左联运算符。例如：a - b - c 被分组成 (a-b)-c，而不是 a - (b - c)：* / % + - &lt;&lt; &gt;&gt; &amp; ^ | &amp;&amp; || as比较运算符，赋值运算符以及范围运算符 .. 不能被链在一起使用。
 代码块和分号
块，也就是一个大括号，是最通用的表达方式，它能产生一个值，可以在任何需要值的地方使用：Some(author) =&gt; 后面是简单的表达式 author.name()，而 None 后面是一个块表达式，它的值是其中的最后一个表达式 ip.to_string() 的值，并且要注意它的后面没有分号。
确实大多数 Rust 代码行都是以 ; 分号结束的，如果一个代码块以 ; 结束，那么它的值是 ()。在 javascript 中，允许省略 ;，但是语言会自动填充。在 Rust 中有没有分号是有不同的意义的：代码块内可以做一些声明，并且在最后返回一个值，能够使代码看起来比较整洁，用多了会觉得很爽。缺点是当忘记加分号时，可能会引发错误。但一般情况下是编译器都会提示我们。
 声明
let 语句的形式如下，其中的 type 和 expr 是可以省略的：let name: type = expr;let 语句可以只声明一个变量而不用初始化，可以在后面的代码中用赋值语句初始化它。这有时候很有用，我们可以先声明一个变量，然后在下面的控制流代中初始化它：这里局部变量有两种不同的方式初始化，但无论哪种方式，name 仅被初始化一次，所以无需声明为 mut 类型，在没有初始化之前使用变量是不允许的。
Rust 代码中允许重新二次定义同名变量，它会在这个二次定义的变量存在期间，将之前的变量屏蔽。在这里，line 开始的类型是 Result&lt;String, io::Error&gt;，后面又是 String，这在代码中是非常常见的，具有同一个语义的变量具有不同的类型。我们甚至可以在代码块中声明一个 fn 或者结构体，但是它们的作用域仅限于这个代码块。当我们在代码块中定义函数时，它是不能访问代码块中的局部变量的。例如，下面的 cmp_by_timestamp_then_name 不能访问变量 v： if 和 match
if 表达式比较简单，形式如下：每个 condition 必须是一个 bool 类型的表达式，Rust 不会对数字或者指针进行隐式转换。condition 两边的括号不是必须的，如果添加了，rustc 会给一个告警。
match 语句很像 C  语言中的 switch，但是更加灵活，下面是一个简单的例子。这很像 switch 语句根据 code 的值具体执行某个分支的表达式，通配符 _ 就像 switch 中的 default，能匹配任何东西，只是它必须放在最后面。将 _ 放在之前，意味着它的优先级更高，在它的之后匹配都不可达。match 表达式经常用于去区分 Option 的两种类型：Some(v) 和 None：match 的通用形式如下：如果 expr 是一个代码块，那么逗号 , 是可以省略的的。Rust 从头开始检查 value 和哪个 pattern 匹配，一旦匹配，表达式 expr 就会被执行，后面的 pattern 就不会被检查了，所以如果我们将通配符 _ 放在最前面，那么在它后面的 pattern 都不会被检查了。rust 中，match 表达式必须包含所有可能的情况，例如下面的代码会编译失败:编译器提示我们有未覆盖的情况，建议我们使用通配符：
error[E0004]: non-exhaustive patterns: `i32::MIN..=-1_i32` and `3_i32..=i32::MAX` not covered
--&gt; src/main.rs:4:11
|
4 |     match code {
|           ^^^^ patterns `i32::MIN..=-1_i32` and `3_i32..=i32::MAX` not covered
|
= note: the matched value is of type `i32`
help: ensure that all possible cases are being handled by adding a match arm with a wildcard pattern, a match arm with multiple or-patterns as shown, or multiple match arms
|
7 ~         2 =&gt; println!(&quot;User Asleep&quot;),
8 ~         i32::MIN..=-1_i32 | 3_i32..=i32::MAX =&gt; todo!(),所有的 if 分支返回的值类型必须是相同的：同理，match 表达式也是，所有的分支必须返回相同类型的值：更多关于 match 的用法可以看 【Rust】实战突破 或者 模式匹配。
 if let
这里还有一个 if 的形式，if let 表达式：如果给定的表达式 expr 匹配 pattern，那么 block1 将会运行；如果不匹配，block2 就会运行。这是一个从 Option 或者 Result 获取数据比较好的方式：if let 可以做的事情 match 都可以做，所以说 if let 只是 match 的一种简写方式： 循环
这里有四种循环表达式：Rust 中的循环语句都是表达式，但是 while 和 for 的值永远是 ()，所以它们不是很有用，loop 倒是可以返回一个值，当然只有在你声明的时候。
while 循环和C语言很像，但是 Rust 中的 condition 必须是精确的 bool 类型。
while let 类似于 if let。在每次循环迭代开始的时候，expr 的值如果匹配 pattern，那么 block 就会运行，负责循环就会退出。
loop 经常用于去写无限循环，它会一直重复执行 block，直到遇到 return，break 或者 panic。
for 循环会计算 iterable 表达式获得一个值，然后运行 block 依次。这里有许多可以迭代的类型，包括标准集合中所有类型，例如: vec 和 HashMap。
标准的C循环：在 rust 中写作如下的形式：.. 运算符可以生成一个 range，它是一个具有两个字段（start 和 end）的简单结构体。0..20 很像标准库中的 std::ops::Range &#123; start: 0, end: 20 &#125;。Range 可以被用于 for 循环，是因为它实现了 std::iter::IntoIterator。
有一点需要记住的是 for 循环会 move 值得所有权并且它包含的元素，所以下面这段代码编译失败：编译器提示我们，由于隐式调用 .into_iter() 方法，strings 包含的值的所有权已经被转移，他已经处于未初始化状态：
error[E0382]: borrow of moved value: `strings`
--&gt; src/main.rs:7:29
    |
2   |     let strings = vec![&quot;hello&quot;, &quot;world&quot;];
    |         ------- move occurs because `strings` has type `Vec&lt;&amp;str&gt;`, which does not implement the `Copy` trait
3   |     for s in strings {
    |              ------- `strings` moved due to this implicit call to `.into_iter()`
...
7   |     println!(&quot;{} error(s)&quot;, strings.len()); // error: use of moved value
    |                             ^^^^^^^^^^^^^ value borrowed here after move
    |这看起来很不方便，改进的方式是使用引用迭代集合，例如：如果我们在迭代过程中需要对它进行更改，可以获取 strings 的 muteable reference：运行成功：
/Users/fudenglong/.cargo/bin/cargo run --color=always --package mandelbrot --bin mandelbrot
    Finished dev [unoptimized + debuginfo] target(s) in 0.00s
    Running `target/debug/mandelbrot`
helloworld2 error(s)Process finished with exit code 0 break 和 continue
可以使用 break 退出 loop 循环，在 loop 的循环体中，可以给 break 一个表达式，它的值变成 loop 的值，loop 中所有 break 的表达式都必须要有相同的类型：continue 表达式用于跳到下次迭代：对于嵌套的循环，我们如何直接从内部退出。在 Rust 中，我们可以给循环一个label，用于在 break 时退出到哪层循环。例如：当然，break 语句也可以将表达式和label一起使用：label 也可以配合 continue 使用。
 return
return 语句用于退出当前的函数，返回值给调用者，特殊情况，return; 其实就是 return (); 的简写。 函数一般可能没有显示的 return 语句，函数体很像一个 block，如果最后一个表达式没有以 ; 结尾，那么它就是函数的返回值，一般情况下，这是 Rust 函数中用于返回值得首选方式。
但这并不意味着 return 是没用的，就像 break 一样，return 可以提前结束函数的运行。例如，下面的示例，当函数调用返回错误时，我们可以提前返回： never 类型 !
! 表示 never 类型。在 Rust 中，有些函数，可能包含死循环，panic!() 或者类似 std::process::exit() ，这些函数都无法正常完成，它们的返回值难以确定是什么类型，例如，标准库中的 std::process::exit()，它的源码是这样的：在Rust中，这些函数没有正常类型，未正常完成的表达式被分配到特殊类型!，并且它们不受类型必须匹配的规则的约束。例如我们编写下面这样的函数： 函数和方法调用
函数调用和方法调用同其他的语言比较类似：Rust 在引用和值之间有明显的区分，所以在传递参数时精确的类型，如果函数需要 i32 类型，你传入的是 &amp;i32 类型就会报错。但是 . 运算符放宽了这些规则，在 player.location() 的方法调用中，player 可能是 Player，&amp;Player，Box&lt;Player&gt; 或者 Rc&lt;Player&gt;。.location() 方法可以通过值或引用来获取 player，因为 Rust 的 . 运算符能够自动解引用或根据需要创建引用。
另外一种语法是和类型关联的函数，例如 Vec::new()，类似于面向对象语言中的静态方法方法调用可以串联起来：Rust 语法的一个怪癖是，在函数调用或方法调用中，泛型类型的常用语法 Vec&lt;T&gt; 不起作用：问题是表达式中的 &lt; 被当做小于运算符，正确的语法是：Rust 社区将 ::&lt;...&gt; 叫做 turbofish，但是我们也可以省略它们，改由Rust进行推断： 字段和索引
结构体字段的访问和其他语言比较类似，tuple 采用相同的语法，只是它只能使用数字作为索引。如果 . 左边是个引用或者智能指针，会自动进行解引用：[] 用于访问数组，slice 或者 vector 的元素：这些变量可以被当做左值表达式，如果它们被声明为 muteable，例如：可以使用 .. 运算符从一个数组，slice 或者 vector 获取一个 slice，例如：.. 运算符可以省略一些操作数，总共有下面这些操作类型，区间是左闭右开类型的，例如：0 .. 3 是 0, 1, 2：..= 运算符可以包含右边的结束值，例如 0 ..= 3 是 0, 1, 2, 3：但是在循环中，必须要有起始位置，因为循环必须要有个起始点。不过在数组切片中，六种形式都是有用的，如果 start 和 end 被省略，就会指向 slice 全部。
下面是一个分值算法的示例，用于实现快速排序： 解引用操作符
一元 * 操作符被用于访问引用指向的值，由于 . 在访问结构体字段或者方法时会自动解引用，所以 * 没有太多发挥的场景。 算数，位运算，比较和逻辑运算符
大多数适合是和C语言比较相似的，我们来看一些特别的例子。- 可以用于表示负数，但是没有对应的 +。与 C 中一样， a % b 计算除法向零舍入的有符号余数或模数。结果与左操作数的符号相同。请注意，% 可用于浮点数和整数：Rust 也继承了 C 的位运算符，&amp;, |, ^, &lt;&lt;, &gt;&gt;，只是 Rust 中使用 ! 表示 NOT 而不是 ~：移位运算符在处理有符号数时进行符号扩展，在处理无符号整数时进行0扩展。
位运算符比比较运算符有更高的优先级，这点和 C 语言不太一样。x &amp; BIT != 0 表示 (x &amp; BIT) != 0。
比较运算符  ==, !=, &lt;, &lt;=, &gt;, &gt;= 中的两个操作数必须要有相同的类型。
逻辑运算符 || 和 &amp;&amp; 两个操作数必须都是 bool 类型。
 赋值
= 赋值运算符用于变量的初始化，或者对可变变量，或者它们的字段，内部元素进行赋值。Rust 不同与其他语言，默认情况下，变量都是不可变的，也就是不能修改。
另外，如果值是 non-copy 类型，那么赋值运算符将会转移它的所有权，值原来的所有者就会变成未初始化状态。
除了基本的赋值运算符之外，还支持组合赋值，例如：+=，*=，-=等等：要注意的是，Rust 不支持C中的链式赋值，所以 a = b = 3 是不允许的，也不支持自增自减运算符 ++ 和 --。
 类型转换
Rust 中的类型转换需要显示的使用 as 关键字：下面是几种允许显示转换的类型：内建的数字类型可以相互转换；将整数转换为另一种整数类型始终是明确定义的。转换为更窄的类型会导致截断。转换为更宽的有符号整数是符号扩展的，无符号整数是零扩展的，依此类推。从浮点类型转换为整数类型会向零舍入：-1.99 as i32 将会得到 -1。如果该值太大而无法放入整数类型，则强制转换会生成整数类型可以表示的最接近的值：1e6 as u8 将是 255；bool 或 char 类型或类似 C 的枚举类型的值可以转换为任何整数类型，但是反过来转换是不允许的，例如，禁止将 u16 强制转换为 char 类型，因为某些 u16 值（如 0xd800）对应于无效的 Unicode 码点，它不是有效的 char 值。有一个标准方法，std::char::from_u32()，它执行运行时检查并返回一个 Option&lt;char&gt;，但这种转换的需求很少。作为一个例外，u8 是唯一可以转换成 char 的类型，因为它的范围 0-255 都是有效的 ASCII 字符；我们说过转换通常需要强制转换，一些涉及引用类型的转换非常简单，即使没有强制转换，语言也会执行它们。下面是一些自动转换的场景：String 类型的值可以自动转换为 &amp;str 类型；
&amp;Vec&lt;i32&gt; 类型的值可以自动转换为 &amp;[i32] 类型；
&amp;Box&lt;Chessboard&gt; 类型的值可以自动转换为 &amp;Chessboard 类型； 闭包
Rust 有闭包，轻量级的类似函数的值。闭包通常由一个参数列表，在竖线之间给出，后跟一个表达式：Rust 可以推断参数类型和返回类型，当然也可以向函数那样明确写出来。但是如果指定了返回类型，则为了语法上的完整性，闭包体必须是一个块：闭包的调用和函数调用语法一样：]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>《Rust 程序设计》</tag>
        <tag>表达式</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】输入输出</title>
    <url>/2022/05/02/Rust/%E3%80%90Rust%E3%80%91%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/</url>
    <content><![CDATA[Rust 用于输入和输出的标准库功能围绕三个Trait组织：Read、BufRead 和 Write：实现 Read 的值具有面向字节的输入的方法，他们被称为 Reader；实现 BufRead 的值是缓冲读取器，它们支持 Read 的所有方法，以及读取文本行等的方法；实现 Write 的值支持面向字节和UTF-8 文本输出，它们被称为 Writer；在本节中，将解释如何使用这些Trait及其方法，涵盖图中所示的读取器和写入器类型，并展示与文件、终端和网络交互的其他方式。 Readers、Writers
Readers 是内容输入源，可以从哪里读取字节。例如：使用 std::fs::File::open 打开的文件；可以从 std::net::TcpStream 代表的网络连接中读取数据；可以从 std::io::stdin() 标准输入读取数据；std::io::Cursor&lt;&amp;[u8]&gt; 和 std::io::Cursor&lt;Vec&lt;u8&gt;&gt; 值，它们是从已经在内存中的字节数组或vector中“读取”的读取器；Writers 是那些你可以把值写入的地方，例如：使用 std::fs::File::create 创建的文件；基于网络连接 std::net::TcpStream 传输数据；std::io::stdout() 和 std::io:stderr() 可以用于向标准输出和标准错误写入内容；std::io::Cursor&lt;Vec&lt;u8&gt;&gt; 类似，但允许读取和写入数据，并在vector中寻找不同的位置；std::io::Cursor&lt;&amp;mut [u8]&gt; 和上面的类似，但是不能增长内部的 buffer，因为它仅仅是已存在的字节数组的引用；由于Reader和Writer有标准的 Trait（std::io::Read 和 std::io::Write），编写适用于各种输入或输出通道的通用代码是很常见的。 例如，这是一个将所有字节从任何读取器复制到任何写入器的函数：这是 Rust 标准库 std::io::copy() 的实现，因为它是泛型的，所以可以把数据从 File 复制到 TcpStream，或者从 Stdin 到内存中的 Vec&lt;u8&gt;。 Readers
std::io::Read 有几个读取数据逇方法，它们所有都以 &amp;mut self 作为参数。reader.read(&amp;mut buffer)：从数据源读取一些字节并将它们存储在给定的缓冲区中，缓冲区参数的类型是 &amp;mut [u8]，这最多读取 buffer.len() 个字节。返回类型是 io::Result&lt;u64&gt;，它是 Result&lt;u64,io::Error&gt; 的类型别名。成功时，u64 值是读取的字节数，它可能等于或小于 buffer.len()，Ok(0) 表示没有数据要读取。
出错时，.read() 返回 Err(err)，其中 err 是 io::Error 值。io::Error 是可打印的。对于程序，它有一个 .kind() 方法，该方法返回 io::ErrorKind 类型的错误代码。这个枚举的成员具有 PermissionDenied 和 ConnectionReset 之类的名称，大多数不可忽视的明显错误，但应特别处理一种错误，io::ErrorKind::Interrupted 对应 Unix 错误代码 EINTR，表示读取恰好被信号中断，除非程序被设计成巧妙地处理信号，否则它应该只是重新读去。
.read() 方法非常低级，甚至继承了底层操作系统的怪癖。如果你正在为一种新型数据源实现 Read，这会给你很大的余地，如果你试图读取一些数据，那会很痛苦。因此，Rust 提供了几种更高级的便利方法。它们都具有 .read() 方面的默认实现，它们都处理 ErrorKind::Interrupted，所以你不必这样做。reader.read_to_end(&amp;mut byte_vec)：从 Reader 中读取剩余的输入追加到 byte_vec，它是 Vec&lt;u8&gt; 类型，返回 io::Result&lt;usize&gt; 表示读取的数量；reader.read_to_string(&amp;mut string)：同上，但是追加数据到 String 中，如果遇到无效的 UTF-8，将返回 ErrorKind::InvalidData。在某些编程语言中，字节输入和字符输入由不同的类型处理。如今，UTF-8 如此占主导地位，以至于 Rust 承认这一事实标准并在任何地方都支持 UTF-8；reader.read_exact(&amp;mut buf)：读取足够的数据以填充给定的缓冲区，参数类型是 &amp;[u8]。如果读取器在读取 buf.len() 字节之前用完数据，则返回 ErrorKind::UnexpectedEof 错误；reader.bytes()：返回输入流的按字节迭代器，类型是 std::io::Bytes。reader.chain(reader2)：将多个 Reader 连接起来，先从当前 reader 读取数据，如果遇到 EOF，则从 reader2 读取；reader.take(n)：创建一个适配器，该适配器最多可以从中读取限制字节。此函数返回一个新的 Read 实例，它最多读取n个字节，之后它将始终返回 EOF (Ok(0))。任何读取错误都不会计入读取的字节数，未来对 read() 的调用可能会成功。 Buffered Readers
为了提高效率，可以缓冲读取器和写入器，这仅仅意味着它们有一块内存（缓冲区），用于在内存中保存一些输入或输出数据。这减少了系统调用，如下图所示，应用程序应该从 BufReader 读取数据，在此示例中通过调用其 .read_line() 方法。BufReader 反过来从操作系统获取更大块的输入。缓冲 Reader 实现了 std::io::Read 和 std::io::BufRead ，后者增加了下面的方法：reader.read_line(&amp;mut line)：读取一行文本追加到 line 中，它是 String 类型，换行符 \n 或者 \r\n 都会追加到 line 中，返回值是 std::io::Result&lt;usize&gt; ，表示读取的字节数量，如果 reader 已经读完，则应该保持不变直接返回 Ok(0)；reader.lines()：在输入的行上返回一个迭代器，项目类型是 io::Result&lt;String&gt;，换行符不包含在字符串中。如果输入具有 Windows 样式的行尾&quot;\r\n&quot;，则两个字符都将被删除。这种方法几乎总是想要的文本输入，接下来的两节展示了它的一些使用示例；reader.read_until(stop_byte, &amp;mut byte_vec)、reader.split(stop_byte)：它们就像 .read_line() 和 .lines()，但面向字节，生成 Vec&lt;u8&gt; 而不是字符串，由调用者选择分隔符 stop_byte；BufRead 还提供了一对低级方法，.fill_buf() 和 .consume(n)，用于直接访问读取器的内部缓冲区。
 Reading Lines
这里有一个实现类似 grep 的函数，它搜索许多文本行，然后将它传入下一个命令：由于要调用 .lines()，需要一个实现 BufRead 的输入源。在这种情况下，我们调用 io::stdin() 来获取通过管道传输给我们的数据。但是，Rust 标准库使用互斥锁保护标准输入。我们调用 .lock() 来锁定 stdin 以供当前线程独占使用，它返回一个实现 BufRead 的 StdinLock 值，在循环结束时，StdinLock 被丢弃，释放互斥锁。
该函数的其余部分很简单，它调用 .lines() 并遍历生成的迭代器。因为这个迭代器产生 Result 值，所以我们使用 ? 操作员检查错误。假设我们想让我们的 grep 程序更进一步，并添加对在磁盘上搜索文件的支持。我们可以使这个函数通用：现在我们可以向它传递一个 StdinLock 或一个缓冲文件：请注意，文件不会自动缓冲，File 实现 Read 但没有实现 BufRead。但是，为文件或任何其他非缓冲读取器创建缓冲读取器很容易，就像 BufReader::new(reader)。（要设置缓冲区的大小，请使用 BufReader::with_capacity(size, reader)）
在大多数语言中，默认情况下文件带有缓冲功能，如果你想要无缓冲的输入或输出，你必须弄清楚如何关闭缓冲。在 Rust 中，File 和 BufReader 是两个独立的库功能，因为有时希望文件没有缓冲，有时希望缓冲来自网络的输入。
完整的程序如下所示： Writers
正如我们所见，输入主要是使用方法完成的，输出有点不同，输出主要用作参数。println!() 和 print!()：都是将信息输出到标准输出，不同的是前者会增加一个换行符，遇到错误都 panic；eprintln!() 和 eprint!()：将信息输出到标准错误，不同的是前者会增加一个换行符，遇到错误都 panic；writeln!() 和  write!()：将信息输出到第一个参数指定的目的地，不同的是前者会增加一个换行符，返回一个 Result；std::io::Write 有以下方法：writer.write(&amp;buf)：将切片 buf 中的一些字节写入底层流。它返回一个 io::Result&lt;usize&gt;。成功时，返回写入的字节数，可能小于 buf.len()，与 Reader::read() 一样，这是一种低级方法，应避免直接使用；writer.write_all(&amp;buf)：写入 buf 所有字节，返回 io::Result&lt;()&gt;；writer.flush()：将缓存的所有数据都写入底层的流中，返回 Result&lt;()&gt;；writer 会被自动关闭，当它们被丢弃的时候，可以使用 BufWriter::new(writer) 基于任何 writer 生成一个带缓冲的 Writer。如果要设置 buffer 大小，可以使用  BufWriter::with_capacity(size, writer)。当 BufWriter 被丢弃的时候，所有缓存的数据被写入底层的 Writer，如果这期间发生错误，将被忽略。为了让程序处理所有可能的错误，在丢弃 BufWriter 之前，使用 .flush() 将缓存的数据写到底层的流中。
 Files
下面列出常用的文件打开方法：std::fs::File::open(filename)：打开已经存在的文件用于读取，返回 std::io::Result，如果文件返回错误；std::fs::File::create(filename)：创建一个文件用于写，如果文件已经存在，将会被清空；如果这些不满足，还可以使用 std::fs::OpenOptions 在打开文件时，设置更多的参数：OpenOptions 有几个方法用于打开文件时设置属性：.append()：设置追加模式；.create()：如果文件存在则打开，不存在则创建；.create_new()：创建新文件，如果文件已经存在则会失败，这个 option 是原子的，另外如果该选项设置，.create() 和 .truncate() 就被忽略；.read()：设置读权限；.truncate()：如果文件已经存在，清空文件；.write()：设置写权限； Seeking
File 也实现了 std::io::Seek，这意味着可以在 File 内跳转，而不是从头到尾一次读取或写入，Seek 是这样定义的：在文件内跳来跳去效率很低，无论是机械硬盘还是固态硬盘，一次寻址所需的时间都与读取几兆字节的数据一样长。
 其他读写类型
这里有其他的读写类型：io::stdin()：返回标准输入用于数据读取，返回值的类型是 std::io::Stdin，因为这个被所有线程共享，所以每次使用都需要使用互斥锁。
Stdin 的 .lock 方法返回 io::StdinLock，它是一个带缓冲的 Reader 持有互斥锁直到丢弃。
出于技术原因，io::stdin().lock() 是无效的，锁持有 Stdin 的引用，这意味着 Stdin 必须被存在一个变量中以至于它的生命周期足够长：io::stdout()、io::stderr()：返回标准输出和标准错误用于数据写入，它们也有 .lock 方法；Vec&lt;u8&gt;：实现了 std::io::Write，写入数据到 u8 序列；std::io::Cursor::new(buf)：创建一个 Cursor，一个从 buf 读取的缓冲读取器，这就是创建读取字符串的阅读器的方式。参数 buf 可以是任何实现 AsRef&lt;[u8]&gt; 的类型，因此也可以传递 &amp;[u8]、&amp;str 或 Vec&lt;u8&gt;。
Cursor 在内部是很简单的，它们只有两个字段：buf 本身和一个整数，即 buf 中下一次读取将开始的偏移量，该位置最初为 0。
Cursor 实现 Read、BufRead 和 Seek，如果 buf 的类型是 &amp;mut [u8] 或 Vec&lt;u8&gt;，那么 Cursor 也会实现 Write。写入 Curosr 会覆盖 buf 中从当前位置开始的字节。如果试图写超出 &amp;mut [u8] 的末尾，会得到一个部分写或一个 io::Error。不过，使用 Curosr 写入 Vec&lt;u8&gt; 的末尾是可以的，它会增大 vector。因此，Cursor&lt;&amp;mut [u8]&gt; 和 Cursor&lt;Vec&lt;u8&gt;&gt; 实现了所有 4 个 std::io::prelude 中的 Trait。std::net::TcpStream：代表底层的 TCP 连接，可读可写；TcpStream::connect((&quot;hostname&quot;, PORT)) 尝试去连接到一个 server 并且返回 io::Result&lt;TcpStream&gt;。std::process::Command：支持生成子进程并将数据传输到其标准输入，如下所示：child.stdin 的类型是 Option&lt;std::process::ChildStdin&gt;，在这里在设置子进程时使用 .stdin(Stdio::piped())，所以 当 .spawn() 成功时，child.stdin 肯定会被填充。如果没有，child.stdin 将是 None。Command 也有类似的方法 .stdout() 和 .stderr()，可以用来请求 child.stdout 和 child.stderr 中的读取器。std::io 模块还提供了一些返回实验性的的读取器和写入器的函数：io::sink()：没有实际操作，所有写操作返回 Ok，但是数据被丢弃了；io::empty()：总是读取成功，但返回属于结束；io::repeat(byte)：返回 Reader 无止境地重复给定字节； 二进制数据、压缩、序列化
许多开源库构建于 std::io 之上提供了很多额外的功能。byteorder 提供了 ReadBytesExt 和 WriteBytesExt 用于二进制数据的读写：flate2 提供读取压缩数据的方法：serde 关联的 serde_json 实现了数据的序列化和反序列化。
serde 也提供了两个关键的 Trait 这用于自动派生序列化和反序列化功能：这将输出：
&#123;&quot;location&quot;:&quot;ShangHai&quot;,&quot;items&quot;:[&quot;apple&quot;],&quot;health&quot;:32&#125;由于派生代码会使编译时间变长，所以使用这个功能需要显示声明： 文件和目录
现在我们已经展示了如何使用读取器和写入器，接下来的几节将介绍 Rust 处理文件和目录的特性，它们位于 std::path 和 std::fs 模块中，所有这些功能都涉及使用文件名，因此我们将从文件名类型开始。
 OsStr、Path
操作系统不会强制文件名是有效的 Unicode，下面是两个创建文本文件的 shell 命令，只有第一个使用有效的 UTF-8 文件名：对于内核，任何字节串（不包括空字节和斜杠）都是可接受的文件名。在 Windows 上也有类似的情况，几乎任何 16位“宽字符”字符串都是可接受的文件名，即使是无效的 UTF-16 字符串也是如此。操作系统处理的其他字符串也是如此，例如命令行参数和环境变量。
Rust 字符串始终是有效的 Unicode，文件名在实践中几乎总是 Unicode，但 Rust 必须以某种方式应对它们不是的情况，这就是 Rust 有 std::ffi::OsStr 和 OsString 的原因。
OsStr 是一个字符串类型，它是 UTF-8 的超集。它的工作是能够表示当前系统上的所有文件名、命令行参数和环境变量，无论它们是否是有效的 Unicode。在 Unix 上，一个 OsStr 可以保存任何字节序列。在 Windows 上，OsStr 使用 UTF-8 的扩展存储，该扩展可以编码任何 16 位值序列，包括不匹配的。
所以我们有两种字符串类型：str 用于实际的 Unicode 字符串；OsStr 用于操作系统可以发出的任何东西。我们将再介绍一个：std::path::Path，用于文件名。Path 与 OsStr 完全相同，但它添加了许多方便的文件名相关方法。
最后，对于每个字符串类型，都有一个对应的 owning 类型：一个 String 拥有一个堆分配的 str，一个 std::ffi::OsString 拥有一个堆分配的 OsStr，一个 std::path::PathBuf 拥有一个堆分配的 Path。所有这三种类型都实现了一个共同的特征，AsRef&lt;Path&gt;，因此我们可以轻松地声明一个接受“任何文件名类型”作为参数的泛型函数。 Path、PathBuf
Path 提供以下方法：Path::new(str)：转换 &amp;str 或者 &amp;OsStr 为 &amp;Path，转换过程中不发生复制，&amp;Path 指向原始 &amp;str 或者 &amp;OsStr 的相同字节；path.parent()：返回路径父目录，以 Option&lt;&amp;Path&gt; 表示，父目录的路径仅仅是当前路径的子串：path.file_name()：返回路径中的最后一个部分，返回类型是 Option&lt;&amp;OsStr&gt;。例如：path.is_absolute(), path.is_relative()：相对路径还是绝对路径；path1.join(path2)：连接两个新路径，返回新的 PathBuf：如果 path2 是绝对路径，仅仅返回 path2 的副本，所以这个方法能被用于转换任何路径为绝对路径：path.components()：返回一个迭代器，包含给定路径从左至右的所有部分，内容类型是 std::path::Component，它是一个枚举，能代表一个文件路径中所有不同的片段：path.ancestors()：返回一个迭代器，返回当前文件或者目录的祖先直到根目录。每个 item 类型是 Path，第一个是它自己：这些方法适用于内存中的字符串，Path 也有一些查询文件系统的方法：.exists()、.is_file()、.is_dir()、.read_dir()、.canonicalize() 等等。 将 Path 转换为字符串有三种方法，每一个都允许 Path 中出现无效 UTF-8 的可能性：path.to_str()：返回 Option&lt;&amp;str&gt;，如果包含无效的 UTF-8，返回 None；path.to_string_lossy()：这基本上是同一件事，但它设法在所有情况下返回某种字符串。如果路径不是有效的 UTF-8，这些方法会创建一个副本，用 Unicode 替换字符 U+FFFD ('�') 替换每个无效的字节序列；path.display()：用于路径打印，它返回的值不是字符串，但它实现了 std::fmt::Display，因此它可以与 format!()、println!() 等一起使用。 如果路径不是有效的 UTF-8，则输出可能包含 � 字符。 文件系统访问
下表列出了 std::fs 提供的用于文件系统访问的函数：Rust 提供了可在 Windows 以及 macOS、Linux 和其他 Unix 系统上行为一致的可移植函数。
所有这些功能都是通过调用操作系统来实现的，例如，std::fs::canonicalize(path) 不仅仅使用字符串处理来消除 . 和..从给定的路径。它使用当前工作目录解析相对路径，并追踪符号链接，如果路径不存在，则为错误。
由 std::fs::metadata(path) 和 std::fs::symlink_metadata(path) 包含文件类型和大小、权限和时间戳等信息。为方便起见，Path 类型有一些内置方法：例如，path.metadata() 与 std::fs::metadata(path) 相同。
 目录读取
可以使用 std::fs::read_dir 列出目录中的内容，或者使用 path::read_dir() :注意 ? 的两种用法，在这段代码中，第一行检查打开目录的错误，第二行检查读取下一个条目的错误。std::fs::DirEntry 一些方法：entry.file_name()：目录或者文件的名称，类型是 OsString；entry.path()：文件或者目录路径，如果我们正在浏览的目录是 /home/jimb，entry.file_name() 是 &quot;.emacs&quot;，那么 entry.path() 将返回 PathBuf::from(&quot;/home/jimb/.emacs&quot;)；entry.file_type()：返回 io::Result&lt;FileType&gt;，FileType 有 .is_file(), .is_dir(), .is_symlink() 方法；当读取目录的时候，. 和 .. 不会包括在内。下面是一个递归复制目录的方法： 平台特定功能
上面的例子中，如果我们是在 Unix 系统中，将会遇到符号链接，但是符号链接 Windows 系统又没有，Rust 使用条件编译解决此类问题。对于这个场景，可以使用 use std::os::unix::fs::symlink，下面是完整程序：使用 #[cfg(unix)] 和 #[cfg(not(unix))] 我们区分了 Unix 和 非 Unix 平台。大多数 Unix 特定的特性不是独立的函数，而是向标准库类型添加新方法的扩展特性，有一个 preclude 模块可用于一次启用所有这些扩展：例如，在 Unix 上，这会为 std::fs::Permissions 添加一个 .mode() 方法，提供对表示 Unix 权限的底层 u32 值的访问。还有 std::fs::Metadata 在 unix 系统上扩展了 std::os::unix::fs::MetadataExt，能够获取UID，UID 等信息。
 Networking
对于底层网络代码，从 std::net 模块开始，它为 TCP 和 UDP 网络提供跨平台支持，使用 native_tls crate 来支持 SSL/TLS。
这些模块为网络上直接的、阻塞的输入和输出提供了构建块，可以用几行代码编写一个简单的服务器，使用 std::net 并为每个连接生成一个线程。 例如，这是一个&quot;echo&quot;服务器：回显服务器只是简单地重复您发送给它的所有内容，这种代码与用 Java 或 Python 编写的代码没有太大区别。但是，对于高性能服务器，需要使用异步输入和输出，后面将介绍 Rust 对异步编程的支持，并展示了网络客户端和服务器的完整代码。
第三方 crate 支持更高级别的协议。例如，reqwest 为 HTTP 客户端提供了一个漂亮的 API。actix-web 提供了高级功能，例如服务和转换特征，它们可以帮助从可插入的部分组成应用程序。websocket 实现了 WebSocket 协议。
]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>《Rust 程序设计》</tag>
        <tag>输入输出</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】结构体</title>
    <url>/2022/04/24/Rust/%E3%80%90Rust%E3%80%91%E7%BB%93%E6%9E%84%E4%BD%93/</url>
    <content><![CDATA[Rust 中也有结构体，类似 C/C++ 中的结构体，python 中的 class 以及 javascript 中的对象。Rust 中除了常规的结构体之外，还有 tuple 结构体，单元结构体。
 结构体
Rust 中约定包括结构体在内的所有类型都采用驼峰法命名，并且首字母大写，而方法和字段采用蛇形命名，即 _ 连接小写单词。例如：结构体初始化：如果局部变量或者函数参数和字段名称同名，还可以省略字段名称，例如：字段访问采用 . 运算符：结构体默认只能在当前模块和子模块中使用，如果想要导出结构体需要使用 pub 标识，字段也是同样的道理，如果字段都是私有的，那么只能使用类似 Vec::new 的构造方法来初始化字段：我们还可以使用相同类型的结构变量去初始化另外一个，使用 .. 运算符，自动填充未显示赋值的字段：p2 除了 name 字段是显示赋值的，其他两个字段都是来源于 p1，这段代码运行之后将输出：
p1: Person &#123; name: &quot;michael&quot;, age: 28, sex: '男' &#125;, pw: Person &#123; name: &quot;skye&quot;, age: 28, sex: '男' &#125; tuple 结构体
之所以叫tuple结构体是因为它长得像，例如：构造tuple结构体就像构造 tuple，只是需要写一个类型：就连字段访问方式也是一样的：内部字段也可以设置访问权限，即是否导出：表达式 Bounds(1024, 768) 看起来像一个函数调用，实际上它就是，定义类型的同时也隐式定义了一个函数：tuple 结构体和常规的结构体基本上是类似的，使用哪个取决于易读性和简洁性。
 Unit 结构体
Unit 结构体 没有字段：这种类型的值不占用内存，很像单元类型()，只是它有自己的类型名称，但它的值只能有一个： 内存布局
常规结构体和 tuple 结构体在内存中的是一样的，它们都包含一系列的值，可能同类型也可能混合类型，例如我们上面定义的结构体：与 C 和 C++ 不同，Rust 没有就如何在内存中对结构的字段或元素进行排序做出具体承诺，Rust 可能为了内存对齐进行调整字段顺序，所以下图仅显示了一种可能的布局：但是，Rust 确实承诺将字段的值直接存储在结构的内存块中。 JavaScript、Python 和 Java 会将 pixels 和 size 值分别放在它们自己的堆分配块中，并让 GrayscaleMap 的字段指向它们，而 Rust 将 pixels 和 size 直接嵌入到 GrayscaleMap 值中， 只有 pixels 向量拥有的堆分配缓冲区保留在其自己的块中。
您可以使用 #[repr(C)] 属性要求 Rust 以与 C 和 C++ 兼容的方式布局结构体。
 实例方法
Rust 方法不像在 C，Go 或者 Java 中那样出现在结构体定义中，而是出现在单独的 impl 块中。一个 impl 块只是 fn 定义的集合，每个定义都成为块顶部命名的结构类型上的一个方法。在这里，例如，我们定义一个 public struct Queue，然后给它两个 public 方法，push 和 pop：定义在 impl 块中的称之为关联函数，因为和特定的类型有关，相反，没有定义在 impl 中称之为自由函数。
Rust 将调用它的值作为第一个参数传递给方法，该参数必须具有特殊名称 self，self 的类型可以省略，所以 self，&amp;self 或者 &amp;mut self 实际上是 self: Queue， self: &amp;Queue， 或者 self: &amp;mut Queue 的简写。
在我们的示例中，push 和 pop 在内部使用 self 访问内部成员，这与 C++ 和 Java 不同，this 对象的成员在方法中直接可见，而 Rust 必须要使用 self 来访问。
这里由于 push 和 pop 都需要修改 Queue，所以它们的取值都是 &amp;mut self，但是我们调用时没必要显示借用可变引用，Rust 会为我们隐式进行转换，例如，q.push 等价于 (&amp;mut q).push()：如果不需要改变 self，那我们可以只获取一个共享引用：如果想获取所有权，那么使用 self： 智能指针
智能指针诸如 Box&lt;T&gt;，Rc&lt;T&gt; 以及 Arc&lt;T&gt; 都可以调用 self 类型的方法，例如：我们也可以将方法的第一个参数类型改成 Rc&lt;Self&gt;，下面的例子中，我们将一个节点添加到父节点中，但是保留 shared_node 的所有权，以在 main 函数中仍然可用：将 Rc&lt;Self&gt; 作为方法的参数，这意味着：我们可以转移 Rc&lt;Self&gt; 的所有权，例如，上面的例子我们可以直接调用：shared_node.append_to(&amp;mut parent);，只是这样，父函数中 shared_node 就不可用了；如果它需要保留 Rc 的所有权，可以像上面这样通过增加引用计数的方式实现；这里有更多的例子。
 类型方法
impl 中定义的函数也可以不将 self 作为它们的参数，这个时候称之为类型方法，就像 Vec::new，经常被用于去实现构造函数，例如：在 Rust 中，将构造函数命名为 new 是惯例，我们已经看到了 Vec::new、Box::new、HashMap::new 等，但是new这个名字并没有什么特别之处，它不是关键字，并且类型通常具有其他关联的函数作为构造函数，例如 Vec::with_capacity。
尽管可以为单个类型拥有许多单独的 impl 块，但它们必须都位于定义该类型的同一个 crate 中。
 关联常量
顾名思义，关联的 const 是常量值，它们通常用于指定类型的常用值。例如，可以定义一个用于线性代数的二维向量以及相关的单位向量：与关联函数非常相似，它们通过命名它们关联的类型来访问：关联的 const 也不必与它关联的类型具有相同的类型; 我们可以使用此功能为类型添加 ID 或名称： 泛型结构体
Rust 支持泛型，泛型可以用于处理逻辑相同，但类型不同的场景，例如，我们可以对之前的 Queue 结构体修改：可以将 Queue&lt;T&gt; 中的 &lt;T&gt; 解读为 对于任何元素类型 T...，所以这个定义解读为：对于任何类型 T，一个 Queue&lt;T&gt; 是两个 Vec&lt;T&gt; 类型的字段。例如，在 Queue&lt;String&gt; 中，T 是 String，因此 older 和 younger 的类型为 Vec&lt;String&gt;。在 Queue&lt;char&gt; 中，T 是 char，事实上，Vec 本身就是一个泛型结构体。
在泛型结构定义中，&lt;&gt; 中使用的类型名称称为类型参数。泛型结构的 impl 块如下所示：可以将 impl&lt;T&gt; Queue&lt;T&gt; 解读为 对于任何类型的 T，以下是 Queue&lt;T&gt; 上可用的一些关联函数。然后，可以使用类型参数 T 作为关联函数定义中的类型。
语法可能看起来有点多余，但 impl&lt;T&gt; 清楚地表明 impl 块涵盖任何类型 T，这将它与为一种特定类型的 Queue 编写的 impl 块区分开来，例如：这里的意思是，这有一些专门为 Queue&lt;f64&gt; 实现的关联函数，其他类型不可用。
我们在前面的代码中使用了 Rust 的 self 参数简写，因为到处写出 Queue&lt;T&gt; 也很啰嗦，所以有了另一种简写，每个 impl 块，无论是否通用，都将特殊类型参数 Self 定义为我们要添加方法的任何类型。在前面的代码中，Self 是 Queue&lt;T&gt;，所以我们可以进一步简化 Queue::new 的定义：在 new 函数中，我们的构造表达式没有任何类型，只写了 Queue&#123; ... &#125;，是因为 Rust 可以函数的签名推断，因为这里只有一种类型 Self，即 Queue&lt;T&gt; 用于函数的返回值。我们也可以使用 Self &#123; ... &#125; 代替上面的 Queue&#123; ... &#125;。
对于关联函数的调用，我们需要使用 tuborfish 运算符：::&lt;&gt;，例如：但是实际应用中，经常交由 Rust 进行推断： 结构体生命周期参数
如果结构体类型包含引用，则必须声明这些引用的生命周期。例如：struct Extrema&lt;'elt&gt; 意味着，给定任何特定的生命周期 'elt，你可以创建一个 Extrema&lt;'elt&gt; 来保存具有该生命周期的引用。这是一个扫描切片并返回最大最小值的函数：在这里，由于 find_extrema 借用了 slice 的元素，它具有生命周期 's，所以我们返回的 Extrema 结构体也使用 's 作为其引用的生命周期。Rust 总是会推断函数调用的生命周期参数，因此对 find_extrema 的调用不需要提及它们：因为返回类型与参数使用相同的生命周期是很常见的，所以当有一个明显的候选者时，Rust 允许我们省略生命周期。我们也可以这样写 find_extrema 的签名，但含义不变： 常用 Trait 派生
通常我们自己的定义的结构体是不支持 &#123;:?&#125; 打印，比较，深拷贝的，如果我们像这样做，就得实现 Copy，Debug，以及 PartialEq，但如果每一次都手动实现，就显得有点痛苦了，好在 Rust 提供了 #[derive] 属性来自动帮我们实现：如果结构体的每个字段都实现了该 trait，则这些 trait 中的每一个都可以为结构体自动实现。我们可以要求 Rust 为 Point 派生 PartialEq，因为它的两个字段都是 f64 类型，它已经实现了 PartialEq。
 内部可变性
内部可变性，简单说就是我们想改变一个不可变的数据，常规做法肯定是行不通的，但是在我们引入两个：Cell&lt;T&gt; 和 RefCell&lt;T&gt; 之后就能解决了。
我们来看一个例子，假设我们要做一个数据采集系统，采集不同类型的站点，但是它们都有一个共同的配置以及某些文件操作句柄用于处理日志等，我们在程序启动的时候，可能就初始化它了：然后，假设我们在采集某个类型的系统时，拥有下面这样的结构体，包含了公共的配置：我们知道 Rc 是一个通过计数实现的只读智能指针，但是我们想在 SpiderRobot 中保留一个文件句柄，它是标准的 File 类型，用来写日志，不过有个问题是，File 必须是 Muteable，因为它所有的方法都要求一个可变引用。
这种情况非常常见，这叫做内部可变性，Rust 为此专门提供了几种类型来解决问题，我们这里先介绍 Cell&lt;T&gt; 和 RefCell&lt;T&gt;。
 Cell&lt;T&gt;
Cell&lt;T&gt; 是一个结构体，它包含一个类型为 T 的私有字段。Cell 的唯一特殊之处在于，即使 Cell 本身没有 mut 访问权限，您也可以获取和设置字段：Cell::new(value)：创建新的 Cell，并且将给定的 value 移动到里面去；cell.get()： 返回 Cell 中 value 的副本；cell.set(value)：将给定的 value 存储到 cell 中，丢掉原先的值，这个方法不许 cell 可变，它的实现如下：当然，这对于名为 set 的方法来说是不寻常的。因为从之前的学习来说，如果我们想要对数据进行更改，我们需要 mut 访问。但出于同样的原因，这一不寻常的细节是 Cell 的全部意义所在，具体背景可参考 Cell 的源代码实现。通过，Cell 我们可以在 SpiderRobot 中统计错误数量：然后，即使 SpiderRobot 的非 mut 方法也可以使用 .get() 和 .set() 方法访问该 u32：但是 Cell 不能让我们调用值的 mut 方法，因为 get 返回的是一个副本，所以它仅仅只能用于实现了 Copy 的类型。
 RefCell&lt;T&gt;
RefCell&lt;T&gt; 和 Cell&lt;T&gt; 不同的是，他可以返回内部值得引用：RefCell::new(value)：创建新的 RefCell；ref_cell.borrow()：返回一个 Ref&lt;T&gt;，这本质上只是对存储在 ref_cell 中的值的共享引用；ref_cell.borrow_mut()：返回 RefMut&lt;T&gt;，本质上是对 ref_cell 中值的可变引用。 如果该值已被借用，则此方法会panic；ref_cell.try_borrow(), ref_cell.try_borrow_mut()：很像 borrow 和 borrow_mut，但是返回 Result。所以当值已经被借用之后，不会 panic，而是返回 Err。只有当你试图打破 mut 引用是独占引用的 Rust 规则时，这两个借用方法才会 panic。例如，这会 panic： 回归正途
现在，我们使用 RefCell&lt;T&gt; 来完成我们打印日志的功能：变量 file 的类型为 RefMut&lt;File&gt;，它可以像对 File 的可变引用一样使用。
Cell 易于使用， 必须调用 .get() 和 .set() 或 .borrow() 和 .borrow_mut() 有点尴尬，但这只是我们为违反规则而付出的代价。 另一个缺点不太明显但更严重：Cell 以及包含它们的任何类型都不是线程安全的，因此，Rust 不允许多个线程同时访问它们。这种情况应该使用 Mutex。
 参考文章Models of Generics and Metaprogramming: Go, Rust, Swift, D and More]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>结构体</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】迭代器</title>
    <url>/2022/04/30/Rust/%E3%80%90Rust%E3%80%91%E8%BF%AD%E4%BB%A3%E5%99%A8/</url>
    <content><![CDATA[迭代器是产生一系列值的值，通常用于循环操作。Rust 的标准库提供了遍历vector、字符串、哈希表和其他集合的迭代器，还提供了从输入流生成文本行、网络连接、用于多线程之间值传递的迭代器，Rust 的迭代器灵活、富有表现力且高效。
在 Rust 中，std::iter::Iterator 和 std::iter::IntoIterator 是实现迭代器的基础。迭代器可以是任何实现了 Iterator 的值，Item 是每次迭代产生的值，next 要么返回 Some(v)，v 是下一个值，要么返回 None 表示迭代结束。
想要被迭代的类型也可以实现 std::iter::IntoIterator，它的 into_iter 返回一个迭代器：我们常用的 for 循环仅仅是先调用 into_iter 生成一个迭代器，然后重复调用迭代器的 next 方法，直到 next 返回 None，预示着迭代结束。 创建迭代器
Rust 标准库文档详细解释了每种类型提供的迭代器类型，但该库遵循一些通用约定来帮助定位并找到需要的东西。
 iter 和 iter_mut
大多数集合类型都提供了 iter 和 iter_mut 方法，它们返回类型的迭代器，生成对每个item的共享或可变引用。像 &amp;[T] 和 &amp;mut [T] 这样的数组切片也有 iter 和 iter_mut 方法。这些方法是获取迭代器的最常用方法，如果不打算让 for 循环为您处理它，可以这样做：这个迭代器的 item 类型是 &amp;i32：每次调用 next 都会产生对下一个元素的引用，直到我们到达vector的末尾。每种类型都可以自由地以最适合其目的的方式实现 iter 和 iter_mut。std::path::Path 上的 iter 方法返回一个迭代器，该迭代器一次生成一个路径信息： into_iter 实现
当一个类型实现 IntoIterator 时，你可以自己调用它的 into_iter 方法，就像 for 循环一样：大多数集合提供了几种 IntoIterator 的实现，例如，&amp;T，&amp;mut T 和 T：&amp;T 类型的迭代器产生的每个值都是对值的共享引用；&amp;mut T 类型的迭代器产生的每个值都对值的可变引用。例如 Vec&lt;String&gt;，调用 (&amp;mut vector).into_iter() 返回了一个迭代器，它的 Item 类型是 &amp;mut String；调用 T 类型的 into_iter() 方法首先会获取集合值的是所有权，在迭代过程中，每个 item 的所有权从集合移动至消费的人；for 循环将 IntoIterator::into_iter 应用于其操作数，因此这三个实现创建了以下习惯用法，用于迭代对集合的共享或可变引用，或使用集合并获取其元素的所有权：并非每种类型都提供所有三种实现。例如，HashSet、BTreeSet 和 BinaryHeap 不会在可变引用上实现 IntoIterator，因为修改它们的元素可能会违反类型的不变性。
切片实现了三个 IntoIterator 变体中的两个，因为它们不拥有自己的元素，所以不存在[T]这种情况。相反，&amp;[T] 和 &amp;mut [T] 的 into_iter 返回一个迭代器，该迭代器生成对元素的共享和可变引用。
 from_fn 和 successors
一个更简单通用的方式是提供一个返回它们的闭包。std::iter::from_fn 调用一个返回 Option&lt;T&gt; 的函数生成一个迭代器：由于这个迭代器永远返回 Some(f64)，所以它永远不会结束，但是我们通过 take(1000) 只取了前 1000 个值。
如果产生的每个值都和前一个相关，那么可以使用 std::iter::successors 函数完成，它接受一个初始值和一个函数并且返回下一个 item：从零开始，successors 通过重复对最后一个点求平方并与参数 c求和。
from_fn 和 successors 都接受 FnMut 闭包，因此闭包可以捕获和修改来自周围范围的变量。例如，这个斐波那契函数使用move闭包来捕获变量并将其用作其运行状态： drain
许多集合类型提供了一个 drain 方法，该方法需要获取集合的可变引用，将对应区间的值从原来的集合中删掉，并且将删除的值以一个新的迭代器返回： 其他迭代器 迭代适配器
一旦有了一个迭代器，Iterator 提供了广泛的适配器方法选择，它们使用一个迭代器并构建一个新迭代器。要了解适配器的工作原理，我们将从两个最流行的 map 和 filter 开始。
 map、filter
Iterator 和 map 方法接受一个闭包或者函数作为参数应用于它的所有元素，然后产生新的迭代器。而 filter 接受一个闭包或函数作为参数，应用于所有元素过滤出符合要求的元素组成新的迭代器。
例如，我们可以使用 map 去将一段文本每行开始和结尾的空格去掉：同样的案例，我们如果想在处理掉首尾的空格之后，还要排除 &quot;iguanas&quot;，我们可以这样做：迭代器适配器就像 shell 中的 pipeline，每个适配器有一个单独的目的。这些适配器函数签名如下所示：在标准库中，map 和 filter 实际上返回名为 std::iter::Map 和 std::iter::Filter 的特定不透明结构类型。然而，仅仅看到它们的名字并不能提供太多信息，所以这里，我们只打算写 -&gt; impl Iterator&lt;Item=...&gt; ，因为它告诉我们真正想知道的：方法返回一个生成给定 item 类型的迭代器。
由于大多数适配器需要获取所有权，因此它们需要 Self  是 Sized。
map 通过值将每个 item 传递给它的闭包，然后将闭包结果的所有权传递给它的消费者。filter 通过共享引用将每个项目传递给它的闭包，在item被选择传递给其消费者的情况下保留所有权。这就是示例必须解引用 s 来和 &quot;iguanas&quot; 比较的原因：filter 闭包的参数 s 的类型是 &amp;&amp;str。
关于迭代器适配器，有两点需要注意。迭代器是惰性的，不调用 next 方法就不会实际运行，也就是不会消费任何 item。前面的例子中，在 collect 调用 filter 返回的迭代器的 next 方法之前，text.lines() 和 map() 不会做任何工作，这点很像 python 中的生成器；迭代适配器是零成本抽象，这意味着 Rust 有足够的信息将每个迭代器的 next 方法内联到其消费者中，然后将整个流程转换为机器代码作为一个单元，也就是我们不用关心适配器的性能开销，Rust 帮我们解决，对于上面的例子，和我们手写下面的代码有同样的性能： filter_map、flat_map
filter_map 类似于 map，但是它的闭包函数返回一个 Option&lt;T&gt; 决定这个值是留还是删掉，有点像 filter 和 map 的结合，该函数的声明如下：举个例子，如果你想从一段以空格分割的字符串中解析出数字，可以这样做：该代码输出：
1.00
0.50
17.00
1.77这个目的可以使用 map 和 filter 配合完成，但是有了 filter_map 就显得有点笨拙了：而 flat_map 和 map 一样，只是它的闭包可以返回多个 item，而不是一个，它的签名如下：举个例子：该代码输出：
Tokyo
Kyoto
São Paulo
Brasília
Nairobi
Mombasa flatten
如果我们要将一个二维数组转换成一维数组，就可以使用 flatten，在这里二维数组的每个元素都是可迭代的，它的定义如下，要求迭代器中的每个元素也都是可迭代的：举个例子：我们可以用 flatten 挑出 Vec&lt;Option&lt;&amp;str&gt;&gt; 中所有 Some&lt;&amp;str&gt;，因为 Option 也是可迭代的，例如，： take、take_while
take 和 take_while 用于决定迭代什么时候结束，前者通过迭代次数，后者通过一个闭包。它们都会获取原迭代器的所有权，它们的定义如下：举个例子，给定一封电子邮件，其中一个空行将标头与邮件正文分开，可以使用 take_while 仅迭代标头： skip、skip_while
skip 和 skip_while 方法是 take 和 take_while 的补充：它们从迭代的开始丢弃一定数量的item，或者丢弃item直到闭包找到一个可接受的项目，剩余的保持不变。它们的签名如下：例如，我们处理命令行参数时，通常丢掉第一个表示程序路径的值：如果想处理上面的邮件中的主体消息而不是标题，我们可以跳过开头的非空行： peekable
peekable 迭代器就是可以让你浏览下一个 item 但是又没实际使用它，就像调用了 next 然后又退回来了（假设），可以将任何迭代器通过转换成 peekable 的 Iterator。它的定义如下：std::iter::Peekable 是实现了 Iterator&lt;Item=Self::Item&gt; 的迭代器，这里的 Self 指的是底层的迭代器。
例如，如果要从字符流中解析数字，则在看到其后的第一个非数字字符之前，无法确定数字的结束位置： fuse
fuse 在迭代器第一次结束，即调用它的 next 方法返回 None 之后永远都返回 None，例如： next_back、rev
如果迭代器实现了 std::iter::DoubleEndedIterator，就可以从两端开始迭代，直到它们相遇迭代结束。该 trait 的定义如下：举个例子：如果一个迭代器是双端迭代器，我们就可以使用 rev 对迭代器进行反转，rev 方法的定义如下：例如： inspect
inspect 对于调试很方便，但在生产代码中使用不多。它只是将闭包应用于每个item的共享引用，然后传递该item。闭包不会影响item，但它可以做一些事情，比如打印它们或对它们进行断言。
例如：小写德语字母“ß”的大写等效项是“SS”，这就是为什么 char::to_uppercase 返回字符的迭代器，而不是单个替换字符。 前面的代码使用 flat_map 将 to_uppercase 返回的所有序列连接成一个字符串，并打印以下内容：
before: 'g'
after: 'G'
before: 'r'
after: 'R'
before: 'o'
after: 'O'
before: 'ß'
after: 'S'
after: 'S'
before: 'e'
after: 'E' chain
chain 可以将多个迭代器连接起来，它的方法声明如下：例如：chain 迭代器是可以反转的，例如： enumerate
enumerate 可以用于在迭代的时候自动加上索引，例如，原本返回 A, B, C 序列，现在返回 (0, A), (1, B), (2, C)。例如：该代码输出：
0, 40
1, 30
2, 20
3, 3
4, 2
5, 1
 zip
zip 用于将两个迭代器合成一个迭代器，每次各从一个中取出一个值，组成一对，直到有一个迭代结束。例如：zip 的参数可以是任何可迭代对象： by_ref
前面看到的大多数的适配器都会获取底层迭代器的所有权，没法再次使用，例如，对于上面的邮件示例，我们想解析邮件标题和邮件内容，可以这样做：调用 lines.by_ref() 借用了一个对迭代器的可变引用，而 take_while 迭代器正是这个引用的所有者。该迭代器在第一个 for 循环结束时退出时被丢掉，因此可以在第二个 for 循环中再次使用行。该代码输出：
Headers:
To: jimb
From: superego &lt;editor@oreilly.com&gt;Body:
Did you get any writing done today?
When will you stop wasting time plotting fractals? cycle
cycle 可以通过底层的迭代器无休止地生成值序列，只要底层的迭代器实现了 std::clone::Clone，因为他需要保存它的初始状态并且在每次循环开始时重用它，例如： 消费迭代器
前面已经讲解了如何创建和转换迭代器，这节来说明如何消费迭代器，除了使用 for 和直接调用 next 之外的其他方法。
 count、sum、product
count 用于统计迭代器中有多少个 item：sum 和 product 用于计算迭代器整数或者浮点数的和或者乘积： max、min
min 和 max 分别返回迭代器内item的最大或者最小值，其中这里的item必须实现 std::cmp::Ord：这些方法返回 Option&lt;Self::Item&gt;，所以它们可以返回 None 如果迭代器内没有 item。
 max_by、min_by
同 max 和 min 一样，只是它们使用自定义的比较函数，例如： max_by_key、min_by_key
max_by_key 和min_by_key 通过传入的闭包选择根据 item 的某些内容来确定最大最小值，它们的定义如下，传入的闭包返回 None 表示这个 item 不参与比较：举个例子，根据 HashMap 的值进行比较： item 序列比较
可以使用 &lt;，== 等比较运算符比较 str，vector 或者 slice，只要它们的 item 支持比较，除此之外还可以使用 eq，lt 等方法进行比较：split_whitespace 使用空格分割字符串生成字符串序列，然后比较字符串而不是按字符比较。
 any、all
any 和 all 引用传入的返回 bool 的函数，判断迭代器的 item 是否存在满足条件还是都满足条件： position、rposition、ExactSizeIterator
position 和 rposition 都是用于从迭代器序列中查找满足条件元素的索引，只是一个从左往右，一个从右往左。如果查找到满足条件的返回 Some(v)，否则返回 None。rposition 需要满足的条件更多，他要求迭代器必须是可反转的，并且是取得其精确长度，需要实现 std::iter::ExactSizeIterator :len 方法返回剩余的项目数，如果迭代完成，is_empty 方法返回 true。
 fold、rfold
fold 方法是一个非常通用的工具，用于在迭代器产生的整个项目序列上累积某种结果。给定一个我们称为累计值的初始值和一个闭包，fold重复地将闭包应用于当前累计值和迭代器的下一item。闭包返回的值作为新的累计值，与下一item一起传递给闭包。
sum，count，product 以及 max 都可以用 fold 来实现：fold 的签名如下：这里，A 是累计值类型。init 参数是一个 A，闭包的第一个参数和返回值以及 fold 本身的返回值也是如此。请注意，累计值被移入和移出闭包，因此可以将 fold 与非 Copy 累计值类型一起使用：rfold 作用类似，它要求迭代器是可以从右往左进行迭代： try_fold、try_rfold
try_fold 方法与 fold 相同，只是迭代过程可以提前退出，而不会消耗迭代器中的所有值。传递给 try_fold 的闭包必须返回一个 Result：如果它返回 Err(e)，try_fold 会立即返回 Err(e) 作为它的值，否则它继续继续处理。因为 try_fold 非常灵活，它被用来实现 Iterator 的许多其他消费者方法。 例如这是 all的实现： nth、nth_back
nth(n) 从迭代器中跳过 n 个 item 返回下一个，nth(0) 等价于 .next()，而且它没有获取迭代器的所有权，所以可以多次调用：它的签名如下：nth_back(n) 需要一个可以双端迭代的迭代器，从后往前找，.nth_back(0) 等价于 .nth_back(0)。
 last
last 返回最后迭代器的最后一个元素，如果迭代器为空，返回 None，例如：它的签名如下：这个从前往后消费迭代器的所有item，即使它是可以 reversible，因此，如果你有一个 reversible 迭代器，而且不想消费所有 item，可以使用 .next_back()。
 find、rfind、find_map
find 依次将迭代器的 item 传入给定的闭包，返回第一个满足条件的，如果直到结束都没有找到，返回 None：rfind 要求迭代器必须是可以从后往前迭代，除此之外和 find 相同。例如：find_map 可以对返回的值进行自定义，而不是迭代器中的类型，它的签名如下：例如，对于上面的例子，我们可以在满足要求时，将返回值包装成 Some(Number)： collect、FromIterator
collect 可以从 Rust 的标准库构建任何类型的集合，只要迭代器产生合适的项目类型：collect 本身并不知道如何构造所有这些类型。相反当一些像 Vec 或 HashMap 这样的集合类型知道如何从一个迭代器构造自己时，它实现了 std::iter::FromIterator： extend
如果一个类型实现了 std::iter::Extend，extend 方法可以从另外一个可迭代的集合添加 item 到自身，它的声明如下所有标准库的集合类型都实现了 Extend。例如： partition
partition 通过传入的闭包将集合分成两拨，例如我们可以将切片数字分成奇数偶数序列：该代码输出：
[10, 34, 1234, 546, 878], [9, 289, 19989, 345]
和 collect 一样，partition 可以创建任何你喜欢的集合，但是两者必须是相同的类型，使用上和 collect 一样，需要指定返回类型。partition 的签名如下： for_each、try_for_each
for_each 的用途和 for 相似，在其中也可使用 break 和 continue 这样的控制结构：改代码输出：
You have received: 4 calling birds
You have received: 3 french hens
You have received: 2 turtle doves如果闭包可以失败，或者需要提前退出，可以使用 try_for_each： 实现迭代器
可以为自己的类型实现 IntoIterator 和 Iterator，这样前面讲的所有方法都可以使用了，for 循环使用 IntoIterator::into_iter 将其操作数转换为迭代器。但是标准库为实现 Iterator 的每种类型提供了 IntoIterator 的全面实现，例如：这里有一个 BinaryTree 的实现，
]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>《Rust 程序设计》</tag>
        <tag>迭代器</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】错误处理</title>
    <url>/2022/04/21/Rust/%E3%80%90Rust%E3%80%91%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[Rust 的错误处理方法非常不同寻常，本节介绍了 Rust 中两种不同类型的错误处理：panic 和 Result。
 Panic
当程序遇到,数组越界，除0，这样很严重的bug时就会panic，在 Result 上调用 .expect() 遇到错误以及断言失败都会发生panic。还有宏 panic!()，用于在代码发现它出错是，想要直接退出。panic!() 接受可选的 println!() 样式参数，用于构建错误消息。
这些都是程序员的错，但我们都会犯错，当这些不该发生的错误发生时，Rust 可以终止进程。来看一个除0的示例：运行这段代码，程序会奔溃的并且打印出调用栈，还提示我们可以设置 RUST_BACKTRACE=full 获得更多的信息：
/Users/fudenglong/.cargo/bin/cargo run --color=always --package mandelbrot --bin mandelbrot
    Finished dev [unoptimized + debuginfo] target(s) in 0.00s
    Running `target/debug/mandelbrot`
thread 'main' panicked at 'attempt to divide by zero', src/main.rs:7:5
stack backtrace:
0: rust_begin_unwind
            at /rustc/4ca19e09d302a4cbde14f9cb1bc109179dc824cd/library/std/src/panicking.rs:584:5
1: core::panicking::panic_fmt
            at /rustc/4ca19e09d302a4cbde14f9cb1bc109179dc824cd/library/core/src/panicking.rs:142:14
2: core::panicking::panic
            at /rustc/4ca19e09d302a4cbde14f9cb1bc109179dc824cd/library/core/src/panicking.rs:48:5
3: mandelbrot::pirate_share
            at ./src/main.rs:7:5
4: mandelbrot::main
            at ./src/main.rs:2:5
5: core::ops::function::FnOnce::call_once
            at /rustc/4ca19e09d302a4cbde14f9cb1bc109179dc824cd/library/core/src/ops/function.rs:248:5
note: Some details are omitted, run with `RUST_BACKTRACE=full` for a verbose backtrace.Process finished with exit code 101线程之间的 panic 是相互独立的，也可以调用 std::panic::catch_unwind() 捕获异常，并且让程序执行。默认发生 panic 时会展开调用栈，此外有两种情况 Rust 不会尝试展开调用栈：如果 .drop() 方法触发了第二次恐慌，而 Rust 在第一次之后仍在尝试清理，这被认为是致命的，Rust 停止展开并中止整个进程；Rust 的恐慌行为是可定制的。如果使用 -C panic=abort 编译，程序中的第一个 panic 会立即中止进程。（使用这个选项，Rust 不需要知道如何展开调用栈，因此这可以减少编译代码的大小。） Result
Rust 中没有异常，而是在会出现错误的函数中会返回一个 Result 类型，它预示着函数会预期执行成功，也可能因异常执失败。当我们调用函数 get_weather 的时候，要么成功返回 Ok(weather)，weather 是 WeatherReport 的一个实例。或者出现错误时返回 Err(error_value)，其中 error_value 是 io:Error 类型。每当我们调用这个函数时，Rust 要求我们编写错误处理程序。如果不对 Result 做一些处理，我们就无法获取 WeatherReport，如果未使用 Result 值，编译器就会警告。
 捕获错误
处理 Result 类型最直接的方式是使用 match 表达式，这类似于其他语言中 try/catch：match 可以处理，但看起来似乎有点冗长。因此 Result&lt;T, E&gt; 提供了很多方法使用，全部方法可以阅读 https://doc.rust-lang.org/std/result/enum.Result.html，下面是一些常用的方法列表：result.is_ok(), result.is_err()：返回一个 bool 表示执行成功还是遇到错误；result.ok()：以 Option(T) 的形式返回成功值，如果结果是成功的则返回 Some(success_value)，否则返回 None；result.err()：以 Option(T) 的返回错误值；result.unwrap_or(fallback)：如果有的话返回成功值，否则返回备选值，丢掉错误；相比 .ok() 来说它是比较好的，因为返回的是 T 而不是 Option&lt;T&gt;，但是只有在存在备选值得时候才有效。result.unwrap_or_else(fallback_fn)：和前面的方法是一样的，不同的是，它需要传递一个函数或闭包。这适用于在错误时有自定义逻辑处理的情况：result.unwrap()：如果 result 是成功的，则返回成功值，否则将会 panic；result.expect(message)：类似于 unwrap()，但是允许提供一个信息在 panic 时打印；result.as_ref()：将 Result&lt;T, E&gt; 转换为 Result&lt;&amp;T, &amp;E&gt;；result.as_mut()：将 Result&lt;T, E&gt; 转换为 Result&lt;&amp;mut T, &amp;mut E&gt;；最后这两个方法和除 .is_ok() 和 .is_err() 之外的方法不同，其他的都会消耗 result 的值，也就是它们会获取 result 的所有权，它们都是接受 self 作为参数。但是有时候我们想在不破坏数据的情况下访问数据，例如，我们想调用 result.ok()，又想保持 result 在我们调用之后任然可用，所以我们可以编写 result.as_ref().ok()，他只是借用 result 而不获取它的所有权，当然返回的也就是 Option&lt;&amp;T&gt; 不再是 Option&lt;T&gt;。
 Result 别名
我们可以给 Result&lt;T, E&gt; 起个别名，让写起来更加简单，就像 std::fs::remove_file 函数：模块通常定义一个 Result 类型别名，以避免必须重复模块中几乎每个函数都一致使用的错误类型。例如，标准库的 std::io 模块包括这行代码：这定义了一个公共类型 std::io::Result&lt;T&gt;，它是 Result&lt;T, E&gt; 的别名，但将 std::io::Error 硬编码为错误类型。实际上，这意味着Rust 会将 std::io::Result&lt;String&gt; 理解为 std::io::Result&lt;String, std::io::Error&gt; 的简写。
 错误打印
我们经常处理错误的方式就是将错误信息打印出来，然后程序继续执行。我们之前都是用 println!() 这个宏来完成的，例如：标注库里面提供了很多错误类型，例如 std::io::Error，std::fmt::Error 和 std::str::Utf8Error 等等，但是它们都实现了 std::error::Error，这意味着所有的错误都有下面的接口：println!()：所有错误类型都可以使用它打印。 使用 &#123;&#125; 格式说明符打印错误通常只显示简短的错误消息。 或者可以使用 &#123;:?&#125; ，以获取错误的调试视图， 这对用户不太友好，但包含额外的技术信息；err.to_string()：返回一个错误信息作为 String；err.source()：返回底层的 err。例如，网络原因导致银行交易失败，然后又导致你的转账被取消，那么 err.souce() 可以返回下层的错误。打印错误值不会同时打印出其来源。如果想确保打印所有可用信息，使用下面的代码示例：writeln! 宏的工作方式与 println! 类似，不同之处在于它将数据写入你选择的流。在这里，我们将错误消息写入标准错误流 std::io::stderr。我们可以使用 eprintln! 宏做同样的事情，但 eprintln! 如果发生错误会 panic。
 错误传播
Rust 中有个 ? 操作符，用于向上传播错误。主要的应用场景是，当我们调用函数遇到错误，但又不想立即处理，只是想把这个错误继续往外传播，让最外层的调用者处理，我们就可以使用它：? 这个操作符的行为取决于 get_weather 函数返回成功结果还是错误结果：成功时，它会获取里面成功的值，也就是获取 WeatherReport，而不是 Result&lt;WeatherReport, io::Error&gt;；出错时，它会立即返回，为了确保有效，? 只能用于具有 Result 返回类型的函数；? 可以看做是 match 的一种简化方式：在 Rust 较老的代码中，这个干工作是用 try! 宏处理的，直到 1.13 引入 ?。错误在程序中是非常普遍，尤其是在与操作系统接口的代码中， 因此 ? 运算符可能会出现在函数的每一行：? 也可以用于 Option 类型，道理和 Result 是相同的。
 处理不同类型错误
有时候，在一个函数中会遇到多种类型的错误，而函数的返回类型是固定的，如果我们使用 ? 向上传播错误就会遇到问题，错误类型不匹配，例如：编译这段代码，会看到如下的错误，总结来说就是 line.parse() 返回的错误没法转换成 io::Error，因为 line.parse() 返回的是 Result&lt;i64 std::num::ParseIntError&gt;，ParseIntError 没法转换成 io::Error：
error[E0277]: `?` couldn't convert the error to `std::io::Error`
--&gt; src/main.rs:9:34
|
5 | fn read_numbers(file: &amp;mut dyn BufRead) -&gt; Result&lt;Vec&lt;i64&gt;, io::Error&gt; {
|                                            --------------------------- expected `std::io::Error` because of this
...
9 |         numbers.push(line.parse()?); // parsing integers can fail
|                                  ^ the trait `From&lt;ParseIntError&gt;` is not implemented for `std::io::Error`
|
= note: the question mark operation (`?`) implicitly performs a conversion on the error value using the `From` trait
= help: the following other types implement trait `From&lt;T&gt;`:
            &lt;std::io::Error as From&lt;ErrorKind&gt;&gt;
            &lt;std::io::Error as From&lt;IntoInnerError&lt;W&gt;&gt;&gt;
            &lt;std::io::Error as From&lt;alloc::ffi::c_str::NulError&gt;&gt;
= note: required because of the requirements on the impl of `FromResidual&lt;Result&lt;Infallible, ParseIntError&gt;&gt;` for `Result&lt;Vec&lt;i64&gt;, std::io::Error&gt;`这里介绍一种错误的处理方法，Rust 标准库中的所有错误都可以转换为 Box&lt;dyn std::error::Error + Send + Sync + 'static&gt; 类型，其中：dyn std::error::Error：表示任意错误；Send + Sync + 'static：能够在多线程之间安全传递；出于方便，我们可以下面的类型，并且对 read_numbers() 函数进行整改，如果想从一个返回 GenericResult 的函数，找到一种特定类型的错误处理，但让其他错误传播出去，可以使用泛型方法 error.downcast_ref::&lt;ErrorType&gt;()。 如果它恰好是要查找的特定类型的错误，它会借用对错误的引用：还有一种处理方式是使用 thiserror 帮我自动实现 std::error::Error。
 忽略错误
有时候，我们可能就是想忽略一个错误，因为某个函数执行成功与否关系不大，例如写日志到 stderr，但是我们如果不处理，编译器会报告警：不过可以使用 let _ = ... 消除这个告警： 处理 main 函数中的错误
使用 ? 向上传递错误大多时候是比较正确的行为，可是当错误传播到 main 函数的时候我们就需要处理。大多时候，我们看到的 main 函数签名都是下面这个样子，它的返回值类型是 ()：所以我们不能使用 ? 传播错误：最简单的方式是使用 .expect()，检查是否调用成功，如果失败就打印错误信息：不过，我们也可以更改这个 main 函数的签名，让它返回 Result 类型，使用 ? 传递错误：但是这种方式打印的错误信息不是很详细，如果想自定义错误输出，还需要自己处理错误： 错误定义
标注库里面的错误不可能满足所有情况，大多时候我们需要自定义错误：但是如果我们希望和标准的错误类型表现一样，我们还需要做点适配：不过，每次都实现这些 trait 是很头疼的，所以我们可使用 thiserror，帮我自动实现：]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>《Rust 程序设计》</tag>
        <tag>错误处理</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】闭包</title>
    <url>/2022/04/30/Rust/%E3%80%90Rust%E3%80%91%E9%97%AD%E5%8C%85/</url>
    <content><![CDATA[很多语言中都有闭包，有的叫匿名函数，有的叫 lambda 函数，用一个最简单的例子演示闭包，例如 sort_by_key 传入的就是一个闭包函数： 变量捕获
闭包可以捕获上下文中的变量，例如，下面的闭包使用了原本属于 sort_by_statistic 函数中的 stat，我们称闭包捕获了 stat：闭包在捕获变量的同时，会自动创建对 stat 的引用，所以该闭包的生命周期不能超过 stat，在函数返回的时候，会自动释放 stat。
 变量偷取
我们来看一个复杂一些的例子，这段代码会编译错误，我们创建了一个新的线程进行排序，我们的闭包函数还引用了 cities 和 stat：这段代码编译失败是因为存在两个原因：由于 start_sorting_thread 中已经包含了对 cities 的可变引用，所以闭包不能在创建新的共享引用；
新创建的线程和调用者所在线程并行，start_sorting_thread 返回时，新线程可能还没开始，而 stat 由于不在作用域中，需要被释放；解决方案我们告诉 Rust，需要偷取闭包所使用的的变量而不是借用，使用关键字 move 来进行声明：因此，Rust 提供了两种使用上下文中数据的方式：引用和偷取。
 闭包和函数类型
我们可以把函数或者闭包作为函数的参数传递，那么他们肯定是有类型的，例如：这里 key_sort_fn 的类型是：fn(&amp;City) -&gt; i64，我们可以把函数存储在结构体字段中，fn 实际上指向函数机器代码的地址，所占空间就是一个机器字，一个函数可以接受另外一个函数作为参数，例如：这个函数没法接受闭包作为参数，因为类型不匹配，fn 只能表示函数，闭包虽然可调用，但不是 fn 类型。如果我们需要它能接受函数或者闭包同时参数，需要更改这个函数的签名，使用泛型约束 F 是一个 Fn 类型：Fn(&amp;City) -&gt; bool 会自动被相关的函和闭包数实现，相当于限定了函数的签名，因此我们可以传入匹配的函数或者闭包。
 闭包性能
在大多数语言中，闭包在堆中分配、动态分派和自动垃圾收集。因此，创建、调用和收集它们中的每一个都会花费一点点额外的 CPU 时间。更糟糕的是，闭包往往会禁止内联，这是编译器用来消除函数调用开销的关键技术。
Rust 闭包没有这些性能缺陷，与 Rust 中的其他所有内容一样，它们不会在堆上分配，除非将它们放入 Box、Vec 或其他容器中。而且由于每个闭包都有不同的类型，只要 Rust 编译器知道你正在调用的闭包的类型，它就可以内联该特定闭包的代码。Rust 的闭包设计使其运行的很快，即使在性能敏感代码中也可以使用它们。
下图展示了不同种类的闭包在内存上的布局：闭包 (a) 使用这两个变量，在内存中，这个闭包看起来像一个包含对它使用的变量的引用的小结构；闭包 (b) 完全一样，只是它是一个 move 闭包，包含了引用的值；闭包 © 不使用其环境中的任何变量，所以这个闭包根本不占用任何内存。 FnOnce
有些闭包只能使用一次，例如，下面的代码中的，闭包将捕获的 String 手动通过 drop 丢掉了，我们在调用的时候，就会出错：编译器会提示我们 my_str 已经被释放过了，它是 FnOnce 类型的：
    error[E0525]: expected a closure that implements the `Fn` trait, but this closure only implements `FnOnce`
    --&gt; src/main.rs:13:13
    |
    13 |     let f = || drop(my_str);
    |             ^^^^^^^^------^
    |             |       |
    |             |       closure is `FnOnce` because it moves the variable `my_str` out of its environment
    |             this closure implements `FnOnce`, not `Fn`
    14 |     call_twice(f);
    |     ---------- the requirement to implement `Fn` derives from here根据提示，我们需要限定 F 是 FnOnce 类型的，就像 a + b 是 Add::add(a, b) 的简写一样，闭包调用展开之后其实是 closure.call() 或者 closure.call_once()： 示例一
如果一个闭包并不转移自己的内部数据，那么它就不是 FnOnce，然而，一旦它被当做 FnOnce 调用，之后就无法再次调用了： 示例二 FnMut
还有另一种闭包，一种包含可变数据或 mut 引用的闭包。Rust 认为非 mut 值可以安全地跨线程共享，但是共享包含 mut 数据的非 mut 闭包是不安全的，从多个线程调用这样的闭包可能会导致各种竞争条件，因为多个线程试图同时读取和写入相同的数据。因此，Rust 多了一类闭包，FnMut。
任何需要 mut 访问值但不删除任何值的闭包都是 FnMut 闭包。 例如：总结一下对三类 Rust 闭包的了解：Fn 是一系列闭包和函数，可以不受限制地多次调用它们，还包括所有 fn 函数；FnMut 指哪些需要 mut 访问捕获变量，并且可多次访问的闭包；FnOnce 指哪些消耗值所有权，并且仅可以被调用一次的闭包；从实现上来看，Fn 是 FnMut 的子 Trait，而 FnMut 又是 FnOnce 的子Trait：限制越少，范围越广泛，这使得 Fn 成为最独特和最强大的类别，FnMut 和 FnOnce 是更广泛的类别，包括具有使用限制的闭包。
FnMut 就像结构体如果想改变数据需要用 let mut 声明一样，如果想改变闭包捕获的数据结构，那么就需要 FnMut：在声明的闭包 c 和 c1 里，我们修改了捕获的 name 和 name1。不同的是 name 使用了引用，而 name1 移动了所有权，这两种情况和其它代码一样，也需要遵循所有权和借用有关的规则。所以，如果在闭包 c 里借用了 name，你就不能把 name 移动给另一个闭包 c1。
这里也展示了，c 和 c1 这两个符合 FnMut 的闭包，能作为 FnOnce 来调用。我们在代码中也确认了，FnMut 可以被多次调用，这是因为 call_mut() 使用的是 &amp;mut self，不移动所有权。 Fn可以看到，它继承了 FnMut，或者说 FnMut 是 Fn 的 super trait。这也就意味着任何需要 FnOnce 或者 FnMut 的场合，都可以传入满足 Fn 的闭包。 Copy、Clone 闭包
对于那些 非 move 闭包，并且只包含共享引用的闭包是可以 Clone 和 Copy 的：对于 move 类型闭包，如果规则更简单，如果闭包中捕获的值都是可 Copy 的，它就是可 Copy 的，如果捕获的是可 Clone 的，那就是可 Clone 的：当克隆 greet 的时候，它里面的每个东西都会被克隆，所以这里有两个 greeting 的副本，它们会被单独修改。
 闭包本质
本质上闭包是一种匿名类型，一旦声明，就会产生一个新的类型，但这个类型无法被其它地方使用。这个类型就像一个结构体，会包含所有捕获的变量。这将输出：
c1: 0, c2: 0, c3: 8, c4: 72, c5: 24, main: 0说明，不带 move 时，闭包捕获的是对应自由变量的引用；带 move 时，对应自由变量的所有权会被移动到闭包结构中。闭包的大小跟参数、局部变量都无关，只跟捕获的变量有关。
]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>《Rust 程序设计》</tag>
        <tag>闭包</tag>
      </tags>
  </entry>
  <entry>
    <title>【Rust】集合类型</title>
    <url>/2022/05/01/Rust/%E3%80%90Rust%E3%80%91%E9%9B%86%E5%90%88%E7%B1%BB%E5%9E%8B/</url>
    <content><![CDATA[Rust 标准库包含几个集合，用于在内存中存储数据的泛型类型。我们已经在前面使用了集合，例如 Vec 和 HashMap。在本章中，我们将详细介绍这两种类型的方法，以及其他6个标准集合。
Rust 一共有8个标准集合类型，它们都是泛型：Vec&lt;T&gt;：一个可增长的、堆分配的 T 类型值数组；VecDeque&lt;T&gt;：与 Vec&lt;T&gt; 类似，但更适合用作先进先出队列，它支持在列表的前面和后面有效地添加和删除值；BinaryHeap&lt;T&gt;：一个优先队列，BinaryHeap 中的值是有组织的，所以它总是有效地找到并删除最大值；HashMap&lt;K, V&gt;：键值对表，通过键查找值很快，item 以任意顺序存储；BTreeMap&lt;K, V&gt;：与 HashMap&lt;K, V&gt; 类似，但它保持entries按键排序。 BTreeMap&lt;String, i32&gt; 以字符串比较顺序存储其entries。除非需要entries保持排序，否则 HashMap 更快；HashSet&lt;T&gt;：一组 T 类型的值。添加和删除值很快，查询给定值是否在集合中也很快；BTreeSet&lt;T&gt;：与 HashSet&lt;T&gt; 类似，但它保持元素按值排序。 同样，除非需要对数据进行排序，否则 HashSet 更快； Vec&lt;T&gt;
vector具有 3 个字段：长度、容量和指向存储元素的堆分配的指针。空 vector，容量为 0，在添加第一个元素之前，不会为其分配堆内存。和所有其他集合类型一样，Vec&lt;T&gt; 实现了 std::iter::FromIterator，所以我们可以通过 .collect() 方法创建，例如：我们再来回顾下 vector 的内存表示：内存表示如下图： 元素访问
最直接的访问是通过索引，如果索引越界会 panic，vector 长度和索引是 usize 类型，尝试使用 u32、u64 或 isize 作为vector索引是错误的，可以根据需要使用 n as usize 进行转换：有几种方法可以轻松访问 vector 或slice的特定元素（请注意，所有slice方法也可用于数组和vector）：slice.first()：返回第一个元素的引用以 Option&lt;&amp;T&gt; 的形式，如果没有就返回 None：slice.last()：类似于 slice.first()，但返回最后一个；slice.get(index)：返回第 index 个元素，不存在返回 None：slice.first_mut(), slice.last_mut(), slice.get_mut(index)：前面几个的变种，只是返回可变借用：因为按值返回 T 意味着转移所有权，所以访问 item 的方法通常通过引用返回这些 item。slice.to_vec()：克隆整个 slice，返回新的，仅仅用于可以 Clone 的 item： Iteration
可以通过值或者引用迭代 vector 或者 slice：如果迭代 Vec&lt;T&gt;，将返回 T，vector 中的值被移除并且消费掉所有权；如果迭代 &amp;[T; N]，&amp;[T]，&amp;Vec&lt;T&gt;，将返回 &amp;T，引用到单独的 item，不会转移它们的所有权；如果迭代 &amp;mut [T; N]，&amp;mut [T]，&amp;mut Vec&lt;T&gt;，将返回 &amp;mut T。 扩容缩容
数组，vector 或者 slice 的长度是它包含的元素的数量，例如：slice.len()：slice 长度，类型是 usize；slice.is_empty()：等价于 slice.len() == 0；下面的方法用于 vector 扩缩容，不能用在数组上，它们的长度在创建的时候就确定了：Vec::with_capacity(n)：创建新的能容纳 n 个元素的 vector；vec.capacity()：返回 vector 的容量，vec.capacity() &gt;= vec.len()；vec.reserve(n)：确认这里有足够的的空间再容纳 n 个元素，即 vec.capacity() &gt;= vec.len() + n，如果已经满足，则什么也不做，如果不够就会申请足够的空间并且将当前的内容移进去；vec.reserve_exact(n)：和 vec.reserve(n) 类似，但是不会申请额外的空间为未来的增长，也就是扩容之后 vec.capacity() = exactly vec.len() + n；vec.shrink_to_fit()：尝试释放额外的空闲空间；Vec&lt;T&gt; 有许多方法可以添加或删除元素，从而改变vector的长度。这些中的每一个都通过 mut 引用获取其自身参数。这两种方法在vector末尾添加或删除单个值：vec.push(value)：将 value 添加到末尾；vec.pop()：移除和返回最后一个元素，返回类型是 Option&lt;T&gt;，返回的是值而不是引用；vec.insert(index, value)：将给定的值插入到指定的 index 处，并且将 vec[index..] 往后移动，如果 index &gt; vec.len()，就会 panic；vec.remove(index)：将给定索引处的值删除，并且将 vec[index+1..] 的值向左移动；vec.resize(new_len, value)：设置 vec 的新长度，如果这会增加长度，将会使用 value 填充增加的值，value 必须实现 Clone；vec.resize_with(new_len, closure)：像 vec.resize()，但是使用闭包构造新的 item，可以用于没有实现 Clone 的场景；vec.truncate(new_len)：设置 vec 的新长度为 new_len，删除 vec[new_len..]，如果 vec.len() &lt; new_len，啥也不做；vec.clear()：删除 vec 所有的元素，类似 vec.truncate(0)；vec.extend(iterable)：将 iterable 中的所有 item 添加到 vec 中；vec.split_off(index)：类似 vec.truncate(index)，但是它返回一个包含被移除值的 Vec，就像多次调用 pop；vec.append(&amp;mut vec2)：将 vec2 中的所有元素移到 vec 中，之后，vec2 就成为空的了，有点类似 extend，但是 extend 会保留 vec2；vec.drain(range)：移除区间内的 item，并且返回移除的元素；vec.retain(test)：删除所有没有通过 test 的 item，test 是 FnMut(&amp;T) -&gt; bool 类型的函数；vec.dedup()：删除连续重复的元素，删除完之后仍然有两个 s：如果要删除所有重复的 item，可以：vec.dedup_by(same)：类似于 vec.dedup()，但是它使用闭包函数判断是否相等，而不是 ==；vec.dedup_by_key(key)：类似于 vec.dedup()，判断两个元素的想等是通过 key(&amp;mut elem1) == key(&amp;mut elem2)，例如，如果 errors 是 Vec&lt;Box&lt;dyn Error&gt;&gt;，你可以这样写： Joining
下面的量方法用于元素本身是数组、slice或vector的数组、slice或vector：slices.concat()：连接所有的item并且返回新的 vector：slices.join(&amp;separator)：类似于前者，但是在连接的过程中可以插入一个分割 item： Splitting
由于 Rust 安全规则的限制，我们没法得到 vector 的多个可变引用，例如：如果 i == j，就会出先可变借用了同一个 item。Rust 有几种方法可以同时借用对数组、slice或向量的两个或多个部分的 mut 引用。 与前面的代码不同，这些方法是安全的，因为根据设计，它们总是将数据拆分为不重叠的区域。 其中许多方法对于使用非 mut slice也很方便，因此每种方法都有 mut 和 non-mut 版本。这些方法都没有直接修改数组、slice或向量。 它们只是返回对内部部分数据的新引用：
 slice.iter()、slice.iter_mut()
生成对每个 slice 中 item 的引用，详见。
 slice.split_at(index)、slice.split_at_mut(index)
将 slice 分成一对返回，slice.split_at(index) 等价于 (&amp;slice[..index], &amp;slice[index..])，如果长度超出越界，就会 panic。
 slice.split_first()、slice.split_first_mut()
返回 (&amp;slice[0], &amp;slice[1..])，slice.split_first() 返回 Option&lt;(&amp;T, &amp;[T])&gt;，如果 slice 为空返回 None。
 slice.split_last()、slice.split_last_mut()
slice.split_last() 的返回类型是 Option&lt;(&amp;T, &amp;[T])&gt;。
 slice.split(is_sep)、 slice.split_mut(is_sep)
将 slice 分割成一个或者多个子 slice，根据传入的 is_sep 函数后者闭包，输出至少包含一个子 slice。
 slice.rsplit(is_sep)、slice.rsplit_mut(is_sep)
从右往左找 split。
 slice.splitn(n, is_sep)、slice.splitn_mut(n, is_sep)
和 slice.split(is_sep) 相同，但是最多 n 个子slcie，多出来的放在最后的子 slice 中；
 slice.rsplitn(n, is_sep)、slice.rsplitn_mut(n, is_sep)
和前面的类似，只是从右往左。
 slice.chunks(n)、slice.chunks_mut(n)
返回长度为 n 的子 slcie，最后一个可以包含少于 n 个 item。
 slice.rchunks(n)、 slice.rchunks_mut(n)
和前面的相同，只是从右往左。
 slice.chunks_exact(n)、slice.chunks_exact_mut(n)
精确按照 n 进行分片，如果最后一个不足 n 个，可以通过 remainder() 访问。
 slice.rchunks_exact(n)、slice.rchunks_exact_mut(n)
同上，只是从右往左。
 slice.windows(n)
采用滑动窗口的方式返回子slice，例如第一个是 slice[0..n]，第二个就是 slice[1..n+1]。如果 n 大于 slice.len() 什么也不会返回，如果 n == 0，panic。
例如：该代码输出：
    1 2 2 3 3 4 4 5  Swappingslice.swap(i, j)：交换 slice[i] 和 slice[j]；slice_a.swap_slice(&amp;mut slice_b)：将两个 slice 完整交换，它们必须要有相同的长度；vec.swap_remove(i)：删除并返回 vec[i]，并且将最后一个元素填充到 vec[i]； 搜索和排序slice.sort()：升序排序；slice.sort_by(cmp)：自定义排序函数或闭包，cmp 必须实现  Fn(&amp;T, &amp;T) -&gt; std::cmp::Ordering；slice.sort_by_key(key)：通过自定义的闭包或者函数 key 升序排列，key 的类型是  Fn(&amp;T) -&gt; K where K: Ord。这个很有用当 T 包含一个或者多个可排序字段时：key 不能返回任何元素的引用：slice.reverse()：就地反转 slice；slice.binary_search(&amp;value)：slice.binary_search_by(&amp;value, cmp)：slice.binary_search_by_key(&amp;value, key)：在已排序的slice上二分查找给定值，这些方法的返回类型是 Result&lt;usize, usize&gt;。 如果 slice[index] 在指定的排序顺序下等于 value，则返回 Ok(index)。 如果没有这样的索引，则它们返回 Err(insertion_point) 以便在 insert_point 插入值将保留顺序。slice.contains(&amp;value)：返回 true 如果 slice 有 item 等于 value。 Slice 比较
如果类型 T 支持 == 和 != 运算符，那么 [T; N]，[T] 以及 Vec&lt;T&gt; 也支持，两个 slice 是相等的，如果他们的值和长度都相等；
如果类型 T 支持 &lt; &lt;= &gt; &gt;= 和 != 运算符，那么 [T; N]，[T] 以及 Vec&lt;T&gt; 也支持。
还有两个比较方法：slice.starts_with(other)：如果 slice 以 other 为前缀，返回 true。slice.starts_with(other)：如果 slice 以 other 为后缀，返回 true。 随机元素slice.choose(&amp;mut rng)：随即返回 slice 一个元素的引用，他返回 Option&lt;&amp;T&gt;，slice 为空时返回 None；slice.shuffle(&amp;mut rng)：随机就地打乱 slice； VecDeque&lt;T&gt;
Vec 仅支持在结尾高效增删元素，而 std::collections::VecDeque&lt;T&gt; 是一个双端队列，支持在两端增删元素：deque.push_front(value)：用于在队列前面插入值；deque.push_back(value)：用于在队尾插入值；deque.pop_front()：删除队首元素；deque.pop_back()：删除队尾元素；deque.front(), deque.back()：获取队首或者队尾元素的引用，返回值是 Option&lt;&amp;T&gt;；deque.front_mut(), deque.back_mut() 类似于前者，只是返回值的可变借用 Option&lt;&amp;mut T&gt;；std::collections::VecDeque&lt;T&gt; 的实现是一个环形 buffer，如下图所示：与vector一样，双端队列可以按值、共享引用或 mut 引用进行迭代。 它们具有三个迭代器方法 .into_iter()、.iter() 和 .iter_mut()，它们可以以通常的方式被索引：deque[index]。
因为双端队列不会将它们的元素连续存储在内存中，所以它们不能继承slice的所有方法。 但是，如果您愿意支付转移内容的成本，VecDeque 提供了一种可以解决此问题的方法：deque.make_contiguous()：将队列整理成连续内存的形式，返回  &amp;mut [T]；Vec::from(deque)：Vec 实现了 From&lt;VecDeque&lt;T&gt;&gt;，这将队列转换成 Vec；VecDeque::from(vec)：VecDeque 实现了 From&lt;Vec&lt;T&gt;&gt;，将 vector 转换成队列，这也是 O(n)，但它通常很快，即使向量很大，因为向量的堆内存可以简单地移动到新的双端队列；这使得从已有 vector 创建队列很方便： BinaryHeap&lt;T&gt;
std::collections::BinaryHeap 是一个二叉堆实现的大顶堆，它只实现了 Vec 的某些方法，例如：BinaryHeap::new()，.len()，.is_empty()，.capacity()，.clear()和
.append(&amp;mut heap2)，下面是它独有的一些方法。heap.push(value)：增加元素到堆；heap.pop()：删除并且返回堆中的最大值，返回值是 Option&lt;T&gt;，如果堆是空的；heap.peek()：返回最大值的引用，返回类型是 Option&lt;&amp;T&gt;；heap.peek_mut()：返回类型是 PeekMut&lt;T&gt;，它代表了堆中最大值的可变引用，并且提供了一个类型关联方法 pop() 以从堆中弹出数据。用这个方法，我们可以基于最大值判断是否要从堆中弹出数据：BinaryHeap 是可迭代的，它有一个 .iter() 方法，但迭代器以任意顺序产生堆的元素，而不是从大到小。要按优先级顺序使用 BinaryHeap 中的值，请使用 while 循环： HashMap&lt;K, V&gt;、BTreeMap&lt;K, V&gt;
map 是键值对的集合，叫做 entries，map 中可以高效地通过 key 查找，不存在两个不同的 entries 有相同的 key。Rust 有两种 map 的实现，HashMap&lt;K, V&gt; 和 BTreeMap&lt;K, V&gt;，它们两个有相同的方法，不同的地方在于两者如何保持entries排列以进行快速查找。
HashMap 存储键值在hash表中，所以要求键的类型必须实现 Hash 和 Eq，下图展示了它在内存中的表示，深色区域是未使用的。所有键、值和缓存的哈希码都存储在单个堆分配表中。 添加entries最终会迫使 HashMap 分配一个更大的表并将所有数据移入其中。BTreeMap 将entries按键顺序存储在树结构中，因此它需要一个实现 Ord 的键类型 K。 下图显示了一个 BTreeMap。 同样，较暗的区域是未使用的备用容量。BTreeMap 将其entries存储在节点中。BTreeMap 中的大多数节点只包含键值对。非叶节点，如该图所示的根节点，也为指向子节点的指针留有空间。 (20, 'q') 和 (30, 'r') 之间的指针指向包含 20 到 30 之间的键的子节点。添加entries通常需要将节点的一些现有entries向右滑动，以保持它们的排序，有时还涉及分配新节点。
Rust 标准库使用 BTree 而不是平衡二叉树，因为 BTree 在现代硬件上更快。 与 BTree 相比，二叉树每次搜索使用的比较次数可能更少，但搜索 BTree 具有更好的局部性——也就是说，内存访问被分组在一起，而不是分散在整个堆中，这会提高内存缓存的命中率，这是一个显着的速度提升。
 创建 mapHashMap::new()、BTreeMap::new()：创建空的 map；iter.collect()：可以从一个 Iterator&lt;Item=(K, V)&gt; 创建新的 HashMap 或者 BTreeMap；HashMap::with_capacity(n)：创建空的 map 至少能存储 n 个 entries，由于它们存储 entries 在一个整个的堆内存中，所以他们有容量及相关的方法 hash_map.capacity()，hash_map.reserve(additional) 和 hash_map.shrink_to_fit()，BTreeMaps 没有这些。 键值处理map.len()：返回 entries 的数量；map.is_empty()：如果 map 没有 entries 返回 true；map.contains_key(&amp;key)：返回 true 如果 map 包含指定 key；map.get(&amp;key)：在 map 中搜索指定 key。如果找到，返回 Some(r)，r 是一个指向对应值的引用。否则，返回 None；map.get_mut(&amp;key)：类似于 map.get(&amp;key)，但是返回指定值的可变引用。一般来说，map允许对存储在其中的值进行 mut 访问，但不能访问键。 这些值是可以随意修改的。键属于map本身；它需要确保它们不会改变，因为entries是按它们的键组织的。就地修改key将是一个错误；map.insert(key, value)：插入或者更新一个 (key, entry) 到 map 中，如果存在旧值返回；map.extend(iterable)：迭代 iterable 将得到 (K, V) 插入到 map 中；map.append(&amp;mut map2)：将 map2 的所有 entries 移动到 map 中；map.remove(&amp;key)：找到并且删除指定 key，如果存在返回删除对应 key 的值，返回类型是 Option&lt;V&gt;；map.remove_entry(&amp;key)：找到并且删除指定 key，如果存在返回删除对应键值对，返回类型是 Option&lt;K, V&gt;；map.retain(test)：删除所有未通过 test 函数的键值对，test 的类型是 FnMut(&amp;K, &amp;mut V) -&gt; bool。对于 map 的每个元素都会调用 test(&amp;key, &amp;mut value)，如果返回 false，这个 key 就会从 map 中删除；不考虑性能，就像这样写：map.clear()：删除所有键值对；一个 map 也可以通过 map[&amp;key] 这种形式查询，map 实现了内建的 std::ops::Index。但是如果给定的 key 不存在，就会 panic，这就像数组越界访问。
对于 .contains_key()，.get()，.get_mut()，.remove() 中的 key，没必要是精确的 &amp;T 类型，这些方法是泛型，它们可以从 K 借用。所以，在 HashMap&lt;String, Fish&gt; 中这样调用 fish_map.contains_key(&quot;conger&quot;) 是没有问题的，即使 &quot;conger&quot; 不是 String 类型，但是它实现了 Borrow&lt;&amp;str&gt;。
由于 BTreeMap&lt;K, V&gt; 按 key顺序存储，所以支持额外的操作：btree_map.split_off(&amp;key)：将 btree_map 一分为二，键小于key的entries留在 btree_map 中，返回包含其他entries的新 BTreeMap&lt;K, V&gt;； Entry
HashMap 和 BTreeMap 都有对应的 std::collections::hash_map::Entry 或者 std::collections::btree_map::Entry 类型，Entry 的重点是消除冗余的映射查找，例如，这里有一些获取或创建学生记录的代码：这可以完成工作，但是访问了 student_map 两三次，每次都要查找，其实我们要的只是有这个 key 更新没有的话插入。entries的想法是我们只进行一次查找，生成一个entries值，然后用于所有后续操作。这个单行代码等效于前面的所有代码，只是它只进行一次查找：student_map.entry(name.to_string()) 返回的 Entry 就像对 map 中某个位置的可变引用，该位置要么被键值对占用，要么空置，这意味着那里还没有Entry。如果为空，则 Entry的 .or_insert_with() 方法会插入一个新记录。
所有的 Entry 都是使用相同的方法创建的：map.entry(key)：返回给定键的 Entry，如果map中没有这样的键，则返回一个空 Entry。此方法通过 mut 引用获取其 self 参数并返回具有匹配生命周期的 Entry：Entry 类型有一个生命周期参数 'a，因为它实际上是一种对map的 mut 引用，只要Entry 存在，它就拥有对map的独占访问权。不幸的是，如果map具有 String 键，则无法将 &amp;str 类型的引用传递给此方法。在这种情况下，.entry() 方法需要一个真正的字符串。Entry 提供了三种处理空条目的方法：map.entry(key).or_insert(value)：确保map包含具有给定键的条目，如果需要，插入具有给定值的新条目。它返回对新值或现有值的 mut 引用。假设我们需要统计投票，可以这样写：map.entry(key).or_default()：确保 map 包含具有给定键的条目，如果需要，插入具有 Default::default() 返回的值的新条目。这仅适用于实现 Default 的类型。与 or_insert 一样，此方法返回对新值或现有值的 mut 引用；map.entry(key).or_insert_with(default_fn)：和前两个方法相同，只是它调用 default_fn() 生成默认值。如果已经存在，default_fn 是不会调用的；假设我们想知道哪些单词出现在哪些文件中。 我们可以写：map.entry(key).and_modify(closure)：如果指定 key 的 Entry 已经存在，将调用闭包并且传入 Entry 的可变借用，然后将 Entry 返回，所以它可以和其他方法串联起来使用；Entry 是枚举类型，例如，HashMap 中的： 迭代 Map
这里还有几个迭代 map 的方法：通过值迭代， for (k, v) in map 产生 (K，V) 对，这将消费 map；通过引用迭代，for (k, v) in &amp;map 产生 (&amp;K, &amp;V) 对；通过可变引用迭代，for (k, v) in &amp;mut map 产生 (&amp;K, &amp;mutV) 对；而 .iter() 和 .iter_mut() 就像按 &amp;map 和 &amp;mut map 迭代。除此之外，还有：map.keys()：返回一个所有 key 引用的迭代器；map.values()：返回一个所有 value 引用的迭代器；map.values_mut()：返回一个所有 value 可变引用的迭代器； HashSet&lt;T&gt;、BTreeSet&lt;T&gt;
集合中的值都是唯一的，Map 和 Set 有不同的方法，但在实现上，Set 就像只有键的映射，而不是键值对。 事实上，Rust 的两种集合类型 HashSet&lt;T&gt; 和 BTreeSet&lt;T&gt; 被实现为 HashMap&lt;T, ()&gt; 和 BTreeMap&lt;T, ()&gt;。
这里有一些集合常用的方法：HashSet::new()、BTreeSet::new()：创建新的集合；iter.collect()：可以用于从迭代器创建一个集合，如果迭代器产生重复值，将会被自动丢弃；HashSet::with_capacity(n)：创建至少能容纳 n 个值的集合；set.len()：返回集合中值的数量；set.is_empty()：返回 true 当集合为空时；set.contains(&amp;value)：当集合包含 value 是返回 true；set.insert(value)：插入集合新的值，返回 true 如果值被添加，如果已经存在返回 false；set.remove(&amp;value)：从集合中删除值，删除成功则返回 true，如果之前不存在则返回 false；set.retain(test)：删除所有没通过测试的值，test 的类型是 FnMut(&amp;T) -&gt; bool，对于集合的每个元素，将调用 test(&amp;value)，如果返回 false，这个值就会被移除； 迭代
有两种迭代集合的方式：按值迭代，for v in set 返回集合的成员；按共享引用迭代，for v in &amp;set 返回集合值的引用；通过可变引用迭代集合是不支持的，这里没有方法获取集合中值的可变引用，而 set.iter() 返回一个迭代器包含集合中值的引用。
HashSet 迭代器，就像 HashMap 迭代器，以任意顺序获取它们的值，而 BTreeSet 迭代器产生的值是有序的。
 某些方法set.get(&amp;value)：返回  Option&lt;&amp;T&gt;，等于 value 的集合中成员的引用；set.take(&amp;value)：像 set.remove(&amp;value)，但是他返回移除的值；set.replace(value)：就像 set.insert(value)，但是如果集合已经包含这个值，这个会返回并替换旧的值，返回类型是 Option&lt;T&gt;； 集合操作set1.intersection(&amp;set2)：返回两个集合之间的交集；set1.union(&amp;set2)：求集合之间的并集；set1.difference(&amp;set2)：求集合之间的差集；set1.symmetric_difference(&amp;set2)：返回只存在其中一个集合中的值的新集合；set1.is_disjoint(set2)：如果 self 与 other 没有共同的元素，则返回 true；set1.is_subset(set2)：如果 set1 是 set2 的子集，将返回 true；set1.is_superset(set2)：如果 set1 是 set2 的超集，将返回 true； Hashing
std::hash::Hash 是标准库中所有可 hash 类型必须实现的，HashMap 的键和 HashSet 的元素都必须实现 Hash 和 Eq。
大对数内部实现了 Eq 的类型也都实现了 Hash，整数，字符和 String 都是可 hash 的，以及 tuple，array，slice 和 vector，只要他们的元素时可 hash 的。
标准库的一个原则是一个值不管存在哪里或者你如何引用，它们都有相同的hash值。因此，一个值和它的引用有相同的hash值，Box&lt;T&gt; 也和它包含的值有相同的 hash 值，一个 vector 和包含相同的数据的slice有同样的hash值。一个字符串和包含相同字符的 &amp;str 有相同的hash值。
结构体和枚举默认没有实现 Hash，但是可以自动派生，只有所有元素可 hash：如果你为一个类型手动实现 PartialEq，你也应该手动实现 Hash。
 自定义 Hash 算法
hash 方法是通用的，因此前面显示的 Hash 实现可以将数据提供给任何实现 Hasher 的类型，这就是 Rust 支持可插入哈希算法的方式。
std::hash::BuildHasher 是表示散列算法初始状态的类型的特征。每个 Hasher 都是一次性使用的，就像一个迭代器：你使用一次就扔掉它，BuildHasher 是可重用的。
每个 HashMap 都包含一个 BuildHasher，每次需要计算哈希码时都会使用它。BuildHasher 值包含哈希算法每次运行时所需的键、初始状态或其他参数。完整计算一个 hash 值如下所示：HashMap 每次在需要计算 hash 值的时候会调用这三个方法，所有方法都是可以内联的，所以非常快。
Rust 的默认哈希算法是 SipHash-1-3，SipHash 速度很快，并且非常擅长最小化哈希冲突。事实上，它是一种密码算法：没有已知的有效方法来生成 SipHash-1-3 冲突。 只要为每个哈希表使用不同的、不可预测的密钥，Rust 就可以抵御一种称为 HashDoS 的拒绝服务攻击，在这种攻击中，攻击者故意使用哈希冲突来触发服务器中最坏情况的性能。
但也许您的应用程序不需要它，如果要存储许多小密钥，例如整数或非常短的字符串，则可以实现更快的哈希函数，但会牺牲 HashDoS 安全性。 fnv 实现了一种这样的算法，即 FNV 哈希，要尝试它，请将此行添加到您的 Cargo.toml：然后导入使用：
]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>《Rust 程序设计》</tag>
        <tag>集合类型</tag>
      </tags>
  </entry>
  <entry>
    <title>常用的eBPF工具安装及简单介绍</title>
    <url>/2024/03/14/eBPF/common-tools-install/</url>
    <content><![CDATA[eBPF，全称“扩展的伯克利数据包过滤器 (Extended Berkeley Packet Filter)”，它是一种数据包过滤技术，是从 BPF (Berkeley Packet Filter) 技术扩展而来的。BPF 提供了一种在内核事件和用户程序事件发生时安全注入代码的机制，这就让非内核开发人员也可以对内核进行控制。随着内核的发展，BPF 逐步从最初的数据包过滤扩展到了网络、内核、安全、跟踪等，而且它的功能特性还在快速发展中，这种扩展后的 BPF 被简称为 eBPF（相应的，早期的 BPF 被称为经典 BPF，简称 cBPF）。实际上，现代内核所运行的都是 eBPF，如果没有特殊说明，内核和开源社区中提到的 BPF 等同于 eBPF。
在 eBPF 之前，内核模块是注入内核的最主要机制。由于缺乏对内核模块的安全控制，内核的基本功能很容易被一个有缺陷的内核模块破坏。而 eBPF 则借助即时编译器（JIT），在内核中运行了一个虚拟机，保证只有被验证安全的 eBPF 指令才会被内核执行。同时，因为 eBPF 指令依然运行在内核中，无需向用户态复制数据，这就大大提高了事件处理的效率。
由于这些突出的特性，eBPF 现如今已经在故障诊断、网络优化、安全控制、性能监控等领域获得大量应用。比如，Facebook 开源的高性能网络负载均衡器 Katran、Isovalent 开源的容器网络方案 Cilium ，以及著名的内核跟踪排错工具 BCC 和 bpftrace 等，都是基于 eBPF 技术实现的。
本文主要简单介绍一些常用的 eBPF 相关工具的安装。 BCC
BCC 是一个用于创建高效内核跟踪和操作程序的工具包，其中包括一些有用的工具和示例。使用 BCC 除了要求内核在 4.1 版本之上，还需要内核编译的时候打开一些开关，具体可以查看这里。除了直接从各个Linux发行版本的应用中心下载之外，这里着重记录源码安装的方式，以 Ubuntu 22.04 为例，不同的版本具体要求可能有所不同，但是大体流程相同，其他的版本请看这里：安装好的 BCC 工具位于 /usr/share/bcc/tools/ 路径之下。使用 BCC 开发 hello world 小程序：
hello.pyhello.c
来看看每一处的具体含义：处导入了 BCC  库的 BPF 模块，以便接下来调用；
调用 BPF() 加载第一步开发的 BPF 源代码；
将 BPF 程序挂载到内核探针（简称 kprobe），其中 do_sys_openat2() 是系统调用 openat() 在内核中的实现；
读取内核调试文件 /sys/kernel/debug/tracing/trace_pipe 的内容，并打印到标准输出中；运行该程序：sudo python3 hello.py输出如下信息：b'      k3s-server-2795005 [000] d...1 265039.419072: bpf_trace_printk: Hello, World!'每个字段的含义如下所示：k3s-server-2795005 表示进程的名字和 PID；
[006] 表示 CPU 编号；
d...1 表示一系列的选项；
265039.419072 表示时间戳；
bpf_trace_printk 表示函数名；
最后的 Hello, World! 是调用 bpf_trace_printk() 传入的字符串； bpftool
bpftool是linux内核自带的用于对eBPF程序和eBPF map进行检查与操作的工具软件。安装使用如下的源码编译方式：如果没有错误，安装之后的二进制文件位于 /usr/local/sbin/bpftool。安装文档： bpftrace
bpftrace 使用 LLVM 作为后端，将脚本编译为 BPF 字节码，并使用 BCC 与 Linux BPF 系统以及现有的 Linux 跟踪功能（内核动态跟踪（kprobes）、用户级动态跟踪（uprobes）和跟踪点）进行交互。bpftrace 语言的灵感来自 awk 和 C，以及 DTrace 和 SystemTap 等前代跟踪器。
在满足系统层面的要求之后，ubuntu 安装 bpftrace 使用如下的命令：sudo apt-get install -y bpftrace 参考连接https://github.com/xdp-project/xdp-tools
How to Build Linux Kernel From Scratch {Step-By-Step Guide}
使用 libbpf-bootstrap 构建 BPF 程序
如何在 Ubuntu 上配置 eBPF 开发环境
AF_XDP技术详解
解读eBPF XDP性能之路：它如何向着DPDK看齐？它在实际中又能带来多大效益？
How to build a kernel with XDP support]]></content>
      <categories>
        <category>eBPF</category>
      </categories>
      <tags>
        <tag>BCC</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/baidu_verify_code-NR10G09zww.html</url>
    <content><![CDATA[350e6c308dc58aea67c07a622da60226]]></content>
  </entry>
  <entry>
    <title>404</title>
    <url>/404/index.html</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Leetcode-Rust</title>
    <url>/Leetcode-Rust/index.html</url>
    <content><![CDATA[本文计划参考 Leetcode-Go 实现 Leetcode-Rust，加强对 Rust 的练习，代码不写不行滴，题目答案可能不是最好的，但是能过。
 map两数之和（0001） 链表两数相加（0002） 滑动窗口无重复字符的最长子串 (0003)
串联所有单词的子串 (0030)
重复的 DNA 序列 (0187)
长度最小的子数组 (0209)]]></content>
  </entry>
  <entry>
    <title>Programming Go</title>
    <url>/Programming-Go/index.html</url>
    <content><![CDATA[ 文章【Golang】Dependency Injection
【Golang】Application Binary Interface
【Golang】Mutex 的实现原理
【Golang】Go Modules
【Golang】汇编语言
【Golang】谈谈 slice 的实现
【Golang】谈谈 map 的实现
【Golang】进程初始化和调度系统
【Golang】Interface 实现原理 学习资料LeetCode-Go
Go 语言高级编程
Go 语言设计与实现
Go 语言原本
Go 语言编程之旅 其他软件frp：快速的反向代理服务器，将本地的服务暴露到公网中；
caddy：快速的多平台 Web 服务器；
mkcert：简单的零配置工具创建本地开发证书；
dive：一个解析 Docekr 镜像的工具；
ngrok：Introspected tunnels to localhost；
nps：内网穿透的代理服务器；
viper：配置解析；
delve：Go 调试器；
restic：快速、安全、高效的备份程序；
podman：管理 OCI 容器和 Pod 的工具；
go-ipfs：IPFS 的 Go 实现；
excelize：Excel 处理；
goreleaser：帮助发布 Go 二进制程序的工具；
wire：Go 依赖注入的实现；
drone：云原生持续发布平台；
gops：列出和诊断系统上当前运行的 Go 进程的工具；
mockery：Golang 的 Mock 代码自动生成器；
mock：Go 的 Mock 框架；]]></content>
  </entry>
  <entry>
    <title>Programming Rust</title>
    <url>/Programming-Rust/index.html</url>
    <content><![CDATA[ Programming Rust
这本书是 O'Reilly 出版社的，对本书进行了学习和记录，内容大体上没有遗漏，只是对一些描述做了精简，出版社书籍链接。文档源码 gamelife1314/gamelife1314.github.io。表述有误的地方请评论或者提 pr 指正。《第3章-Fundamental Types》
《第4章-Ownership and Moves》
《第5章-References》
《第6章-Expressions》
《第7章-Error Handling》
《第8章-Crates and Modules》
《第9章-Structs》
《第10章-Enums and Patterns》
《第11章-Traits and Generics》
《第12章-Operator Overloading》
《第13章-Utility Traits》
《第14章-Closures》
《第15章-Iterators》
《第16章-Collections》
《第17章-Strings and Text》
《第18章-Input and Output》
《第19章-Concurrency》
《第20章-Asynchronous Programming》
《第21章-Macros》
《第22章-Unsafe Code》
《第23章-Foreign Functions》 其他文章Rust 生命周期
Rust 学习笔记
Rustup 介绍
Rust 交叉编译
Rust 二进制文件体积减小
【Rust】二进制体积减小
Rust 格式化
Rust 正则表达式
文件和目录
anyhow &amp; thiserror
Rust 在线题目测试
gdb 速查手册
lldb 使用帮助
用 GitHub Actions 进行持续集成
GitHub Action 构建 Rust 程序加速
Rust Docker Tutorial
【Rust日报】关于 pprof-rs 内部工作原理的一些笔记 WEBreqwest：高级 HTTP 客户端；
actix-web：Web 框架；
surf：跨平台 HTTP 客户端，简单易用；
rocket：web 框架；
axum：使用 Tokio、Tower 和 Hyper 构建的符合人体工程学的模块化 Web 框架；
diesel：Rust 的 ORM 框架；
SeaORM：Rust 的 ORM 框架；
sqlx：异步的纯 Rust 实现的 Sql 工具箱；
yew：Yew 是一个设计先进的 Rust 框架，目的是使用 WebAssembly 来创建多线程的前端 web 应用。
seed：创建 Web 前端应用的 Rust 框架；
MoonZoon：Rust 全栈框架；
comrak：markdown 解析； FFIpyo3
neon 编译min-sized-rust：减小 Rust 二进制文件体积； 协议hyper：快速的 HTTP 实现；
tonic：原生的 grpc 客户段和服务端，支持 async/await；
prost：Rust 的 protocol buffer 实现；
tungstenite：websocket 协议实现； 测试headless_chrome：一个高级的控制无头浏览器或者 Chromium 的框架；
thirtyfour：类似 Selenium 的自动化测试框架；
fantoccini：通过 WebDriver 以编程方式与网页交互的高级 API； GUIiced
druid
tauri
sixtyfps
rust-skia
tiny-skia
areweguiyet 命令行dialoguer：可以用于构建交互式命令行；
indicatif：用于提供友好的进度条；
clap
tui：Rust 终端 UI； 云原生kube-rs
krator
krustlet 嵌入式wg：嵌入式设备工作组的协调存储库；
akri：一个管理嵌入式设备的云原生项目；
awesome-embedded-rust 区块链solana
password-hashes 数据库bonsaidb：Rust 写的本地数据库； 数据类型fnv：基于 Fowler–Noll–Vo 算法实现的 HashMap；
dashmap：Rust 中超快的并发 map； 静态网站mdBook：类似 gitbook 的 Rust 实现；
getzola：静态网站生成器； wasmtimespin：Spin 用于使用 WebAssembly 构建和运行快速、安全和可组合的云微服务；
trunk：构建、打包以及发布 wasm 应用；
wasmer：Wasmer 提供基于 WebAssembly 的超轻量级容器，其可以在任何地方运行：从桌面到云、以及 IoT 设备，并且也能嵌入到 任何编程语言中；
wasmtime：单独的 wasm 运行时；
WasmEdge：WasmEdge 是一个轻量级、高性能和可扩展的 WebAssembly 运行时，适用于云原生、边缘和去中心化应用程序。它为无服务器应用程序、嵌入式功能、微服务、智能合约和物联网设备提供支持；
rustwasm：rustwasm 生态系统；
wasm-pack：wasm 工作流工具；
wasm-bindgen：提供Wasm 模块和 JavaScript 之间级交互的高级 API。
bytecodealliance 机器学习tensorflow
PyTorch
scikit-learn 日志监控tracing：日志处理；
rust-prometheus
opentelemetry-rust 并发异步smol：一个小而快的异步运行时；
rayon：计算密集型任务的任务分解；
tokio：Tokio 是一个事件驱动的非阻塞 I/O 平台，用于使用 Rust 编程语言编写异步应用程序。
actix：Rust 的 actor 框架；
bastion：高可用分布式容错运行时；
waker_fn：转换闭包为 waker；
crossbeam：提供很多用于并发编程的工具，例如线程阻塞；
async_trait：提供了一个宏，可以在 trait 中包含异步的方法；
futures-lite：完全兼容 futures，提供了 pin!； 其他 cratethiserror：自动派生标准库中的 std::error::Error；
anyhow：提供了 anyhow::Result&lt;T&gt; 用于任何可能失败返回错误的函数；
lazy_static：可以用于初始化全局可变静态变量；
[once_cell`](https://crates.io/crates/once_cell)：`once_cell`提供了`unsync::OnceCell`和`sync::OnceCell`这两种`Cell`，用来存储堆上的信息，并且具有最多只能赋值一次的特性；
unicode-width：获取 Unicode 字符宽度；
enum_primitive：提供宏能自动从数字转换成枚举；
serde_json：json 序列化；
argonautica：使用 Argon2 hashing algorithm 进行密码 hash；
parking_lot：提供了比标准库更快的 Mutex 等；
itertools：扩展了内置的 Iterator，提供了更多的迭代适配器方法；
bytes：处理二进制内容的库；
colored：在终端中添加颜色的最简单方法；
tabled：以表格的形式输出结构体和枚举；
chrono：Rust 的日期和时间处理库；
nom：解析器组合库；
rusoto_core：Rust 实现的 AWS SDK；
polars：用于 Rust 和 Python 快速的 DataFrame 库；
pprof-rs：借助 backtrace-rs 实现的 Rust CPU 分析器； 学习资料Rust 程序设计语言
Rust 语言圣经
Rust 秘典
Rust 秘典（中文）
Rust 版本指南
通过例子学 Rust
《Rust Macros小书》
Cargo 手册
Rustdoc 手册
Rustc 手册
命令行手册
嵌入式手册
WEBASSEMBLY 手册
Rust 参数手册
rustlings：Rust 知识检测；
rust-quiz：Rust 知识检测；
spec.ferrocene.dev 在线工具releases.rs
Replit：在线支持 crate 和 cargo；
Godbolt：支持在线查看 Rust 汇编生成；]]></content>
  </entry>
  <entry>
    <title>categories</title>
    <url>/categories/index.html</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>tags</title>
    <url>/tags/index.html</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>云原生</title>
    <url>/%E4%BA%91%E5%8E%9F%E7%94%9F/index.html</url>
    <content><![CDATA[ 系列文章容器技术探索
单机容器网络
跨主机容器网络
容器运行时介绍
Iptables 介绍
K8S 集群部署
K8S CNI 网络
K8S 作业管理
K8S 证书管理
K8S Gateway
Istio 实战笔记
K8S 服务&amp;Ingress
K8S 持久化与数据挂载 常用命令
 kubectl污点添加和去除：kubectl taint nodes ctrlnode node-role.kubernetes.io/control-plane:NoSchedule
kubectl taint nodes ctrlnode node-role.kubernetes.io/control-plane:NoSchedule-节点标签：kubectl label node node1 node-role.kubernetes.io/worker=worker
kubectl label nodes ctrlnode pvtype-根据标签查询Pod：kubectl get pods -l app=nginx -owidePod扩缩容：kubectl scale --current-replicas=2 --replicas=3 deployment/nginx-deployment查询Pod中的容器：kubectl get pods nginx-deployment-848dd6cfb5-2gvg9 -o jsonpath=&#123;.spec.containers[*].name&#125;进入Pod中的容器：kubectl exec nginx-deployment-848dd6cfb5-2gvg9 -n default -it -c nginx -- /bin/bash
kubectl -n kube-system exec ds/cilium -- cilium statusService创建：从deploy创建服务
kubectl expose deploy nginx-deployment --port=8080 --target-port=80 --type=ClusterIP --name=nginx-deploy-clusterip-svc创建Pod：创建并且Attach
kubectl run mytools -it --rm --image=praqma/network-multitool --image-pull-policy=IfNotPresent --command -- /bin/bash
仅创建
kubectl run mytools --image=praqma/network-multitool --image-pull-policy=IfNotPresent更新镜像：kubectl set image -n deploy-test deployment/nginx-deploy nginx=nginx:1.16.1 --record
kubectl patch statefulset nginx-sts --type='json' -p='[&#123;&quot;op&quot;: &quot;replace&quot;, &quot;path&quot;: &quot;/spec/template/spec/containers/0/image&quot;, &quot;value&quot;:&quot;nginx:1.16.1&quot;&#125;]'滚动更新历史：kubectl rollout history -n deploy-test deployment/nginx-deploy回滚:kubectl rollout undo -n deploy-test deployment/nginx-deploy --to-revision=1重启 Deploy：kubectl rollout restart deployment cert-manager -n cert-manager crictl查询容器PID：crictl inspect -o go-template --template &quot;&#123;&#123; .info.pid &#125;&#125;&quot; 15f86364ed865进入容器：nsenter -a -t $(crictl inspect -o go-template --template '&#123;&#123;.info.pid&#125;&#125;' 6a5985ec11357) ctr导入镜像：ctr images import --platform linux/amd64 --base-name michael/netperf michael_netperf.tar docker查询容器PID：docker inspect --format &quot;&#123;&#123; .State.Pid &#125;&#125;&quot; 52d2b3478c88导出镜像docker save -o michael_netperf.tar michael/netperf:arm64 michael/netperf:amd64
gzip michael_netperf.tar导入镜像docker load &lt; busybox.tar.gz
docker load --input fedora.tar跨平台镜像编译docker run --privileged --rm tonistiigi/binfmt --install all
docker buildx build --platform linux/arm64 -t michael/netperf --load .删除 &lt;none&gt; 镜像：docker rmi -f $(docker images -f &quot;dangling=true&quot; -q)镜像编译设置代理：设置代理
docker build -t rb-dev:musl --build-arg https_proxy=http://1127.0.0.1:3128 --build-arg http_proxy=http://127.0.0.1:3128 . 常用链接预编译通用CNI插件下载地址]]></content>
  </entry>
  <entry>
    <title>《剑指offer》</title>
    <url>/%E5%89%91%E6%8C%87offer/index.html</url>
    <content><![CDATA[《剑指offer》Go 和 Rust 代码实现。
 参考文章吴师兄学算法]]></content>
  </entry>
</search>
